#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\begin_preamble
\usepackage{helvet}
\renewcommand{\familydefault}{\sfdefault}
\usepackage{ragged2e}
\usepackage{blindtext}
\usepackage{fancyhdr}
\usepackage{algorithm}
\usepackage{algpseudocode}
\pagestyle{fancy}
\fancyhead{}
\fancyhead[RO,LE]{Doubly dispersive channels equalization using deep learning techniques}
\fancyfoot[CO,RE]{Emilio Tonix}
\fancyfoot{}
\fancyfoot[LE,RO]{\thepage}
\fancyfoot[CO,RE]{Emilio Tonix}

\usepackage{listings}
\usepackage{xcolor}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}


\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}

\lstset{style=mystyle}
\end_preamble
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "Courier"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family rmdefault
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref true
\pdf_bookmarks true
\pdf_bookmarksnumbered false
\pdf_bookmarksopen false
\pdf_bookmarksopenlevel 1
\pdf_breaklinks false
\pdf_pdfborder true
\pdf_colorlinks false
\pdf_backref false
\pdf_pdfusetitle true
\papersize default
\use_geometry true
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 2.5cm
\topmargin 2.5cm
\rightmargin 2.5cm
\bottommargin 2.5cm
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Standard
\align center
\begin_inset Graphics
	filename Imagenes/Cinvestav_Logo-transformed.jpeg
	lyxscale 13
	scale 12

\end_inset


\end_layout

\begin_layout Standard
\align center

\size larger
Centro de Investigación y de Estudios Avanzados del I.P.N 
\end_layout

\begin_layout Standard
\align center

\size larger
Unidad Guadalajara 
\end_layout

\begin_layout Standard
\align center

\end_layout

\begin_layout Standard
\align center

\series bold
\size huge
\color black
Exploring Deep Learning Techniques for Equalizing Doubly Dispersive Channels
\end_layout

\begin_layout Standard

\series bold
\color white
.
\end_layout

\begin_layout Standard
\align center

\size larger
\color black
A thesis presented by:
\end_layout

\begin_layout Standard
\align center

\series bold
\size larger
\color black
Luis Emilio Tonix Gleason
\end_layout

\begin_layout Standard
\align center

\size larger
\color black
to obtain the degree of:
\end_layout

\begin_layout Standard
\align center

\series bold
\size larger
\color black
Master in Science
\end_layout

\begin_layout Standard
\align center

\size larger
\color black
in the subject of:
\end_layout

\begin_layout Standard
\align center

\series bold
\size larger
\color black
Electrical Engineering
\end_layout

\begin_layout Standard
\align center

\size larger
\color black
Thesis Advisors:
\end_layout

\begin_layout Standard
\align center

\series bold
\size larger
\color black
Dr.
 Ramón Parra Michel
\end_layout

\begin_layout Standard
\align center

\series bold
\size larger
\color black
Dr.
 Fernando Peña Campos
\end_layout

\begin_layout Standard
\align center

\end_layout

\begin_layout Standard
\align center

\series bold
\size larger
\color black
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill Guadalajara, Jalisco 
\backslash
today
\end_layout

\end_inset

 
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newpage
\end_layout

\end_inset


\end_layout

\begin_layout Section*
\noindent

\size huge
\color black
Acknowledgment 
\size large
\color inherit

\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newline
\end_layout

\end_inset

 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent
\align block

\size large
Thank you for reading this; I appreciate it.
 I'm expecting that your work will benefit greatly from this material.
 I won't hesitate to say that you might have done your job more effectively
 than I did.
 Progress in science is a way to skepticism and having the best information
 from multiple sources to meet your individual standards.
  
\end_layout

\begin_layout Standard

\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newpage
\end_layout

\end_inset


\end_layout

\begin_layout Section*

\size huge
Resumen 
\size large

\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newline
\end_layout

\end_inset

 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent
\align block

\size large
En la actualidad, la tecnología de redes de comunicación inalámbricas de
 alta movilidad está en constante evolución, y tiene aplicaciones en diversos
 ámbitos, tales como la seguridad vial, la conducción autónoma, el monitoreo
 remoto de vehículos, el vuelo de drones y los requisitos de 6G.
 Los transmisores RF, que se emplean en los sistemas de telecomunicaciones
 para transmitir información, codifican dicha información a través de la
 amplitud y la fase de una señal portadora, comúnmente conocida como datos
 IQ.
 Sin embargo, al viajar a través de un canal de alta movilidad, estos datos
 sufren distorsión, debido a la dispersión doble de dicho canal, lo que
 implica que las propiedades de la señal se ven afectadas por el desplazamiento,
 difusión en el tiempo y la frecuencia.
 Aunque existen algoritmos tradicionales que requieren ecualizadores iterativos
 complejos, que pueden ser lentos en términos de tiempo de ejecución pero
 precisos, también existen ecualizadores más sencillos, aunque menos precisos.
 En este trabajo se analizarán algunas soluciones basadas en redes neuronales,
 buscando un equilibrio entre la complejidad del tiempo y la precisión para
 hacer frente a este desafío.
 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newline
\end_layout

\end_inset

 
\end_layout

\begin_layout Standard
\align block

\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
Es posible afirmar que los algoritmos convencionales han demostrado ser
 eficaces en el desarrollo actual.
 Sin embargo, los recientes avances en redes neuronales han simplificado
 problemas que antes eran intratables, como el descifrado de secuencias
 de ADN o la creación de imágenes a partir de texto.
 En resumen, abordan con éxito problemas no lineales.
 El objetivo de este trabajo es imitar técnicas de ecualización conocidas
 con naturaleza lineal, como los ecualizadores MSE, LMMSE y no linealies
 como MAP.
 Durante las pruebas realizaremos un seguimiento de diferentes tamaños de
 constelaciones y tasas de error de bit en una variedad de situaciones de
 interferencia y ruido.
 Esperamos que la tasa de error de bits disminuya hasta, o funcione ligeramente
 mejor que, el modelo de oro, que son los ecualizadores mencionados previamente.
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newline
\end_layout

\end_inset

 
\end_layout

\begin_layout Standard
\align block

\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
Los últimos enfoques en investigación literaria demuestran la existencia
 de diversas estrategias que se aproximan a lograr una buena ecualización,
 aunque no registran todas las etapas de la ecualización basándose en métodos
 tradicionales.
 Por otro lado, se presentará una estrategia que incluso aborde condiciones
 más complicadas del canal, tales como canales de línea de vista o la falta
 de ella.
 Finalmente, pero no menos importante, se busca promover una mayor investigación
 en este campo prácticamente inexplorado por algunos equipos de comunicación.
\end_layout

\begin_layout Standard

\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newpage
\end_layout

\end_inset


\end_layout

\begin_layout Section*

\size huge
Abstract
\size large
 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newline
\end_layout

\end_inset

 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
Due to their primary uses in control, road safety, autonomous driving, remote
 monitoring of vehicles, drone flying, and 6G needs, the development of
 high-mobility wireless communication networks is cutting-edge technology.
 The RF broadcasts, which are used by telecommunications systems to transfer
 encoded information over the amplitude and phase of a carrier signal, are
 normally called IQ data.
 However, this data is distorted as it travels through a high mobility channel.
 High mobility channels are doubly dispersive, which means that the signal
 properties are mixed with some temporal frequency shifting and spreading.
 There are some traditional algorithms that may require complex iterative
 equalizers that can be slow in terms of execution time.
 However, there are also simpler equalizers that may not be as precise.
 In this work, we will investigate the use of neural network-based solutions
 and consider how we should balance time complexity and accuracy to meet
 this challenge.
 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newline
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
We can categorically assert that conventional algorithms continue to work
 well in the context of contemporary development.
 However, recent advances in neural networks have simplified problems that
 were previously intractable, such as deciphering DNA sequences or creating
 images from text.
 In short, they successfully tackle non-linear issues.
 The objective of this work is to mimic well-known equalization techniques
 with linear properties such as MSE and LMMSE, as well as non-linear techniques
 like MAP equalizers.
 We will evaluate how well the equalization performs under various noise
 conditions and with various bit-size encodings.
 We anticipate that the bit error rate will drop to, or perform slightly
 better than, the golden model, which are the aforementioned equalizers.
 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newline
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
According to literature studies, there are a few cutting-edge methodologies
 that approach this goal but fall short of fully documenting all of the
 steps of equalization.
 This article presents a method for dealing with more complex circumstances,
 such as line of sight or a lack of it.
 Lastly, we aim to encourage further research into this largely untapped
 area by some communication teams.
 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newline
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent
\align block

\end_layout

\begin_layout Standard

\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newpage
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset toc
LatexCommand tableofcontents

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newpage
\end_layout

\end_inset


\end_layout

\begin_layout Standard

\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
This chapter's main goal is to provide an overview of the technical facts
 and some of the current issues that prompted this study.
\end_layout

\begin_layout Subsection
Document organization
\end_layout

\begin_layout Standard

\size large
The structure of this document is as follows: 
\end_layout

\begin_layout Itemize

\series bold
\size large
Chapter 1 Theoretical Framework: 
\series default
Fundamental ideas and concepts behind the current project.
 Outlines the core concepts necessary to comprehend this study
\end_layout

\begin_layout Itemize

\series bold
\size large
Chapter 2 State of Art:
\series default
 Examines the existing literature on classical equalization methods and
 compares them to deep learning models.
 
\end_layout

\begin_layout Itemize

\series bold
\size large
Chapter 3 Present work:
\series default
 The present work includes the Python implementation of various models,
 to train and test different experiments, as well as an overview of the
 software architecture that makes this possible.
 The focus is on explainable deep learning models of Quadrature Amplitude
 Modulation (QAM) equalization based on neural networks, including the design
 of the proposed models.
 Additionally, the description, characteristics, and comparison with related
 work will also be discussed
\end_layout

\begin_layout Itemize

\series bold
\size large
Chapter 4 Results and Analysis:
\series default
 Explains the conception and execution of the idea, the experiments carried
 out, and the analysis of the outcomes.
 Here, we compare the BER (Bit Error Rate) graphs of our studied models.
\end_layout

\begin_layout Itemize

\series bold
\size large
Chapter 5 Conclusion and Outlook: 
\series default
The conclusions and potential future directions of this study are determined.
\end_layout

\begin_layout Subsection
\paragraph_spacing onehalf
Background
\end_layout

\begin_layout Standard

\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
It takes a lot of expertise in the field of communications to model different
 types of channels, account for various channel flaws, and create the best
 signaling and detecting systems that guarantee a reliable data flow.
 The design of transmit signals in communications enables simple analytical
 techniques for symbol detection for a range of channel and system models,
 including multipath, doppler spread, and white Gaussian noise (AWGN) over
 constellation symbol detection.
 
\begin_inset CommandInset citation
LatexCommand cite
key "aghvami2005channel"
literal "false"

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newline
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
One of the guiding principles of communication system design is the division
 of signal processing into a series of distinct blocks, each of which performs
 a clearly defined and isolated functions such as source or channel coding,
 modulation, channel estimation, and equalization.
 This strategy has made it possible for us to have the effective, adaptable,
 and controlled systems we have today, but it is not certain whether individuall
y tuned processing blocks will yield the best end-to-end performance 
\begin_inset CommandInset citation
LatexCommand cite
key "proakis2002communication"
literal "false"

\end_inset

.
 During implementation, we will also consider the abstraction of the other
 communication blocks and assume that the channel has already been estimated.
 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newline
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Diagrams/Typical_Block_Diagram.png
	lyxscale 50
	scale 40

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Typical communication system block diagram 
\begin_inset CommandInset citation
LatexCommand cite
key "ChannelDiagram"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
On the other hand, the design philosophy guiding the creation of the 6G
 architecture will be "AI native.", allowing the network to become intelligent,
 capable of solving individual stages of the channel, and able to self-learn
 and self-adapt in response to changing network dynamics 
\begin_inset CommandInset citation
LatexCommand cite
key "The_Roadmap_to_6G"
literal "false"

\end_inset

.
 It has been demonstrated that NNs are capable of approximating any function
 
\begin_inset CommandInset citation
LatexCommand cite
key "HORNIK1989359"
literal "false"

\end_inset

, and current research has demonstrated an astounding aptitude for algorithmic
 learning 
\begin_inset CommandInset citation
LatexCommand cite
key "8697857"
literal "false"

\end_inset

.
 Due to the challenge of defining real-world images or language with strict
 mathematical models, deep learning (DL) excels in fields like computer
 vision and natural language processing.
 For example, while it is now simple to develop DL algorithms that learn
 to complete this task with accuracy greater than that of humans 
\begin_inset CommandInset citation
LatexCommand cite
key "Surpassing_Human_Level_Performance"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Despite this, we assume that the DL applications we evaluate in this thesis
 are a useful and insightful way to fundamentally rethink the problem of
 communications network design, and they show promise for performance improvemen
ts in complex communications scenarios that are difficult to describe with
 tractable mathematical models.
 Finally, we will look for the equalization stage, which, if it is seen
 in the diagram above, fits on the channel decoder.
 
\end_layout

\begin_layout Subsection
OFDM
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
Orthogonal Frequency Division Multiplexing (OFDM) is a digital communication
 technique that divides the available bandwidth into a large number of narrowban
d subcarriers, and transmits data by modulating the subcarriers with symbols.
 OFDM is widely used in wireless and wired communication systems, such as
 Wi-Fi, LTE, and DOCSIS.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent
\align block

\size large
The basic blocks of an OFDM system are:
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Diagrams/OFDM_typical.png
	lyxscale 50
	scale 40

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
OFDM basic diagram 
\begin_inset CommandInset citation
LatexCommand cite
key "OFDMdiagram"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Itemize

\series bold
\size large
Binary sequence
\series default
: This block generates the data to be transmitted.
 The data is usually a sequence of bits.
\end_layout

\begin_layout Itemize
\align block

\series bold
\size large
QAM mapping
\series default
: Bits are grouped into blocks called symbols usally named as alphabet 
\begin_inset Formula $\boldsymbol{\mathbb{A}}$
\end_inset

.
 We have a set of bits 
\begin_inset Formula $2^{\mathbb{A}}$
\end_inset

 grouped inside the alphabet.
 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\align block

\series bold
\size large
IFFT block
\series default
: This block applies an Inverse Fast Fourier Transform (IFFT) to the modulated
 symbols, dividing them into a set of subcarriers.
\end_layout

\begin_layout Itemize
\align block

\series bold
\size large
Cyclic prefix
\series default
: Helps OFDM symbols to reduce inter-symbol interference.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
At regular intervals, the transmitter inserts recognizable symbols known
 as "pilots" into the transmitted signal.
 These pilots are selected to have a known value and to be separated from
 one another by a given number of symbols.
 By comparing the known transmission symbols to the received symbols, the
 receiver can then utilize the pilots to estimate the channel.
 This may lower the system's data throughput.
 Subsequently, the equalizer performs channel equalization using the coefficient
s obtained by the estimator, to reduce the distortions caused by the communicati
on channel in the received data.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Since we have been provided with a dataset that contains previously estimated
 channels, we will not prioritize the channel estimation component of this
 project.
 Rather, in order to minimize errors and impairments at the receiver and
 to transmit the symbols as accurately as possible, we will focus on canceling
 the effects of the received, but well-known, channel during the communication
 process.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
We are entering a new research area as we attempt to generalize the pseudo
 inverse of the channel to cancel its effects.
 It is well known that the matrix inverse is not a continuous function,
 as some matrices may not have an inverse or may be singular.
 However, we are using a subset of invertible matrices to mitigate this
 issue, and also considering realistic physical phenomena.
 Additionally, we must grapple with the numerical instability of the matrix
 inverse, as well as the use of complex numbers in a neural network.
\end_layout

\begin_layout Subsubsection
Advantages and Disadvantages in OFDM
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
The advantages offered by OFDM systems in broadband systems are as follows
 
\begin_inset CommandInset citation
LatexCommand cite
key "ofdm_book"
literal "false"

\end_inset

:
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\align block

\series bold
\size large
High spectral efficiency
\series default
: OFDM can transmit a large amount of data over a wide frequency band by
 dividing the available bandwidth into multiple narrowband subcarriers.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\align block

\series bold
\size large
Robustness to channel impairments
\series default
: OFDM is less sensitive to frequency-selective fading and interference
 than other multiplexing techniques, making it well-suited for use in wireless
 communication systems.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\align block

\series bold
\size large
Ease of implementation
\series default
: OFDM can be implemented using simple digital signal processing techniques,
 making it relatively easy to design and implement.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
Some disadvantages of OFDM include:
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\align block

\series bold
\size large
High peak-to-average power ratio
\series default
: OFDM signals have a high peak-to-average power ratio, which can cause
 problems in power amplifier systems and limit the range of the transmitted
 signal.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\align block

\series bold
\size large
Sensitivity to timing errors: 
\series default
OFDM is sensitive to timing errors, which can cause inter-symbol interference
 and reduce the performance of the system.
\end_layout

\begin_layout Itemize

\series bold
\size large
Sensitivity to Doppler spread:
\series default
 Doppler spread causes interference between the subcarriers.
\end_layout

\begin_layout Subsection
QAM and IQ data
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
QAM (Quadrature Amplitude Modulation) 
\begin_inset CommandInset label
LatexCommand label
name "subsec:QAM-and-IQ"

\end_inset

is a type of digital modulation that encodes data onto a carrier signal
 by modulating the amplitude and phase of the signal.
 It is commonly used in digital communication systems to transmit digital
 data over analog channels.
 IQ data refers to the in-phase and quadrature components of a complex-valued
 signal.
 In digital communication systems, the IQ data is typically used to represent
 the amplitude and phase of the modulated carrier signal.
 It's ussualy represented with complex numbers in an alphabet 
\begin_inset Formula $\mathbb{A}\in\mathbb{C}^{n}$
\end_inset

.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Diagrams/16QAM.png
	lyxscale 20
	scale 20

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Caption Standard

\begin_layout Plain Layout
16-QAM constellation 
\begin_inset CommandInset citation
LatexCommand cite
key "wiki_16qam"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\size large
 In the field of communication systems, a QAM constellation refers to a
 graphical representation of the symbol points in an alphabet on the complex
 plane.
 Each point represents a specific combination of the in-phase and quadrature
 components of the modulated signal.
 The number of points in the constellation is determined by the number of
 possible combinations of in-phase and quadrature values, which is in turn
 determined by the number of bits per symbol used in the QAM modulation
 scheme.
 For instance, in a 16-QAM constellation, there are 16 symbol points arranged
 in a square grid, with each point corresponding to 4 bits of data.
 The distance between points in the constellation serves as an indicator
 of the signal-to-noise ratio required for reliable transmission of the
 data.
 It is common for QAM constellations to utilize gray code for assigning
 the symbol points in a manner that minimizes the error rate.
 However, this is not the only method that can be employed for this purpose
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/QAM_noise.jpg
	lyxscale 80
	scale 50

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
QPSK and 16 QAM with noise and phase displacement 
\begin_inset CommandInset citation
LatexCommand cite
key "QAMwithNoise"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
SNR
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
SNR 
\begin_inset CommandInset label
LatexCommand label
name "subsec:SNR"

\end_inset

stands for Signal-to-Noise Ratio which contrasts the strength of the signal
 with the strength of the noise.
 The most common way to measure it is in decibels (dB).
 In general, higher numbers indicate a better specification because there
 is a greater ratio of useful information (the signal) to unwanted data
 (the noise).
 The following equation displays the necessary power spectral density of
 the noise.
 
\begin_inset CommandInset citation
LatexCommand cite
key "proakis2002communication"
literal "false"

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size larger
\begin_inset Formula 
\begin{equation}
\boldsymbol{N_{0}=\frac{P_{signal}}{P_{noise}}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size larger
\begin_inset Formula 
\begin{equation}
\boldsymbol{P_{signal}=\sum|s|^{2}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
For realistic simulations, noise is typically an AWGN, which is useful.
 In order to simulate bit error rates, AWGN can generate appropriate power
 levels.
 Typically, noise power is determined by its variance 
\begin_inset Formula $\boldsymbol{\sigma^{2}}$
\end_inset

, which in simulations is used as follows.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size larger
\begin_inset Formula 
\begin{equation}
\boldsymbol{\sigma^{2}=10^{\frac{SNR_{dB}}{10}}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Misunderstandings have arisen regarding the signs assigned to the positive
 and negative exponents in the equation.
 While there are conflicting explanations in various sources, to clear up
 any confusion, it's important to consider the visual representation of
 the equation
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size larger
\begin_inset Formula 
\begin{equation}
\boldsymbol{N_{0}=\frac{P_{signal}}{P_{noise}}=\frac{\sum|s|^{2}}{10^{\frac{SNR_{dB}}{10}}}=\sum|s|^{2}\times10^{-\frac{SNR_{dB}}{10}}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The higher the SNR, the better the quality of the signal, since the noise
 is relatively weaker.
 In practice, the SNR is usually calculated for a specific frequency band
 or for a specific signal-processing method.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The necessary noise variance (noise power) for producing Gaussian random
 noise, assuming complex IQ plane for all digital modulations, is given
 by
\end_layout

\begin_layout Standard

\size larger
\begin_inset Formula 
\begin{equation}
\boldsymbol{n=\sqrt{(N_{0}/2)}*(randn(size(s))+j*randn(size(s)))}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard

\size large
with the recived signal 
\end_layout

\begin_layout Standard

\size larger
\begin_inset Formula 
\begin{equation}
\boldsymbol{r=s+n}
\end{equation}

\end_inset


\end_layout

\begin_layout Subsubsection
BER
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
In digital communication systems, 
\begin_inset CommandInset label
LatexCommand label
name "subsec:BER"

\end_inset

the transmission of data is not always error-free.
 Bit errors may occur due to various factors such as noise, interference,
 distortion, and fading.
 Bit Error Rate (BER) is a common metric used to quantify the quality of
 a digital communication system by measuring the probability of bit errors.
 BER is defined as the ratio of the number of erroneous bits to the total
 number of transmitted bits.
 It is usually expressed in terms of power, as the probability of error
 is dependent on the signal-to-noise ratio (SNR) and the channel conditions.
 The BER can be mathematically represented as follows:
\end_layout

\begin_layout Standard

\size large
\begin_inset Formula 
\begin{equation}
\mathsf{\boldsymbol{BER=\frac{N_{err}}{N_{tot}}}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
where 
\begin_inset Formula $N_{err}$
\end_inset

 is the number of erroneous bits and 
\begin_inset Formula $N_{tot}$
\end_inset

 is the total number of transmitted bits.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The BER is a critical parameter for evaluating the performance of a digital
 communication system.
 A high BER indicates poor system performance, which can lead to loss of
 data, degraded audio or video quality, or even complete system failure.
 Therefore, the BER is used as a benchmark to ensure that the digital communicat
ion system meets the required performance specifications.
\end_layout

\begin_layout Subsubsection
BLER 
\begin_inset CommandInset label
LatexCommand label
name "subsec:BLER"

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Block Error Rate (BLER) is a measure of the reliability of a communication
 system or a data transmission system by blocks.
 BLER is defined as the ratio of the number of blocks of data received with
 errors to the total number of blocks of data transmitted.
 It is commonly used in wireless communication systems, where the transmission
 of data can be affected by various factors such as fading, interference,
 and noise.
 In such systems, BLER is often used to evaluate the performance of the
 system and to determine the optimal operating parameters such as power,
 coding, and modulation schemes.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\boldsymbol{BLER=\frac{BlockErrCount}{TotalBlocks}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
To check for errors in a block of data, a cyclic redundancy check (CRC)
 is often used 
\begin_inset CommandInset citation
LatexCommand cite
key "CRC"
literal "false"

\end_inset

.
 Given the estimated values and the ground truth, instead of comparing bit
 by bit, a set of symbols is taken, and a CRC is calculated for a given
 chunk of the data.
 If the CRC of the equalized chunk is equal to the real value, there are
 no errors.
 However, if the CRC differs, the chunk is marked as incorrect, and it is
 added to the BLER count.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{algorithm}[ht] 
\backslash
caption{Block Error Rate Calculation with CRC} 
\backslash
label{alg:block_error_rate_crc} 
\backslash
begin{algorithmic}[1] 
\backslash
Require 
\backslash
Statex Input data is 48 blocks of 48 symbols 
\backslash
Statex $txbits$: array of transmitted blocks 
\backslash
Statex $rxbits$: array of received blocks 
\backslash
Statex $crc
\backslash
_func$: CRC function for generating CRC codes 
\backslash
Ensure 
\backslash
Statex $BLER$: Block Error Rate of the communication system 
\backslash
State $total
\backslash
_blocks 
\backslash
gets 48$ 
\backslash
State $bad
\backslash
_blocks 
\backslash
gets 0$ 
\backslash
For{$n 
\backslash
gets 0$ to $47$} 
\backslash
State $tx
\backslash
_crc 
\backslash
gets crc
\backslash
_func(txbits[n].tobytes())$ 
\backslash
State $rx
\backslash
_crc 
\backslash
gets crc
\backslash
_func(rxbits[n].tobytes())$ 
\backslash
If{$tx
\backslash
_crc 
\backslash
neq rx
\backslash
_crc$} 
\backslash
State $bad
\backslash
_blocks 
\backslash
gets bad
\backslash
_blocks + 1$ 
\backslash
EndIf 
\backslash
EndFor 
\backslash
State $BLER 
\backslash
gets bad
\backslash
_blocks / total
\backslash
_blocks$ 
\backslash
State 
\backslash
Return $BLER$ 
\backslash
end{algorithmic} 
\backslash
end{algorithm}
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
\paragraph_spacing onehalf
Channel
\size large
 
\begin_inset CommandInset label
LatexCommand label
name "subsec:Channel"

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newline
\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Dispersion and doubly dispersion
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
Dispersion, in the context of radio communication systems, refers to the
 spreading out of a signal over a range of frequencies or wavelengths as
 it travels through a medium, such as air.
 This phenomenon can lead to distortion of the signal and negatively impact
 the performance of the communication system.
 There are various factors that can contribute to dispersion, including
 the distance the signal travels, the presence of obstacles or reflections,
 and the frequency of the signal.
 Techniques such as equalization, adaptive modulation, and error correction
 codes can be used to mitigate the effects of dispersion.
 A doubly dispersive channel is a type of communication channel that exhibits
 dispersion in two dimensions, such as time and frequency.
 This means that the signals transmitted through the channel are spread
 out in both time and another aspect, such as frequency or spatial dimensions.
 
\begin_inset CommandInset citation
LatexCommand cite
key "rappaport2002wireless"
literal "false"

\end_inset


\end_layout

\begin_layout Subsubsection
Multipath fading and doppler shift
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent
\align block

\size large
A multipath fading channel is a type of wireless communication channel that
 experiences fading of the transmitted signal due to multiple paths of the
 signal between the transmitter and receiver.
 This can occur when the signal reflects off of obstacles such as buildings
 or terrain, or when it is refracted by the atmosphere.
 Multiple paths of the transmitted signal can cause constructive and destructive
 interference at the receiver, resulting in rapid fluctuations in the received
 signal strength.
 This can cause the signal to fade in and out, which can affect the quality
 and reliability of the communication.
 
\begin_inset CommandInset citation
LatexCommand cite
key "balanis_2012"
literal "false"

\end_inset

.
 We begin with the ray-tracing technique and make advantage of the physical
 geometry of the propagation environment to create a deterministic model
 of the wireless channel.
 The delay of a signal refers to the time it takes for the signal to travel
 from the transmitter to the receiver, and the Doppler shift of a signal
 refers to the frequency shift of the signal due to the relative motion
 between the transmitter and receiver.
\size default

\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Diagrams/Propagation.png
	lyxscale 50
	scale 30

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Caption Standard

\begin_layout Plain Layout
Delay multipath 
\begin_inset CommandInset citation
LatexCommand cite
key "hong_thaj_viterbo_2022"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard

\series bold
\size larger
\begin_inset Formula 
\begin{equation}
\boldsymbol{\mathbf{r(t)=g_{1}s(t-\tau_{1})+g_{2}s(t-\tau_{2})}}
\end{equation}

\end_inset


\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\mathbf{r(t)}$
\end_inset

 recieved signal
\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\mathbf{g_{n}}$
\end_inset

 baseband equivalent complex gain(attenuation)
\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\mathbf{\boldsymbol{\tau_{1}=\frac{r_{1}}{c}}}$
\end_inset

 where c is the speed of light
\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\mathbf{\boldsymbol{\tau_{2}=\frac{(r_{2}+r_{3})}{c}}}$
\end_inset

 delay in reflected path
\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\boldsymbol{\mathbf{\tau_{2}-\tau_{1}}}$
\end_inset

 delay spread
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
In wireless communication, the Doppler shift can cause changes in the frequency
 of a signal as it travels from the transmitter to the receiver.
 This can happen when the transmitter or receiver (or both) are moving relative
 to each other, causing the frequency of the signal to shift.
 The Doppler shift can affect the performance of a wireless communication
 system by causing changes in the signal-to-noise ratio and the signal-to-interf
erence ratio, which can degrade the quality of the signal and make it more
 difficult to detect and decode.
\begin_inset CommandInset citation
LatexCommand cite
key "marsland2013radio"
literal "false"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Diagrams/DopplerBasic.png
	lyxscale 50
	scale 40

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Doppler shifts due to the different angles of arrival 
\begin_inset CommandInset citation
LatexCommand cite
key "hong_thaj_viterbo_2022"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard

\size larger
\begin_inset Formula 
\begin{equation}
\boldsymbol{\mathbf{r(t)=g_{1}e^{j2\pi\nu_{1}(t-\tau_{1})}s(t-\tau_{1})+g_{2}e^{j2\pi\nu_{2}(t-\tau_{2})}s(t-\tau_{2})}}
\end{equation}

\end_inset


\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\mathbf{\boldsymbol{\nu_{1}=\frac{v}{c}f_{c}}}$
\end_inset

 LOS doppler shift
\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\mathbf{\boldsymbol{\nu_{1}=\frac{v*cos(\theta)}{c}f_{c}}}$
\end_inset

 doppler shift in reflected path
\end_layout

\begin_layout Standard
\align block

\size large
We can generalize for time dependent function the gain as follows: 
\end_layout

\begin_layout Standard

\size larger
\begin_inset Formula 
\begin{equation}
\boldsymbol{\mathbf{g(\tau_{i},t)=g_{i}e^{j2\pi\nu_{i}(t-\tau_{i})}}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent
\align block

\size large
Therefore impulse time-frequency response of channel at fixed time t, can
 be obtained by taking fourier transform along the delay dimension of 
\begin_inset Formula $\mathbf{\boldsymbol{g(\tau,t)}}$
\end_inset


\end_layout

\begin_layout Standard

\size larger
\begin_inset Formula 
\begin{equation}
\mathbf{\boldsymbol{H(f,t)=\int g(\tau,t)e^{-j2\pi f\tau}d\tau}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent
\align block

\size large
A time-frequency channel is a type of communication channel that is characterize
d by time-varying frequency-selective fading.
 This means that the channel experiences changes in its frequency response
 over time, resulting in variations in the amplitude and phase of the signals
 transmitted through it.
 Because a channel is assumed to have a slow time-varying function of t,
 we refer to this phenomenon as having a wide sense of being stationary.
 
\begin_inset CommandInset citation
LatexCommand cite
key "rappaport2002wireless"
literal "false"

\end_inset


\end_layout

\begin_layout Subsubsection
Wide sense stationary
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
A wide sense stationary (WSS) process is a stochastic process in which the
 mean and the autocorrelation function of the process do not change over
 time.
 As a result, the process' statistical characteristics, such as the mean,
 variance, and autocorrelation, remain consistent across time.
 In signal processing and telecommunications, WSS processes are frequently
 used to simulate signals that are stationary over a period of time.
 A generalization of strictly stationary processes, or processes in which
 the mean and auto-correlation function are constant over time, are WSS
 processes.
 
\begin_inset CommandInset citation
LatexCommand cite
key "papoulis2002probability"
literal "false"

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent
\align block

\size large
A wide sense stationary (WSS) process can be described by the following
 equations:
\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent
\align block

\size large
The mean of the process is constant over time, and can be represented by
 the equation:
\end_layout

\begin_deeper
\begin_layout Standard

\size large
\begin_inset Formula 
\begin{equation}
\mathbf{\boldsymbol{E[X(t)]=\mu}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard

\size large
Where 
\begin_inset Formula $\boldsymbol{E[X(t)]}$
\end_inset

 is the expected value of the process at time t, and 
\begin_inset Formula $\boldsymbol{μ}$
\end_inset

 is the constant mean of the process.
\end_layout

\end_deeper
\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent
\align block

\size large
The autocovariance of the process, which is a measure of the correlation
 between two points in time, is also constant over time, and can be represented
 by the equation:
\end_layout

\begin_deeper
\begin_layout Standard

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{R_{X}(t1,t2)=E[(X(t_{1})-\mu)(X(t_{2})-\mu)]=R(t_{1}-t_{2})}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
Where
\begin_inset Formula $\boldsymbol{R_{X}(t_{1},t_{2})}$
\end_inset

is the autocovariance of the process at times t1 and t2, and 
\begin_inset Formula $\boldsymbol{R(t_{1}-t_{2})}$
\end_inset

 is the autocovariance function of the process, which is a function of the
 time difference between t1 and t2
\end_layout

\end_deeper
\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent
\align block

\size large
The autocorrelation function of the process, which is a measure of the correlati
on between two points in time, is also constant over time, and can be represente
d by the equation
\end_layout

\begin_deeper
\begin_layout Standard

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{r_{X}(t1,t2)=\frac{R_{X}(t_{1},t_{2})}{\sqrt{R_{X}(t_{1},t_{1})R_{X}(t_{2},t_{2})}}=r(t_{1}-t_{2})}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
Where 
\begin_inset Formula $\mathbf{r_{X}(t_{1},t_{2})}$
\end_inset

 is the autocorrelation function of the process at times t1 and t2, and
 
\begin_inset Formula $\boldsymbol{r(t_{1}-t_{2})}$
\end_inset

 is the autocorrelation function of the process, which is a function of
 the time difference between t1 and t2.
\end_layout

\end_deeper
\begin_layout Subsection
Equalization
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
A telecom channel equalizer is a device or algorithm used in telecommunications
 systems to compensate for distortion or other impairments in a communication
 channel.
 The equalizer uses signal processing techniques to estimate the characteristics
 of the channel, such as the impulse response or the frequency response,
 and then applies a correction to the transmitted signal to counteract the
 effects of the channel on the received signal.
 This can improve the performance of the communication system by reducing
 errors and increasing the data rate or signal-to-noise ratio.
 Bluetooth, WiFi, IOT, drones, V2V, wireless broadband, and satellite communicat
ions are just a few of the everyday applications they can be used for.
 
\begin_inset CommandInset citation
LatexCommand cite
key "goldsmith_2005"
literal "false"

\end_inset

 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newline
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Diagrams/Equalizer_Basic.jpg
	lyxscale 30
	scale 15

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Basic Equalizer
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Our goal is to develop an equalizer based on deep learning techniques and
 research how it performs in terms of timing and memory complexity.
 We take as a reference the classical methods that manage a good bit error
 rate, and we will take them as a golden model of accuracy.
 
\end_layout

\begin_layout Subsubsection
Estimator
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
An estimator is a statistical function that maps an observation to an estimate
 of a parameter of the signal being observed, normally known as 
\size larger

\begin_inset Formula $\hat{\boldsymbol{\theta}}$
\end_inset


\size large
 .It is a mathematical function that takes the data, usually in the form
 of a sample, and produces an estimate of an unknown parameter of the underlying
 probability distribution.
 It's important to note that the quality of an estimator is usually measured
 by some metric such as Mean Squared Error (MSE), Mean Absolute Error (MAE)
 or Maximum Likelihood (ML) that indicates how well the estimator is able
 to estimate the true parameter 
\begin_inset CommandInset citation
LatexCommand cite
key "MSE_MMSE"
literal "false"

\end_inset

.
\end_layout

\begin_layout Subsubsection
Zero forcing
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The Zero Forcing Equalizer (ZFE)
\begin_inset CommandInset label
LatexCommand label
name "subsec:Zero-forcing"

\end_inset

 is a technique used in communication systems to reduce the impact of intersymbo
l interference (ISI), caused by the presence of multiple signal paths in
 a communication channel.
 Although the ZFE is effective, it has some limitations, such as being susceptib
le to noise and unable to handle certain types of channel distortions.
 Nevertheless, it can improve the performance of communication systems in
 specific scenarios.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
In our case, we are dealing with a matrix channel that is already in the
 frequency domain.
 To accelerate the ZFE process, we extract the main diagonal of the channel
 matrix using the "diag(H)" operation.
 Then, we apply the operation of "Y" divided by "diag(H)" to obtain the
 estimated transmitted symbols, where 
\begin_inset Formula $\boldsymbol{Y=Hx+w}$
\end_inset

.
 The H matrix, which multiplies the input data x, is almost canceled out
 in the final approach.
 Specifically, we have 
\begin_inset Formula $\hat{x}\simeq x+\frac{w}{diag(H)}$
\end_inset

, where w is the noise vector and diag(H) is the main diagonal of the channel
 matrix H.
 This expression shows that the estimated transmitted symbols are obtained
 by adding the input data to the noise vector w divided by the main diagonal
 of the channel matrix.
 In the equations bellow the estimator is shown.
 
\end_layout

\begin_layout Standard
\align center

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{\hat{x}=\frac{Y}{diag(H)}=\frac{Hx+w}{diag(H)}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\noindent

\size large
Based on a paper, we will use zero forcing as a preprocessing stage for
 some of our experiments
\begin_inset CommandInset citation
LatexCommand cite
key "ZeroForcingEqNN"
literal "false"

\end_inset

.
\end_layout

\begin_layout Subsubsection
MSE
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
MSE equalization, or minimum mean square error, is a posterior estimator.It
 is a measure of how well the estimator, denoted by 
\size larger

\begin_inset Formula $\hat{\boldsymbol{\theta}}$
\end_inset


\size large
, is able to estimate the true parameter, denoted by 
\size larger

\begin_inset Formula $\boldsymbol{\theta}$
\end_inset


\size large
, based on the observed data .It is calculated after the estimator has been
 applied to the data and produces a single scalar value that indicates how
 far the estimated values are from the true values on average.
\begin_inset CommandInset citation
LatexCommand cite
key "MSE_MMSE"
literal "false"

\end_inset

 This technique is commonly used in digital communication systems to improve
 the performance of an equalizer by reducing the mean square error (MSE)
 between the transmitted and received signals.
 It can provide significant improvements in the performance of the channel
 equalization by reducing the effects of noise, interference, and other
 impairments 
\begin_inset CommandInset citation
LatexCommand cite
key "proakis2002communication"
literal "false"

\end_inset

.
 In the context of machine learning, our neural network will be a non-linear
 estimator and can be evaluated by this estimator.
 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align center

\size larger
\begin_inset Formula 
\begin{equation}
\boldsymbol{MSE(\hat{\theta})=E[(\theta-\hat{\theta})^{2}]}
\end{equation}

\end_inset


\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\align block

\size large
\begin_inset Formula $\boldsymbol{\theta}$
\end_inset

 is the transmitted signal with the original values
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\align block

\size large
\begin_inset Formula $\boldsymbol{\hat{\theta}}$
\end_inset

 is the predicted values of the received signal.
\end_layout

\begin_layout Subsubsection
MMSE
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
Since MMSE equalization is a linear equalization technique, the transmitted
 signal is first adjusted using a linear filter before being sent across
 the channel.
 By choosing the proper filter coefficients for the linear filter, the purpose
 of MMSE equalization is to reduce the MSE between the sent and received
 signals.
 The MMSE criteria, which stipulates that the filter coefficients should
 be set to minimize the MSE between the sent and received signals, may be
 used to compute the filter coefficients.
 The equation below can be used to do this: 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align center

\size larger
\begin_inset Formula 
\begin{equation}
\boldsymbol{MMSE=min(E[(\theta-\hat{\theta})^{2}])}
\end{equation}

\end_inset


\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\align block

\size large
\begin_inset Formula $\boldsymbol{x}$
\end_inset

 is the transmitted signal.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\align block

\size large
\begin_inset Formula $\boldsymbol{y}$
\end_inset

 is the received signal.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\align block

\size large
\begin_inset Formula $\boldsymbol{\hat{\theta}=E[x|y]}$
\end_inset

 is an estimator given by Y to an estimate the X
\end_layout

\begin_layout Subsubsection
LS
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
Least squares (LS)
\begin_inset CommandInset label
LatexCommand label
name "subsec:LS"

\end_inset

 equalization is a linear equalization method that aims to minimize the
 mean squared error (MSE) between the estimated and the transmitted symbols.
 The noise component of x is disregarded by the LS (Least-Squares) equalizer,
 which treats it as a deterministic variable.
 A linear filter 
\begin_inset Formula $\boldsymbol{W}$
\end_inset

 that minimize the mean square error between 
\begin_inset Formula $\boldsymbol{\hat{x}}$
\end_inset

 and 
\begin_inset Formula $\boldsymbol{Hx}$
\end_inset

.
 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
The argmin function is a mathematical function that returns the indices
 of the minimum values of a given array or matrix.
 It is often used in optimization problems, where it is used to find the
 values of the variables that minimize some objective function.
\begin_inset CommandInset citation
LatexCommand cite
key "argmin_reference"
literal "false"

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size larger
\begin_inset Formula 
\begin{equation}
\boldsymbol{W_{Ls}=argmin||\hat{x}-Hx||^{2}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
With the solution in the Moore-Penrose pseudoinverse 
\begin_inset Formula $\boldsymbol{H^{+}}$
\end_inset

.The Moore-Penrose pseudoinverse is often used to solve linear least squares
 problems, which involve finding the values of variables that minimize the
 sum of the squares of the residuals (the differences between the observed
 values and the values predicted by the model).
 It can also be used to compute a "best fit" solution for systems of linear
 equations that do not have a unique solution.
 
\begin_inset CommandInset citation
LatexCommand cite
key "strang2019linear"
literal "false"

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size larger
\begin_inset Formula 
\begin{equation}
\boldsymbol{H^{+}=(H^{H}H)^{-1}H^{H}}
\end{equation}

\end_inset


\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\boldsymbol{H}$
\end_inset

 Channel matrix
\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\boldsymbol{H^{+}}$
\end_inset

Moore-Penrose pseudoinverse 
\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\boldsymbol{H^{H}}$
\end_inset

 Hermiatian transpose matrix.
 Complex square matrix that is equal to its own conjugate transpose
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
Its resistance to noise makes it appealing in a variety of communication
 systems, however because the noise component is ignored, it cannot operate
 satisfactorily with low SNR (signal to noise ratio).
 
\end_layout

\begin_layout Subsubsection
LMMSE
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
A form of linear filter called the Linear Minimum Mean Squared Error (LLMSE)
\begin_inset CommandInset label
LatexCommand label
name "subsec:LMMSE"

\end_inset

 Equalizer seeks to reduce the mean squared error (MSE) between the actual
 signal 
\begin_inset Formula $\boldsymbol{x}$
\end_inset

 and an estimation of the signal 
\begin_inset Formula $\boldsymbol{\hat{x}}$
\end_inset

.
 Incorporating second-order statistics of the data and the noise and treating
 the noise as a random variable allows it to achieve this.
 Compared to the Least Squares (LS) algorithm, this can perform better when
 there is low signal-to-noise ratio (SNR).
 To put it another way, the LLMSE equalization is a method that can be applied
 to restore precision to a signal that has been distorted by noise, especially
 when the noise level is high.
 When there is a low signal-to-noise ratio (SNR) and a significant quantity
 of noise in the signal, it performs exceptionally well.
\end_layout

\begin_layout Standard

\size larger
\begin_inset Formula 
\begin{equation}
\boldsymbol{W_{LMMSE}=argminE||x-\hat{x}||^{2}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
This equation consider AWGN (Additive White Gaussian Noise) with variance
 
\begin_inset Formula $\boldsymbol{\sigma^{2}}$
\end_inset

.
 It is called "white" because it has a flat power spectral density, meaning
 that it has equal power at all frequencies.
 It is called "additive" because it can be added to a signal without changing
 its distribution.
 
\end_layout

\begin_layout Standard

\size larger
\begin_inset Formula 
\begin{equation}
\boldsymbol{W_{LMMSE}=(H^{H}H+\sigma^{2}I)^{-1}H^{H}}
\end{equation}

\end_inset


\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\boldsymbol{\sigma^{2}}$
\end_inset

 variance of AWGN
\end_layout

\begin_layout Subsubsection
Pros and Cons
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
As we can see in the previous methods, the calculation of the equalization
 matrices is mainly based on finding the pseudo-inverse of certain matrix
 factors.
 However, directly solving for the inverse of the matrix can be computationally
 complex 
\begin_inset Formula $O(N^{3})$
\end_inset

 and, in addition, numerically unstable.
 This occurs if the matrix has a very small determinant, in which case the
 true solution may be subject to large perturbations.
 This will lead to a very complicated circuit architecture for numerical
 calculation.
\end_layout

\begin_layout Subsection

\size large
Neuronal
\size default
 networks
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Neural networks are a type of artificial intelligence system designed to
 mimic the functioning of the human brain.
 They consist of interconnected nodes, or "neurons," which are capable of
 processing information and making decisions based on that information.
 These networks are usually organized into layers, with each layer containing
 a different number of neurons.
 The input layer receives input from the external environment, while the
 output layer produces the final result or decision based on that input.
 The layers in between the input and output layers are called hidden layers,
 and they perform various intermediate calculations and processing tasks.
 Neural networks are trained using large amounts of data, allowing them
 to learn and make predictions or decisions based on that data.
 In this study case, the data consists of realistic channel realizations.
\end_layout

\begin_layout Subsubsection
Linear Layer
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
A linear layer in a neural network is a type of layer that applies a linear
 transformation to the input data.
 This transformation can be represented by a 
\series bold
matrix
\series default
 of weights, denoted as 
\size larger

\begin_inset Formula $\boldsymbol{W_{n}}$
\end_inset


\size large
 ,and a biases 
\series bold
vector
\series default
, denoted as
\size larger
 
\begin_inset Formula $\boldsymbol{b_{n}}$
\end_inset


\size large
, which are learned during the training process.
 The subscript 
\size larger

\begin_inset Formula $\boldsymbol{n}$
\end_inset


\size large
 refers to the nth layer.
 The output of a linear layer is calculated by performing a matrix and vector
 product between the input data 
\size larger

\begin_inset Formula $\boldsymbol{X_{n-1}}$
\end_inset

 
\size large
and the weights 
\size larger

\begin_inset Formula $\boldsymbol{W_{n}}$
\end_inset


\size large
 as well as adding the biases.
 
\end_layout

\begin_layout Standard

\size larger
\begin_inset Formula 
\begin{equation}
\boldsymbol{X_{n}=W_{n}X_{n-1}+b_{n}}
\end{equation}

\end_inset


\end_layout

\begin_layout Itemize

\size larger
\begin_inset Formula $\boldsymbol{W_{n}}$
\end_inset


\size large
weight matrix at layer n.
\end_layout

\begin_layout Itemize

\size larger
\begin_inset Formula $\boldsymbol{b_{n}}$
\end_inset

 
\size large
bias at layer n
\end_layout

\begin_layout Itemize

\size larger
\begin_inset Formula $\boldsymbol{X_{n-1}}$
\end_inset


\size large
Input or last layer data
\end_layout

\begin_layout Itemize

\size larger
\begin_inset Formula $\boldsymbol{X_{n}}$
\end_inset

 
\size large
Output data
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Diagrams/NN_eq.png
	lyxscale 70
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Output as Y and input as X.
 Vector matrix representation of system.
 Desing done with manim
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Backpropagation 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
The goal of the layer is to optimize the weights parameters so that they
 fit a target referred to as the ground truth.
 The error, denoted by E, is calculated as the difference between the predicted
 output (
\begin_inset Formula $\hat{X}$
\end_inset

) and the actual target output (
\begin_inset Formula $X_{n}$
\end_inset

).
 To achieve this, we will utilize the backpropagation algorithm, which is
 a common method in the field of artificial neural networks for training
 the network by adjusting the weights between neurons in the network.
 
\size larger

\begin_inset Formula 
\begin{equation}
\boldsymbol{Err=\hat{X}-X_{n}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
This method analyzes the error rate in relation to the weights and inputs.
 As we adjust our trainable parameters, {
\size larger

\begin_inset Formula $\boldsymbol{W_{n}}$
\end_inset


\size large
, 
\size larger

\begin_inset Formula $\boldsymbol{b_{n}}$
\end_inset


\size large
}, the error will change accordingly.
 The goal is to minimize the error, or to find a point where the error gradient
 is zero.
\begin_inset CommandInset citation
LatexCommand cite
key "Goodfellow-et-al-2016"
literal "false"

\end_inset


\end_layout

\begin_layout Standard

\size larger
\begin_inset Formula 
\begin{equation}
\boldsymbol{\nabla W=\frac{\partial E}{X_{n\text{+1}}}\times X_{n-1}^{T}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard

\size larger
\begin_inset Formula 
\begin{equation}
\boldsymbol{\nabla X_{n-1}=W_{n}^{T}\times\frac{\partial E}{X_{n\text{+1}}}}
\end{equation}

\end_inset


\end_layout

\begin_layout Itemize

\size larger
\begin_inset Formula $\boldsymbol{\nabla W}$
\end_inset


\size large
Gradient of weights.The gradient is a multi-variable generalization of the
 derivative.
\end_layout

\begin_layout Subsubsection
Learning rate
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
During the process of updating the weights, the learning rate is a hyperparamete
r that determines the size of the update step applied during the training
 of a neural network..
 It is a scalar value that is used to multiply the gradient of the loss
 function with respect to the weights of the network during gradient descent.
 The learning rate determines how fast the weights of the network are updated
 during training.
 A smaller learning rate results in slower updates, while a larger learning
 rate results in faster updates.
 The learning rate is typically set manually, and finding the optimal learning
 rate for a given problem is an important aspect of training a neural network.

\size default
 
\begin_inset CommandInset citation
LatexCommand cite
key "learningrate"
literal "false"

\end_inset

 
\end_layout

\begin_layout Standard

\size larger
\begin_inset Formula 
\begin{equation}
\boldsymbol{W_{n}=W_{n}-\gamma\nabla W}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard

\size larger
\begin_inset Formula 
\begin{equation}
\boldsymbol{b_{n}=b_{n}-\gamma\frac{\partial E}{X_{n}}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
If the learning rate is set too low, the optimization process may become
 stuck in a local minimum or local maximum.
 A local minimum is a point in the optimization landscape where the cost
 function has a lower value than the surrounding points, but is not the
 global minimum.
 A local maximum is a point where the cost function has a higher value than
 the surrounding points, but is not the global maximum.
 This can lead to suboptimal performance or even failure of the optimization
 process.
 On the other hand, if the learning rate is set too high, the optimization
 process may oscillate or diverge, also leading to suboptimal performance.
 It is important to choose an appropriate learning rate for the optimization
 process in order to avoid these problems.
\end_layout

\begin_layout Subsubsection
Basic code implementation
\end_layout

\begin_layout Standard

\size large
Although it may seem difficult to implement the code, it is actually quite
 simple as it involves encapsulating the results of the previous layer's
 calculations.
\end_layout

\begin_layout Standard

\size large
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
lstinputlisting[language=python]{Codigo/Linear.py}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
And a basic implmentation of the Linear Class.
\end_layout

\begin_layout Standard

\size large
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
lstinputlisting[language=python]{Codigo/TestLinear.py}
\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Activation functions 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Activation functions are used in neural networks to introduce non-linearity
 into the network.
 This is important because many real-world problems are non-linear in nature
 and a neural network with only linear functions would not be able to model
 such problems accurately.
 Activation functions allow the network to learn more complex patterns in
 the data and improve the accuracy of the network.
 They also help to prevent the network from becoming stuck in a local minimum
 or plateau during training.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/ActivationFunctions.png
	lyxscale 10
	scale 10

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Activation function.
 (a) Sigmoid, (b) tanh, (c) ReLU.
 
\begin_inset CommandInset citation
LatexCommand cite
key "ActivationFunctionsImages"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The most popular activation functions in neural networks are the sigmoid
 function, the hyperbolic tangent (tanh) function, and the rectified linear
 unit (ReLU) function.
 The sigmoid function maps any input value to a range between 0 and 1, while
 the tanh function maps input values to the range between -1 and 1.
 The ReLU function is a linear function that maps all negative input values
 to 0 and all positive input values to their original value.
\begin_inset CommandInset citation
LatexCommand cite
key "ActivationFunctions"
literal "false"

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
However, there are "hardened" versions of activation functions that can
 be evaluated computationally faster yet produce similar results.
 Examples of these include hardtanh and hardsigmoid.
 The Hardtanh function is defined as: 
\end_layout

\begin_layout Standard

\size larger
\begin_inset Formula 
\begin{equation}
\boldsymbol{hardtanh(x)=\begin{cases}
-1, & \text{if }x<-1\\
x, & \text{if }-1\le x\le1\\
1, & \text{if }x>1
\end{cases}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Hardtanh.png
	lyxscale 25
	scale 25

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Hardtanh(red) and Tanh(blue)
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Loss functions
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
A loss function is often defined as a scalar function of the model's parameters,
 the input data, and the true output.
 It quantifies how well the model is able to fit the data, and it's commonly
 used to evaluate the performance of different models and to select the
 best one.
 In terms of estimators, a loss function can be seen as a measure of how
 well the estimator is able to estimate the true parameter.
 The goal of training a machine learning model is to find the optimal set
 of parameters that minimize the loss function.
 There are different types of loss functions, each one is suitable for different
 types of problems.
 For example, in a regression problem, the mean squared error (MSE) is a
 commonly used loss function, while in a classification problem, the cross-entro
py loss is often used.
 
\end_layout

\begin_layout Subsubsection
Cross Entropy Loss
\begin_inset CommandInset label
LatexCommand label
name "subsec:Cross-Entropy-Loss"

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Previously, we have discussed the Mean Squared Error (MSE) in the context
 of estimators.
 However, there is another cost function, known as the cross-entropy loss,
 which can be utilized for evaluating models in the context of classification
 problems.
 Prior to elaborating on the cross-entropy loss, it is imperative to also
 discuss the softmax function.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The softmax function is a mathematical technique which transforms a vector
 of real numbers into a probability distribution over the classes.
 The output of the softmax function is a vector of values between 0 and
 1 that sum up to 1, which can be interpreted as probabilities.
 The softmax function is employed in this context as it provides a means
 to convert the output, or scores, of the model into a probability distribution
 that represents the uncertainty of the model's predictions.
 Additionally, the softmax function ensures that the probability of each
 class falls within the range of 0 and 1 and that the sum of all class probabili
ties is 1, which is a necessary requirement for a probability distribution.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/softmax.png
	lyxscale 40
	scale 40

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Softmax used to map real numbers to probabilty distribution.
\begin_inset CommandInset label
LatexCommand label
name "fig:Softmax"

\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "softmax"
literal "false"

\end_inset

 
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
After the softmax output, it is measured by the cross-entropy loss function,
 which checks the dissimilarity between the predicted and true probability
 distributions.
 One of the many advantages of this function is that it is also easy to
 compute and differentiate, making it a suitable loss function for gradient-base
d optimization algorithms.
 The goal of the training process is to minimize the Kullback-Leibler divergence.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size larger
\begin_inset Formula 
\begin{equation}
\boldsymbol{D_{KL}(P||Q)=\sum P(i)log\frac{P(i)}{Q(i)}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
This equation is also known as relative entropy.
 This function will determine which of the given classes is more likely.
 The predicted class distribution is represented by 
\begin_inset Formula $P(y|x_{i};\theta)$
\end_inset

 where 
\begin_inset Formula $\theta$
\end_inset

 are the parameters and the true class distribution is represented by 
\begin_inset Formula $P^{*}(y|x_{i})$
\end_inset

 which are taken into consideration.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size larger
\begin_inset Formula 
\begin{equation}
\boldsymbol{D_{KL}(P^{*}(y|x_{i})||P(y|x_{i};\theta)=\sum P^{*}(y|x_{i})log\frac{P^{*}(y|x_{i})}{P(y|x_{i};\theta)}}
\end{equation}

\end_inset


\size large
Rewriting the logarithm as two individual sections, we can observe that
 the left part of the equation below does not depend on the 
\begin_inset Formula $\theta$
\end_inset

 parameter.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size larger
\begin_inset Formula 
\begin{equation}
\boldsymbol{\sum\underbrace{P^{*}(y|x_{i})log(P^{*}(y|x_{i}))}_{\text{Independent of }\theta}-P^{*}(y|x_{i})P(y|x_{i};\theta)}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
And then we aim to make both distributions as similar as possible using
 the best estimator.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size larger
\begin_inset Formula 
\begin{equation}
\boldsymbol{\underset{\theta}{\text{argmin}}D_{KL}(P^{*}||P)\equiv\underset{\theta}{\text{argmin}}-\sum_{y}P^{*}(y|x_{i})P(y|x_{i};\theta)}
\end{equation}

\end_inset


\end_layout

\begin_layout Subsection
Effective Techniques for Improving Model Generalization
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
In the field of machine learning, it is important to ensure that the models
 we build are able to accurately and effectively make predictions on new
 data.
 However, it is common for models to suffer from issues such as overfitting
 or poor generalization to new data.
 In this section, we will explore three techniques that can be used to improve
 the performance of machine learning models: 
\series bold
regularization
\series default
, 
\series bold
normalization
\series default
, and 
\series bold
standardization
\series default
.
 By properly applying these techniques, we can mitigate the risks of overfitting
 and improve the ability of our models to generalize to new data.
 
\begin_inset CommandInset citation
LatexCommand cite
key "Regularization_Bisong,Normalization_layers,standarization"
literal "false"

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\shape italic
\size large
\emph on
\bar under
\color black
Our data set, which includes doubly dispersive channels of a complex nature,
 requires extra attention.
 We will use distorted vectors or inverse matrices, which can result in
 numerical instability, as our ground truth.
 These extra precautions will help to guarantee the process' success.
 Ignoring these recommendations may result in unsatisfactory outcomes, as
 the neural network may not generalize as well and may perform poorly.
 
\begin_inset CommandInset citation
LatexCommand cite
key "ComplexnumbersNN"
literal "false"

\end_inset


\end_layout

\begin_layout Subsubsection
Regularization
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
Regularization is a technique used in machine learning to prevent overfitting.
 Overfitting occurs when a model is overly complex and captures the noise
 in the training data, rather than the underlying relationships.
 This results in poor generalization to new data.
 Regularization works by adding a penalty term to the objective function
 that the model is trying to minimize.
 This penalty term discourages the model from learning relationships that
 are too complex, and encourages it to learn simpler relationships that
 generalize better.
 There are several methods for regularization, including 
\begin_inset CommandInset citation
LatexCommand cite
key "Goodfellow-et-al-2016"
literal "false"

\end_inset

:
\end_layout

\begin_layout Enumerate
\align block

\size large
L1 regularization: This method adds a penalty term to the cost function
 that is proportional to the absolute value of the weights.
\end_layout

\begin_layout Enumerate
\align block

\size large
L2 regularization: This method adds a penalty term to the cost function
 that is proportional to the square of the weights.
\end_layout

\begin_layout Enumerate
\align block

\size large
Dropout regularization: This method randomly sets a fraction of the weights
 in the model to zero during training, which helps to prevent overfitting
 by reducing the number of parameters in the model.
 Dropout is only applied during the training process, and all neurons are
 available during evaluation.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename trasasdenivelRegularization.png
	lyxscale 50
	scale 60

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Level sets of the loss function and L1,L2 regularization 
\begin_inset CommandInset citation
LatexCommand cite
key "regimage"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
To implement regularization, you can modify the cost function of the model
 to include the regularization term.
 For example, in L2 regularization, the cost function would be modified
 to include the sum of the squares of the weights, as shown in the following
 equation:
\end_layout

\begin_layout Standard

\size larger
\begin_inset Formula 
\begin{equation}
\boldsymbol{J(W)=\frac{\lambda}{2}||w||^{2}=\frac{\lambda}{2}\sum_{j=1}^{m}w_{j}^{2}}
\end{equation}

\end_inset


\end_layout

\begin_layout Itemize

\size larger
\begin_inset Formula $\boldsymbol{\lambda}$
\end_inset

 
\size large
regularization parameter
\end_layout

\begin_layout Itemize

\size larger
\begin_inset Formula $\boldsymbol{J(W)}$
\end_inset

 
\size large
Cost function
\end_layout

\begin_layout Subsubsection
Normalization 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Data is scaled using a process called normalization to give it a unit norm
 (or length).
 This is frequently done to improve the data's suitability for particular
 machine learning algorithms, such as those that use gradient descent or
 have a set range for acceptable input data.
 When comparing various features, normalization can also be used to scale
 down the data to a common scale.
 Data normalization methods include min-max normalization, mean normalization,
 and z-score normalization.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\series bold
\size large
Normalization of complex numbers
\series default
 involves dividing a complex number by its magnitude (or absolute value)
 to obtain a complex number with a magnitude of 1.
 This is typically done to simplify calculations and make it easier to compare
 complex numbers.
 The normalized form of a complex number is often written as ẑ = z/|v|,
 where z is the original complex number and ẑ is the normalized form and
 |v| is the max magnitud of the entire vector of the complex numbers.
 Normalization of complex numbers is useful in many applications, including
 signal processing and control systems, where it is often necessary to compare
 complex numbers on an equal footing.
 
\begin_inset CommandInset citation
LatexCommand cite
key "ComplexnumbersNN"
literal "false"

\end_inset


\end_layout

\begin_layout Standard

\size larger
\begin_inset Formula 
\begin{equation}
\boldsymbol{ẑ=\frac{z}{|v|}}
\end{equation}

\end_inset


\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\boldsymbol{|v|}$
\end_inset

 Maximum magnitud of the vector
\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\mathsf{\boldsymbol{z}}$
\end_inset

 Input value
\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\boldsymbol{ẑ}$
\end_inset

 Normalized value
\end_layout

\begin_layout Subsubsection
Standarization 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
Standardization is a method used in machine learning to transform the values
 of a feature or set of features to a standard scale.
 The standard scale is typically defined as having a mean of 0 and a standard
 deviation of 1.
 Standardization is often used as a preprocessing step before training a
 model, as it can help to improve the performance and convergence of the
 model.
 Standardization can be useful when the features in the dataset have different
 scales or units, as it can help to bring them onto a common scale and make
 it easier for the model to learn from the data.
 Standardization can be applied to both real and complex-valued data.
\end_layout

\begin_layout Standard

\size larger
\begin_inset Formula 
\begin{equation}
\boldsymbol{\hat{z}=\frac{z-\mu}{\sigma}}
\end{equation}

\end_inset


\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\boldsymbol{\mu}$
\end_inset

 Mean of the data
\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\boldsymbol{\sigma}$
\end_inset

 Standard deviation of the data
\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\mathsf{\boldsymbol{z}}$
\end_inset

 Input value
\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\boldsymbol{ẑ}$
\end_inset

 Standarized value
\end_layout

\begin_layout Subsubsection
Gradient clipping
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Gradient clipping is a technique used to prevent the gradients of a neural
 network from becoming too large during training.
 It is commonly used to mitigate the problem of exploding gradients, which
 can occur when the gradients become too large and cause the model's parameters
 to diverge.
 This means that if the gradient exceeds this threshold, it will be set
 to the threshold value.
 This effectively limits the size of the gradients and keeps them from becoming
 too large.
 
\begin_inset Formula $ $
\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{algorithm} 
\backslash
caption{Gradient Clipping} 
\end_layout

\begin_layout Plain Layout


\backslash
begin{algorithmic}[1] 
\end_layout

\begin_layout Plain Layout


\backslash
State threshold $
\backslash
gets$ max
\backslash
_norm 
\end_layout

\begin_layout Plain Layout


\backslash
For{each parameter p in the model}     
\end_layout

\begin_layout Plain Layout


\backslash
State $ 
\backslash
boldsymbol{g} 
\backslash
gets 
\backslash
frac{
\backslash
partial
\backslash
epsilon}{
\backslash
partial
\backslash
theta}$     
\end_layout

\begin_layout Plain Layout


\backslash
If{$
\backslash
left
\backslash
|
\backslash
boldsymbol{g}
\backslash
right
\backslash
| > threshold$}         
\end_layout

\begin_layout Plain Layout


\backslash
State $
\backslash
boldsymbol{g} 
\backslash
gets 
\backslash
frac{
\backslash
boldsymbol{g}}{
\backslash
left
\backslash
|grad
\backslash
right
\backslash
|} 
\backslash
times$ threshold     
\end_layout

\begin_layout Plain Layout


\backslash
EndIf     
\end_layout

\begin_layout Plain Layout


\backslash
State 
\end_layout

\begin_layout Plain Layout

update
\backslash
_parameter(p, grad) 
\end_layout

\begin_layout Plain Layout


\backslash
EndFor 
\end_layout

\begin_layout Plain Layout


\backslash
end{algorithmic} 
\end_layout

\begin_layout Plain Layout


\backslash
end{algorithm} 
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/GradiantClipping.png
	scale 70

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Gradient clipping
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Z-score
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The Z-score,
\begin_inset CommandInset label
LatexCommand label
name "subsec:Z-score"

\end_inset

 also known as standard score, is a statistical measure that indicates how
 many standard deviations an observation or data point is from the mean
 of a data set.
 It is used to standardize data and compare individual observations to a
 population or sample mean.
 The magnitude of the z-score represents how far away the data point is
 from the mean in terms of standard deviations.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
This method has its own section in our results due to its relevance.
 It helps us to remove outliers and make our results more stable.
 Outliers are data points that are significantly different from the other
 data points in the data set and can skew statistical analyses or machine
 learning models.
 Z-score can be used to identify and reduce outliers in a data set.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
To identify outliers using z-score, we first calculate the z-score for each
 data point in the data set.
 We can then set a threshold z-score value, usually between 2 and 3, beyond
 which any data point is considered an outlier.
 Data points that have a z-score above the threshold are identified as outliers
 and can be removed from the data set.
 This can help to improve the accuracy and reliability of our results or
 predictions.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{z=\frac{x_{i}-\mu}{\sigma}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
We use the z-score to filter outliers with a desired level of confidence,
 which is typically set at 95%.
 This corresponds to a z-score of 1.96, which means that approximately 95%
 of the data points would fall within the confidence interval.
 The 95% confidence level is commonly used in statistical analyses as a
 standard level of confidence
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/ConfidenceInterval.png
	lyxscale 70
	scale 70

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
95% Confidence interval 
\begin_inset CommandInset citation
LatexCommand cite
key "z_score_drawing"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Convolutional Neuronal Networks
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
A convolutional neural network (CNN) is a type of deep learning neural network
 that is primarily used for image and video recognition.
 It is designed to process data that has a grid-like topology, such as an
 image.
 The network is composed of multiple layers, including 
\series bold
convolutional layers
\series default
, 
\series bold
activation layers
\series default
, 
\series bold
pooling layers 
\series default
and
\series bold
 linear layers
\series default
.
 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The convolutional layers apply a set of filters to the input data, where
 each filter is a small matrix of weights.
 This ones are used to identify features in the data such as 
\series bold
edges
\series default
, 
\series bold
textures
\series default
, and 
\series bold
shapes
\series default
, specifically, we will be utilizing these layers to extract the relationship
 of intercarrier symbol interference (ISI) and to perform dimensionality
 reduction.
 
\begin_inset CommandInset citation
LatexCommand cite
key "Conv1"
literal "false"

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "Goodfellow-et-al-2016"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\size large
The 
\series bold
activation layers
\series default
 or activation functions introduce non-linearity to the network, allowing
 it to learn complex representations of the input data.
 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\size large
The 
\series bold
pooling layers
\series default
 reduce the spatial dimensions of the data, which helps to reduce overfitting
 and computational cost.
\end_layout

\begin_deeper
\begin_layout Itemize
\paragraph_spacing onehalf

\size large
Max pooling is used to pick the feature with the highest activation in a
 small region of the input feature map
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\size large
Average pooling is used to reduce the spatial size of the input data by
 taking the average of the values of a small region of the input feature
 map.
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Diagrams/Max_pool_avg_pool.jpg
	lyxscale 40
	scale 20

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Average and max pooling
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Itemize
\noindent
\align block

\series bold
\size large
Linear layers
\series default
 classify the features extracted by the convolutional layers into the desired
 output.
\end_layout

\begin_layout Standard
\noindent
\align block

\size large
It should be noted that what is commonly referred to as 'convolution' in
 the context of convolutional neural networks (CNNs) is actually a cross-correla
tion operation, denoted with symbol 
\begin_inset Formula $\mathbf{\bigstar}$
\end_inset

 and convolution usually is used 
\begin_inset Formula $\boldsymbol{*}$
\end_inset

.
 The term 'convolution' is used only for convention purposes.
 The basic concept behind cross-correlation is to take a small matrix, referred
 to as a kernel or filter, and slide it over the input data (such as an
 image or audio signal).
 At each position, the kernel is multiplied element-wise with the underlying
 data, and the results are summed to produce a single output value, referred
 to as a feature map.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Diagrams/Conv2d_Kernel.jpg
	lyxscale 30
	scale 25

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Caption Standard

\begin_layout Plain Layout
Basic cross-correlation operation
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
The output of the convolution operation is a feature map, where each element
 in the feature map is computed as follows:
\end_layout

\begin_layout Standard

\size larger
\begin_inset Formula 
\begin{equation}
\boldsymbol{Y_{ij}=\sum K_{ab}\circ I_{i+a,j+b}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Where kernel(a,b) is the value of the filter at position (a,b), input(i+a,j+b)
 is the value of the input at position (i+a,j+b) and output(i,j) is the
 output value at position (i,j)
\end_layout

\begin_layout Subsubsection
Channels
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
A channel refers to a specific feature or dimension of the input data.
 For example, in the case of image data, a channel can represent a color
 channel such as red, green, or blue.
 These channels are used to extract different features of the input image,
 and they are processed separately by the CNN.
 In our case study, we can use channels as a division between the real and
 imaginary parts, or for feature extraction of intercarrier symbol interference
 (ISI).
 We can have N channels as input and M channels as output, depending on
 how many features we want to deal with.
 In the image below, we show a case of 3 channel input and two channel output,
 also with a bias term.
\size default

\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/ConvolutionExpansion.png
	lyxscale 50
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Convolutional Neural Network with 3-channel Input and 2-channel Output,
 including bias term
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
A Generalized View of Linear Layers through Convolutional Neural Networks
\end_layout

\begin_layout Standard

\size large
Let's take a more detailed look at the math, given the following terms.
\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\boldsymbol{j}$
\end_inset

 input channels with
\begin_inset Formula $\boldsymbol{X_{j}}$
\end_inset

 matrices
\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\boldsymbol{d}$
\end_inset

 ouput channels 
\begin_inset Formula $\boldsymbol{Y_{d}}$
\end_inset

matrices and this ones an output size of 
\begin_inset Formula $\boldsymbol{X_{j}-K_{ij}}$
\end_inset


\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\boldsymbol{K_{ij}}$
\end_inset

 kernels,where 
\begin_inset Formula $\boldsymbol{i}$
\end_inset

 maps to 
\begin_inset Formula $\boldsymbol{Y_{d}}$
\end_inset

 and 
\begin_inset Formula $\boldsymbol{j}$
\end_inset

 to 
\begin_inset Formula $\boldsymbol{X_{j}}$
\end_inset


\end_layout

\begin_layout Itemize
\noindent
\align block

\size large
\begin_inset Formula $\mathbf{\bigstar}$
\end_inset

 cross-correlation
\end_layout

\begin_layout Standard

\size larger
\begin_inset Formula 
\begin{equation}
\boldsymbol{Y_{d}=B_{d}+\sum_{j=1}^{n}X_{j}\bigstar K_{ij}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
We can think of the matrices as individual blocks and visualize them in
 the image below.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Conv2dGeneralization.png
	lyxscale 40
	scale 60

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset Formula $Y_{d}$
\end_inset

 output given kernels
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Finally, with the use of abstraction, we can further simplify the problem
 by representing it as a generalized version of tensors.
 The internal tensor is given by the sum of the cross-correlations between
 X channels and kernels.
 In a more general perspective, this can be viewed as the inner product
 of two tensors.
\end_layout

\begin_layout Standard

\size larger
\begin_inset Formula 
\begin{equation}
\boldsymbol{Y=B+\langle K,X\rangle}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/MetaDense.png
	lyxscale 50
	scale 70

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Higher dimensionality abstract version 
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
It's worth noting that when we consider a kernel of 1 dimension and an input
 of 1 channel, we can see that a dense layer is just a specific case of
 a 2D convolutional layer (Conv2D).
 Just as equation (15) and figure (8)
\end_layout

\begin_layout Subsection
FLOPS
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
FLOPS stands for "floating point operations per second." It is a measure
 of the computational performance of a computer or processor, and it indicates
 how many floating point arithmetic operations can be performed in one second.
 Floating point operations include addition, subtraction, multiplication,
 and division, as well as more complex operations like trigonometric functions,
 logarithms, and exponentials.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
FLOPS is commonly used as a benchmark for evaluating the performance of
 CPUs, GPUs, and other computing devices.
 It is often used in the context of high-performance computing, scientific
 simulations, and machine learning applications, where large amounts of
 data must be processed quickly.
 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
One approach to measuring FLOPS that we used in this work is to calculate
 the execution time and multiply it by the number of operations in each
 equalizer.
 This allows us to visualize the time complexity and efficiency of the equalizer
s.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\boldsymbol{FLOPS\simeq\frac{1}{ExecTime}*Operations}
\end{equation}

\end_inset


\end_layout

\begin_layout Subsection
Objectives
\end_layout

\begin_layout Subsubsection
General Objective
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
We should analyze and test different techniques of neural networks applied
 to frequency channel equalization, which is commonly used in OFDM.
 The NN models will be based on existing equalizers with well-known equations.
\end_layout

\begin_layout Subsubsection
Particular Objective
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
Our objective is to equalize a double dispersive channel, also known as
 a frequency-time channel and intercarrier symbol interference (ISI) through
 the utilization of various neural network strategies.
 These strategies will focus on specific stages of the existing equalization
 process.
 We aim to leverage the non-linearity of neural networks and employ techniques
 such as dimensionality expansion and reduction.
 Our aim is to recover QAM and PSK constellation symbols that have been
 distorted by a channel with both line-of-sight (LOS) and non-line-of-sight
 (NLOS) conditions, plus Gaussian noise.
 Our ultimate goal is to achieve a bit error rate (BER) comparable to that
 of the "golden models" or to reduce the computational complexity of current
 methods.
 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newpage
\end_layout

\end_inset


\end_layout

\begin_layout Section
State of Art
\end_layout

\begin_layout Subsection
Introduction
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
To support our research and development, we conducted a thorough study of
 several key papers, which we organized into different categories based
 on their relevance to the project.
 In the following sections, I will provide a brief overview of how each
 of these articles contributed to the development of our project.
 Please note that many papers in the literature deal with smaller input
 and channel sizes than the 48x48 size used in our research.
 It is possible that these studies were mostly focused on proofs of concepts
 or making results fit better.
 Nevertheless, we opted for a larger channel size to create a more realistic
 scenario for our research.
 So BER/SNR metrics should be based on the golden models rather than on
 these articles.
\end_layout

\begin_layout Subsection
\paragraph_spacing onehalf
\noindent

\size large
The Roadmap to 6G – AI Empowered Wireless Networks 
\begin_inset CommandInset citation
LatexCommand cite
key "The_Roadmap_to_6G"
literal "false"

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The integration of AI technologies in the communication network provides
 a promising future for efficient and reliable communication in 6G and beyond.
 The "intelligent PHY layer" paradigm, through its ability to self-learn
 and self-optimize, ensures that the system remains efficient and reliable
 despite the various hardware and channel effects.
 This model leverages AI technologies to enhance communication efficiency
 and performance, and can autonomously learn and enhance performance through
 the integration of cutting-edge sensing and data-gathering tools.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Hardware heterogeneity necessitates system redesign for different hardware
 settings, which can be overcome using transfer learning.
 This approach adjusts the neural network weights to work with custom hardware
 architecture, regardless of the training on floating point or fixed point
 backpropagation.
 Therefore, network architecture is more crucial than numeric resolution
 in contrast to traditional methods.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Papers/RoadMap6G.png
	lyxscale 50
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Roadmap showing the evolution of deep learning models in telecom and justifying
 our research 
\begin_inset CommandInset citation
LatexCommand cite
key "The_Roadmap_to_6G"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
In conclusion, we present a roadmap in the image above depicting the expected
 evolution of deep learning in the coming years.
 This image justifies the necessity of our research.
 The picture shows the progression of models from simpler to more intelligent
 systems, with the intelligence level displayed in circles on the right
 side of the image.
\end_layout

\begin_layout Subsection
\paragraph_spacing onehalf
\noindent

\size large
A Novel OFDM Equalizer for Large Doppler Shift Channel through Deep Learning
 
\begin_inset CommandInset citation
LatexCommand cite
key "ZeroForcingEqNN"
literal "false"

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset CommandInset label
LatexCommand label
name "subsec:A-Novel-OFDM"

\end_inset

This documentation describes the proposed neural architecture called Cascaded
 Net (CN) for equalization in OFDM systems.
 The use of a zero-forcing preprocessor aims to prevent the network from
 getting stuck in a saddle point or local minimum point.
 The CN neural architecture is designed to address the equalization problem
 in OFDM systems with Rayleigh fading and large Doppler shifts.
 By cascading a deep trainable network behind a zero-forcing preprocessor,
 the CN architecture achieves superior performance in comparison to traditional
 equalization methods.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Papers/ZeroForcePreprocess.png
	lyxscale 50
	scale 40

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Deep learning equalizer with prepocesing stage.
 
\size large

\begin_inset CommandInset citation
LatexCommand cite
key "ZeroForcingEqNN"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
As they are performing frequency domain equalization, their base equation
 is the same as ours.
 
\begin_inset Formula $\boldsymbol{Y=Hx+W}$
\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The Cascade net is defined as follows.
 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\hat{\boldsymbol{X_{0}=(H^{H}H)^{-1}H^{H}Y}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{z_{i}=w_{i}\left[\begin{array}{c}
H^{H}Y\\
\hat{X_{i}}\\
H^{H}H\hat{x_{i}}
\end{array}\right]+b_{i}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{\hat{X_{i+1}}=\phi(z_{i})}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Where 
\begin_inset Formula $\boldsymbol{w}$
\end_inset

 and 
\begin_inset Formula $\boldsymbol{b}$
\end_inset

 representes weights and bias as trainnable parameters.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{\phi=tanh\left(\frac{x}{|t_{i}|}\right)}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Papers/CascaNet.png
	lyxscale 50
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Cascade Net 
\size large

\begin_inset CommandInset citation
LatexCommand cite
key "ZeroForcingEqNN"
literal "false"

\end_inset


\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "Preprocesing"

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Their loss function or estimator is based on the Euclidean distance, with
 a logarithmic regularization of outliers and the objective of minimizing
 the distance between points.
 They accumulate the total estimation for each layer i and finally sum it
 up.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\mathbf{loss(X_{\theta}^{CN}(H,Y))=\sum_{i=1}^{L}log(i)||X-\hat{X||^{2}}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
To deal with complex matrix number they make a reformulation in the matrix
 as follows.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center

\size large
\begin_inset Graphics
	filename Imagenes/Papers/ComplexMatrix.png
	lyxscale 50
	scale 70

\end_inset


\size default

\begin_inset Caption Standard

\begin_layout Plain Layout
Matrix reformulation 
\size large

\begin_inset CommandInset citation
LatexCommand cite
key "ZeroForcingEqNN"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
BER perfomance
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The image below shows a benchmark of different equalizers, including ZF
 (Zero Forcing), PIC (Parallel Interference Cancellation), DET (Deep MIMO
 Detection Network)
\begin_inset CommandInset citation
LatexCommand cite
key "DeepMimoOFDM"
literal "false"

\end_inset

], and CN (Cascaded Net).
 The modulation they used in the experiment below is QPSK.
 and they assume that CSI is perfect.
 The receiver is trained off-line for the single-user system with fixed
 Doppler shift.
 If Subcarrier number 
\begin_inset Formula $N$
\end_inset

 is 32, 
\begin_inset Formula $f_{N}$
\end_inset

 equals to 0.16.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Papers/CascadeResults.png

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
QPSK equalization with different strategies in the paper 
\begin_inset CommandInset citation
LatexCommand cite
key "ZeroForcingEqNN"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent

\size large
Classical PIC methods perform well in low subcarrier frequency scenarios
 (
\begin_inset Formula $f_{N}$
\end_inset

 less than 0.1).
 However, their performance degrades significantly with an increase in subcarrie
r frequency due to significant error propagation, as stated in the first
 section.
\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent

\size large
Deep MIMO detection (Det) faces a flat error curve in high SNR scenarios.
\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent

\size large
Cascaded Net (CN) consistently performs well compared to Zero Forcing (ZF)
 and Det, which is in line with the argument made in the third section.
\end_layout

\begin_layout Subsubsection
\paragraph_spacing onehalf
\noindent
Performance Improvement Strategies for our solutions
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
As a conclusion, we have opted to use 
\begin_inset Formula $\boldsymbol{H^{H}Y}$
\end_inset

 instead of pure 
\begin_inset Formula $\boldsymbol{Y}$
\end_inset

 as an input for certain neural networks in our research.
 We have also implemented zero forcing as an additional preprocessing stage.
 These strategies have proven to be effective as they bring constellation
 points closer to one another, reducing the network's burden to equalize
 the signal to the ideal state, particularly when dealing with long distances
 between ideal point and recieved point.
 
\end_layout

\begin_layout Subsection
\paragraph_spacing onehalf
\noindent

\size large
Recent Advances in Neural Network Techniques For Channel Equalization:A
 Comprehensive Survey 
\begin_inset CommandInset citation
LatexCommand cite
key "Recent_Advances_in_Neural_Network_Techniques_for_Channel_Equalization"
literal "false"

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
This paper provides an overview of various channel equalization methods,
 including the Multilayer Perceptron (MLP) equalizer, Functional Link Artificial
 Neural Network (FLANN) equalizer, Chebyshev Neural Network (NN) equalizer,
 and Radial Basis Function NN (RBFNN) equalizer.
 Additionally, it presents a literature review and application of Recursive
 Neural Network (RNN) and Fuzzy Neural Network equalizers.
\end_layout

\begin_layout Subsubsection
FLANN
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
The primary difference between FLANN hardware and MLP configuration is that
 the nonlinear mapping replaces only the input, output, and hidden layers.
 This mapping uses a non-linear function to transform the input vector,
 mapping it to a higher-dimensional space.
 The expansion function, called the functional link, is typically a polynomial
 function of the input variables.
 In our final experiments, we explored the concept of searching for equalization
 in a higher-dimensional space, but did not utilize the polynomial function
 approach.
\end_layout

\begin_layout Subsubsection
RBF
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Radial basis functions (RBFs) are a type of basis function used in function
 approximation and machine learning algorithms.
 RBFs are a class of functions that depend only on the distance from the
 center of the function, and their output decreases as the distance from
 the center increases.
 Gaussian RBF: This function takes the form of 
\begin_inset Formula $e^{(-r^{2}/2)}$
\end_inset

, where r is the Euclidean distance from the center of the function.
 This RBF is widely used in machine learning and function approximation
 algorithms due to its smoothness and symmetry.
\end_layout

\begin_layout Subsubsection
RNN
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
The article concludes by stating that Recurrent Neural Networks (RNNs) generally
 outperform feed-forward neural networks (FNNs) and other methods.
 RNNs approximate a finite impulse response (IIR) filter, whereas other
 methods approximate a finite impulse response (FIR) filter.
 It is worth noting that IIR filters are known to be unstable, but recent
 advances in neural networks, such as LSTM, GRU, and Transformers, have
 been developed to overcome this limitation 
\end_layout

\begin_layout Subsubsection
Conclusion
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
The article discusses various approaches using different network architectures.
 However, it lacks any BER/SNR plots and focuses solely on QPSK study.
 According to this research, Recurrent Neural Networks (RNNs) 
\begin_inset CommandInset citation
LatexCommand cite
key "RNN_LSTM"
literal "false"

\end_inset

 appear to be the most effective solution, rendering other proposed strategies
 unnecessary.
 Due to the significant advancements in Recurrent Neural Networks (RNNs)
 over the years, powerful tools such as Sequence to Sequence (Seq2Seq)
\begin_inset CommandInset citation
LatexCommand cite
key "seq_to_seq"
literal "false"

\end_inset

, Attention
\begin_inset CommandInset citation
LatexCommand cite
key "Attention"
literal "false"

\end_inset

, and the Transformer
\begin_inset CommandInset citation
LatexCommand cite
key "transformer"
literal "false"

\end_inset

 models have emerged.
 More recently, the Vision Transformer (ViT) 
\begin_inset CommandInset citation
LatexCommand cite
key "dosovitskiy2020image"
literal "false"

\end_inset

 has also been introduced.
 Given these developments, it is important to prioritize working with ViT,
 which represents a new and promising direction for image analysis.
 Additionally, there is currently no similar technique in the existing literatur
e that deals with channel equalization, making the ViT an even more valuable
 tool for OFDM equalization, treating constelations points as sections of
 an image.
 In the infographic below, we have designed a timeline to make the evolution
 of sequence analysis models clearer.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Networks/TimeLineEvolution.jpg
	lyxscale 20
	scale 28

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsection
\paragraph_spacing onehalf
\noindent

\size large
An Introduction to Deep Learning for the Physical Layer 
\begin_inset CommandInset citation
LatexCommand cite
key "Intro_DL_Physical_Layer"
literal "false"

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
This paper provides a detailed overview of neural networks and their application
 to channel equations, with formal mathematical description included.
 The paper describes the formal structure of feed-forward neural networks,
 as well as some applications of convolutional neural networks, that was
 described in the first section.
 It also introduces autoencoders for end-to-end communication systems and
 proposes the idea that an autoencoder can be used to characterize a complete
 channel.
 What's remarkable about this approach is that it can be extended to channel
 models and loss functions for which the optimal solutions are unknown,
 making it highly versatile.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Papers/ChannelAutoencoder.png

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Autoencoder as Channel 
\size large

\begin_inset CommandInset citation
LatexCommand cite
key "Intro_DL_Physical_Layer"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
In addition, the authors use adversarial networks to manage multiple transmitter
-receiver pairs with competing capacity.
 Although the Multiple-Input Multiple-Output (MIMO) scenario is not currently
 implemented, it could be a promising area for future work.
 Finally, the authors also discuss modulation classification, which involves
 using Convolutional Neural Networks (CNNs) to automatically detect the
 modulation scheme used in a communication process.
\end_layout

\begin_layout Subsubsection
\paragraph_spacing onehalf
\noindent
Autoencoder
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The goal of the transmitter is to send one of M possible messages,
\begin_inset Formula $\boldsymbol{s∈M=\left\{ 1,2,...,M\right\} }$
\end_inset

, to the receiver using n discrete uses of the communication channel.
 To achieve this, the transmitter applies a transformation, 
\begin_inset Formula $\boldsymbol{f:M→Rn}$
\end_inset

, to the message 
\begin_inset Formula $s$
\end_inset

, generating a transmitted signal 
\begin_inset Formula $\boldsymbol{x=f(s)∈\mathbb{R}^{n}}$
\end_inset

.
 Typically, the transmitter hardware imposes constraints on 
\begin_inset Formula $x$
\end_inset

, such as an energy constraint 
\begin_inset Formula $\boldsymbol{(||x||_{2}^{2}≤n)}$
\end_inset

, an amplitude constraint (
\begin_inset Formula $\boldsymbol{|xi|≤1}$
\end_inset

 
\begin_inset Formula $\boldsymbol{\forall i}$
\end_inset

), or an average power constraint (
\begin_inset Formula $\boldsymbol{E|xi|≤1}$
\end_inset


\begin_inset Formula $\boldsymbol{\forall i}$
\end_inset

).
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The communication rate of this system is 
\begin_inset Formula $\boldsymbol{R=\frac{k}{n}}$
\end_inset

 [bit/channel use], where 
\begin_inset Formula $\boldsymbol{k=log_{2}(M).}$
\end_inset

In the notation (n,k), the system is able to send one of 
\begin_inset Formula $\boldsymbol{M=2^{k}}$
\end_inset

 messages (i.e., k bits) through n channel uses.
 The communication channel is characterized by the conditional probability
 density function 
\begin_inset Formula $\boldsymbol{p(y|x}$
\end_inset

), where 
\begin_inset Formula $\boldsymbol{y∈Rn}$
\end_inset

 represents the received signal.
 After receiving 
\begin_inset Formula $\boldsymbol{y}$
\end_inset

, the receiver applies a transformation 
\begin_inset Formula $\boldsymbol{g:\mathbb{R}^{n}→M}$
\end_inset

 to generate the estimate 
\begin_inset Formula $\boldsymbol{ŝ}$
\end_inset

 of the transmitted message 
\begin_inset Formula $\boldsymbol{s}$
\end_inset

.
 As finall loss function it is used cross entropy loss, which is mention
 in chapter one.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Papers/BasedlineAE_results.png
	lyxscale 50
	scale 80

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
BLER for the AE in differen (n,k) baseline communication.
\size large

\begin_inset CommandInset citation
LatexCommand cite
key "Intro_DL_Physical_Layer"
literal "false"

\end_inset


\size default
 
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Conclusion
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
In this paper, was explored the idea that an autoencoder can learn channel
 representation using all the information available in the system.
 However, this research has not yet attempted more complex constellations,
 such as QAM16.
 In our research, we will build on this idea by using an autoencoder for
 encoding only, and employing a forced decoding approach with a zero-forcing
 algorithm.
\end_layout

\begin_layout Subsection
\paragraph_spacing onehalf
\noindent

\size large
A Survey of Complex-Valued Neural Networks 
\begin_inset CommandInset citation
LatexCommand cite
key "A_Survey_of_Complex_valued_nueronal_Netoworks"
literal "false"

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
\begin_inset CommandInset label
LatexCommand label
name "subsec:A-Survey-of"

\end_inset

It is widely recognized that IQ data is represented by complex numbers,
 which can pose challenges when working with them.
 This paper offers a detailed description of a new loss function and the
 necessary adjustments required to perform backpropagation in complex networks.
 Additionally, the paper demonstrates how to preprocess data, activation
 functions, and cost functions, which can be valuable for conducting experiments
 with complex data or complex neural networks.
\end_layout

\begin_layout Subsubsection
Normalize unitary circle
\end_layout

\begin_layout Standard

\size large
If we look at data in the complex plane we should first at deal with normalizati
on, and normalization is given by diviing the data by his absolute max,
 which lead all poins inside a unitary circle.
 
\begin_inset CommandInset label
LatexCommand label
name "subsec:Normalize-unitary-circle"

\end_inset


\end_layout

\begin_layout Standard

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{f(z)=\frac{z}{max(|z|)}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard

\size large
The image below demonstrates how a complex network can handle polar segmentation
, and how weights and biases can be used to define a vector in the complex
 plane
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Papers/ComplexCircle.png

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
A Geometric Interpretation of Segmentation and Function Evaluation in the
 Complex Plane.
 
\begin_inset CommandInset citation
LatexCommand cite
key "A_Survey_of_Complex_valued_nueronal_Netoworks"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Activation functions
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The hyperbolic tangent is an example of a fully complex activation function
 and has been utilized in 
\begin_inset CommandInset citation
LatexCommand cite
key "tanh_complex"
literal "false"

\end_inset

.
 It is apparent that singularities in the output may arise due to values
 on the imaginary axis.
 To prevent an explosion of values, it is necessary to appropriately scale
 the inputs, which mention in the normalization in the section above.
 According to some researchers, imposing the strict constraint of requiring
 the activation function to be holomorphic may not be necessary.
 A holomorphic function is a complex-valued function of a complex variable
 that is complex differentiable at every point within its domain.
 In other words, a function 
\begin_inset Formula $\boldsymbol{f(z)}$
\end_inset

 is holomorphic at a point 
\begin_inset Formula $\boldsymbol{z}$
\end_inset

 if the limit of the difference quotient of 
\begin_inset Formula $\boldsymbol{f(z)}$
\end_inset

 as 
\begin_inset Formula $\boldsymbol{z}$
\end_inset

 approaches that point exists and is independent of the path of approach.
 Therefore, for a basic implementation, we should split the evaluation into
 real and imaginary parts as separate sections to activate the values.
 It's important to note that the real and imaginary parts should not be
 mixed.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Papers/tanhcomplex.png

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Complex function separate for each real and imaginary part.
 
\begin_inset CommandInset citation
LatexCommand cite
key "Survey_Complex_valued_NN"
literal "false"

\end_inset

 
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Loss functions
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
One approach to dealing with the error is to take the complex magnitude
 of the differences between the estimator and the ground truth.
 Given 
\begin_inset Formula $\boldsymbol{d\in\mathbb{C}^{N}}$
\end_inset

(ground truth) and 
\begin_inset Formula $\boldsymbol{o\in\mathbb{C}^{N}}$
\end_inset

(estimated output), the error 
\begin_inset Formula $\boldsymbol{e=d-o}$
\end_inset

 we can calculate the complex mean square loss in a non-negative scalar.
 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{L(e)=\sum_{k=0}^{N-1}|e_{k}|^{2}=\sum_{k=0}^{N-1}e_{k}\overline{e_{k}}}\label{eq:46}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
If we take a polar approach where 
\begin_inset Formula $d=re^{i\phi}$
\end_inset

 and 
\begin_inset Formula $o=\hat{r}e^{i\hat{\phi}}$
\end_inset

, we can convert the error into a log function to bring points closer and
 cancel the exponentials.
 Rewritten in this way, the equation becomes:
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{(e_{log}):=\sum_{k=0}^{N-1}e_{k}\overline{e_{k}}=\sum_{k=0}^{N-1}(log(o_{k})-log(d_{k}))*\overline{((log(o_{k})-log(d_{k})))}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\align center

\size large
\begin_inset Formula $\boldsymbol{log\left(\frac{o_{k}}{d_{k}}\right)*\overline{log\left(\frac{o_{k}}{d_{k}}\right)}=log\left(\frac{\hat{r}e^{i\hat{\phi}}}{re^{i\phi}}\right)*log\left(\frac{\hat{r}e^{-i\hat{\phi}}}{re^{-i\phi}}\right)=log\left(\frac{\hat{r}}{r}e^{i(\hat{\phi}-\phi)}\right)*log\left(\frac{\hat{r}}{r}e^{-i(\hat{\phi}+\phi)}\right)}$
\end_inset


\end_layout

\begin_layout Standard
\align center

\size large
\begin_inset Formula $\boldsymbol{\left[log(\frac{\hat{r}}{r})+log\left(e^{i(\hat{\phi}-\phi)}\right)\right]*\left[log(\frac{\hat{r}}{r})+log\left(e^{-i(\hat{\phi}-\phi)}\right)\right]=}$
\end_inset


\end_layout

\begin_layout Standard
\align center

\size large
\begin_inset Formula $\boldsymbol{\left[log(\frac{\hat{r}}{r})+i(\hat{\phi}-\phi)\right]*\left[log(\frac{\hat{r}}{r})-i(\hat{\phi}-\phi)\right]}=$
\end_inset


\end_layout

\begin_layout Standard
\align center

\size large
Multiply out the terms 
\end_layout

\begin_layout Standard
\align center

\size large
\begin_inset Formula $\boldsymbol{log^{2}(\frac{\hat{r}}{r})+i(\hat{\phi}-\phi)log(\frac{\hat{r}}{r})-i(\hat{\phi}-\phi)log(\frac{\hat{r}}{r})-i^{2}(\hat{\phi}-\phi)^{2}}$
\end_inset


\end_layout

\begin_layout Standard
\align center

\size large
Simplify
\end_layout

\begin_layout Standard
\align center

\size large
\begin_inset Formula $\boldsymbol{log^{2}(\frac{\hat{r}}{r})+(\hat{\phi}-\phi)^{2}}$
\end_inset


\end_layout

\begin_layout Standard
\align center

\size large
We multiply the angle and radius by 0.5 in the loss function to give them
 equal importance since both are equally significant for the loss.
 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{Loss(e_{log})=\frac{1}{2}\left(log\left[\frac{\hat{r}}{r}\right]^{2}+\left[\hat{\phi}-\phi\right]^{2}\right)}\label{eq:48}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
We now have an explicit representation of magnitude and phase in the loss
 function, which could be helpful in the polar equalization approach.
\end_layout

\begin_layout Subsubsection
Conclusion
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
This theory was helpful in implementing a neural network with complex values
 directly, without splitting real part or phase and magnitude.
 However, in our experiments, it did not yield good results, but we took
 it into account and recorded the experiment.
\end_layout

\begin_layout Subsection
\paragraph_spacing onehalf
\noindent

\size large
MobileNet 
\begin_inset CommandInset citation
LatexCommand cite
key "MobileNet"
literal "false"

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
MobileNet achieves its high efficiency by using depthwise separable convolutions
, which are a combination of a depthwise convolution and a pointwise convolution
, while still maintaining high accuracy.
 In terms of time complexity, MobileNet has a lower multiplications compared
 to regular CNNs.
 This results in faster inference times and lower memory requirements,as
 its name says usefull for mobile applications, also include embbeded system
 applications for edge computing.
 However, it's worth noting that the trade-off for MobileNet's efficiency
 has a little less accuracy compared to regular CNNs.
\end_layout

\begin_layout Subsubsection
Depthwise Separable Convolution
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Convolution is a mathematical concept that measures the overlap between
 two functions as one of them slides over the other.
 Mathematically, it can be expressed as a sum of products.
 However, standard convolution operations can be slow to perform due to
 the number of multiplications required.
 An alternative method called depth-wise separable convolution can be used
 to speed up the process.
 This method breaks down the convolution process into two parts: depthwise
 convolution and pointwise convolution.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Let us briefly review the fundamental concepts of convolution on an input
 volume.
 Let's take an input volume F with dimensions DF x DF x M, where DF represents
 the width and height of the input volume and M is the number of input channels.
 In the case of a color image, M would be equal to 3 for the R, G, and B
 channels.
 We perform convolution on a kernel K, which has dimensions DK x DK x M.
 The output will be in the shape of DG x DG x 1.
 When we apply N kernels to the input, we obtain an output volume G with
 dimensions DG x DG x N.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Papers/TraditionalConv.png
	lyxscale 50
	scale 70

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Traditional convolution
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
In a traditional convolution, filters are applied across all input channels
 and their values are combined in a single step.
 However, in depthwise separable convolution, this process is split into
 two stages.
 The first stage is depthwise convolution, which applies convolution to
 a single input channel at a time.
 To perform depthwise convolution, we use filters or kernels K, which are
 of shape DK x DK x 1.
 Here, DK is the width and height of the square kernel, and it has a depth
 of 1 because this convolution is only applied to a single channel.
 Therefore, we require M such DK x DK x 1 kernels over the entire input
 volume F, where F has a shape DF x DF x M.
 For each of these M convolutions, we get an output of DG x DG x 1 in shape.
 By stacking these outputs together, we obtain an output volume G of shape
 DG x DG x M, which marks the end of the first phase, that is, the end of
 depthwise convolution.
 The number of multiplications in the depthwise convolution phase is obtained
 by applying these multiplications to all M input channels separately, with
 each channel having its own kernel.
 Therefore, the total number of multiplications in this phase is :
\end_layout

\begin_layout Standard

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{\boldsymbol{DW=M\times D_{G}{}^{2}\times D_{k}{}^{2}}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Papers/DepthwiseConv.png
	lyxscale 70
	scale 70

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Depthwise convolution
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Pointwise convolution refers to a 1x1 convolution operation applied to each
 of the output channels generated by the depthwise convolution.
 In this step, the input is a volume of shape DG x DG x M, where M is the
 number of output channels generated by the depthwise convolution.
 The filter used for this operation, denoted as KPC, has a shape of 1 x
 1 x M, which means that it is applied across all M output channels.
 The resulting output has the same width and height as the input DG x DG,
 and the number of output channels can be controlled by using N filters.
 Therefore, the final output volume of the depthwise separable convolution
 has a shape of DG x DG x N.
 And hence, the number of multiplications for one instance of convolution
 is M.
 This is applied to the entire output of the first phase, which has a width
 and height of DG.
 So the total number of multiplications for this kernel is DG x DG x M.
 So for some N kernels, we'll have this multiplications :
\end_layout

\begin_layout Standard

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{PW=N\times DG\times DG\times M}
\end{equation}

\end_inset


\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center

\size large
\begin_inset Graphics
	filename Imagenes/Papers/Pointwise.png
	lyxscale 70
	scale 70

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout

\size large
Pointwise convolution
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Hence, the total multiplication count is the sum of multiplication counts
 in the depthwise and pointwise convolution stages.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{\mathbf{Total=DW+PW=M\times D_{G}{}^{2}\times D_{k}{}^{2}+N\times DG\times DG\times M}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{\boldsymbol{Total=M\times D_{G}^{2}(D_{K}^{2}+N)}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
We can compare the computational efficiency of standard convolution with
 depthwise convolution by computing their ratio.
 This ratio is obtained by summing the reciprocal of the depth of the output
 volume, denoted as N, and the reciprocal of the squared dimensions of the
 kernel, denoted as DK.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{\boldsymbol{\frac{DepthWise}{Standard}=\frac{M\times D_{G}^{2}(D_{K}^{2}+N)}{N\times D_{G}^{2}\times D_{k}^{2}\times M}=\frac{1}{N}+\frac{1}{D_{k}^{2}}}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
To better understand this, let's take an example.
 Suppose the output feature volume N is 1024, and the kernel size is 3,
 which means DK is 3.
 Plugging these values into the equation, we obtain a ratio of 0.112.
 This indicates that standard convolution requires 9 times more multiplications
 than depthwise separable convolution.
 This significant difference in computational power can have a considerable
 impact on the performance and efficiency of convolutional neural networks.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{table}[htbp] 
\backslash
centering 
\backslash
caption{Depthwise Separable vs Full Convolution MobileNet} 
\backslash
label{tab:my-table} 
\backslash
begin{tabular}{|l|c|c|c|} 
\backslash
hline Model & ImageNet Accuracy & Mult-Adds (Million) & Parameters (Million)
 
\backslash

\backslash
 
\backslash
hline Conv MobileNet & 71.7
\backslash
% & 4866 & 29.3 
\backslash

\backslash
 
\backslash
hline MobileNet & 70.6
\backslash
% & 569 & 4.2 
\backslash

\backslash
 
\backslash
hline 
\backslash
end{tabular} 
\backslash
end{table} 
\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
MobileNetV3 
\begin_inset CommandInset citation
LatexCommand cite
key "MobilenetV3"
literal "false"

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "subsec:MobileNetV3"

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
The MobileNetV3 architecture uses a combination of depthwise separable convoluti
ons, linear bottlenecks, and other optimizations to reduce the number of
 parameters and computational complexity while maintaining high accuracy.
 It also includes new design elements, such as dynamic activation functions
 and network architecture search techniques, to improve performance on a
 variety of tasks.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{table}[h] 
\backslash
centering 
\backslash
caption{MobileNet architectures} 
\backslash
label{tab:mobilenet} 
\backslash
begin{tabular}{|c|c|c|c|} 
\backslash
hline 
\backslash
textbf{Model} & 
\backslash
textbf{Input Resolution} & 
\backslash
textbf{FLOPS} & 
\backslash
textbf{Parameters} 
\backslash

\backslash
 
\backslash
hline MobileNet v1 & 224x224 & 569 M & 4.2 million 
\backslash

\backslash
 
\backslash
hline MobileNet v2 & 224x224 & 300 M & 3.4 million 
\backslash

\backslash
 
\backslash
hline MobileNet v3 & 224x224 & 219 M & 5.4 million 
\backslash

\backslash
 
\backslash
hline 
\backslash
end{tabular} 
\backslash
end{table}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
FLOPS stands for "Floating Point Operations Per Second".
 It is a measure of a computer's performance based on the number of floating
 point operations (such as additions, subtractions, multiplications, and
 divisions) it can perform in a second.
 It is commonly used to measure the performance of computer processors or
 the computational requirements of machine learning models.
\end_layout

\begin_layout Subsubsection
Reduced complexity for activation functions
\end_layout

\begin_layout Standard

\size large
One of the key components of his low computational cost is the implementation
 of hardsigmoid and hardswish function, which is quite similar that we done
 with hardtanh but with other activation function type.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
hswish[x]=x\frac{RELU6(x+3)}{6}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Papers/hardsigmoid.png

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Hard functions 
\begin_inset CommandInset citation
LatexCommand cite
key "MobilenetV3"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
These functions are integrated into the final stage of MobileNet to serve
 as more efficient functions.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Papers/LastMobileNetv3.png

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Last section optimized 
\begin_inset CommandInset citation
LatexCommand cite
key "MobilenetV3"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Conclusion
\end_layout

\begin_layout Standard
\noindent

\size large
For our project, we have opted to use MobileNetv3 to compress the communication
 channel and encode it into a lower-dimensional representation.
 Since MobileNet is highly efficient, it is one of our top choices for research,
 especially given the constraints in telecom where data processing speed
 could be a critical factor.
\end_layout

\begin_layout Subsection
\paragraph_spacing onehalf
\noindent

\size large
Attention Is All You Need 
\begin_inset CommandInset citation
LatexCommand cite
key "transformer"
literal "false"

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
"Attention is All You Need" is a research paper published by Google in 2017
 that introduced the Transformer model, a neural network architecture for
 sequence-to-sequence modeling.
 The Transformer model is designed to handle variable-length sequences of
 input data and generate variable-length output sequences, making it particularl
y useful for tasks such as machine translation and natural language processing.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The Transformer model differs from previous neural network architectures
 by relying solely on attention mechanisms for input and output processing,
 eliminating the need for recurrent
\begin_inset CommandInset citation
LatexCommand cite
key "RNN_LSTM"
literal "false"

\end_inset

 and convolutional layers
\begin_inset CommandInset citation
LatexCommand cite
key "Conv1"
literal "false"

\end_inset

.
 The attention mechanism
\begin_inset CommandInset citation
LatexCommand cite
key "Attention"
literal "false"

\end_inset

 allows the model to focus on different parts of the input sequence when
 generating the output sequence, making it more accurate and efficient than
 previous models.
\end_layout

\begin_layout Subsubsection
Embedding
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The embedding refers to the process of representing 
\series bold
discrete input
\series default
 tokens as 
\series bold
continuous vectors
\series default
 that can be processed by the model.
 This is achieved using an embedding layer, which maps each input token
 to a high-dimensional 
\begin_inset Formula $\mathbb{R}^{N}$
\end_inset

 vector in a learned embedding space.
 Words cannot be represented as numbers directly.
 Normally, numerical data is transformed into a discrete representation,
 but in order to process it through a transformer network, these discrete
 representations need to be mapped to a continuous vector space using an
 embedding layer.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The input size of an embedding layer is typically the size of the vocabulary
 
\begin_inset Formula $|A|$
\end_inset

, i.e., the number of unique tokens that the model can expect to encounter
 in the input.
 For example, if the vocabulary size is 10,000, then the input size of the
 embedding layer would be 10,000.
 The output size of the embedding layer is determined by the desired dimensional
ity of the embedding space 
\begin_inset Formula $\mathbb{R}^{M}$
\end_inset

, which is a hyperparameter that can be tuned by the model developer.
 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Normally, each word is assigned a unique index, and this index corresponds
 to a row in the embedding matrix.
 To obtain the embedding vector for a word, we retrieve the corresponding
 row from the matrix and multiply it by each element in row to get the new
 vector 
\begin_inset Formula $V$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Networks/EmbbededLayer.jpg
	lyxscale 30
	scale 40

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Embbeded Matrix
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The embedding layer allows the model to capture the semantic relationships
 between different input tokens, and enables it to perform tasks such as
 language modeling and machine translation.
 Is typically followed by positional encoding, which adds information about
 the position of each input token in the sequence.
 Together, the embedding and positional encoding components provide a way
 for the model to process variable-length input sequences of discrete tokens
 in an efficient and effective manner.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Let X be an input sequence of length T, where each element 
\begin_inset Formula $x_{i}$
\end_inset

 is an integer representing the 
\begin_inset Formula $i$
\end_inset

-th token in the vocabulary.
 Let 
\begin_inset Formula $E$
\end_inset

 be a learned embedding matrix of size
\begin_inset Formula $V\times d$
\end_inset

, where 
\begin_inset Formula $V$
\end_inset

 is the size of the vocabulary and 
\begin_inset Formula $d$
\end_inset

 is the dimension of the embedding space.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The embedding layer can be defined as follows:
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\text{E}(X)=[\text{e}_{1},\text{e}_{2},\dots,\text{e}_{T}]
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Positional encoding can be added to the embeddings as follows:
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\text{E'}(X)=[\text{e'}_{1},\text{e'}_{2},\dots,\text{e'}_{T}]
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
where 
\begin_inset Formula $\text{e'}_{i}=\text{e}_{i}+\text{PE}_{i}$
\end_inset

, and 
\begin_inset Formula $\text{PE}_{i}$
\end_inset

 is the 
\begin_inset Formula $i$
\end_inset

-th row of a learned positional encoding matrix of size 
\begin_inset Formula $T\times d$
\end_inset

.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The resulting embeddings 
\begin_inset Formula $\text{E'}(X)$
\end_inset

 are continuous vectors in a high-dimensional embedding space that can be
 processed by the transformer model.
\end_layout

\begin_layout Subsubsection
Multihead attention
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
One of the key components of the Transformer model is multi-head attention.
 Multi-head attention allows the model to attend to different parts of the
 input sequence simultaneously, by splitting the input data into multiple
 representations and computing attention on each of them.
 This allows the model to capture complex relationships between different
 parts of the input sequence, and enables it to handle long sequences more
 efficiently.
 In multi-head attention mechanism of a transformer model, the input sequence
 is split into multiple vectors (heads), and each of these vectors is processed
 independently.
 The attention mechanism then operates on these vectors to compute weighted
 combinations that represent different aspects of the input sequence.The
 multi-head attention mechanism consists of three linear transformations:
 Query, Key, and Value.
 These transformations are learned parameters that are used to compute the
 attention scores and weights for each head.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Papers/Attention.png
	scale 120

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Attention respect to input vectors 
\begin_inset CommandInset citation
LatexCommand cite
key "singh2020multihead"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
Query: This transformation takes the current decoder state as input and
 maps it to a query vector.
 The query vector is used to compute the similarity between the decoder
 state and each of the key vectors.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
Key: This transformation takes the encoder output as input and maps it to
 a key vector.
 The key vector is used to compute the similarity between the decoder state
 and each of the query vectors.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
Value: This transformation takes the encoder output as input and maps it
 to a value vector.
 The value vector is used to compute the weighted sum of the encoder output,
 based on the attention weights calculated from the query and key vectors.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Papers/Multihead.png
	scale 80

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Caption Standard

\begin_layout Plain Layout
Multihead attention 
\begin_inset CommandInset citation
LatexCommand cite
key "transformer"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Let 
\begin_inset Formula $Q$
\end_inset

, 
\begin_inset Formula $K$
\end_inset

, and 
\begin_inset Formula $V$
\end_inset

 be the query, key, and value matrices, respectively, for one head of the
 multi-head attention mechanism.
 Let 
\begin_inset Formula $d_{k}$
\end_inset

 be the dimension of the key vectors, and let 
\begin_inset Formula $d_{v}$
\end_inset

 be the dimension of the value vectors.
 Let 
\begin_inset Formula $h$
\end_inset

 be the number of heads.
 Then, the multi-head attention mechanism can be defined as follows:
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align center

\size large
\begin_inset Formula 
\begin{equation}
MultiHead(Q,K,V)=Concat(head_{1},\ldots,headh_{h})W^{O}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align center

\size large
where
\end_layout

\begin_layout Standard
\align center

\size large
\begin_inset Formula $\text{head}_{i}=\text{Attention}(QW_{i}^{Q},KW_{i}^{K},VW_{i}^{V})$
\end_inset

 and
\end_layout

\begin_layout Standard
\align center

\size large
\begin_inset Formula $\ensuremath{W_{i}^{Q}\in\mathbb{R}^{d{model}\times d_{k}}}$
\end_inset

,
\begin_inset Formula $\ensuremath{W_{i}^{K}\in\mathbb{R}^{d_{model}\times d_{k}}}$
\end_inset

,
\begin_inset Formula $\ensuremath{W_{i}^{V}\in\mathbb{R}^{d_{model}\times d_{v}}}$
\end_inset

and 
\begin_inset Formula $\ensuremath{W^{O}\in\mathbb{R}^{hd_{v}\times d_{model}}}$
\end_inset

 are learned weight matrices.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align center

\size large
The Attention function can be defined as follows:
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align center
\begin_inset Formula 
\begin{equation}
Attention(Q,K,V)=softmax(\frac{QK^{T}}{\sqrt{d_{k}}}+Mask)V
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Papers/Dot product.png
	lyxscale 40
	scale 40

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Self attention dot product 
\begin_inset CommandInset citation
LatexCommand cite
key "singh2020multihead"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Mask
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
In multi-head attention mechanism of a transformer model, a mask is a binary
 matrix that is used to selectively prevent certain elements of the input
 sequence from being attended to by the model.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Papers/Mask.png
	scale 60

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Mask example
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard

\size large
There are two types of masks commonly used in the transformer model: padding
 masks and sequence masks.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\size large
Padding masks: These masks are used to ignore padding tokens in the input
 sequence, which are added to ensure that all input sequences are of the
 same length.
 Padding tokens have no semantic meaning and should not be attended to by
 the model.
 A padding mask is a binary matrix that has a value of 0 for padding tokens
 and 1 for all other tokens.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\size large
Sequence masks: These masks are used to ensure that each position in the
 output sequence can only attend to positions that have already been processed.
 This is important for tasks such as language modeling, where the model
 is trained to predict the next word in a sequence based on the previous
 words.
 A sequence mask is a binary matrix that has a value of 0 for all future
 positions in the sequence and 1 for all other positions.
 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Masks are applied to the attention mechanism by adding them to the attention
 weights before computing the weighted sum of the input sequence.
 The mask ensures that certain elements of the input sequence are not attended
 to by the model, which can improve the accuracy and efficiency of the model.
\end_layout

\begin_layout Subsubsection
Encoder Decoder
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Once we have all building blocks we can say that transformer model consists
 of an encoder and a decoder.
 The encoder processes the input sequence, using multi-head attention and
 position encoding to create a fixed-length representation of the input.
 The decoder then generates the output sequence, using multi-head attention
 and position encoding to attend to the input representation and generate
 each output token.
 The model is trained using maximum likelihood estimation, where the goal
 is to minimize the cross-entropy loss between the predicted output sequence
 and the ground truth.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Papers/TransformerEncodeDecode.png
	lyxscale 50
	scale 70

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Transformer with encoder and decoder sections 
\begin_inset CommandInset label
LatexCommand label
name "fig:Transformer-with-encoder"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
In the transformer diagram, "Nx" is typically used to represent the number
 of encoder-decoder layers in the model.
 For example, a transformer model with 6 encoder layers and 6 decoder layers
 might be represented as "Nx=6" in the diagram.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The output of the Transformer model is a sequence of tokens, which can be
 interpreted as a sequence of words, or other discrete units depending on
 the task at hand.
 These tokens can be further processed by other components of a larger system,
 such as a language model or a downstream task-specific model.
\end_layout

\begin_layout Subsubsection
Autoregresion
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
In an autoregressive mode in the context of an autoencoder, the decoder
 network is designed to generate the output sequence one element at a time,
 based on the previously generated elements.
 In other words, the decoder network takes the previous elements of the
 output sequence as input and generates the next element of the sequence.
 This is in contrast to a non-autoregressive mode, where the decoder network
 generates the entire output sequence at once, without considering the previousl
y generated elements.
\end_layout

\begin_layout Subsubsection
Conclusion
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
Given that our data is sequential in nature and can be interpreted symbol
 by symbol, the Transformer architecture can be applied in the equalization
 stage.
 The resulting encoding-decoding process could be an effective method for
 canceling Inter-Symbol Interference (ISI) using attention mechanisms.
 However, the challenge is that the data is in continuous space and we may
 lose positional encoding if we directly treat continuous data.
 Additionally, the Transformer architecture outputs symbols and not continuous
 values, so we need a mechanism to discretize our received data 
\begin_inset Formula $Y$
\end_inset

 and apply a token for each position to interpret the equalization as a
 machine translation.
 Therefore, our next step is to find a paper that can address this problem,
 as it could be the final key piece of evidence to support our proposal.
\end_layout

\begin_layout Subsection
\paragraph_spacing onehalf
\noindent

\size large
An image is worth 16x16 words 
\begin_inset CommandInset citation
LatexCommand cite
key "dosovitskiy2020image"
literal "false"

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "subsec:An-image-is"

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
The Vision Transformer is a deep learning architecture that is specifically
 designed for image classification tasks.
 Unlike traditional Convolutional Neural Networks (CNNs) that use convolutional
 layers to extract features from images, the ViT uses self-attention mechanisms
 to capture relationships between different parts of the image.
 Its architecture takes as input a sequence of patches, where each patch
 represents a small square region of the image.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Papers/pasted1.png
	lyxscale 80
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Basic example of image splitting in a grid for automatic fungi recognition.
 
\begin_inset CommandInset citation
LatexCommand cite
key "visionTransformer"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
These patches are then flattened and passed through a linear projection
 layer to obtain a sequence of embeddings, which are then fed into a series
 of transformer encoder layers.
 The transformer encoder layers use self-attention mechanisms to model the
 relationships between the different patches in the input sequence.
 This allows the ViT to capture long-range dependencies between different
 parts of the image, which is particularly useful for image classification
 tasks where the spatial relationship between different parts of the image
 is important.
 It takes as input an image and outputs a class label or a set of class
 probabilities, based on the features extracted from the image.
\end_layout

\begin_layout Subsubsection
\paragraph_spacing onehalf
\noindent
The Grid
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The "16x16 words" phrase refers to the fact that the input image is divided
 into a grid of 16x16 patches, each of which is treated as a "word" in the
 input sequence.
 This means that the ViT processes the image as a sequence of 256 patches,
 each represented by an embedding, instead of as a single 2D array of pixel
 values.
 However, there is a trade-off between grid size and computational complexity,
 as larger grids require more memory and processing power to train.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Papers/VITexample-transformed.png
	lyxscale 30
	scale 15

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Vision transforrmer example of 14X14 
\begin_inset CommandInset citation
LatexCommand cite
key "CollabVIT"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Conclusion
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
In conclusion, this paper has been instrumental in the development of our
 Gridnet architecture.
 Our approach involves using the complex plane as a 2D space, much like
 an image, where IQ data points fall into specific grids.
 We then assign each grid a patch-encoded value based on its position.
 Instead of using a traditional encoder, we utilized a transformer decoder
 to equalize the data with the ground truth.
 Our goal is to leverage the grid-based structure of the complex plane to
 effectively eliminate Inter-Symbol Interference (ISI) through the use of
 multihead attention mechanisms.
 This paper has provided us with important insights and tools that will
 help us to continue improving our approach for a range of signal processing
 applications.
\end_layout

\begin_layout Section
Methodology
\end_layout

\begin_layout Subsection
Dataset
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
This project has a dataset of 20,000 channel realizations, each with a size
 of 48x48.
 The dataset is divided into two groups of 10,000: the first group consists
 of Line-of-Sight (LOS) channel realizations, and the second group consists
 of Non-Line-of-Sight (NLOS) channel realizations.
 Each value in the matrix is a complex number with a format of complex128,
 float64 for the real and imaginary parts.
 The data is stored in the .mat format, which is commonly used for storing
 variables on disk from Matlab code.
 However, the dataset is used in Python using the Scipy library.
 To ensure robust predictions, the LOS and NLOS channels have been shuffled,
 with one group following the other.
 As neural networks typically do not work well with complex numbers, the
 real and imaginary parts of the channels have been separated into two channels
 in an image.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Channels/NLOS_Channel_log_view.png
	lyxscale 70
	scale 50

\end_inset


\begin_inset Graphics
	filename Imagenes/Channels/LOS_Channel_log_view.png
	lyxscale 70
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
A comparison of LOS and NLOS channel magnitud in a log scale representation.
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Software 
\size large
Architecture
\end_layout

\begin_layout Subsubsection
Data set
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
In the field of machine learning, data is typically split into three sets:
 training, validation, and testing.
\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf

\series bold
\size large
Training set
\series default
: The training set is a subset of the data used to train the model.
 The model uses the training data to learn the relationships between the
 input features and the target output.
 The model parameters are updated during the training process to minimize
 the prediction error.
\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent

\series bold
\size large
Validation set
\series default
: The validation set is a subset of the data used to evaluate the model
 during training.
 The purpose of the validation set is to ensure that the model is not overfittin
g to the training data.
 Overfitting occurs when the model is too complex and learns the noise in
 the training data instead of the underlying relationships.
 The model is evaluated on the validation set after each training epoch,
 and its performance is used to determine when to stop training or to adjust
 the model's hyperparameters.
\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent

\series bold
\size large
Testing set
\series default
: The testing set is a subset of the data used to evaluate the model's performan
ce after training.
 The model is never trained on the test set and its performance on the test
 set provides an estimate of its generalization performance to new, unseen
 data.
 The test set is used to determine the final accuracy of the model and its
 ability to make predictions on new data.
\end_layout

\begin_layout Subsubsection
Class design and documentation
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
To achieve code reusability, it is important to write modular and maintainable
 code that incorporates class inheritance and shared attributes.
 In order to further enhance the object-oriented programming (OOP) structure
 of our code, we implement the factory pattern.
 The factory pattern allows us to create multiple experiments with little
 changes but have the same base build and experiment structure, increasing
 code efficiency and reusability 
\begin_inset CommandInset citation
LatexCommand cite
key "DesignPatterns"
literal "false"

\end_inset

.
 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
This, combined with the PyTorch Lightning framework, has made the development
 process much easier and faster.
 PyTorch Lightning also offers tools for distributed training that can be
 used to scale the training of big models across several GPUs
\begin_inset CommandInset citation
LatexCommand cite
key "gpu-basic-training"
literal "false"

\end_inset

, TPUs 
\begin_inset CommandInset citation
LatexCommand cite
key "mnist-tpu-training"
literal "false"

\end_inset

, or machines.
 This tooling also facilitates the concept of batches, which involves having
 multiple realizations of the dataset in the format [BATCH, seq_len] or
 [BATCH, channel, height, width].
 By using batches, the training time is reduced and it becomes more manageable
 to handle large amounts of data.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Codigo/SoftwareDiagrams/networkdevelop.png
	lyxscale 50
	scale 28

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Software Architecture Diagram Planning
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
These are the main classes used in the software development:
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
Channel
\end_layout

\begin_deeper
\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
Loads a .mat file containing complex channel coefficient data and converts
 it into a numpy array.
 The class has a constructor __init__ that takes a Boolean parameter LOS
 (default value True) indicating whether to load the line-of-sight (LOS)
 or non-line-of-sight (NLOS) channel data.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
The Channel class has a single attribute con_list that is the numpy array
 containing the channel data.
 The class also defines a __getitem__ method that returns the channel data
 for a specific index in the array.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
The code also imports the scipy.io and numpy libraries and sets up the path
 to the directory containing the .mat files.
 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
Imports the Download_Mat_files function from the DownloadFiles module, and
 adds the path to the conf and tools directories to the Python path.
 
\end_layout

\end_deeper
\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
QAM
\series default
 
\end_layout

\begin_deeper
\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
This class QAM is used to generate QAM modulation schemes and perform demodulati
on on a complex symbol vector.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
The constructor initializes the QAM modulation scheme.
 It takes in the following parameters:
\end_layout

\begin_deeper
\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
num_symbols: The number of QAM symbols to generate.
 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
constelation: The size of the QAM constellation.
 Valid values are 4, 16, 32, and 64.
 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
cont_type: The type of constellation used.
 Valid values are "Data", "Unit_Pow", and "Norm".
 
\end_layout

\begin_deeper
\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
Data
\series default
: constelation as it is.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
Unit_Pow
\series default
: normalized power constelation
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
Norm
\series default
: Normalized constelation to max magnitud to 1 in the complex plane.
 
\end_layout

\end_deeper
\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
noise: Deprecated
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
noise_power: Deprecated
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
load_type: A flag indicating the type of loading.
 Valid values are "Complete" and "Alphabet".
 
\end_layout

\begin_deeper
\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
Complete
\series default
: This is used to get the complex plane data points
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
Alphabet
\series default
: Get the token values, which could be used to retrieve the symbols sent
 without having to put them in the complex domain.
\end_layout

\end_deeper
\end_deeper
\end_deeper
\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
Rx: 
\series default
This class is a PyTorch Dataset that generates a dataset for a communication
 channel.
 The channel is defined by a complex matrix H, and QAM symbols are generated
 with specific parameters such as constellation size, constellation type,
 and load type.
 The dataset consists of a total of 20000 realizations, with each realization
 containing 48 QAM symbols.
 The class generates QAM symbols, generates a complex matrix H, applies
 the channel to the symbols, and adds additive white Gaussian noise to the
 signal.
 The class also defines the AWGN method to add noise with a given SNR.
 The dataset can be loaded as batches using PyTorch's DataLoader.
 The class overloads the __getitem__ method to return the channel tensor
 and the corresponding transmitted tensor.
 The channel tensor is a 48x48x2 tensor of the real and imaginary parts
 of the complex matrix H, and the transmitted tensor is either the QAM symbol
 bits or the QAM symbol complex values depending on the load type.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Codigo/UML/Classes_rx.png
	lyxscale 70
	scale 40

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Rx and their aggregated classes
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
RX_loader
\series default
: This class also splits the dataset into three parts for training, validation,
 and testing.
 The SNR_BER_TEST method of the class is used to calculate the bit error
 rate (BER) for different signal-to-noise ratio (SNR) values.
 This method uses the predict method of the trainer object to predict the
 values of the output of the model and then calculate the BER.
 Class also defines methods to calculate the output of the system given
 the input, including Get_Y, MSE_X, LMSE_X, and ZERO_X.
 These methods calculate the channel output, estimate the transmitted symbols,
 and perform equalization to reduce the effect of the channel on the received
 symbols.
 The class also defines a method to filter the data based on z-score.
\end_layout

\begin_deeper
\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
init
\series default
: Initializes the Rx_loader object with the specified batch size, QAM and
 loading type.
 It also loads the RX dataset and splits it into training, validation and
 testing sets.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
SNR_calc
\series default
: Calculates the signal-to-noise ratio (SNR) and bit error rate (BER) given
 the predicted output and the actual output.
 This is used for internal evaluation in the predict section of the Lightning
 API.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
SNR_BER_TEST:
\series default
 Performs an SNR-BER test by iterating through a range of SNR values and
 printing the BER for each value.
 It also saves the BER values to a CSV file.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
Get_Y:
\series default
 Takes in three arguments: H (channel tensor), x (transmitted symbol tensor),
 conj (boolean flag to indicate whether to take the complex conjugate of
 h), and noise_activ (boolean flag to indicate whether to add noise to the
 received signal).
 It returns the received signal tensor Y of shape (batch_size, 48).
 
\end_layout

\begin_deeper
\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
If noise_activ is True
\series default
, it adds complex Gaussian noise to the received signal Y[i].
 The noise power is computed as the ratio of the signal power to the signal-to-n
oise ratio (SNR) in decibels.
 The noise is generated using the PyTorch function torch.randn to create
 random Gaussian noise with zero mean and standard deviation of sqrt(Pn/2),
 where Pn is the noise power.
 More detail in 
\color blue

\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:SNR"
plural "false"
caps "false"
noprefix "false"

\end_inset


\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
If conj is True
\series default
, it takes the complex conjugate of h using the method 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newline
\end_layout

\end_inset

 conj().resolve_conj(), and performs matrix multiplication with Y[i].
 This helps in data preprocesing in section
\color blue
 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:A-Novel-OFDM"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
 more detail in 
\color blue

\begin_inset CommandInset ref
LatexCommand nameref
reference "Preprocesing"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
 image.
\end_layout

\end_deeper
\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
MSE_X
\series default
: Computes the minimum mean square error (MMSE) estimate of the transmitted
 signal x given the channel matrix H and received signal Y.
 It returns a tensor of shape (batch_size, 48) of complex values.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
LMSE_X
\series default
: Computes the linear minimum mean square error (LMMSE) estimate of the
 transmitted signal x given the channel matrix H, received signal Y and
 SNR.
 It returns a tensor of shape (batch_size, 48) of complex values.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
Chann_diag
\series default
: Extracts the diagonal of each channel matrix in the tensor and returns
 them as a tensor of shape (batch_size, 48) of complex values.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
ZERO_X
\series default
: The method starts by computing the diagonal elements of the channel tensor
 using the 
\series bold
Chann_diag
\series default
 method.
 This helper method extracts the diagonal of each matrix in the tensor and
 combines them into a new tensor.
 Next, the method applies Zero Forcing (ZF) equalization by dividing the
 received signal tensor Y by the diagonal tensor of the channel tensor chann.
 The output is an estimated signal tensor x_hat, which is a tensor of complex
 values with a shape of (batch_size, 48).
 The method returns this tensor as its output.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
filter_z_score
\series default
: Filters out outlier data points from the tensor based on the z-score.
 It returns a filtered tensor and the indices of the valid data points.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
filter_z_score_matrix
\series default
: Filters out outlier data points from the diagonal tensor of a batch of
 channel matrices based on the z-score.
 It returns a filtered tensor and the indices of the valid data points.
\end_layout

\begin_deeper
\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
The default value of the threshold parameter in the filter_z_score() method
 of the Rx_loader class is 1.96, which corresponds to a 95% confidence level
 assuming a normal distribution.
 This means that data points whose absolute z-score is greater than 1.96
 will be considered as outliers and filtered out.
 However, this value can be adjusted by the user based on their specific
 requirements.
\end_layout

\end_deeper
\end_deeper
\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Codigo/UML/Classes_data_loader.png
	lyxscale 70
	scale 40

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Rx Data Loader and usefull classes
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The Rx_loader class is implemented in all classes throughout the project
 for multiple experiments.
 The golden models also use this class because all final application classes
 inherit from this class and use the PyTorch Lightning framework to create
 powerful combinations between custom datasets and helper functions required
 for preprocessing.
\end_layout

\begin_layout Subsubsection
Generic Network Implementation
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The training_step and validation_step methods both call the common_step
 method, which contains the shared implementation between the two.
 This approach reduces code duplication and helps keep the implementation
 DRY (Don't Repeat Yourself)
\begin_inset CommandInset citation
LatexCommand cite
key "CleanCode"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The common_step method takes a batch of data and an optional flag to indicate
 whether the batch is being used for prediction.
 It then performs the 
\series bold
pre-processing
\series default
 of the data, which includes different strategies such as 
\color blue

\begin_inset CommandInset ref
LatexCommand nameref
reference "subsec:Zero-forcing"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
, obtaining Y with its conjugate 
\color blue

\begin_inset CommandInset ref
LatexCommand eqref
reference "Preprocesing"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
, normalizing values 
\color blue

\begin_inset CommandInset ref
LatexCommand eqref
reference "subsec:Normalize-unitary-circle"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
, and filtering outliers by z-score
\color blue
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "subsec:Z-score"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
After the pre-processing is done, the method evaluates the model by computing
 the predicted output and comparing it with the target output.
 The 
\series bold
evaluation
\series default
 process involves passing the pre-processed data through the neural network
 model, which generates the predicted output.
 The predicted output is then compared with the target output using a loss
 function, which calculates the difference between them.
 The method returns the loss value, which is used for updating the model's
 parameters during training.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
By separating the common implementation from the specific training and validatio
n logic, we can easily reuse the same code for different stages of the training
 process, and focus on implementing the logic that is specific to each stage.
 This results in cleaner and more maintainable code, as well as faster developme
nt times.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Codigo/UML/GeneriNet.png
	lyxscale 70
	scale 40

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Generic Net
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Golden Model
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
In this project, the golden model serves as a benchmark for evaluating the
 performance of new models.
 The golden model is based on three equalizers: Least squares (LS), Linear
 Minimum Mean Squared Error (LMMSE), and zero forcing, which are discussed
 in more detail in sections
\color blue
 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:LS"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
, 
\color blue

\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:LMMSE"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
 , 
\color blue

\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Zero-forcing"
plural "false"
caps "false"
noprefix "false"

\end_inset

 
\color inherit
of this document,respectively.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
When evaluating the performance of a communication system, it is standard
 practice to plot both the Bit Error Rate 
\color blue
(
\begin_inset CommandInset ref
LatexCommand nameref
reference "subsec:BER"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
) and Signal-to-Noise Ratio (SNR) on the same graph, with SNR on the x-axis
 and BER on the y-axis.
 BER measures the number of errors that occur in a transmitted data stream,
 relative to the total number of bits transmitted, while SNR measures the
 strength of the signal relative to the background noise.
 Comparing the BER and SNR values allows us to evaluate the system's performance
 under different levels of noise.
 A higher SNR indicates a stronger signal relative to the background noise,
 which should result in a lower BER.
 Therefore, as the SNR increases, the BER should decrease.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/Golden_4QAM.png
	lyxscale 40
	scale 55

\end_inset


\begin_inset Graphics
	filename Imagenes/Results/Golden_16QAM.png
	lyxscale 40
	scale 55

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Caption Standard

\begin_layout Plain Layout
Golden model plot QPSK and 16QAM
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Defining the Golden class, which takes the mode ("MSE"(LS), "LMSE", or "ZERO")
 as input and initializes the Rx_loader superclass with the given BATCHSIZE,
 QAM, and "Complete" load.
 Depending on the mode, the class sets the self.estimator attribute to the
 MSE_X, LMSE_X, or ZERO_X method.
 The class also defines the forward method, the configure_optimizers method,
 and the predict_step method, which calculates the bit error rate (BER)
 for a given batch of data.
 Finally, the class defines the predict_dataloader method, which returns
 the test_loader.
 In the main section of the script, a PyTorch Lightning Trainer object is
 instantiated.
 Finally, the SNR_BER_TEST method of the Golden object is called with the
 Trainer object and a file name for the output log.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/ZeroForcingVSGolden.png
	lyxscale 55
	scale 55

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Golden model LMMSE vs ZeroForing
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
\paragraph_spacing onehalf
\noindent
PhaseNet
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
This neural network corrects the distortion and restores the original phase
 given channel and noise.
 It can be used in applications such as phase modulation or PSK.
 However, the network encounters a problem when evaluating the error between
 the estimated and real values.
 When the estimated value is in the second quadrant of the complex plane
 and the real value is in the third quadrant, the error becomes quite large.
 This is because the error is measured as the difference in angles, and
 traversing the second, fourth, and third quadrants causes the error to
 increase significantly.
 It is important to note that angle values are usually represented within
 the range of 
\begin_inset Formula $-\pi$
\end_inset

 to 
\begin_inset Formula $\pi$
\end_inset

 in pytorch and numpy libraries.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Networks/ErrorAngle.png
	scale 80

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Angle error - Red represents high error and green represents smaller error.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
To address the issue of computing the error and achieving precise adjustment
 of the estimation, we adopted a new technique.
 This technique involves generating a complex number with a fixed radius
 of 1 and a variable angle.
 Since neural networks only output angles, we truncated the ground truth
 complex values to a radius of one.
 We used Euler's formula to construct this complex number in rectangular
 form, based only on the angle.
 Specifically, we used the output of the neural network, denoted as 
\begin_inset Formula $\boldsymbol{O(\hat{\theta})}$
\end_inset

, with a radius of one to build the complex number.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{O(\hat{\theta})=e^{i\hat{\theta}}=cos(\hat{\theta})+i*sin(\hat{\theta})}
\end{equation}

\end_inset

By using this approach, we can concentrate solely on the phasors (angles)
 and keep a constant radius.
 We can objectively measure the difference between the complex value of
 the estimated and real values using the method of least squares.
 This method allows us to calculate the difference between two quadrants
 more accurately, resulting in better estimation correction.
 However, to avoid getting a complex error and obtain only a numerical error
 value, we calculate the mean squared error (MSE) separately for the real
 and imaginary parts.Furthermore, by limiting the radius to 1, the loss is
 bounded, preventing it from exploding and introducing a large error.
 This can help with the convergence of the neural network.
 The equation below shows the error measurement that was developed.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{MSE\left(\hat{\theta}\right)=\frac{1}{2}\left(E\left[(cos(\hat{\theta})-x_{real})^{2}\right]+E\left[(sin(\hat{\theta})-x_{imag})^{2}\right]\right)}\label{eq:62}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\align center

\size large
However this expresion can be rewriten and it can be expand each term as
 follows:
\end_layout

\begin_layout Standard
\align center

\size large
\begin_inset Formula $\boldsymbol{E\left[\cos^{2}(\hat{\theta})\right]-2x_{\text{real}}E\left[\cos(\hat{\theta})\right]+x_{\text{real}}^{2}+E\left[\sin^{2}(\hat{\theta})\right]-2x_{\text{imag}}E\left[\sin(\hat{\theta})\right]+x_{\text{imag}}^{2}}$
\end_inset


\end_layout

\begin_layout Standard
\align center

\size large
We can simplify this by noting that:
\end_layout

\begin_layout Standard
\align center

\size large
\begin_inset Formula $\boldsymbol{E\left[\cos^{2}(\hat{\theta})\right]+E\left[\sin^{2}(\hat{\theta})\right]=E\left[\cos^{2}(\hat{\theta})+\sin^{2}(\hat{\theta})\right]=E\left[1\right]=1}$
\end_inset


\end_layout

\begin_layout Standard
\align center

\size large
and
\end_layout

\begin_layout Standard
\align center

\size large
\begin_inset Formula $\boldsymbol{-2x_{\text{real}}E\left[\cos(\hat{\theta})\right]-2x_{\text{imag}}E\left[\sin(\hat{\theta})\right]=-2(x_{\text{real}}\cos(\hat{\theta})+x_{\text{imag}}\sin(\hat{\theta}))}$
\end_inset


\end_layout

\begin_layout Standard
\align center

\size large
Substituting these simplifications back into the previous equation gives:
\end_layout

\begin_layout Standard
\align center

\size large
\begin_inset Formula $\boldsymbol{\frac{1}{2}\left(1-2(x_{\text{real}}\cos(\hat{\theta})+x_{\text{imag}}\sin(\hat{\theta}))+x_{\text{real}}^{2}+x_{\text{imag}}^{2}\right)}$
\end_inset


\end_layout

\begin_layout Standard
\align center

\size large
which can be further simplified to:
\end_layout

\begin_layout Standard
\align center

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{\frac{1}{2}\left((\cos(\hat{\theta})-x_{\text{real}})^{2}+(\sin(\hat{\theta})-x_{\text{imag}})^{2}\right)}\label{eq63}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The final result is the same as the squared Euclidean distance, multiplied
 by a factor of 1/2.
 In complex form, it is represented by the squared magnitude of the difference
 between the complex numbers, which is equivalent to 
\color blue

\begin_inset CommandInset ref
LatexCommand formatted
reference "eq:46"
plural "false"
caps "false"
noprefix "false"

\end_inset

 
\color inherit
with a fixed radius of 1
\end_layout

\begin_layout Standard

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{MSE\left(\hat{\theta}\right)=|O(\hat{\theta})-x|^{2}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard

\size large
Where 
\begin_inset Formula $|.|$
\end_inset

 is the magnitud of the complex number.
\end_layout

\begin_layout Subsubsection
Preprocesing
\end_layout

\begin_layout Standard
\noindent
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{table}[h] 
\backslash
centering 
\backslash
caption{Preprocessing flags PhaseNet} 
\backslash
label{tab:preprocessing} 
\backslash
begin{tabular}{|c|c|} 
\backslash
hline 
\backslash
textbf{Preprocessing} & 
\backslash
textbf{Enable} 
\backslash

\backslash
 
\backslash
hline Conjugate & True 
\backslash

\backslash
 
\backslash
hline Z-score & True 
\backslash

\backslash
 
\backslash
hline  Zero-Forcing & False 
\backslash

\backslash
 
\backslash
hline 
\backslash
end{tabular} 
\backslash
end{table}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Based on the experimentation, it can be concluded that preprocessing plays
 a crucial role in enabling the neural network to converge successfully.
 As demonstrated in the paper 
\shape italic
A Novel OFDM Equalizer for Large Doppler Shift Channel through Deep Learning
\shape default
\color blue
 
\begin_inset CommandInset ref
LatexCommand vpageref
reference "subsec:A-Novel-OFDM"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
, preprocessing helped to achieve a successful outcome.
 In this network, our first preprocessing stage is to multiply 
\begin_inset Formula $Y$
\end_inset

 by the Hermitian transpose of the channel, 
\begin_inset Formula $H^{H}Y$
\end_inset

.
 This results in 
\begin_inset Formula $H^{H}Y$
\end_inset

 being the input to the network.
 Next, we apply a z-score filter 
\begin_inset CommandInset ref
LatexCommand vpageref
reference "subsec:Z-score"
plural "false"
caps "false"
noprefix "false"

\end_inset

 with a 95% confidence interval to eliminate outliers.
 Finally, we normalize angles from -pi to pi to -1 to 1.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Codigo/UML/PhasNet.png
	lyxscale 70
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Preprocesing Stages
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Parameters
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{table}[H]   
\backslash
centering   
\backslash
caption{Number of Parameters in the PyTorch nn.Sequential block}   
\backslash
label{tab:num_params}   
\backslash
begin{tabular}{|l|l|l|}     
\backslash
hline     
\backslash
textbf{Layer} & 
\backslash
textbf{Output Shape} & 
\backslash
textbf{Number of Parameters} 
\backslash

\backslash
     
\backslash
hline     
\backslash
texttt{nn.Linear(48, 240, bias=True)} & 
\backslash
texttt{(batch
\backslash
_size, 240)} & 
\backslash
texttt{(48 + 1) * 240 = 11,760} 
\backslash

\backslash
     
\backslash
hline     
\backslash
texttt{nn.Hardtanh()} & 
\backslash
texttt{(batch
\backslash
_size, 240)} & 
\backslash
texttt{0} 
\backslash

\backslash
     
\backslash
hline     
\backslash
texttt{nn.Linear(240, 720, bias=True)} & 
\backslash
texttt{(batch
\backslash
_size, 720)} & 
\backslash
texttt{2 * 240$^2$ + 2 * 240 = 346,320} 
\backslash

\backslash
     
\backslash
hline     
\backslash
texttt{nn.Linear(720, 240, bias=True)} & 
\backslash
texttt{(batch
\backslash
_size, 240)} & 
\backslash
texttt{4 * 240$^2$ + 2 * 240 = 1,388,160} 
\backslash

\backslash
     
\backslash
hline     
\backslash
texttt{nn.Hardtanh()} & 
\backslash
texttt{(batch
\backslash
_size, 240)} & 
\backslash
texttt{0} 
\backslash

\backslash
     
\backslash
hline     
\backslash
texttt{nn.Linear(240, 48, bias=True)} & 
\backslash
texttt{(batch
\backslash
_size, 48)} & 
\backslash
texttt{(240 + 1) * 48 = 11,568} 
\backslash

\backslash
     
\backslash
hline     
\backslash
multicolumn{2}{|r|}{
\backslash
textbf{Total}} & 
\backslash
textbf{1,757,808 = 13.39 MB} 
\backslash

\backslash
     
\backslash
hline   
\backslash
end{tabular} 
\backslash
end{table} 
\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Hyperparameters
\end_layout

\begin_layout Standard

\size large
SNR stands for Signal-to-Noise Ratio during training.
 This value is applicable to all networks.
 During testing, the SNR is subjected to varying values.

\size default
 
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{table}[H]   
\backslash
centering   
\backslash
caption{Hyperparameters}   
\backslash
label{tab:hyperparams}   
\backslash
begin{tabular}{|l|l|}     
\backslash
hline     
\backslash
textbf{Hyperparameter} & 
\backslash
textbf{Value} 
\backslash

\backslash
 
\backslash
hline     BATCHSIZE & 10 
\backslash

\backslash
 
\backslash
hline     QAM & 16 
\backslash

\backslash
 
\backslash
hline     NUM
\backslash
_EPOCHS & 2 
\backslash

\backslash
 
\backslash
hline     INPUT
\backslash
_SIZE & 48 
\backslash

\backslash
 
\backslash
hline     HIDDEN
\backslash
_SIZE & 240 
\backslash

\backslash
 
\backslash
hline     LEARNING
\backslash
_RATE & 8e-5 
\backslash

\backslash
 
\backslash
hline     CONJ & True 
\backslash

\backslash
 
\backslash
hline  SNRdB & 35 
\backslash

\backslash
 
\backslash
hline 
\backslash
end{tabular} 
\backslash
end{table} 
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
PolarNet
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The Polar_Net consists of two networks: PhaseNet, which we've seen before,
 and a new network called Mag_net.
 The Polar_Net is an integration of these two as pretrained networks.
 Since we're already familiar with PhaseNet, let's now focus on describing
 MagNet.
\end_layout

\begin_layout Subsubsection
MagNet Preprocesing and loss function
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The architecture of MagNet is quite similar to that of Polar_Net, but with
 fewer parameters in the hidden layer.
 As a result, we won't go into as much detail about the layer architecture.
 However, we'll still pay close attention to the preprocessing stage.
 Unlike PhaseNet, MagNet doesn't use the Hermitian transpose of the channel.
 Instead, it uses the diagonal of the channel to perform zero forcing equalizati
on as a preprocessing step.
 Next, a z-score filter is applied, followed by complex normalization by
 absolute.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The loss function for MagNet remains quite simple, let 
\begin_inset Formula $\boldsymbol{O(\hat{\theta})}$
\end_inset

 be the output of the network, which approximates the magnitude of the ground
 truth, and the magnitude of a complex number is denoted by 
\begin_inset Formula $\boldsymbol{|.|}$
\end_inset

, the folowing error is given: 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{MSE(\hat{\theta})=E\left[\left(O(\hat{\theta})-|\theta|\right)^{2}\right]}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
To put it another way, the network produces its output in terms of the magnitude
 of the complex numbers.
 Then, for the loss function, the absolute value of the complex value of
 the ground truth is taken.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Codigo/UML/MagNet.png
	lyxscale 70
	scale 60

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
MagNet Preprocesing
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Magnet Parameters
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{table}[h]   
\backslash
centering   
\backslash
caption{Number of Parameters in the PyTorch nn.Sequential block}   
\backslash
label{tab:num_params}   
\backslash
begin{tabular}{|l|l|l|}     
\backslash
hline     
\backslash
textbf{Layer} & 
\backslash
textbf{Output Shape} & 
\backslash
textbf{Number of Parameters} 
\backslash

\backslash
     
\backslash
hline     
\backslash
texttt{nn.Linear(48, 120, bias=True)} & 
\backslash
texttt{(batch
\backslash
_size, 120)} & 
\backslash
texttt{(48 + 1) * 120 = 5,880} 
\backslash

\backslash
     
\backslash
hline     
\backslash
texttt{nn.Hardtanh()} & 
\backslash
texttt{(batch
\backslash
_size, 120)} & 
\backslash
texttt{0} 
\backslash

\backslash
     
\backslash
hline     
\backslash
texttt{nn.Linear(120, 240, bias=True)} & 
\backslash
texttt{(batch
\backslash
_size, 240)} & 
\backslash
texttt{2 * 120$^2$ + 2 * 120 = 29,040} 
\backslash

\backslash
     
\backslash
hline     
\backslash
texttt{nn.Linear(240, 120, bias=True)} & 
\backslash
texttt{(batch
\backslash
_size, 120)} & 
\backslash
texttt{4 * 120$^2$ + 2 * 120 = 57,840} 
\backslash

\backslash
     
\backslash
hline     
\backslash
texttt{nn.Hardtanh()} & 
\backslash
texttt{(batch
\backslash
_size, 120)} & 
\backslash
texttt{0} 
\backslash

\backslash
     
\backslash
hline     
\backslash
texttt{nn.Linear(120, 48, bias=True)} & 
\backslash
texttt{(batch
\backslash
_size, 48)} & 
\backslash
texttt{(120 + 1) * 48 = 5,856} 
\backslash

\backslash
     
\backslash
hline     
\backslash
multicolumn{2}{|r|}{
\backslash
textbf{Total}} & 
\backslash
textbf{98,716 = 789.7 KB} 
\backslash

\backslash
     
\backslash
hline   
\backslash
end{tabular} 
\backslash
end{table} 
\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
MagNet Hyperparameters
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{table}[H] 
\backslash
centering 
\backslash
caption{Hyperparameters} 
\backslash
label{tab:hyperparams} 
\backslash
begin{tabular}{|l|l|} 
\backslash
hline 
\backslash
textbf{Hyperparameter} & 
\backslash
textbf{Value} 
\backslash

\backslash
 
\backslash
hline BATCHSIZE & 10 
\backslash

\backslash
 
\backslash
hline QAM & 16 
\backslash

\backslash
 
\backslash
hline NUM
\backslash
_EPOCHS & 10 
\backslash

\backslash
  
\backslash
hline INPUT
\backslash
_SIZE & 48 
\backslash

\backslash
 
\backslash
hline HIDDEN
\backslash
_SIZE & 120 
\backslash

\backslash
 
\backslash
hline LEARNING
\backslash
_RATE & 5e-5 
\backslash

\backslash
 
\backslash
hline SNRdB & 25 
\backslash

\backslash
 
\backslash
hline 
\backslash
end{tabular} 
\backslash
end{table}
\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
All Together
\end_layout

\begin_layout Standard
The final size of the network is the sum of the Magnet parameters and the
 Phase parameters, which is approximately 
\series bold
0.753 MB + 13.39 MB = 14.143 MB
\series default
.
 The reason why Magnet has fewer parameters is that more parameters in the
 magnitude can lead to overfitting and the network may not generalize well
 with new data.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Codigo/UML/PolarNet.png
	lyxscale 70
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Overview of PolarNet
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Complex Net
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
This network was motivated in the paper A Survey of Complex-Valued Neural
 Networks 
\color blue

\begin_inset CommandInset ref
LatexCommand vpageref
reference "subsec:A-Survey-of"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color black
.
 The main idea is to investigate the use of complex-valued neural networks
 and attempt to reduce the number of network parameters.
 However, this approach may increase the time complexity due to the need
 for complex number operations between each layer.
 Additionally, we aim to utilize state-of-the-art loss functions proposed
 in mathematical formulas 
\color blue

\begin_inset CommandInset ref
LatexCommand formatted
reference "eq:46"
plural "false"
caps "false"
noprefix "false"

\end_inset

 
\color black
and 
\color blue

\begin_inset CommandInset ref
LatexCommand formatted
reference "eq:48"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color black
.Finally, for preprocessing, the hermitian transpose and normalization steps
 are applied.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Codigo/UML/ComplexUML.png
	lyxscale 70
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Complex Network Implementation
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Codigo/UML/ComplexNet.png
	lyxscale 70
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Complex Preprocesing
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\color black
In the upcoming subsections, we will explain the components required to
 construct a complex network.
 
\end_layout

\begin_layout Subsubsection
Apply Complex
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
One of the key components of layers in this stage is the apply_complex functions
 which is part of the complexLinear layers.
 The apply_complex(fr, fi, input, dtype = torch.complex128) function takes
 as input the real and imaginary parts of the weights fr and fi, the input
 tensor input, and a data type dtype for the output tensor.
 It applies a complex-valued linear transformation to the input tensor,
 given by the expression:
\end_layout

\begin_layout Standard

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{Re(z)=Re(fr)*Re(x)-Im(fi)*Im(x)}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{Im(z)=Re(fi)*Re(x)+Im(fr)*Im(x)}
\end{equation}

\end_inset


\end_layout

\begin_layout Subsubsection
\paragraph_spacing onehalf
\noindent
Complex Linear
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
The ComplexLinear(in_features, out_features) class defines a custom PyTorch
 module for a complex-valued linear layer.
 It has two attributes: fc_r is a standard PyTorch Linear module that applies
 a linear transformation to the real part of the input, and fc_i is another
 Linear module that applies a linear transformation to the imaginary part
 of the input.
 The forward(input) method of this module applies the complex-valued linear
 transformation separately to the real and imaginary parts of the input
 tensor using the apply_complex function.
\end_layout

\begin_layout Subsubsection
\paragraph_spacing onehalf
\noindent
Hardtanh Complex
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
The HardTahn_complex class defines a custom PyTorch module for a complex-valued
 hard tanh activation function.
 It has two attributes: hard_real is a standard PyTorch Hardtanh module
 that applies the hard tanh function to the real part of the input tensor,
 and hard_imag is another Hardtanh module that applies the hard tanh function
 to the imaginary part of the input tensor.
 The forward(input) method of this module applies the hard tanh function
 separately to the real and imaginary parts of the input tensor, and then
 combines them into a complex-valued tensor using torch.float64 and the +1j*
 syntax to create a complex number.
 
\end_layout

\begin_layout Subsubsection
Parameters
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{table}[H] 
\backslash
centering 
\backslash
begin{tabular}{|l|l|l|l|} 
\backslash
hline 
\backslash
textbf{Layer} & 
\backslash
textbf{Input Size} & 
\backslash
textbf{Output Size} & 
\backslash
textbf{Number of Parameters} 
\backslash

\backslash
 
\backslash
hline Linear 1 & 48 & 120 & 11,520 
\backslash

\backslash
 
\backslash
hline HardTanh 1 & 120 & 120 & 0 
\backslash

\backslash
 
\backslash
hline Linear 2 & 120 & 240 & 138,240 
\backslash

\backslash
 
\backslash
hline Linear 3 & 240 & 240 & 115,440 
\backslash

\backslash
 
\backslash
hline Linear 4 & 240 & 120 & 57,720 
\backslash

\backslash
 
\backslash
hline HardTanh 2 & 120 & 120 & 0 
\backslash

\backslash
 
\backslash
hline Linear 5 & 120 & 240 & 138,240 
\backslash

\backslash
 
\backslash
hline Linear 6 & 240 & 48 & 23,088 
\backslash

\backslash
 
\backslash
hline Total & 48 & 48 & 484,248 = 3.87 MB 
\backslash

\backslash
 
\backslash
hline 
\backslash
end{tabular} 
\backslash
caption{Number of parameters in the complex network.} 
\backslash
end{table} 
\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
HyperParameters
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{table}[h] 
\backslash
centering 
\backslash
begin{tabular}{|l|l|} 
\backslash
hline 
\backslash
textbf{Parameter} & 
\backslash
textbf{Value} 
\backslash

\backslash
 
\backslash
hline Batch Size & 50 
\backslash

\backslash
 
\backslash
hline QAM & 16 
\backslash

\backslash
 
\backslash
hline Number of Epochs & 100 
\backslash

\backslash
 
\backslash
hline Learning Rate & 0.00001 
\backslash

\backslash
 
\backslash
hline SNRdB & 40 
\backslash

\backslash
 
\backslash
hline 
\backslash
end{tabular} 
\backslash
caption{Values for network hyperparameters.} 
\backslash
end{table} 
\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Loss functions
\end_layout

\begin_layout Standard

\size large
In the experiments, we evaluate the performance of the complex network using
 both custom loss functions
\size default
 
\size large
\color blue

\begin_inset CommandInset ref
LatexCommand formatted
reference "eq:46"
plural "false"
caps "false"
noprefix "false"

\end_inset

 
\color black
and 
\color blue

\begin_inset CommandInset ref
LatexCommand formatted
reference "eq:48"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color black
.

\color inherit
 The results of these experiments are presented in the next section.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Networks/ComplexLoss.png
	lyxscale 70
	scale 70

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Loss functions code
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsection
MobileNet zeroForcing
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
We conducted experiments with this network to study how well convolutional
 neural networks can be developed in signal equalization.
 However, we opted to employ the efficient architecture of MobileNet as
 our network's goal is to improve the effectiveness of the zero-forcing
 method for communication channels.
 Given the relative simplicity of the zero-forcing algorithm, we determined
 that the 
\color blue

\begin_inset CommandInset ref
LatexCommand nameref
reference "subsec:MobileNetV3"
plural "false"
caps "false"
noprefix "false"

\end_inset

 
\color inherit
architecture was well-suited for our purposes.
 Its time efficiency and competence relative to zero-forcing made it a suitable
 choice.
 However, in the presence of noise in the channel data, the conventional
 zero-forcing approach may not be effective as it does not consider noise
 in its nature.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The channel is initially a 1x48x48 matrix, but it must be transformed into
 a single vector of length 1x48 for the zero-forcing approach to be applicable.
 Thus, this implementation employs two modified MobileNets to process the
 channel data.
 One network is responsible for extracting the absolute value of the channel
 matrix, while the other network extracts the angle matrix of the channel.
 Notably, the first and last layers were modified to fit the specific problem.
 In the image below, they are marked in red.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/MobileNetCustom.png
	lyxscale 70
	scale 70

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Ilustartion of mobileNet customized for our target problem
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The models used in this project were taken from the PyTorch framework, so
 there was no need to test their functionality.
 We did not use pre-trained weights and instead trained the models from
 scratch.
 Thanks to the GPU, we were able to train the models faster.

\size default
 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The idea behind this is to replicate the process of traditional zero-forcing
 
\begin_inset Formula $\boldsymbol{\frac{Y}{H}}$
\end_inset

, where the channel matrix is represented by 
\begin_inset Formula $\boldsymbol{H}$
\end_inset

 and the received signal is represented by 
\begin_inset Formula $\boldsymbol{Y=Hx+n}$
\end_inset

.
 In this process, we estimate the channel using the equation:
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{\hat{x}=\frac{Y}{\hat{\theta}}}
\end{equation}

\end_inset

 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
where 
\begin_inset Formula $\boldsymbol{\hat{\theta}}$
\end_inset

 represents the output of the model.
 However, as we want the estimator values to be in the range of 
\begin_inset Formula $\boldsymbol{0<\hat{\theta}<1}$
\end_inset

, we need to rearrange the estimation equation as follows:
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{\hat{x}=Y*\hat{\theta}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
As we are working with polar coordinates, we should note that when multiplying
 two phasors, their amplitudes are multiplied, and their angles are added
 together.
 So basically net compensate the distorted phasor 
\begin_inset Formula $Y$
\end_inset

 and estimation equations has this form:
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{O(\hat{\theta})=Y_{mag}*\hat{\theta_{mag}}\angle\hat{\theta}_{angle}+Y_{angle}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard

\size large
Finally the MSE loss between this estimated 
\begin_inset Formula $O(\hat{\theta})$
\end_inset

 and the true value is given this form.
 
\end_layout

\begin_layout Standard

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{MSE(\hat{\theta})=E\left[\left(O(\hat{\theta})-\theta\right)^{2}\right]}
\end{equation}

\end_inset


\end_layout

\begin_layout Subsubsection
\paragraph_spacing onehalf
\noindent
Software Implementation 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
In the common_step method, the input data is processed by the PredesignedModel
 network, which is a pre-trained MobileNetv3 network that is modified to
 fit the problem.
 The output of the PredesignedModel network is passed through two separate
 layers: one layer for the magnitude and one layer for the angle of the
 signal.
 The angle layer is used to estimate the phase shift of the received signal.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
It's worth noting that the channel is treated as an image of two channels,
 one for the real and the other for the imaginary part.
 In the software implementation, a complex128 channel of 1 channel is built,
 and then the absolute and angle of this 1 channel matrix is taken to feed
 both mobile nets.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
In this code implementation, the channel magnitude is normalized to the
 maximum magnitude of 1.
 This normalization is done after building the Y, to avoid altering the
 results of calculating the input signal.
 Then the z-score is computed, and outliers are filtered with a confidence
 interval of 99%.
 Finally, for the angle error calculation, the same ideas as in PolarNet
 are followed.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Codigo/UML/MobileNetForwar.png
	lyxscale 80
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
MobileNet Forward process
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Loss Function
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
For the loss function we face the same issue as PhaseNet regarding the calculati
on of angle errors.
 To avoid this problem, we adopt a similar solution, which involves fixing
 the radius to 1 and comparing the angles 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq63"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 So we end up with 3 evalautons for a single loss function.
 However, in this loss, we chose to emphasize the Phasor concept to make
 it more intuitive.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\begin_inset Formula 
\begin{equation}
\boldsymbol{Loss=}\boldsymbol{\begin{array}{c}
\frac{1}{2}MSE(Y_{mag}*\hat{\theta_{mag}},x_{mag})+\\
\frac{1}{4}MSE\left(\left[1\angle\hat{\theta}_{angle}+Y_{angle}\right]_{real},\left[1\angle x_{angle}\right]_{real}\right)+\\
\frac{1}{4}MSE\left(\left[1\angle\hat{\theta}_{angle}+Y_{angle}\right]_{imag},\left[1\angle x_{angle}\right]_{imag}\right)
\end{array}}
\end{equation}

\end_inset


\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf

\size large
The first term computes the MSE between the magnitudes of the estimated
 signal 
\begin_inset Formula $\boldsymbol{Y_{mag}*\hat{\theta_{mag}}}$
\end_inset

 and the true signal magnitud 
\begin_inset Formula $\boldsymbol{x_{mag}}$
\end_inset

.
 Here, 
\begin_inset Formula $\boldsymbol{Y_{mag}}$
\end_inset

 is the magnitude of the received signal 
\begin_inset Formula $\boldsymbol{Y}$
\end_inset

, and 
\begin_inset Formula $\boldsymbol{\hat{\theta_{mag}}}$
\end_inset

 is the estimated magnitude given by network.
\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf

\size large
The second term computes the mean squared error (MSE) between the real component
s of the estimated phasor, with fixed radius plus phase correction, and
 the real value of the angle of x
\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf

\size large
The same as second term in loss, but with imaginary part.
 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The function also includes weighting factors for each term.
 The first term is weighted by 1/2, while the second and third terms are
 each weighted by 1/4.
\end_layout

\begin_layout Subsubsection
Parameters
\end_layout

\begin_layout Standard
MobileNetV3 model has about 2.24 million parameters in an efficient way.
 
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{table}[h] 
\backslash
centering 
\backslash
begin{tabular}{|c|c|c|} 
\backslash
hline 
\backslash
textbf{Name} & 
\backslash
textbf{Type} & 
\backslash
textbf{Params} 
\backslash

\backslash
 
\backslash
hline 0 & loss
\backslash
_f & MSELoss 
\backslash
_ 0 
\backslash

\backslash
 
\backslash
hline 1 & abs
\backslash
_net & PredesignedModel = 1.6 M 
\backslash

\backslash
 
\backslash
hline 2 & angle
\backslash
_net & PredesignedModel = 1.6 M 
\backslash

\backslash
 
\backslash
hline 3 & final
\backslash
_merge
\backslash
_abs & Sequential = 18.6 K 
\backslash

\backslash
 
\backslash
hline 4 & final
\backslash
_merge
\backslash
_ang & Sequential = 18.6 K 
\backslash

\backslash
 
\backslash
hline 
\backslash
multicolumn{2}{|c|}{
\backslash
textbf{Total size}} & 
\backslash
textbf{3.2 MB + 37.2 KB} 
\backslash

\backslash
 
\backslash
hline 
\backslash
end{tabular} 
\backslash
caption{Model architecture} 
\backslash
end{table} 
\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
HyperParameter
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{table}[h] 
\backslash
centering 
\backslash
begin{tabular}{|l|l|} 
\backslash
hline 
\backslash
textbf{Parameter} & 
\backslash
textbf{Value} 
\backslash

\backslash
 
\backslash
hline Batch Size & 50 
\backslash

\backslash
 
\backslash
hline Number of Epochs & 50 
\backslash

\backslash
 
\backslash
hline Learning Rate & 0.0001 
\backslash

\backslash
 
\backslash
hline SNRdB & 30 
\backslash

\backslash
 
\backslash
hline 
\backslash
end{tabular} 
\backslash
caption{Neural network hyperparameters} 
\backslash
label{tab:nn_params} 
\backslash
end{table}
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
\paragraph_spacing onehalf
GridNet
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
At the moment we were conducting this research, nothing had been done before
 with transformers and signal equalization.
 We are aware that transformers are a heavier network, but recent advances
 in Edge Computing TPU processors 
\begin_inset CommandInset citation
LatexCommand cite
key "coral2020accelerator"
literal "false"

\end_inset

 are making them a more feasible solution at a relatively low cost.
 While there is a paper called "Radio Transformer"
\begin_inset CommandInset citation
LatexCommand cite
key "RadioTransformer"
literal "false"

\end_inset

 in the state of the art, it is used for modulation recognition, not for
 signal equalization.
 Additionally, historically, this paper does not align with "Attention is
 All You Need" 
\begin_inset CommandInset citation
LatexCommand cite
key "transformer"
literal "false"

\end_inset

 paper since it was written in 2016, whereas "Attention is All You Need"
 was written in 2017.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
While we were initially inspired by the concept of an image being worth
 16x16 words 
\begin_inset CommandInset citation
LatexCommand cite
key "dosovitskiy2020image"
literal "false"

\end_inset

 as described in the state of the art 
\color blue

\begin_inset CommandInset ref
LatexCommand formatted
reference "subsec:An-image-is"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
, we took this idea further by considering the encoder and decoder for the
 original transformer design 
\color blue

\begin_inset CommandInset ref
LatexCommand formatted
reference "fig:Transformer-with-encoder"
plural "false"
caps "false"
noprefix "false"

\end_inset

 
\color inherit
.
 Additionally, we challenged the assumption that the grid must be based
 on Euclidean geometry and instead rethought the grid in terms of a polar
 geometry.
 This paradigm shift was justified by the fact that our best results were
 obtained using polar representation.
 Furthermore, polar representation results in a non-uniformly distributed
 grid, where values closer to the center are penalized more heavily.
 This is useful because, in the presence of additive white noise, values
 are not expected to be centered, but rather more commonly found towards
 the edges of the polar representation.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The main idea is to divide the complex plane into grids, with each grid
 slot considered as a bucket.
 When a received value 
\begin_inset Formula $\boldsymbol{Y_{i}}$
\end_inset

 arrives, it is placed in an incorrect bucket 
\begin_inset Formula $\boldsymbol{B_{i}},$
\end_inset

which is assigned a number 
\begin_inset Formula $\boldsymbol{A_{i}}$
\end_inset

.
 To train the network, we assign the ground truth value with its correct
 bucket number 
\begin_inset Formula $\boldsymbol{B_{j}}$
\end_inset

and calculate the maximum likelihood cost function between the estimation
 and ground truth , similar to correcting mistranslated text in a language
 task.
 Multihead attention improves Bucket calculation, because it takes care
 of the values passed before.
 In the context of signal processing, this attention mechanism helps to
 handle the ISI (Inter-Symbol Interference), which is a major challenge
 in dealing with a doubly dispersive 
\color blue

\begin_inset CommandInset ref
LatexCommand nameref
reference "subsec:Channel"
plural "false"
caps "false"
noprefix "false"

\end_inset

 .
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Finally, after predicting the bucket 
\begin_inset Formula $\boldsymbol{B_{j}},$
\end_inset

the value passes through the degrid process, which involves placing the
 value in the middle of the patch coordinates.
 This process helps to further equalize the value as it is forced to be
 placed in only this position or any other patch.
\end_layout

\begin_layout Subsubsection
\paragraph_spacing onehalf
Square Grid
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The encoding process involves binning the real and imaginary parts of the
 data into a set of discrete bins and mapping them onto a 2D grid.
 The decoding process reverses this process by mapping the values back to
 their original locations in the complex plane.
 The smallest number used for the grid is 4 because number 2 is reserved
 for the start of sentence token (<sos>) and 3 is reserved for the end of
 sentence token (<eos>), making it compatible with language models.
 The largest number corresponds to the number of bins used in the encoding
 process.
 In other words number of bins is the size of our alphabet.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Codigo/UML/SquareGrid.png
	lyxscale 70
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Class attibutes to do the grid with bins
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
step
\series default
: A float value that represents the step size for binning, from -.85 to .85.
 Note that step is for quadrant and not all plane.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
binsx
\series default
: A tensor that contains the bins for the real part of the data.
 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
binsy
\series default
: A tensor that contains the bins for the imaginary part of the data.
 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
binxy
\series default
: A tensor that contains a 2D bin index matrix for encoding.
 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
x_indices
\series default
: A tensor that stores the indices of the bins for the real part of the
 data.
 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
y_indices
\series default
: A tensor that stores the indices of the bins for the imaginary part of
 the data.
 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
indices_shape
\series default
: A tuple that stores the shape of the input data for encoding.
 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
real_decoded
\series default
: A tensor that stores the decoded values for the real part of the data.
 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
imag_decoded
\series default
: A tensor that stores the decoded values for the imaginary part of the
 data.
 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
decoded_shape
\series default
: A tuple that stores the shape of the input data for decoding.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Encoding Recipe: 
\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent

\size large
Loop over the binsx for the real and binsy for the imaginary parts, and
 check if the data value falls in the range of bin i and bin i+1.
\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent

\size large
Save all the values that fall in the bin as x_indices and y_indices.
 These indices behave more like coordinates for the matrix of binsxy.
\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent

\size large
Encoding is done by putting the indices in the binxy vector.
 The binxy vector returns a numerical token that represents the position
 of the complex plane.
\end_layout

\begin_layout Standard

\size large
Here's an elegant code implementation 
\end_layout

\begin_layout Standard

\size large
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
lstinputlisting[language=python,firstline=39, lastline=48]{Codigo/GridCode.py}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Networks/GridNet.png
	lyxscale 80
	scale 70

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Square grid enconding values with a step of 1/7 per cuadrant
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Decoding Recipe: 
\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent

\size large
Loop over the binsxy matrix and create a mask of indices that correspond
 to the encoded values
\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent

\size large
Use the mask of indices to assign values from the binsx and binsy vectors
 to the corresponding real and imaginary decoded vectors.
 Add half a step to each value to place it in the center of the bin.
\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent

\size large
Build a complex number vector using the real and imaginary decoded vectors.
\end_layout

\begin_layout Standard

\size large
Here's an elegant code implementation 
\end_layout

\begin_layout Standard

\size large
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
lstinputlisting[language=python,firstline=64, lastline=76]{Codigo/GridCode.py}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The gridding step ensures that all possible values in the complex plane
 are now bounded by the alphabet size |A|, which can be beneficial for neural
 networks even if it doesn't compromise the space between QAM points spacing.
 In the picture bellow we show some points that was enconded and decoded,
 and we appreciate how they are centered after decoding.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Networks/SquareGridDegrid.png
	lyxscale 50
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Points after encoding and decoding, shown in a centered position of the
 binxy
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Polar Grid
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The Polar Grid is quite similar to the number ordering of the Square Grid,
 as it starts with 4 as its initial number.
 However, in this code implementation, instead of having x and y bins, we
 will have radius and angle bins.
 One thing to note is that now we have two steps that can be totally independent
: one step for the radius and the other for the angle.
 In the Square Grid, the step was the same for both x and y coordinates.
 One main advantage of the polar grid is that we don't need to take care
 of the angle measurement error, as the encoding will handle it within the
 transformer.
 However, the polar grid uses more space with fewer patches compared to
 the square grid.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Codigo/UML/RadGrid.png
	lyxscale 70
	scale 70

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Class attributes for the Radial Grid
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
step_radius
\series default
: Steps between 0 and 1
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
step_angle
\series default
: Steps between 0 and 
\begin_inset Formula $\boldsymbol{\pi}$
\end_inset


\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
binsr
\series default
: Number of bins for radius
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
binsa
\series default
: Numbers of bins for angles
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
binra
\series default
: Combined Grid between radius and angle.
 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Encoding Recipe: 
\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent

\size large
Loop over the binsr for the radius and binsa for the angle, and check if
 the data value falls in the range of bin i and bin i+1.
\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent

\size large
Save all the values that fall in the bin as r_indices and a_indices.
 These indices behave more like coordinates for the matrix of binsra.
\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent

\size large
Encoding is done by putting the indices in the binra vector.
 The binra vector returns a numerical token that represents the position
 of the complex plane.
\end_layout

\begin_layout Standard

\size large
Here's an elegant code implementation 
\end_layout

\begin_layout Standard

\size large
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
lstinputlisting[language=python,firstline=38, lastline=49]{Codigo/RadGrid.py}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Networks/RadGrid.png
	lyxscale 80
	scale 80

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Radial Grid encoding values.
 Radius step = 0.25 and angle step = pi/6
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Decoding Recipe: 
\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent

\size large
Loop over the binsra matrix and create a mask of indices that correspond
 to the encoded values
\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent

\size large
Use the mask of indices to assign values from the binsr and binsa vectors
 to the corresponding radius and angle decoded vectors.
 Add half a step to each value to place it in the center of the bin.
\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent

\size large
Build a complex number vector using the magnitud and phase decoded vectors.
\end_layout

\begin_layout Standard

\size large
Here's an elegant code implementation 
\end_layout

\begin_layout Standard

\size large
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
lstinputlisting[language=python,firstline=59, lastline=74]{Codigo/RadGrid.py}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Similarly to the square grid, the values in the polar grid are also centered
 in the grid during decoding, thus closing again the possible states of
 the points in the complex plane.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Networks/RadGridOriginalData.png
	lyxscale 50
	scale 57

\end_inset


\begin_inset Graphics
	filename Imagenes/Networks/RadGridOriginal_Decoded_Data.png
	lyxscale 50
	scale 57

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Points after encoding and decoding, shown in a centered position of the
 binra
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Transformer implementation
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Our transformer implementation can handle both grids by simply changing
 a hyperparameter, which provides a generic interface for experimentation.
 For positional embedding, we use a logical sequence of numbers ranging
 from 0 to 48 positions.
 Although there were some experiments with the sin embedding, it did not
 work well for this task.
 We apply a padding mask to the source and pass it to the transformer.
 The transformer is not a custom implementation but rather a predefined
 block already available in PyTorch that contains an encoder and decoder.
 Note that we implemented a transformer from scratch during the study of
 this network, but we decided to use PyTorch's standard APIs instead.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The vocabulary size is determined based on the number of patches we have
 in the grid strategy.
 This means that the number of possible values that a patch can take in
 the grid is equal to the number of patches in the grid.
 For example, if we have a grid with 25 patches, then the vocabulary size
 is 25.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The loss function used in the training process is given by the cross-entropy
 
\color blue

\begin_inset CommandInset ref
LatexCommand formatted
reference "subsec:Cross-Entropy-Loss"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
.
 This is a commonly used loss function for multi-class classification tasks,
 such as image classification.
 Mathematically, the cross-entropy loss measures the distance between the
 predicted probability distribution and the true probability distribution.
 In the context of the grid encoding task, the predicted probability distributio
n is the distribution over the patches in the grid, and the true probability
 distribution is a one-hot vector representing the true patch in the grid.
 The figure 
\begin_inset CommandInset ref
LatexCommand formatted
reference "fig:Transformer-with-encoder"
plural "false"
caps "false"
noprefix "false"

\end_inset

 in the state of the art can be used to visualize the transformer architecture
 , at the right is placed the transformer decoder which its has output the
 output probabilities for symbol 
\begin_inset Formula $A_{i}$
\end_inset

 using the softmax function 
\begin_inset CommandInset ref
LatexCommand formatted
reference "fig:Softmax"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Codigo/UML/GridNet.png
	lyxscale 50
	scale 40

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
GridNet Workflow
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Autoregression in predicting mode
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Autoregression in a Transformer refers to the technique of feeding previously
 generated output tokens as input to the model in order to generate subsequent
 tokens.
 In other words, the model generates one token at a time, and each token
 is conditioned on the previously generated tokens.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
This autoregression technique is achieved in a Transformer through a process
 called self-attention.
 Self-attention allows the model to capture dependencies between different
 positions in the input sequence by weighing each input token's relevance
 to the current token being generated.
 During training, the model learns to attend to the most relevant tokens
 from the previous generated output, which in turn influences the distribution
 of probabilities over the vocabulary for the next token.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
In practice, autoregression in a Transformer involves a process called decoding,
 where the model generates tokens one at a time, starting with a special
 start-of-sequence <sos> token and continuing until a special end-of-sequence
 <eos> token is generated or a maximum sequence length is reached.
 The output tokens generated by the model at each decoding step are fed
 back as input to the model for the next step, creating a feedback loop
 that allows the model to incorporate information from previously generated
 tokens to generate subsequent ones.
\end_layout

\begin_layout Subsubsection
Noise in Trainning
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
This network is the only one that uses variable noise ratios during training
 to help the model generalize better.
 The noise varies each epoch and is determined by the following equation:
\end_layout

\begin_layout Standard

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{SNR_{dB}=45-5\times(mod(Epoch,4))}
\end{equation}

\end_inset


\end_layout

\begin_layout Subsubsection
Transformer hyperparameters
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
In this section, we first list the hyperparameters that directly affect
 the final parameter size of the model.
 Before we show the table, let's review the meaning of the parameters to
 better understand the hyperparameters table.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
Embedding_size
\series default
: the embedding size refers to the size of the vector that is used to represent
 each input token in the network.
 Each token in the input sequence is mapped to a high-dimensional vector
 of fixed size, which is called the embedding.
 The embedding captures the semantic meaning of the token in a continuous
 vector space, which can be learned by the network during training.
 In practice, the embedding size is often set to a value between 100 and
 1000, depending on the size of the input vocabulary and the complexity
 of the task
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
Num_heads
\series default
: Is a hyperparameter that controls the number of parallel self-attention
 mechanisms in the network.
 Self-attention is a mechanism that allows the model to weigh the importance
 of different positions in the input sequence when making a prediction.
 Self-attention is applied to the input sequence multiple times, with different
 linear projections of the input sequence used as inputs to each attention
 mechanism
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
Encoder and Decoder Layers
\series default
: The output of the encoder layer is a sequence of hidden representations
 that captures the relevant information from the input sequence.Both the
 encoder and decoder layers can be stacked multiple times to improve the
 quality of the feature representation and the final output sequence.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
Forward Expansion
\series default
: After performing multi-head attention on the input, the result is passed
 through a feedforward neural network (FFN) layer, which typically consists
 of two fully connected layers with a ReLU activation function in between,
 in our case was ever setup to GELU activation function.
 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
Dropout
\series default
: The dropout rate to apply during training to prevent overfitting.
 This value typically ranges between 0.1 and 0.3.
\end_layout

\begin_layout Standard

\size large
Other parameters, such as CONJ_ACTIVE, refer to the same preprocessing step
 of taking the conjugate of the channel 
\begin_inset Formula $H^{H}Y$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{table}[h] 
\backslash
centering  
\backslash
begin{tabular}{|l|l|} 
\backslash
hline 
\backslash
textbf{Hyperparameters} & 
\backslash
textbf{Value} 
\backslash

\backslash
 
\backslash
hline BATCHSIZE & 100 
\backslash

\backslash
 
\backslash
hline QAM & 16 
\backslash

\backslash
 
\backslash
hline NUM
\backslash
_EPOCHS & 24 
\backslash

\backslash
 
\backslash
hline SNR & 45-25 
\backslash

\backslash
 
\backslash
hline CONJ
\backslash
_ACTIVE & True 
\backslash

\backslash
 
\backslash
hline NOISE & True 
\backslash

\backslash
 
\backslash
hline LEARNING
\backslash
_RATE & .0001 
\backslash

\backslash
 
\backslash
hline GRID & Square 
\backslash

\backslash
 
\backslash
hline STEP & 1/7 
\backslash

\backslash
 
\backslash
hline 
\backslash
end{tabular} 
\backslash
caption{Square GridNet hyperparameters} 
\backslash
label{tab:transformer_hyper} 
\backslash
end{table}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{table}[h] 
\backslash
centering  
\backslash
begin{tabular}{|l|l|} 
\backslash
hline 
\backslash
textbf{Hyperparameters} & 
\backslash
textbf{Value} 
\backslash

\backslash
 
\backslash
hline BATCHSIZE & 100 
\backslash

\backslash
 
\backslash
hline QAM & 16 
\backslash

\backslash
 
\backslash
hline NUM
\backslash
_EPOCHS & 13 
\backslash

\backslash
 
\backslash
hline SNR & 45-20 
\backslash

\backslash
 
\backslash
hline CONJ
\backslash
_ACTIVE & True 
\backslash

\backslash
 
\backslash
hline NOISE & True 
\backslash

\backslash
 
\backslash
hline LEARNING
\backslash
_RATE & .0001 
\backslash

\backslash
 
\backslash
hline GRID & Polar 
\backslash

\backslash
 
\backslash
hline STEP
\backslash
_RADIUS & 0.25 
\backslash

\backslash
 
\backslash
hline STEP
\backslash
_ANGLE & $
\backslash
pi/6$ 
\backslash

\backslash
 
\backslash
hline 
\backslash
end{tabular} 
\backslash
caption{Polar GridNet hyperparameters} 
\backslash
label{tab:transformer_hyper} 
\backslash
end{table}
\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Parameters
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{table}[H] 
\backslash
centering 
\backslash
begin{tabular}{|l|l|} 
\backslash
hline 
\backslash
textbf{Name} & 
\backslash
textbf{Value} 
\backslash

\backslash
 
\backslash
hline loss
\backslash
_f & CrossEntropyLoss 
\backslash

\backslash
 
\backslash
hline src
\backslash
_word
\backslash
_embedding & Embedding (101 K) 
\backslash

\backslash
 
\backslash
hline src
\backslash
_position
\backslash
_embedding & Embedding (25.6 K) 
\backslash

\backslash
 
\backslash
hline trg
\backslash
_word
\backslash
_embedding & Embedding (101 K) 
\backslash

\backslash
 
\backslash
hline trg
\backslash
_position
\backslash
_embedding & Embedding (25.6 K) 
\backslash

\backslash
 
\backslash
hline transformer & Transformer (44.1 M) 
\backslash

\backslash
 
\backslash
hline fc
\backslash
_out & Linear (102 K) 
\backslash

\backslash
 
\backslash
hline dropout & Dropout (0) 
\backslash

\backslash
 
\backslash
hline 
\backslash
multicolumn{2}{|l|}{Total params: 44.5 M} 
\backslash

\backslash
 
\backslash
multicolumn{2}{|l|}{Total estimated model params size (MB): 177.990} 
\backslash

\backslash
 
\backslash
hline 
\backslash
end{tabular} 
\backslash
caption{Square Grid Transformer Parameters} 
\backslash
label{tab:polar-grid-transformer-parameters} 
\backslash
end{table}
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{table}[H] 
\backslash
centering 
\backslash
begin{tabular}{|l|l|} 
\backslash
hline 
\backslash
textbf{Name} & 
\backslash
textbf{Value} 
\backslash

\backslash
 
\backslash
hline loss
\backslash
_f & CrossEntropyLoss 
\backslash

\backslash
 
\backslash
hline src
\backslash
_word
\backslash
_embedding & Embedding (26.1 K) 
\backslash

\backslash
 
\backslash
hline src
\backslash
_position
\backslash
_embedding & Embedding (25.6 K) 
\backslash

\backslash
 
\backslash
hline trg
\backslash
_word
\backslash
_embedding & Embedding (26.1 K) 
\backslash

\backslash
 
\backslash
hline trg
\backslash
_position
\backslash
_embedding & Embedding (25.6 K) 
\backslash

\backslash
 
\backslash
hline transformer & Transformer (69.3 M) 
\backslash

\backslash
 
\backslash
hline fc
\backslash
_out & Linear (26.2 K) 
\backslash

\backslash
 
\backslash
hline dropout & Dropout (0) 
\backslash

\backslash
 
\backslash
hline 
\backslash
multicolumn{2}{|l|}{Total params: 69.5 M} 
\backslash

\backslash
 
\backslash
multicolumn{2}{|l|}{Total estimated model params size (MB): 277.842} 
\backslash

\backslash
 
\backslash
hline 
\backslash
end{tabular} 
\backslash
caption{Polar Grid Transformer Parameters} 
\backslash
label{tab:polar-grid-transformer-parameters} 
\backslash
end{table}
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
To summarize, the Radial Grid prioritizes investing less in the vocabulary
 size and compensating for it by adjusting other hyperparameters such as
 multi-head attention and increasing the number of feedforward parameters
 in order to achieve better results.
\end_layout

\begin_layout Section
Results
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The equalization of signals in telecommunications is a challenging problem,
 particularly when dealing with noisy scenarios.
 To evaluate the effectiveness of various equalization methods, we conducted
 an average of five experiments in a consistent manner and then averaged
 the results.
 This methodology helps to smooth out the curves and provide a reliable
 representation of the performance of each method.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
In our research, we focused on both noisy and non-noisy scenarios and evaluated
 the performance of our method across a wide range of signal-to-noise ratios
 (SNRs) ranging from 45 to 5 with a step of 2 between each SNR.
 This comprehensive evaluation helped us to identify the strengths and weaknesse
s of each method and determine which methods are most effective in different
 scenarios.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Our performance metrics are the
\color blue
 
\begin_inset CommandInset ref
LatexCommand nameref
reference "subsec:BER"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
 (Bit Error Rate) and 
\color blue

\begin_inset CommandInset ref
LatexCommand nameref
reference "subsec:BLER"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
 (Block Error Rate) , which have been explained in the theoretical framework.
 BER measures the ratio of incorrectly received bits to the total number
 of transmitted bits, while BLER measures the ratio of incorrectly received
 blocks to the total number of transmitted blocks.
 A lower value for both metrics indicates better performance of the system.
\end_layout

\begin_layout Subsubsection
Contributions
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
One of the key contributions of our research is the development of new networks
 specifically designed for this task.
 PhaseNet, PolarNet, and ComplexNet are completely new contributions to
 the state of the art, as they were developed from scratch specifically
 for this research.
 These networks incorporate some preprocessing techniques taken from the
 state of the art, but the frame sizes used in other studies are relatively
 small compared to the 48 required in this work.
 Furthermore, we not only dealt with QPSK but also with 16QAM, which required
 consideration of both phase and amplitude.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
In contrast, MobileNet and GridNet are based on existing models with some
 modifications.
 However, in the case of GridNet, the Polar Grid preprocessing stage is
 entirely new and unexplored, which adds a new dimension to the state-of-the-art
 in signal equalization and deep learning.
 The Polar Grid can be thought of as a natural evolution required from the
 existing Square Grid.
 However, the use of transformers in deep learning is a cutting-edge technique
 that is still in the experimental stage for image recognition and natural
 language processing.
 Therefore, researchers have not had to deal with the requirement of complex
 numbers, which can be treated in a polar system and consequently in the
 Polar Grid.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
After conducting some research, we found that there is no existing paper
 or document discussing the use of transformers in the signal processing
 scenario.
\end_layout

\begin_layout Subsection
PhaseNet
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The angle error adjustment implemented in the PhaseNet methodology has been
 found to be very useful for signal equalization.
 The network performs well across a range of signal-to-noise ratios, from
 5dB to 35dB.
 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
However, the graph shows a fall in performance at an SNR of 35dB compared
 to 45dB.
 This is because the model was trained using data with an SNR of 35dB, as
 indicated in the hyperparameters table of PhaseNet.
 When the model encounters new data with less noise, it does not equalize
 the signal as well as it was trained to do.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Therefore, it is important to carefully balance the SNR of the training
 data to ensure that the model can perform well across a wide range of noise
 conditions.
 This will help to improve the generalization ability of the model and ensure
 that it can handle various noise conditions.
 By doing so, the model can provide more reliable and accurate signal equalizati
on in practical applications.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/PhaseNET/QPSK_vs_LMMSE_PhasNet.png
	lyxscale 70
	scale 80

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
QPSK BER : PhaseNet vs.
 LMMSE
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
On the other hand, the block error rate performs very well and reduces the
 highest noise scenario to an order of magnitude.
 This helps to show that erroneous bits are specific outlier groups in certain
 blocks, and in general, the equalizer guarantees good frame recovery.
 Next, we can observe the same effect explained in the last paragraph about
 the 35dB fall.
 However, there is another fall in the BLER at 20dB SNR values.
 One possible reason for this is that the noise is canceling some factor
 of the channel, causing these points to be closer together and causing
 the network to find some points as the best ones.
 But this is not possible in noisier scenarios because the noise has much
 power.
 For 20dB, the signal is 100 times stronger than the noise, and an increase
 of 10dB represents a tenfold increase in noise power, which essentially
 means that information is lost and not feasible to recover.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/BLER/Results_PhaseNet-10_3_2023-23_39.png
	lyxscale 80
	scale 80

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
QPSK BLER : PhaseNet vs.
 LMMSE
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsection
PolarNet
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
This network combines a 16-PSK PhaseNet equalization with an additional
 MagNet equalization.
 In this model, we assume that phase and magnitude are completely separate
 from each other.
 One of the main reasons is to maintain a more modular architecture, which
 means that in a future implementation, it can be equalized a 16-PSK or
 16-QAM with almost the same processing stages.
 Another key feature is that each network is specialized, reducing the error
 to only its specific task.
 Therefore, in theory, this will make the error not influence each other.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Observing the graph below, it can be seen that the model flattens at a BER
 of 
\begin_inset Formula $10^{-3}$
\end_inset

 from 30dB to 45dB.
 The main reason errors get stuck in neural networks is that they are generalize
rs, which means that they learn to make predictions based on patterns in
 the training data.
 Therefore, all points seen forward should be treated with the expected
 behavior.
 In the case of training both networks and given MSE error applied to both
 in the training stages, the least error was from 
\begin_inset Formula $10^{-4}$
\end_inset

, which is pretty good enough of a nueronal networks using MSE.
 However, when we mixed both networks, the error increases to 
\begin_inset Formula $10^{-3}$
\end_inset

, resulting in an almost linear relation with BER.
 Finnally we can se the same valley pattern in 20-25dB, as a result of the
 PhaseNet integration in the Polarnet.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/PolarNet/Polar_16QAM.png
	lyxscale 70
	scale 80

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
16-QAM BER: PolarNet vs.
 LMMSE 
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing double

\size large
For the BLER graph, we can visualize a smoother performance with lower values
 between 35dB and 15dB, and it almost saturates at the same point as the
 LMMSE.
 It can be seen that the same model error truncation applies to this metric,
 but it is not so far away from the golden model in the lowest noise scenarios.
 In general, this means that most of the BLER is given by outlier values,
 and the system can equalize consistently between a certain quantity of
 blocks.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/BLER/Results_PolarNet-10_3_2023-23_36.png
	lyxscale 80
	scale 80

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
16-QAM BLER: PolarNet vs.
 LMMSE
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsection
ComplexNet
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
In complex net we try two different loss functions to traing the neuronal
 network.
 However, logarithmic polar loss was not as effective because it produced
 high loss numbers that were larger than 1, which may not be very meaningful
 for the network.
 As a result, the network had difficulties updating its weights and optimizing
 its performance using this loss function.
 On the other hand, the complex MSE loss was much more effective because
 its output values were lower than those of the initial loss functions.
 This made it easier for the networks to determine which parameters were
 good or not.
 By using an effective loss function, the network can optimize its performance
 and achieve higher accuracy in its predictions.
 This is particularly important in communication systems where accuracy
 and reliability are critical for successful operation.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/ComplexNet/ComplexNet.png
	lyxscale 70
	scale 80

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
16-QAM BER: ComplexNet with Two Losses vs.
 LMMSE
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
In the BLER results, we avoided plotting the ComplexNet Polar Loss training
 because it performed poorly with a BLER of 1 across all blocks.
 On the other hand, Abs loss networks attempted to approximate the golden
 standard, but were not quite good enough.
 One of the main reasons for this is that the proposed methods in the state-of-t
he-art literature and the ones implemented in our research are not mature
 enough to help with the equalization task.
 As seen in 
\begin_inset CommandInset citation
LatexCommand cite
key "A_Survey_of_Complex_valued_nueronal_Netoworks"
literal "false"

\end_inset

, there are some assumptions about the activation functions in the complex
 plane.
 Additionally, we used automatic differentiation provided by the pytorch
 framework, which may have struggled with complex conjugation.
 Implementing a solution from complex differentiation can be challenging
 and may require a separate research project for someone with strong mathematica
l skills.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/BLER/Results_ComplexNet-10_3_2023-23_43.png
	lyxscale 80
	scale 80

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
16-QAM BLER: ComplexNet with Two Losses vs.
 LMMSE
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsection
MobileNet
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Although MobileNet was not very effective, it is still considered one of
 the fastest convolutional neural networks in the state of the art in terms
 of processing speed.
 From SNR23 and below, it could be a viable option instead of zero forcing.
 In fact, it performs better than zero forcing in the range of 15dB to 25dB,
 which is encouraging because it supports the hypothesis that it is essentially
 a zero forcing with noise consideration.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/MobileNEt/MobileNet_16QAM.png
	lyxscale 70
	scale 80

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
16-QAM BER: MobileNet vs.
 ZeroForcing
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Since the MobileNet has knowledge of the noise and works as a denoiser,
 its block rate is lower than the golden model until it is permitted.
 Consequently, we naturally obtain an error model that ranges from 35dB
 to high SNR, while this one is performing better than the zero-forcing
 method at lower SNR than 30dB.
 It is important to note, however, that the MobileNet has a higher computational
 complexity, and there is a trade-off between computational speed and accuracy.
 Nevertheless, MobileNet is one of the fastest and most lightweight convolutiona
l neural networks in the state of the art.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/BLER/Results_MobileNet-10_3_2023-23_45.png
	lyxscale 80
	scale 80

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
16-QAM BLER: MobileNet vs.
 ZeroForcing
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsection
GridNet
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
We conducted experiments with different grid steps for GridNet Square and
 found that the best step size was 1/7.
 In conclusion, having more batches in the complex planes results in higher
 resolution but lower tolerance to noise, as the networks can quickly overfit.
 On the other hand, using larger steps means that points affected by noise
 fall within the same region or closer to each other, which could be advantageou
s in noisy scenarios.
 However, having squares that are too large could be harmful for final equalizat
ion because the grids can be bigger than the distances between the ideal
 constellation points.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/GridNet/SquareGrid.png
	lyxscale 80
	scale 80

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
16-QAM BER: GridNet Square Grid vs LMMSE
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/BLER/Results_GridNetSquare-11_3_2023-0_24.png
	lyxscale 80
	scale 80

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
16-QAM BLER: GridNet Square Grid vs LMMSE
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
GridNet with a polar grid resulted in some of the best performance between
 25dB and 45dB.
 Our hypothesis that the attention mechanisms used are highly effective
 in reducing inter-symbol interference (ISI) is true, such that the channel
 and noise are almost completely recovered.
 However, below 25dB, the model cannot handle the noise as effectively and
 begins to present errors.
 We trained the model with variable noise levels ranging from 25dB to 45dB,
 and the hypothesis that the best equalization occurs within this range
 is supported by the image below.
 It may seem that reducing the noise training range could result in better
 performance within the training range, but this idea is incorrect.
 Training the network with more noise scenarios would cause the network
 to learn more about the noise than the relevant data, resulting in a noisy
 overfit.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/GridNet/Results_-12_3_2023-22_49.png
	lyxscale 80
	scale 80

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
16-QAM BER: GridNet Polar Grid vs LMMSE
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/BLER/Results_GridNetPolar-12_3_2023-22_34.png
	lyxscale 80
	scale 80

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
16-QAM BLER: GridNet Polar Grid vs LMMSE
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Comparing both methods, Square and Polar, we notice that Polar performs
 better from 15dB and beyond, but for the noisier scenarios, Square Net
 is the better option.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Caption Standard

\begin_layout Plain Layout
GridNet Both Grid comparison and LMMSE
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
All methods comparison
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
In a general perspective, PolarNet appears to perform well in the presence
 of noise and could be a good choice due to its low memory footprint.
 It can be considered the winner in the range between 13dB and 23dB.
 However, in the most critical scenarios, it may not be the best option.
 If we want to trade off between fast processing and accuracy, PolarNet
 is the ideal choice.
 For less noisy scenarios above 25dB, GridNet Polar is the winner.
 And for the most noisy scenarios, GridNet Square is the best option.
 If the SNR noise is well known in a production application, a good idea
 would be to mix these three networks for different scenarios to produce
 the best equalizer.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/All/GeneralView1.png
	lyxscale 70
	scale 70

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
General View of all methods
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/All/GeneralViewUntil25Db.png
	lyxscale 80
	scale 80

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Closer look to all methods, from 5db to 27dB
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
Taking a closer look at the most noisy scenario, we can see that GridNet
 Square achieves the best equalization performance, followed by GridNet
 Polar, and last but not least, PolarNet.
\size default

\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/All/GeneralViewUntil14dB.png
	lyxscale 80
	scale 80

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Closer look to all methods, from 5db to 16dB
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
FLOPS
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
In this section, we estimated the complexity of the model and calculated
 the FLOPS for each equalizer.
 To accomplish this task, we used the execution time and performed a static
 code analysis to estimate the number of parameters.
 By considering both the number of parameters and the execution time, we
 could approximate the FLOPS of the equalizers.
 Additionally, it is important to consider the processor and operating system
 on which the algorithms run.
 In the table below, we provide a detailed description of the specifications
 of the system used to conduct the experiments.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{table}[htbp]   
\backslash
centering   
\backslash
caption{Processor specifications}    
\backslash
begin{tabular}{|l|l|}     
\backslash
hline     Property & Value 
\backslash

\backslash
  
\backslash
hline     Architecture & x86
\backslash
_64 
\backslash

\backslash
 
\backslash
hline    CPU op-mode(s) & 32-bit, 64-bit 
\backslash

\backslash
  
\backslash
hline   Address sizes & 43 bits physical, 48 bits virtual 
\backslash

\backslash
 
\backslash
hline    Byte Order & Little Endian 
\backslash

\backslash
 
\backslash
hline   CPU(s) & 16 
\backslash

\backslash
  
\backslash
hline   Model name & AMD Ryzen 7 3700X 8-Core Processor 
\backslash

\backslash
 
\backslash
hline    CPU family & 23 
\backslash

\backslash
 
\backslash
hline    Model & 113 
\backslash

\backslash
 
\backslash
hline     Thread(s) per core & 2 
\backslash

\backslash
 
\backslash
hline    Core(s) per socket & 8 
\backslash

\backslash
 
\backslash
hline     Frequency boost & enabled 
\backslash

\backslash
 
\backslash
hline    CPU max MHz & 4426.1709 
\backslash

\backslash
   
\backslash
hline  CPU min MHz & 2200.0000 
\backslash

\backslash
  
\backslash
hline   BogoMIPS & 7186.16 
\backslash

\backslash
  
\backslash
hline      
\backslash
end{tabular}   
\backslash
label{tab:processor_specs} 
\backslash
end{table}
\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
LMMSE
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The matrix inversion operation requires 
\begin_inset Formula $O(n^{3})$
\end_inset

 operations, where n is the matrix size.
 Therefore, the total number of operations involved in this operation is
 48 x 48 x 2 for the conjugate and Hermitian transpose operations, 48 x
 48 x 48 x 2 for the matrix multiplication operations, 48 x 48 x 3 for the
 identity matrix, scalar multiplication, and matrix addition operations,
 and 
\begin_inset Formula $O(n^{3})$
\end_inset

 for the matrix inversion operation.
 Combining these operations yields a total of 223,872 operations for this
 particular operation.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{table}[H] 
\backslash
centering 
\backslash
caption{Number of Operations by Type} 
\backslash
label{tab:operations} 
\backslash
begin{tabular}{|l|l|} 
\backslash
hline Operation & Number of Operations 
\backslash

\backslash
 
\backslash
hline Conjugate & $48 
\backslash
times 48 
\backslash
times 2$ 
\backslash

\backslash
 
\backslash
hline Hermitian transpose & $48 
\backslash
times 48 
\backslash
times 2$ 
\backslash

\backslash
 
\backslash
hline Matrix multiplication & $48 
\backslash
times 48 
\backslash
times 48 
\backslash
times 2$ 
\backslash

\backslash
 
\backslash
hline Identity matrix & $48 
\backslash
times 48 
\backslash
times 1$ 
\backslash

\backslash
 
\backslash
hline Scalar multiplication & $48 
\backslash
times 48 
\backslash
times 1$ 
\backslash

\backslash
 
\backslash
hline Matrix addition & $48 
\backslash
times 48 
\backslash
times 3$ 
\backslash

\backslash
 
\backslash
hline Matrix inversion (approximate) & 110,592 
\backslash

\backslash
 
\backslash
hline Matrix multiplication & $48 
\backslash
times 48 
\backslash
times 2$ 
\backslash

\backslash
 
\backslash
hline 
\backslash
textbf{Total number of operations} & 
\backslash
textbf{223,872} 
\backslash

\backslash
 
\backslash
hline 
\backslash
end{tabular} 
\backslash
end{table}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard

\size large
The time measurements in the code give an average time of 5.96e-02, which
 is equal to t = 59.6 ms.
 Therefore, the estimated FLOPS is calculated as follows:
\end_layout

\begin_layout Standard

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{FLOPS\simeq\frac{1}{59.6ms}\times223,872=3.74\times10^{6}}
\end{equation}

\end_inset


\end_layout

\begin_layout Subsubsection
Zero Forcing
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Extract diagonal: self.Chann_diag(chann).
 This involves 48 extractions of diagonal elements.
 Element-wise division: Y/self.Chann_diag(chann).
 This involves 48 divisions of complex numbers.
 So the total number of operations in this line of code is approximately
 48*2 = 96.
 The time measurements in the code give an average time of 2.62e-03, which
 is equal to t = 2.62 ms.
 Therefore, the estimated FLOPS is calculated as follows:
\end_layout

\begin_layout Standard

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{FLOPS\simeq\frac{1}{2.62ms}\times96=36\times10^{3}}
\end{equation}

\end_inset


\end_layout

\begin_layout Subsubsection
PhaseNet,PolarNet, ComplexNet
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Given the in the methodology seciton the total number of operations in the
 forward pass is approximately 1,761,808.
 To calculate the FLOPS, we need to divide the total number of operations
 by the execution time which give us 1.19e-01.
 Therefore, the approximate FLOPS for this model is:
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{FLOPS\simeq\frac{1,761,808}{.119}=14.8\times10^{6}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
for Polar Net is 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{FLOPS\simeq\frac{1,761,808+5,856}{.392}=4.5\times10^{6}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
and for ComplexNet is
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{FLOPS\simeq\frac{484,248}{.173}=2.7\times10^{6}}
\end{equation}

\end_inset


\end_layout

\begin_layout Subsubsection
MobileNet
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{FLOPS\simeq\frac{3,236,000}{.834}=3.88\times10^{6}}
\end{equation}

\end_inset


\end_layout

\begin_layout Subsubsection
GridNet
\end_layout

\begin_layout Standard
for GridNet Square is 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{FLOPS\simeq\frac{44.5\times10^{6}}{1.93}=23.05\times10^{6}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
for GridNet Polar is 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{FLOPS\simeq\frac{69.5\times10^{6}}{2.5}=27.8\times10^{6}}
\end{equation}

\end_inset


\end_layout

\begin_layout Subsubsection
Ranking by FLOPS
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{table}[H] 
\backslash
centering 
\backslash
caption{FLOPS Ranking} 
\backslash
label{tab:operations} 
\backslash
begin{tabular}{|l|l|} 
\end_layout

\begin_layout Plain Layout


\backslash
hline Name & FLOPS 
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

Zero Forcing & $36
\backslash
times10^{3}$ 
\backslash

\backslash
 
\backslash
hline 
\end_layout

\begin_layout Plain Layout

ComplexNet & $2.7
\backslash
times10^{6}$ 
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

LMMSE & $3.74
\backslash
times10^{6}$ 
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

MobileNet & $3.88
\backslash
times10^{6}$ 
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

PolarNet & $4.5
\backslash
times10^{6}$ 
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

PhaseNet & $14.8
\backslash
times10^{6}$ 
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

GridNet Square & $23.05
\backslash
times10^{6}$ 
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

GrideNet Polar & $27.8
\backslash
times10^{6}$ 
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout


\backslash
end{tabular} 
\backslash
end{table}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Section
Conclusion and Outlook
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
In conclusion, the field of neural networks has seen tremendous advancements
 in recent years, with the development of more complex architectures, such
 as deep neural networks, convolutional neural networks, and transformers.
 It is essential to strike a balance between accuracy and memory footprint
 for signal equalization to avoid affecting data throughput.
 These advancements have led to significant improvements in the ability
 of neural networks to process complex data, including doubly dispersive
 channels.
 These developments have resulted in numerous practical applications, ranging
 from self-driving cars and drone flying to the development of new 6G technologi
es.
 However, despite the remarkable progress made in the field, there are still
 many challenges that need to be addressed, such as reducing noise overfitting,
 managing outliers, MIMO signal cleaning, and the need for more formal mathemati
cal descriptions of some network architectures.
 Further research is necessary to continue to advance the field and unlock
 the full potential of neural networks in the telecom area, which is an
 area that is just starting to show its potential.
\end_layout

\begin_layout Subsection
Future Work
\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent

\size large
Model quantization is a technique for reducing the memory footprint and
 computational cost of deep neural networks by converting the weights and
 activations of the network to a lower numerical precision format.
 This typically involves converting floating-point values to fixed-point
 or integer values, which requires fewer bits to represent the same range
 of values.Quantization can significantly reduce the memory and power requirement
s of neural networks, making them more suitable for deployment on resource-const
rained devices such as mobile phones and embedded systems.
 However, it can also lead to a loss of accuracy, particularly when using
 low-precision formats.
 Therefore, adjustments need to be made to the network architecture and
 training process to ensure that the quantized network still achieves good
 performance.
 One example of a system that uses model quantization for efficient inference
 is Google's Coral platform.
 Coral is a hardware and software platform for developing and deploying
 machine learning models on edge devices such as the Raspberry Pi and Google's
 Tensor Processing Units (TPUs).
 Coral includes a set of tools for quantizing and compressing neural network
 models to run on the Coral Edge TPU, a custom ASIC designed for low-power,
 high-performance inference.
 The Edge TPU supports 8-bit integer quantization and provides up to 4 TOPS
 (trillion operations per second) of performance while consuming only a
 few watts of power.
 Coral's quantization tools include both post-training and quantization-aware
 training methods, and are compatible with popular deep learning frameworks
 such as TensorFlow and PyTorch.
\begin_inset CommandInset citation
LatexCommand cite
key "coral2020accelerator"
literal "false"

\end_inset


\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent

\size large
One potential future work is to use the latest reinforcement learning algorithms
 to discover a matrix inversion algorithm.
 AlphaTensor is a well-known network that discovers many provably correct
 matrix multiplication algorithms that improve over existing algorithms
 in terms of the number of scalar multiplications, and is adaptable to different
 use-cases, including discovering algorithms for structured matrix multiplicatio
n and optimizing for actual runtime.
 The results demonstrate that the space of matrix multiplication algorithms
 is richer than previously thought, and AlphaTensor can efficiently search
 this space to discover novel algorithms that outperform human-designed
 ones on the same hardware.
 Therefore, a possible future direction could be to create an algorithm
 that outperforms existing ones and achieves a time complexity of almost
 
\begin_inset Formula $O(N^{2})$
\end_inset

 for matrix inversion.
\begin_inset CommandInset citation
LatexCommand cite
key "alphatensor"
literal "false"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newpage
\end_layout

\end_inset


\end_layout

\begin_layout Section
References
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset CommandInset bibtex
LatexCommand bibtex
btprint "btPrintCited"
bibfiles "Bibliography"
options "plain"

\end_inset


\end_layout

\begin_layout Standard

\end_layout

\begin_layout Standard

\end_layout

\begin_layout Standard

\end_layout

\begin_layout Standard

\end_layout

\end_body
\end_document
