#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\begin_preamble
\usepackage{helvet}
\renewcommand{\familydefault}{\sfdefault}
\usepackage{ragged2e}
\usepackage{blindtext}
\usepackage{fancyhdr}
\usepackage{algorithm}
\usepackage{algpseudocode}
\pagestyle{fancy}
\fancyhead{}
\fancyhead[RO,LE]{Doubly dispersive channels equalization using deep learning techniques}
\fancyfoot[CO,RE]{Emilio Tonix}
\fancyfoot{}
\fancyfoot[LE,RO]{\thepage}
\fancyfoot[CO,RE]{Emilio Tonix}

\usepackage{listings}
\usepackage{xcolor}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}


\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}

\lstset{style=mystyle}
\end_preamble
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "Courier"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family rmdefault
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref true
\pdf_bookmarks true
\pdf_bookmarksnumbered false
\pdf_bookmarksopen false
\pdf_bookmarksopenlevel 1
\pdf_breaklinks false
\pdf_pdfborder true
\pdf_colorlinks false
\pdf_backref false
\pdf_pdfusetitle true
\papersize default
\use_geometry true
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 2.5cm
\topmargin 2.5cm
\rightmargin 2.5cm
\bottommargin 2.5cm
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Standard
\align center
\begin_inset Graphics
	filename Imagenes/Cinvestav_Logo-transformed.jpeg
	lyxscale 13
	scale 12

\end_inset


\end_layout

\begin_layout Standard
\align center

\size larger
Centro de Investigación y de Estudios Avanzados del I.P.N 
\end_layout

\begin_layout Standard
\align center

\size larger
Unidad Guadalajara 
\end_layout

\begin_layout Standard
\align center

\end_layout

\begin_layout Standard
\align center

\series bold
\size huge
\color black
Deep learning-based OFDM symbol detection in doubly dispersive channels
\end_layout

\begin_layout Standard

\series bold
\color white
.
\end_layout

\begin_layout Standard
\align center

\size larger
\color black
A thesis presented by:
\end_layout

\begin_layout Standard
\align center

\series bold
\size larger
\color black
Luis Emilio Tonix Gleason
\end_layout

\begin_layout Standard
\align center

\size larger
\color black
to obtain the degree of:
\end_layout

\begin_layout Standard
\align center

\series bold
\size larger
\color black
Master in Science
\end_layout

\begin_layout Standard
\align center

\size larger
\color black
in the subject of:
\end_layout

\begin_layout Standard
\align center

\series bold
\size larger
\color black
Electrical Engineering
\end_layout

\begin_layout Standard
\align center

\size larger
\color black
Thesis Advisors:
\end_layout

\begin_layout Standard
\align center

\series bold
\size larger
\color black
Dr.
 Ramón Parra Michel
\end_layout

\begin_layout Standard
\align center

\series bold
\size larger
\color black
Dr.
 Fernando Peña Campos
\end_layout

\begin_layout Standard
\align center

\end_layout

\begin_layout Standard
\align center

\series bold
\size larger
\color black
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill Guadalajara, Jalisco 
\backslash
today
\end_layout

\end_inset

 
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newpage
\end_layout

\end_inset


\end_layout

\begin_layout Section*
\noindent

\size huge
\color black
Acknowledgment 
\size large
\color inherit

\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newline
\end_layout

\end_inset

 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent
\align block

\size large
Thank you for reading this; I appreciate it.
 I'm expecting that your work will benefit greatly from this material.
 I won't hesitate to say that you might have done your job more effectively
 than I did.
 Progress in science is a way to skepticism and having the best information
 from multiple sources to meet your individual standards.
  
\end_layout

\begin_layout Standard

\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newpage
\end_layout

\end_inset


\end_layout

\begin_layout Section*

\size huge
Resumen 
\size large

\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newline
\end_layout

\end_inset

 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent
\align block

\size large
Las redes inalámbricas de alta movilidad, como la comunicación vehículo
 a vehículo (V2V), tienen aplicaciones en seguridad vial, conducción autónoma,
 monitoreo remoto de vehículos y 6G.
 Para ello, se utiliza el esquema de modulación OFDM, en el cual la información
 se divide en subportadoras que se transmiten simultáneamente con modulación
 de amplitud en cuadratura (QAM).
 En este caso, el canal sufre de fenómenos como la dispersión en frecuencia
 que comprometen la integridad de los datos recibidos.
 Para abordar esto, se presentan igualadores convencionales o iterativos,
 los cuales son más precisos pero requieren más tiempo de procesamiento.
 Dado el compromiso entre precisión y costo de procesamiento, este trabajo
 presenta soluciones basadas en redes neuronales como una alternativa para
 la tarea de igualación en el esquema de modulación OFDM.
 Dichas soluciones de aprendizaje profundo van desde las más sencillas (feedforw
ard) hasta las más complejas (transformers), y se consideran las métricas
 de tasa de error de bits (BER) y tasa de error de bloques (BLER) para evaluar
 la precisión de la igualación.
 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newline
\end_layout

\end_inset

 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
El propósito de este trabajo es desarrollar aproximaciones de la técnica
 de aprendizaje profundo al problema de ecualización de canales doble dispersivo
s en sistemas de comunicación con modulación OFDM, y comparar su desempeño
 contra las técnicas de ecualización lineales "Forzado a Cero", MSE, LMMSE,
 así como contra las técnicas no lineales OSIC y NearML.
 Durante las pruebas realizadas, se hizo un seguimiento de constelaciones
 QPSK y 16-QAM con una SNR de 5 dB hasta 45 dB.
 Se observó que algunas redes neuronales propuestas a lo largo del proyecto
 obtuvieron un BER menor que los modelos de referencia en ciertas regiones
 de SNR.
 Con ello, se puede visualizar un impacto potencial en los protocolos LTE
 y Wi-Fi, para proporcionar conectividad en V2V, ya que son tecnologías
 de comunicación inalámbrica que utilizan OFDM.
 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newline
\end_layout

\end_inset

 
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newpage
\end_layout

\end_inset


\end_layout

\begin_layout Section*

\size huge
Abstract
\size large
 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newline
\end_layout

\end_inset

 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
High-mobility wireless networks, such as vehicle-to-vehicle (V2V) communication,
 have applications in road safety, autonomous driving, remote vehicle monitoring
, and 6G.
 For this, the OFDM modulation scheme is used, in which information is divided
 into subcarriers that are transmitted simultaneously with quadrature amplitude
 modulation (QAM).
 In this case, the channel suffers from phenomena such as frequency dispersion
 that compromise the integrity of received data.
 To address this, conventional or iterative equalizers are presented, which
 are more accurate but require more processing time.
 Given the trade-off between accuracy and processing cost, this work presents
 deep learning-based solutions as an alternative for equalization in the
 OFDM modulation scheme.
 These deep learning solutions range from the simplest (feedforward) to
 the most complex (transformers), and the bit error rate (BER) and block
 error rate (BLER) metrics are considered to evaluate the accuracy of equalizati
on.
 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newline
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The purpose of this work is to present deep learning-based approximations
 of equalization techniques with linear nature, such as Zero Forcing, MSE,
 LMMSE, and non-linear techniques such as OSIC and NearML.
 During the conducted tests, QPSK and 16-QAM constellations were tracked
 with an SNR ranging from 5 dB to 45 dB.
 It was observed that some proposed neural networks throughout the project
 obtained a lower BER than reference models in certain SNR regions.
 This can potentially impact LTE and Wi-Fi protocols, providing connectivity
 for V2V, as they are wireless communication technologies that use OFDM.
 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newpage
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent
\align block

\end_layout

\begin_layout Standard
\begin_inset CommandInset toc
LatexCommand tableofcontents

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newpage
\end_layout

\end_inset


\end_layout

\begin_layout Standard

\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The main goal of this chapter is to provide an overview of the technical
 aspects necessary to understand the problem statement of this study.
\end_layout

\begin_layout Subsection
Document organization
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The structure of this document is as follows: 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\series bold
\size large
Chapter 1 Theoretical Framework: 
\series default
Fundamental ideas and concepts behind the current project.
 Outlines the core concepts necessary to comprehend this study.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\series bold
\size large
Chapter 2 State of Art:
\series default
 This section examines recent research on equalization using deep learning.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\series bold
\size large
Chapter 3 Methodology:
\series default
 This work presents a Python implementation of various models for training
 and testing different experiments, along with an overview of the software
 architecture that enables these experiments.
 The primary focus is on developing explainable deep learning models for
 Quadrature Amplitude Modulation (QAM) equalization using neural networks,
 including the design of the proposed models.
 Additionally, each network's features are described, such as preprocessing,
 number of parameters, hyperparameters, and references to the state-of-the-art
 that support certain development stages.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\series bold
\size large
Chapter 4 Results and Analysis:
\series default
 In this section, the conception and execution of the idea, the experiments
 conducted, and the analysis of the results are covered.
 A comparison of the studied models is provided in graphs and tables, with
 a focus on their bit error rate (BER), block error rate (BLER), floating-point
 operations per second (FLOPS), and complexity.
 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\series bold
\size large
Chapter 5 Conclusion and Outlook: 
\series default
A conclusion is drawn based on the results, contributions, and potential
 future directions of this study.
\end_layout

\begin_layout Subsection
\paragraph_spacing onehalf
Background
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
It takes a lot of expertise in the field of communications to model different
 types of channels, account for various channel flaws, and create the best
 signaling and detecting systems that guarantee a reliable data flow.
 The design of transmit signals in communications enables simple analytical
 techniques for symbol detection for a range of channel and system models,
 including multipath, doppler spread, and white Gaussian noise (AWGN) over
 constellation symbol detection.
 
\begin_inset CommandInset citation
LatexCommand cite
key "aghvami2005channel"
literal "false"

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newline
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
One of the guiding principles of communication system design is the division
 of signal processing into a series of distinct blocks as we seen in 
\color blue
Figure
\color inherit
 
\color blue

\begin_inset CommandInset ref
LatexCommand ref
reference "fig:TelecomBlocks"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
 , each of which performs a clearly defined and isolated functions such
 as source or channel coding, modulation, channel estimation, and equalization.
 
\begin_inset CommandInset citation
LatexCommand cite
key "proakis2002communication"
literal "false"

\end_inset

.
 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newline
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Diagrams/Typical_Block_Diagram.png
	lyxscale 50
	scale 40

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Typical communication system block diagram 
\begin_inset CommandInset label
LatexCommand label
name "fig:TelecomBlocks"

\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "ChannelDiagram"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
In this study, our main focus will be on the equalization stage.
 Our team has previously completed a project on channel estimation and equalizat
ion using classical QR methods, and we have also implemented an FPGA-based
 equalization stage for the 802.11p standard 
\begin_inset CommandInset citation
LatexCommand cite
key "V2V"
literal "false"

\end_inset

.
 The 802.11p standard is commonly used for V2V (Vehicle-to-Vehicle) communication
 with the OFDM modulation scheme.
 
\begin_inset CommandInset citation
LatexCommand cite
key "QRGonzalo"
literal "false"

\end_inset

.
 Therefore, the data is processed with a size of 48 symbols, resulting in
 a 48x48 channel.
 As a result, this work does not prioritize the channel estimation component.
 Instead, the main objective is to cancel the effects of the received signal
 through the channel and noise, which is well-known due to the previous
 research.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
By employing neural networks, we aim to generalize a pseudo-inverse non-linear
 system that cancels out channel and noise effects.
 However, it is important to note that the matrix inverse is not always
 well-defined, and its time complexity is 
\begin_inset Formula $O(N^{3})$
\end_inset

.
 The pseudo-inverse is a well-known technique used to solve matrix inversion
 problems when the matrix is not invertible or singular
\begin_inset CommandInset citation
LatexCommand cite
key "strang2019linear"
literal "false"

\end_inset

.
 Neural networks have been demonstrated to approximate any function 
\begin_inset CommandInset citation
LatexCommand cite
key "HORNIK1989359"
literal "false"

\end_inset

, and current research has demonstrated an astounding aptitude for algorithmic
 learning 
\begin_inset CommandInset citation
LatexCommand cite
key "8697857"
literal "false"

\end_inset

.
 Due to the challenge of defining real-world images or language with strict
 mathematical models, deep learning (DL) excels in fields like computer
 vision 
\begin_inset CommandInset citation
LatexCommand cite
key "MobileNet"
literal "false"

\end_inset

 and natural language processing
\begin_inset CommandInset citation
LatexCommand cite
key "transformer"
literal "false"

\end_inset

.
\end_layout

\begin_layout Subsection
OFDM
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
Orthogonal Frequency Division Multiplexing (OFDM) is a digital communication
 technique that divides the available bandwidth into a large number of narrowban
d subcarriers and transmits data by modulating the subcarriers with symbols.
 OFDM is widely used in wireless and wired communication systems, such as
 Wi-Fi, LTE, and DOCSIS, which are described by well-known standards, as
 referenced follows 
\begin_inset CommandInset citation
LatexCommand cite
key "WiFi"
literal "false"

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "LTE"
literal "false"

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "docsis4"
literal "false"

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent
\align block

\size large
The basic blocks of an OFDM system are described in 
\color blue
Figure2
\color inherit
:
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Diagrams/OFDM_typical.png
	lyxscale 50
	scale 40

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
OFDM basic diagram 
\begin_inset CommandInset citation
LatexCommand cite
key "OFDMdiagram"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Itemize

\series bold
\size large
Binary sequence
\series default
: This block generates the data to be transmitted.
 The data is usually a sequence of bits.
\end_layout

\begin_layout Itemize
\align block

\series bold
\size large
QAM mapping
\series default
: Bits are grouped into blocks called symbols usally named as alphabet 
\begin_inset Formula $\mathbb{A}$
\end_inset

.
 We have a set of bits 
\begin_inset Formula $2^{\mathbb{A}}$
\end_inset

 grouped inside the alphabet.
 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\align block

\series bold
\size large
IFFT block
\series default
: This block applies an Inverse Fast Fourier Transform (IFFT) to the modulated
 symbols, dividing them into a set of subcarriers.
\end_layout

\begin_layout Itemize
\align block

\series bold
\size large
Cyclic prefix
\series default
: Helps OFDM symbols to reduce inter-symbol interference.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
At regular intervals, the transmitter inserts recognizable symbols known
 as "pilots" into the transmitted signal.
 These pilots are selected to have a known value and to be separated from
 one another by a given number of symbols.
 This estimation involves analyzing the correlations between the received
 signal and the known pilot symbols, and then using this information to
 estimate the channel response.
 Using the estimated channel response, the receiver then performs channel
 equalization to remove the distortions caused by the communication channel
 from the received signal 
\begin_inset CommandInset citation
LatexCommand cite
key "ChannelEstimation1"
literal "false"

\end_inset

, and also there are more complex methods that can handle delay-time channel
 estimation in an efficient embbeded pilot 
\begin_inset CommandInset citation
LatexCommand cite
key "ChannelEstimation2"
literal "false"

\end_inset

.
\end_layout

\begin_layout Subsubsection
Advantages and Disadvantages in OFDM
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
The advantages offered by OFDM systems in broadband systems are as follows
 
\begin_inset CommandInset citation
LatexCommand cite
key "ofdm_book"
literal "false"

\end_inset

:
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\align block

\series bold
\size large
High spectral efficiency
\series default
: OFDM can transmit a large amount of data over a wide frequency band by
 dividing the available bandwidth into multiple narrowband subcarriers.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\align block

\series bold
\size large
Robustness to channel impairments
\series default
: OFDM is less sensitive to frequency-selective fading and interference
 than other multiplexing techniques, making it well-suited for use in wireless
 communication systems.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\align block

\series bold
\size large
Ease of implementation
\series default
: OFDM can be implemented using simple digital signal processing techniques,
 making it relatively easy to design and implement.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
Some disadvantages of OFDM include:
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\align block

\series bold
\size large
High peak-to-average power ratio
\series default
: OFDM signals have a high peak-to-average power ratio, which can cause
 problems in power amplifier systems and limit the range of the transmitted
 signal.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\align block

\series bold
\size large
Sensitivity to timing errors: 
\series default
In OFDM systems, the receiver needs to estimate the timing of the received
 signal accurately.
 If the receiver timing is off, the subcarriers' orthogonality is lost,
 leading to inter-carrier interference (ICI).
 
\end_layout

\begin_layout Itemize

\series bold
\size large
Sensitivity to Doppler spread:
\series default
 Doppler spread causes interference between the subcarriers.
\end_layout

\begin_layout Subsection
QAM and IQ data
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
QAM (Quadrature Amplitude Modulation) 
\begin_inset CommandInset label
LatexCommand label
name "subsec:QAM-and-IQ"

\end_inset

is a type of digital modulation that encodes data onto a carrier signal
 by modulating the amplitude and phase of the signal.
 It is commonly used in digital communication systems to transmit digital
 data over analog channels.
 IQ data refers to the in-phase and quadrature components of a complex-valued
 signal.
 In digital communication systems, the IQ data is typically used to represent
 the amplitude and phase of the modulated carrier signal.
 It's ussualy represented with complex numbers in an alphabet 
\begin_inset Formula $\mathbb{A}\in\mathbb{C}^{n}$
\end_inset

.
 In the field of communication systems, a QAM constellation refers to a
 graphical representation of the symbol points in an alphabet on the complex
 plane.
 Each point represents a specific combination of the in-phase and quadrature
 components of the modulated signal, and it is encoded with a binary value.
 We can visualize better in
\color blue
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:16-QAM-constellation"
plural "false"
caps "false"
noprefix "false"

\end_inset

.

\color inherit
 The number of points in the constellation is determined by the number of
 possible combinations of in-phase and quadrature values, which is in turn
 determined by the number of bits per symbol used in the QAM modulation
 scheme.
 For instance, in a 16-QAM constellation, there are 16 symbol points arranged
 in a square grid, with each point corresponding to 4 bits of data.
 It is common for QAM constellations to utilize gray code for assigning
 the symbol points in a manner that minimizes the error rate
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Diagrams/16QAM.png
	lyxscale 20
	scale 20

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Caption Standard

\begin_layout Plain Layout
16-QAM constellation 
\begin_inset CommandInset label
LatexCommand label
name "fig:16-QAM-constellation"

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "wiki_16qam"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\size large
 The points in the QAM constellation can also be affected by phase and amplitude
 distortion caused by channel and noise, as seen in
\color blue
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:QAMNoiseCloud"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
.
 This can lead to some clouds of points being placed in the wrong location,
 resulting in incorrect decoding of the bits and introducing errors.
 To correct for this problem, an equalizer is needed to recover the values
 to their original encoding
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/QAM_noise.jpg
	lyxscale 80
	scale 50

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
QPSK and 16 QAM with noise and phase displacement 
\begin_inset CommandInset label
LatexCommand label
name "fig:QAMNoiseCloud"

\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "QAMwithNoise"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
\paragraph_spacing onehalf
Channel
\size large
 
\begin_inset CommandInset label
LatexCommand label
name "subsec:Channel"

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newline
\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Dispersion and doubly dispersion
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Time delay dispersion is a measure of the variation in the arrival times
 of a signal's components caused by transmission through a communication
 channel.
 It is a type of distortion that can occur in wireless communication systems
 and is due to the differences in the propagation paths taken by different
 parts of the transmitted signal.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Time delay dispersion can cause inter-symbol interference (ISI) in digital
 communication systems, which can lead to errors in the received signal.
 To mitigate the effects of time delay dispersion, techniques such as equalizati
on, adaptive modulation, and error correction codes can be used.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
A doubly dispersive channel is a type of communication channel that exhibits
 dispersion in two dimensions, such as time and frequency, or time and spatial
 dimensions.
 This means that the signals transmitted through the channel are spread
 out in both dimensions, which can cause additional distortion and complexity
 in the communication system.
 To overcome the challenges of a doubly dispersive channel, advanced techniques
 such as joint equalization and channel estimation can be employed.
 
\begin_inset CommandInset citation
LatexCommand cite
key "rappaport2002wireless"
literal "false"

\end_inset


\end_layout

\begin_layout Subsubsection
Multipath fading and doppler shift
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
A multipath fading channel is a type of wireless communication channel that
 experiences fading of the transmitted signal due to multiple paths of the
 signal between the transmitter and receiver.
 This can occur when the signal reflects off of obstacles such as buildings
 or terrain, or when it is refracted by the atmosphere.
 Multiple paths of the transmitted signal can cause constructive and destructive
 interference at the receiver, resulting in rapid fluctuations in the received
 signal strength.
 This can cause the signal to fade in and out, which can affect the quality
 and reliability of the communication.
 
\begin_inset CommandInset citation
LatexCommand cite
key "balanis_2012"
literal "false"

\end_inset

.
 We begin with the ray-tracing technique and make advantage of the physical
 geometry of the propagation environment to create a deterministic model
 of the wireless channel.
 The delay of a signal refers to the time it takes for the signal to travel
 from the transmitter to the receiver as seen in 
\color blue
Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Delay-multipath"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
, and the Doppler shift of a signal refers to the frequency shift of the
 signal due to the relative motion between the transmitter and receiver.
\size default

\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Diagrams/Propagation.png
	lyxscale 50
	scale 30

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Caption Standard

\begin_layout Plain Layout
Delay multipath 
\begin_inset CommandInset label
LatexCommand label
name "fig:Delay-multipath"

\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "hong_thaj_viterbo_2022"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard

\series bold
\size large
\begin_inset Formula 
\begin{equation}
r(t)=g_{1}s(t-\tau_{1})+g_{2}s(t-\tau_{2})
\end{equation}

\end_inset


\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $r(t)$
\end_inset

 recieved signal
\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\mathbf{g_{n}}$
\end_inset

 baseband equivalent complex gain (attenuation)
\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\tau_{1}=\frac{r_{1}}{c}$
\end_inset

 where c is the speed of light
\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\tau_{2}=\frac{(r_{1}+r_{3}}{c}$
\end_inset

 delay in reflected path
\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\tau_{1}-\tau_{1}$
\end_inset

 delay spread
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
In wireless communication, the Doppler shift can cause changes in the frequency
 of a signal as it travels from the transmitter to the receiver.
 This can happen when the transmitter or receiver (or both) are moving relative
 to each other, causing the frequency of the signal to shift.
 The Doppler shift can affect the performance of a wireless communication
 system by causing changes in the signal-to-noise ratio and the signal-to-interf
erence ratio, which can degrade the quality of the signal and make it more
 difficult to detect and decode 
\begin_inset CommandInset citation
LatexCommand cite
key "marsland2013radio"
literal "false"

\end_inset

.
 
\color blue
Figure 6
\color inherit
 illustrates a vehicle in motion and how the reflected path affects the
 Doppler shift.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Diagrams/DopplerBasic.png
	lyxscale 50
	scale 40

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Doppler shifts due to the different angles of arrival 
\begin_inset CommandInset citation
LatexCommand cite
key "hong_thaj_viterbo_2022"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard

\size large
\begin_inset Formula 
\begin{equation}
r(t)=g_{1}e^{j2\pi\nu_{1}(t-\tau_{1})}s(t-\tau_{1})+g_{2}e^{j2\pi\nu_{2}(t-\tau_{2})}s(t-\tau_{2})
\end{equation}

\end_inset


\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\nu_{1}=\frac{v}{c}f_{c}$
\end_inset

 LOS doppler shift
\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\nu_{1}=\frac{v*cos(\theta)}{c}f_{c}$
\end_inset

 doppler shift in reflected path
\end_layout

\begin_layout Standard
\align block

\size large
We can generalize for time dependent function the gain as follows: 
\end_layout

\begin_layout Standard

\size large
\begin_inset Formula 
\begin{equation}
g(\tau_{i},t)=g_{i}e^{j2\pi\nu_{i}(t-\tau_{i})}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent
\align block

\size large
Therefore impulse time-frequency response of channel at fixed time t, can
 be obtained by taking fourier transform along the delay dimension of 
\begin_inset Formula $g(\tau,t)$
\end_inset


\end_layout

\begin_layout Standard

\size large
\begin_inset Formula 
\begin{equation}
H(f,t)=\int g(\tau,t)e^{-j2\pi f\tau}d\tau
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent
\align block

\size large
A time-frequency channel is a type of communication channel that is characterize
d by time-varying frequency-selective fading.
 This means that the channel experiences changes in its frequency response
 over time, resulting in variations in the amplitude and phase of the signals
 transmitted through it.
 Because a channel is assumed to have a slow time-varying function of t,
 we refer to this phenomenon as having a wide sense of being stationary.
 
\begin_inset CommandInset citation
LatexCommand cite
key "rappaport2002wireless"
literal "false"

\end_inset


\end_layout

\begin_layout Subsection
Equalization
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
A telecom channel equalizer as shown in 
\color blue
Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Basic-Equalizer"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
 is a device or algorithm used in telecommunications systems to compensate
 for distortion or other impairments in a communication channel.
 The equalizer uses signal processing techniques to estimate the characteristics
 of the channel, such as the impulse response or the frequency response,
 and then applies a correction to the transmitted signal to counteract the
 effects of the channel on the received signal.
 This can improve the performance of the communication system by reducing
 errors and increasing the data rate or signal-to-noise ratio.
 Bluetooth, WiFi, IOT, drones, V2V, wireless broadband, and satellite communicat
ions are just a few of the everyday applications they can be used for.
 
\begin_inset CommandInset citation
LatexCommand cite
key "goldsmith_2005"
literal "false"

\end_inset

 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newline
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Diagrams/Equalizer_Basic.jpg
	lyxscale 30
	scale 15

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Basic Equalizer 
\begin_inset CommandInset label
LatexCommand label
name "fig:Basic-Equalizer"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Our goal is to develop an equalizer based on deep learning techniques and
 research how it performs in terms of timing and memory complexity.
 We take as a reference the classical methods that manage a good bit error
 rate, and we will take them as a golden model of accuracy.
 
\end_layout

\begin_layout Subsection
Equalizers
\end_layout

\begin_layout Subsubsection
Linear
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
Zero Forcing Equalizer (ZFE) : Employed to mitigate intersymbol interference
 (ISI) that results from multiple signal paths in a communication channel.
 Despite its efficacy, the ZFE has some limitations, including susceptibility
 to noise and inability to handle certain types of channel distortion.
 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
Least Squares(LS): A method used in signal processing to estimate a signal
 from noisy data.
 In this method, the estimate is chosen to minimize the sum of the squared
 differences between the observed data and the predicted data.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
Linear Minimum Mean Square Error (LMMSE): Signal processing technique used
 to estimate a signal from noisy data, given knowledge of the noise statistical
 properties.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\size large
Complexity: 
\end_layout

\begin_deeper
\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
Zero Forcing Equalizer (ZFE): This method is the fastest and has a time
 complexity of 
\begin_inset Formula $O(N)$
\end_inset

, making it an efficient equalization method.
 It involves dividing the main diagonal of the channel matrix.
\end_layout

\begin_layout Itemize

\size large
Least Squares (LS): This method has a higher time complexity of 
\begin_inset Formula $O(N^{3})$
\end_inset

 as it includes matrix inversion.
 
\end_layout

\begin_layout Itemize

\size large
Linear Minimum Mean Square Error (LMMSE): This method also has a time complexity
 of 
\begin_inset Formula $O(N^{3})$
\end_inset

 as it includes matrix inversion.
 However, it is a more advanced signal processing technique that estimates
 a signal from noisy data, given knowledge of the signal's statistical propertie
s.
\end_layout

\end_deeper
\begin_layout Subsubsection
Nonlinear
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\size large
Approach to symbol detection: 
\end_layout

\begin_deeper
\begin_layout Itemize
\paragraph_spacing onehalf

\size large
OSIC: This algorithm processes the received signal in a sequential manner,
 starting from the strongest to the weakest received symbol.
 It detects the strongest symbol first and then removes its interference
 from the received signal before detecting the next symbol.
 This process continues until all symbols are detected.
 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\size large
NearML: Is a tree search algorithm that explores all possible symbol combination
s and computes the distances between the received signal and candidate symbols.
 It then selects the candidate with the minimum total distance as the detected
 transmitted symbol.
 The algorithm employs pruning techniques to reduce the search space while
 still maintaining good detection performance.
\end_layout

\end_deeper
\begin_layout Itemize
\paragraph_spacing onehalf

\size large
Complexity: 
\end_layout

\begin_deeper
\begin_layout Itemize
\paragraph_spacing onehalf

\size large
OSIC: The complexity of the algorithm is relatively lower compared to NearML,
 as it processes the received signal in a sequential manner and does not
 require an exhaustive search of all possible symbol combinations.
 This makes OSIC faster and more suitable for real-time applications with
 lower computational resources.
 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\size large
NearML: The complexity of NearML is higher, as it involves an exhaustive
 search of all possible symbol combinations in the tree.
 However, the pruning techniques employed in the algorithm help reduce the
 search space and improve computational efficiency.
\end_layout

\end_deeper
\begin_layout Subsection
Problem statement
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The 802.11p standard for V2V communication, based on the OFDM modulation
 scheme, is susceptible to channel impairments during data transmission,
 particularly multipath fading and Doppler shift.
 Additionally, the problem of ICI in the received symbols introduces distortion
 in the IQ data, leading to incorrect received symbols.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
However, linear equalization methods rely on finding the pseudo-inverse
 of matrix, which can be computationally expensive 
\begin_inset Formula $O(N^{3})$
\end_inset

 and numerically unstable.
 Matrix instability arises when the determinant is very small.
 However, classical non-linear methods can reduce BER further, but with
 higher complexity due to their iterative nature.
\end_layout

\begin_layout Subsection
Hypothesis
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Well applied deep learning techniques have the ability to learn and model
 complex non-linear relationships between the received signal and the transmitte
d signal.
 Therefore, they can be used as an alternative to traditional methods of
 channel equalization, including linear techniques such as LS and LMMSE,
 and non-linear techniques such as OSIC and NearML.
 This approach can help to overcome the non-linear distortions introduced
 by the channel, which is particularly useful given the multiple factors
 affecting the received symbols, including all channel effects such as ISI
 and noise.
 Furthermore, most deep learning architectures can be evaluated using a
 feedforward process.
\end_layout

\begin_layout Subsection
Objectives
\end_layout

\begin_layout Subsubsection
General Objective
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
Develop and evaluate a neural network-based approach for frequency channel
 equalization in OFDM systems that breaks the equalization process into
 simpler parts and combines preprocessing methods (e.g., 
\begin_inset Formula $\boldsymbol{H^{H}}$
\end_inset

, zero forcing) with the non-linear capabilities of neural networks.
\end_layout

\begin_layout Subsubsection
Particular Objective
\end_layout

\begin_layout Itemize

\size large
Evaluate performance across various noise levels (5dB to 45dB)
\end_layout

\begin_layout Itemize

\size large
Investigate deep learning techniques such as feedforward layers, complex
 numbers layers, convolutional layers, and transformers.
\end_layout

\begin_layout Itemize

\size large
Recover QAM and PSK received symbols distorted by LOS and NLOS channel condition
s using feedforward neural network layers that correct both phase and magnitude.
\end_layout

\begin_layout Itemize

\size large
Employ non-linear dimensionality reduction using CNN (Convolutional Neural
 Networks) to apply zero forcing or some related method.
\end_layout

\begin_layout Itemize

\size large
Achieve BER and BLER comparable to "golden models," which include some linear
 techniques such as LS, LMMSE, Zero Forcing, and non-linear techniques like
 OSIC, NearML.
\end_layout

\begin_layout Itemize

\size large
Examine transformers and attention mechanisms to reduce ICI.
\end_layout

\begin_layout Itemize

\size large
Use the FLOPS metric and time complexity for benchmarking and analysis.
\end_layout

\begin_layout Itemize

\size large
Benchmark and tradeoff between suitable neural network architectures for
 different situations.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newpage
\end_layout

\end_inset


\end_layout

\begin_layout Section
State of Art
\end_layout

\begin_layout Subsection
Introduction
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
This section introduces fundamental signal estimation concepts, applied
 to Orthogonal Frequency Division Multiplexing (OFDM) equalization techniques.
 Non-linear equalizers are examined, revealing their accuracy yet highlighting
 their increased complexity.
 The role of neural networks in signal processing scenarios is then explored,
 considering the evolution from Feed Forward layers 
\color blue

\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Linear-Layer"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
 to Convolutional Neural Networks (CNNs) 
\color blue

\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:CNN"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
, then to MobileNet 
\color blue

\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:MobileNetV3"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
, and finally to Transformers 
\color blue

\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Attention-Is-All"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
.
 Their mathematical foundations and the role of matrix products in the neural
 network process, which can also be used in equalization calculations, are
 outlined.
 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Furthermore, in the applied field and while blending the concepts of equalizatio
n and neural networks, two significant papers are introduced: one discussing
 OFDM equalization and its previous implementation with Neural Networks
 
\color blue

\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:A-Novel-OFDM"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
, and the other addressing the challenge of handling complex numbers within
 Neural Networks 
\color blue

\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:A-Survey-of"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
, an ongoing issue in development.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Finally, the implementation of transformers is reviewed, starting from their
 foundational building blocks 
\color blue

\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Attention-Is-All"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
 and extending to image Transformers 
\color blue

\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:An-image-is"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
.
 The focus on Convolutional Neural Networks and Image Transformers is justified
 by their potential to treat the equalization problem as an image problem.
 For CNN 
\color blue

\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:CNN"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
, the channel can be treated as an image and then processed.
 For the Image Transformer 
\color blue

\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:An-image-is"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
, the constellation of received points can be directly taken as an image
 divided by grids.
 The following bullet points will aid in navigating this section
\end_layout

\begin_layout Enumerate

\size large
Estimation
\end_layout

\begin_deeper
\begin_layout Enumerate

\size large
Bias and variance
\end_layout

\end_deeper
\begin_layout Enumerate

\size large
OFDM Equalization Techniques
\end_layout

\begin_deeper
\begin_layout Enumerate

\size large
LS,MMSE,LMMSE
\end_layout

\end_deeper
\begin_layout Enumerate

\size large
Introduction to Neural Networks
\end_layout

\begin_deeper
\begin_layout Enumerate

\size large
RoadMap into 6G
\end_layout

\begin_layout Enumerate

\size large
Introduction into physical layer and timeline of NN evolution from RNN to
 Transformers.
 
\end_layout

\end_deeper
\begin_layout Enumerate

\size large
Mathematical Description of Neural Networks and CNN
\end_layout

\begin_deeper
\begin_layout Enumerate

\size large
Includes MobileNetV3 as an Efficient Variant of CNN
\end_layout

\end_deeper
\begin_layout Enumerate

\size large
Cutting-Edge Papers
\end_layout

\begin_deeper
\begin_layout Enumerate

\size large
OFDM Equalization in Large Doppler Shift Channel through Deep Learning
\end_layout

\begin_layout Enumerate

\size large
Survey of Complex Valued Neural Networks
\end_layout

\end_deeper
\begin_layout Enumerate

\size large
Transformers
\end_layout

\begin_deeper
\begin_layout Enumerate

\size large
Encoder-Decoder, embedding and multihead attention.
\end_layout

\begin_layout Enumerate

\size large
Image Transformers and Grid
\end_layout

\end_deeper
\begin_layout Subsection
Estimators
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
An estimator is a statistical function that maps an observation 
\begin_inset Formula $\theta$
\end_inset

 to an estimate of a parameter., normally known as 
\begin_inset Formula $\boldsymbol{\hat{\theta}}$
\end_inset

.
 It is a mathematical function that takes the data, usually in the form
 of a sample, and produces an estimate of an unknown parameter of the underlying
 probability distribution.
 It's important to note that the quality of an estimator is usually measured
 by some metric such as Mean Squared Error (MSE), Mean Absolute Error (MAE)
 or Likelihood that indicates how well the estimator is able to estimate
 the true parameter 
\begin_inset CommandInset citation
LatexCommand cite
key "MSE_MMSE"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
In the context of estimation theory, there are two key concepts to understand:
 posterior estimators and biased/unbiased estimators.
\begin_inset CommandInset citation
LatexCommand cite
key "statiticsbook"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\series bold
\size large
Posterior estimator
\series default
: Is a method of estimating a parameter by incorporating prior knowledge
 or belief about the parameter's distribution.
 This prior information is combined with the observed data to derive a posterior
 distribution for the parameter.
 The posterior distribution represents our updated belief about the parameter
 after considering the observed data.
 The estimator is then derived from this posterior distribution.
 The posterior estimator can be the mean, median, or mode of the posterior
 distribution, depending on the specific problem and desired properties
 of the estimator.
 Let's denote the parameter of interest as 
\begin_inset Formula $𝜃$
\end_inset

 and the observed data as 
\begin_inset Formula $X$
\end_inset

.
 Bayes' theorem can be written as
\end_layout

\begin_deeper
\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
P(\boldsymbol{\theta}|\boldsymbol{X})=\frac{P(\boldsymbol{X}|\boldsymbol{\theta})*P(\boldsymbol{\theta})}{P(\boldsymbol{X})}
\end{equation}

\end_inset


\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\size large
\begin_inset Formula $P(\boldsymbol{\theta}|\boldsymbol{X})$
\end_inset

 is the posterior distribution of the parameter 
\begin_inset Formula $\boldsymbol{𝜃}$
\end_inset

 given the data 
\begin_inset Formula $\boldsymbol{X}$
\end_inset

.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\size large
\begin_inset Formula $P(\boldsymbol{X}|\boldsymbol{𝜃})$
\end_inset

 is the likelihood of observing the data 
\begin_inset Formula $\boldsymbol{X}$
\end_inset

 given the parameter 
\begin_inset Formula $\boldsymbol{𝜃}$
\end_inset

.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\size large
\begin_inset Formula $P(\boldsymbol{𝜃})$
\end_inset

 is the prior distribution of the parameter 
\begin_inset Formula $\boldsymbol{𝜃}$
\end_inset

, representing our beliefs about 
\begin_inset Formula $\boldsymbol{𝜃}$
\end_inset

 before observing the data.
 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\size large
\begin_inset Formula $P(\boldsymbol{X})$
\end_inset

 is the marginal likelihood of the data, which can be thought of as a normalizat
ion constant.
\end_layout

\end_deeper
\begin_layout Itemize
\paragraph_spacing onehalf

\series bold
\size large
Biased estimator:
\series default
 Is an estimator whose expected value does not equal the true value of the
 parameter being estimated.
 In other words, the estimator consistently overestimates or underestimates
 the true parameter value.
 Bias can be due to the estimator's functional form, the presence of outliers
 in the data, or other factors that systematically affect the estimator.
 The concept of bias estimator can be represented mathematically using the
 following equation:
\end_layout

\begin_deeper
\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
Bias\left(\boldsymbol{\hat{\theta}}\right)=E\left(\boldsymbol{\hat{\theta}}\right)-\boldsymbol{𝜃}
\end{equation}

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
\paragraph_spacing onehalf

\series bold
\size large
Unbiased estimator:
\series default
 On average, the estimator provides an accurate estimate of the parameter.
 However, it's important to note that an unbiased estimator can still have
 a large variance, which means that individual estimates can be far from
 the true parameter value.
 The concept of unbiased estimator can be represented mathematically using
 the following equation:
\end_layout

\begin_deeper
\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
E\left(\boldsymbol{\hat{\theta}}\right)=\boldsymbol{\theta}
\end{equation}

\end_inset


\end_layout

\end_deeper
\begin_layout Subsubsection
MSE 
\begin_inset CommandInset label
LatexCommand label
name "subsec:MSE"

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
Mean squared error (MSE) is a widely used performance metric in estimation
 theory to evaluate the accuracy of an estimator.
 It measures the average of the squared differences between the estimated
 values and the true parameter values.
 In other words, MSE quantifies the difference between the estimator and
 the true parameter value, considering both the bias and the variance of
 the estimator.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align center

\size large
\begin_inset Formula 
\begin{equation}
MSE(\boldsymbol{\hat{\theta}})=E[(\boldsymbol{\hat{\theta}}-\boldsymbol{\theta})^{2}]
\end{equation}

\end_inset


\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\align block

\size large
\begin_inset Formula $\boldsymbol{\theta}$
\end_inset

 is the true parameter values with the original values
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\align block

\size large
\begin_inset Formula $\boldsymbol{\hat{\theta}}$
\end_inset

 is the estimate parameter values of the received signal.
\end_layout

\begin_layout Standard

\size large
However, reducing the MSE involves managing the trade-off between bias and
 variance.
 This trade-off can be more clearly seen when the MSE is decomposed into
 the sum of the squared bias and the variance, we can better visualize the
 idea rewritting the formula 
\begin_inset CommandInset citation
LatexCommand cite
key "statiticsbook"
literal "false"

\end_inset

: 
\end_layout

\begin_layout Standard

\size large
\begin_inset Formula 
\begin{equation}
MSE(\boldsymbol{\hat{\theta}})=E\left\{ \left[\left(\boldsymbol{\hat{\theta}}-E\left(\boldsymbol{\hat{\theta}}\right)\right)+\left(E\left(\boldsymbol{\hat{\theta}}\right)-\boldsymbol{\theta}\right)\right]^{2}\right\} =var(\boldsymbol{\hat{\theta}})+\left(E\left(\boldsymbol{\hat{\theta}}\right)-\boldsymbol{\theta}\right)^{2}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard

\size large
\begin_inset Formula 
\begin{equation}
MSE(\boldsymbol{\hat{\theta}})=var(\boldsymbol{\hat{\theta}})+Bias^{2}(\boldsymbol{\theta})
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The bias-variance trade-off refers to the challenge of finding an estimator
 that minimizes both bias and variance.
 In practice, this trade-off means that an estimator with low bias may have
 high variance, while an estimator with low variance may have high bias.
 The goal is to find the optimal balance between bias and variance, resulting
 in the lowest MSE and the best overall estimator performance.
\end_layout

\begin_layout Subsubsection
Bias and variance in Deep Learning
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
In the context of deep learning models, including neural networks, bias
 refers to the error introduced by approximating a real-world problem with
 a simplified model, while variance represents the model's sensitivity to
 small fluctuations in the training data.
 A neural network with a high bias tends to produce simpler models that
 may not capture the true underlying relationship between inputs and outputs,
 resulting in underfitting.
 On the other hand, a network with high variance tends to overfit the training
 data, capturing noise and being sensitive to small changes in the input
 data.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
In supervised learning with neural networks, the goal is to find the right
 balance between bias and variance to achieve good generalization performance
 on unseen data.
 This can be achieved by selecting the appropriate network architecture,
 using regularization techniques, and fine-tuning hyperparameters.
\end_layout

\begin_layout Subsection
Equalization techniques
\end_layout

\begin_layout Subsubsection
OFDM Time-Frequency Input-Output Relationship
\begin_inset CommandInset label
LatexCommand label
name "subsec:OFDM-Time-Frequency-Input-Output"

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The system model considers the OFDM modulation that forms the basis of the
 802.11p standard and excludes the cyclic prefix (CP).
 In this model, the received signal for the k-th symbol at the receiver,
 represented in the complex baseband, can be expressed as a circular convolution
:
\end_layout

\begin_layout Standard

\size large
\begin_inset Formula 
\begin{equation}
y^{k}[n]=\sum_{l=0}^{L-1}h^{k}[n,l]x^{k}[(n-l)_{N}]+w^{k}[n]
\end{equation}

\end_inset


\end_layout

\begin_layout Standard

\size large
Where 
\begin_inset Formula $n=\{0,\cdots,N-1\},l=\{0,\cdots,L-1\}$
\end_inset

.
 The transmitted signal at the k-th block and the n-th sample is represented
 by 
\begin_inset Formula $x^{k}[n]$
\end_inset

.
 The term 
\begin_inset Formula $h^{k}[n,l]$
\end_inset

 represents the impulse response of the channel at the k-th block and the
 instance 
\begin_inset Formula $n$
\end_inset

 with 
\begin_inset Formula $l$
\end_inset

 previous samples.
 The circular convolution shown in (11) between impulse response 
\begin_inset Formula $h^{k}[n,l]$
\end_inset

 and 
\begin_inset Formula $x^{k}[n]$
\end_inset

 can be rewritten as:
\end_layout

\begin_layout Standard

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{Y^{k}}=\boldsymbol{H^{k}X^{k}}+\boldsymbol{W^{k}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
where the vector terms are:
\end_layout

\begin_layout Standard

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{Y^{k}}=\left[y^{k}[0]y^{k}[1]y^{k}[2]\dots y^{k}[N-1]\right]^{T}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{X^{k}}=\left[x^{k}[0]x^{k}[1]x^{k}[2]\dots y^{k}[N-1]\right]^{T}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{W^{k}}=\left[w^{k}[0]w^{k}[1]w^{k}[2]\dots w^{k}[N-1]\right]^{T}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
and matrix 
\begin_inset Formula $\boldsymbol{H}^{k}$
\end_inset

 is the channel frequency response with shape 
\begin_inset Formula $NxN$
\end_inset

 descibed as follows: 
\end_layout

\begin_layout Standard

\size large
\begin_inset Formula 
\begin{equation}
[\boldsymbol{H^{k}}]_{n,n'}=h^{k}[n,(n-n')_{N}]
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Assuming a constant k.
 The objective of the receiver is to estimate 
\begin_inset Formula $\boldsymbol{\hat{X}}$
\end_inset

 the transmitted signal 
\begin_inset Formula $\boldsymbol{X}$
\end_inset

 from the received signal 
\begin_inset Formula $\boldsymbol{Y}$
\end_inset

, which can be done by applying an inverse channel matrix to the received
 signal.
 This can be expressed as:
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{\hat{X}=H^{-1}Y}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
However, the inverse channel matrix may not always exist or may be difficult
 to compute, especially in the presence of noise and channel distortions.
 Therefore, various signal processing techniques such as equalization, filtering
, and error correction codes are used to improve the accuracy and reliability
 of the transmitted signal estimation.
 These techniques involve manipulating the received signal Y to extract
 the transmitted signal x and minimize the effects of noise and channel
 distortions.
\end_layout

\begin_layout Subsubsection
Zero forcing 
\begin_inset CommandInset label
LatexCommand label
name "subsec:Zero-forcing-sec"

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The Zero Forcing Equalizer (ZFE) constitutes a method employed within communicat
ion systems to mitigate the influence of intersymbol interference (ISI),
 which arises due to the existence of numerous signal pathways in a communicatio
n channel.
 Despite its effectiveness, the ZFE exhibits certain drawbacks, including
 vulnerability to noise and an inability to address particular forms of
 channel distortion.
 The procedure involves extracting the principal diagonal from the channel
 matrix 
\begin_inset Formula $\boldsymbol{H}$
\end_inset

 and conducting an element-wise division of the received signal 
\begin_inset Formula $\boldsymbol{Y}$
\end_inset

 by this diagonal.
 As we seen before in 
\color blue

\begin_inset CommandInset ref
LatexCommand eqref
reference "subsec:OFDM-Time-Frequency-Input-Output"
plural "false"
caps "false"
noprefix "false"

\end_inset

 
\color inherit

\begin_inset Formula $\boldsymbol{H}$
\end_inset

 matrix is already in the frequency domain.
 To extract the main diagonal of the channel matrix we call operator "
\begin_inset Formula $diag(\boldsymbol{H})$
\end_inset

" described as follows:
\begin_inset Formula 
\begin{equation}
\boldsymbol{H_{\text{diag}}}=\text{diag}(\boldsymbol{H})=diag\left(\begin{bmatrix}h_{11} & 0 & \dots & 0\\
0 & h_{22} & \dots & 0\\
\vdots & \vdots & \ddots & \vdots\\
0 & 0 & \dots & h_{nl}
\end{bmatrix}\right)=\left(\begin{array}{c}
h_{11}\\
h_{22}\\
\vdots\\
\vdots\\
h_{nl}
\end{array}\right)
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Ideally, the off-diagonal elements of the channel matrix H are relatively
 small, making the most significant values lie on the diagonal.
 Our estimated parameter leads in the folowing expresion
\end_layout

\begin_layout Standard
\align center

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{\hat{\theta}^{k}}=[y^{k}[0]\div h[0,0],y^{k}[1]\div h[1,1],\dots y^{k}[n]\div h[n,l]\label{eq:ZeroForcing}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\noindent

\size large
Based on the paper
\begin_inset CommandInset citation
LatexCommand cite
key "ZeroForcingEqNN"
literal "false"

\end_inset

, we will use zero forcing as a preprocessing stage for some of our experiments.
\end_layout

\begin_layout Subsubsection
LS
\size large
 
\begin_inset CommandInset label
LatexCommand label
name "subsec:LS"

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Least squares (LS) equalization is a linear equalization method that aims
 to minimize the sum of squared errors between the estimated and the transmitted
 symbols.
 The method calculates the coefficients of a linear filter that minimizes
 the difference between the given parameter 
\begin_inset Formula $\theta$
\end_inset

 and the estimated signal 
\begin_inset Formula $\boldsymbol{\hat{\theta}}$
\end_inset

, where the estimation is based on the transmitted signal and a model of
 the communication channel 
\begin_inset Formula $\boldsymbol{H}$
\end_inset

.
 By minimizing the sum of squared errors, the LS equalizer is able to remove
 or reduce the effects of channel distortion, noise, and interference on
 the received signal, resulting in improved signal integrity.
 To achieve the solution, it is used the Moore-Penrose pseudoinverse 
\begin_inset Formula $\boldsymbol{H^{+}}$
\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "strang2019linear"
literal "false"

\end_inset

 which is often used to solve linear least squares problems.
 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{H^{+}=(H^{H}H)^{-1}H^{H}}
\end{equation}

\end_inset


\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\size large
\begin_inset Formula $\boldsymbol{H}$
\end_inset

 Channel matrix
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\size large
\begin_inset Formula $\boldsymbol{H^{+}}$
\end_inset

Moore-Penrose pseudoinverse 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\size large
\begin_inset Formula $\boldsymbol{H^{H}}$
\end_inset

 Hermiatian transpose matrix.
 Complex square matrix that is equal to its own conjugate transpose.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Finally the least squares equation is given by :
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{\hat{\theta}}=\boldsymbol{(H^{H}H)^{-1}H^{H}Y}
\end{equation}

\end_inset


\end_layout

\begin_layout Subsubsection
MMSE
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The main difference between Minimum Mean Squared Error (MMSE) and Least
 Squares (LS) methods is that MMSE takes into account the statistical properties
 of the measurement noise and models the uncertainty in the observations,
 while LS assumes that the observation noise is zero and does not model
 any uncertainty in the measurements.
 The MMSE equalizer balances the trade-off between bias and variance.
 MMSE equalization can be thought of as a compromise between the desire
 to eliminate ISI (which could introduce bias) and the need to limit noise
 amplification (which affects variance).
 The objective of MMSE equalization can be expressed as:
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
MMSE=min(E[(\boldsymbol{\hat{\theta}}-\boldsymbol{\theta})^{2}])
\end{equation}

\end_inset


\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\size large
\begin_inset Formula $\boldsymbol{\theta}$
\end_inset

 is the transmitted signal.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\size large
\begin_inset Formula $\boldsymbol{\hat{\theta}}$
\end_inset

 is the estimated signal.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Mathematically, the MMSE estimator is defined as 
\begin_inset Formula $\boldsymbol{\hat{\theta}}_{MMSE}=E[\boldsymbol{X}|\boldsymbol{Y}]$
\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Here, 
\begin_inset Formula $\boldsymbol{\hat{\theta}}_{MMSE}$
\end_inset

 is the estimate of the transmitted signal 
\begin_inset Formula $\boldsymbol{\theta}$
\end_inset

 given the received signal 
\begin_inset Formula $\boldsymbol{Y}$
\end_inset

.
 The MMSE estimator computes the conditional expectation of 
\begin_inset Formula $\boldsymbol{\theta}$
\end_inset

 given the observed signal 
\begin_inset Formula $\boldsymbol{Y}$
\end_inset

.
 This means that the MMSE estimator takes into account both the prior informatio
n about 
\begin_inset Formula $\boldsymbol{\theta}$
\end_inset

 and the likelihood of observing 
\begin_inset Formula $\boldsymbol{Y}$
\end_inset

 given 
\begin_inset Formula $\boldsymbol{\theta}$
\end_inset

.
\end_layout

\begin_layout Subsubsection
LMMSE 
\size large

\begin_inset CommandInset label
LatexCommand label
name "subsec:LMMSE"

\end_inset

 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The Linear Minimum Mean Squared Error (LMMSE) estimator is a linear version
 of the MMSE estimator.
 While the MMSE estimator can be nonlinear, the LMMSE estimator restricts
 itself to linear functions of the observed data.
 The goal of the LMMSE estimator is to find a linear estimate of the transmitted
 signal that minimizes the mean squared error between the transmitted signal
 and its linear estimate, given the received signal.
 Compared to the Least Squares (LS) algorithm, this can perform better when
 there is low signal-to-noise ratio (SNR).
 To put it another way, the LMMSE equalization is a method that can be applied
 to restore precision to a signal that has been distorted by noise, especially
 when the noise level is high.
 When there is a low signal-to-noise ratio (SNR) and a significant quantity
 of noise in the signal, it performs exceptionally well.
 Mathematically, the LMMSE estimator is defined as:
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{\hat{\theta}}_{LMMSE}=E[\boldsymbol{\theta}]+\boldsymbol{C}_{\theta Y}\boldsymbol{C}_{YY}^{-1}(\boldsymbol{Y}-E[\boldsymbol{Y}])
\end{equation}

\end_inset


\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\size large
\begin_inset Formula $E[\theta]$
\end_inset

 is the prior expectation of the transmitted signal.
 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\size large
\begin_inset Formula $\boldsymbol{C}_{\theta Y}$
\end_inset

 is the cross-covariance matrix between the transmitted signal and the received
 signal.
 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\size large
\begin_inset Formula $\boldsymbol{C}_{YY}$
\end_inset

 is the covariance matrix of the received signal.
 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\size large
\begin_inset Formula $E[\boldsymbol{Y}]$
\end_inset

 is the prior expectation of the received signal.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The LMMSE estimator seeks to find a linear estimate of 
\begin_inset Formula $\boldsymbol{\theta}$
\end_inset

 given the received signal 
\begin_inset Formula $\boldsymbol{Y}$
\end_inset

:
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{\hat{\theta}}_{LMMSE}=\boldsymbol{WY}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
where 
\begin_inset Formula $\boldsymbol{W}$
\end_inset

 is the LMMSE equalizer matrix.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Using the LMMSE estimator definition 
\begin_inset Formula $\boldsymbol{\hat{\theta}}_{LMMSE}$
\end_inset

, we can derive the LMMSE equalizer matrix W:
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{W}=\boldsymbol{C}_{\theta Y}\boldsymbol{C}_{YY}^{-1}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
We know that the covariance matrix of 
\begin_inset Formula $\boldsymbol{Y}$
\end_inset

, 
\begin_inset Formula $\boldsymbol{C}_{YY}$
\end_inset

, is given by:
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{C}_{YY}=\boldsymbol{H}\boldsymbol{C}_{\theta\theta}\boldsymbol{H^{H}}+\sigma^{2}\boldsymbol{I}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
where 
\begin_inset Formula $\boldsymbol{C}_{\theta\theta}$
\end_inset

 is the covariance matrix of 
\begin_inset Formula $\boldsymbol{\theta}$
\end_inset

, and 
\begin_inset Formula $\boldsymbol{H^{H}}$
\end_inset

 denotes the conjugate transpose (Hermitian) of the matrix 
\begin_inset Formula $\boldsymbol{H}$
\end_inset

.
 This equation consider AWGN (Additive White Gaussian Noise) with variance
 
\begin_inset Formula $\sigma^{2}$
\end_inset

.
 It is called "white" because it has a flat power spectral density, meaning
 that it has equal power at all frequencies.
 It is called "additive" because it can be added to a signal without changing
 its distribution.
 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Now, we need to find the cross-covariance matrix between 
\begin_inset Formula $\boldsymbol{\theta}$
\end_inset

 and 
\begin_inset Formula $\boldsymbol{Y}$
\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{C}_{\theta Y}=E[(\boldsymbol{\theta}-E[\boldsymbol{\theta}])(\boldsymbol{Y}-E[\boldsymbol{\theta}])^{H}]=E[\boldsymbol{\theta}\boldsymbol{Y}^{H}]=\boldsymbol{C}_{\theta\theta}H^{H}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Assuming that the transmitted symbols are uncorrelated with equal power,
 we have
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{C}_{\theta\theta}=E[\boldsymbol{\theta}\boldsymbol{\theta}^{H}]=\rho\boldsymbol{I}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
where
\begin_inset Formula $\boldsymbol{\rho}$
\end_inset

 is the average symbol power, and for simplicity we keep at unitary power.
 Substituting back the elements from Eq.
 25, we obtain the final estimation equation.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{W}=\boldsymbol{H}(\boldsymbol{HH^{H}}+\sigma^{2}\boldsymbol{I})^{-1}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{\hat{\theta}}_{LMMSE}=(\boldsymbol{H^{H}H}+\sigma^{2}\boldsymbol{I})^{-1}\boldsymbol{H^{H}}\boldsymbol{Y}\label{eq:LMMSE}
\end{equation}

\end_inset


\end_layout

\begin_layout Subsection
Non-linear equalizers
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
NearML (Near Maximum Likelihood)
\begin_inset CommandInset citation
LatexCommand cite
key "nearmLequalization"
literal "false"

\end_inset

 and OSIC (Ordered Successive Interference Cancellation) 
\begin_inset CommandInset citation
LatexCommand cite
key "OSIC_V2V"
literal "false"

\end_inset

 are two non-linear signal equalization techniques used in digital communication
 systems to mitigate the challenges posed by signal distortions.
 These methods provide better symbol detection accuracy than linear equalizers,
 and can improve overall system performance.
 However, they compromise time complexity due to the iterative nature of
 their applications.
 In our research team, these methods have been previously applied in MATLAB
 for benchmarking purposes in the work titled 
\begin_inset Quotes eld
\end_inset

Evaluation of OFDM Systems With Virtual Carriers Over V2V Channels
\begin_inset Quotes erd
\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "Gonza"
literal "false"

\end_inset

.
 We needed to perform a coding language translation to Python in order to
 make a fairer metric comparison under the same conditions as all the other
 Equalization methods and Nueronal Networks.
 Additionally, there was a well-planned architecture to integrate these
 methods in an almost transparent manner.
 Additional information about the software architecture can be found in
 the methodology section.
\end_layout

\begin_layout Subsubsection
OSIC
\begin_inset CommandInset label
LatexCommand label
name "subsec:OSIC"

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Ordered Successive Interference Cancellation (OSIC) algorithm accepts four
 inputs: the received signal vector, the channel matrix, the constellation
 points, and the indices of the detected symbols.
 The algorithm starts by initializing several variables needed for the algorithm.
 It then goes through each column of the channel matrix in reverse order.
 For each column, it estimates the corresponding transmitted symbol by dividing
 the received signal by the channel matrix value.
 Then, it calculates the squared distance between the estimated symbol and
 each constellation point.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The algorithm selects the constellation point with the smallest squared
 distance as the detected symbol and updates the received signal vector
 accordingly.
 This process helps to cancel the interference caused by previously detected
 symbols and improves the overall detection performance.
 Finally, the detected symbols are rearranged according to the given indices
 and stored in an output tensor.
 The algorithm returns this tensor containing the estimated transmitted
 symbols.
\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\mathbf{Y}$
\end_inset

: The received signal, which is a complex-valued column vector of length
 
\begin_inset Formula $N$
\end_inset

.
 
\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\mathbf{H}$
\end_inset

: The channel matrix of size 
\begin_inset Formula $N\times N$
\end_inset

, which represents the channel coefficients 
\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\mathbb{\boldsymbol{A}}$
\end_inset

: The set of constellation points, which represents the possible symbol
 values in the modulation scheme used for the transmitted signal.
 
\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $r$
\end_inset

: A temporary variable used for storing the residual signal during the algorithm.
 It is initialized as the received signal 
\begin_inset Formula $\mathbf{y}$
\end_inset

 and updated in each iteration of the loop.
 
\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $k$
\end_inset

: The loop index representing the current column of the channel matrix being
 considered.
 
\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\boldsymbol{a_{est}}$
\end_inset

: The estimated transmitted symbol value for the k-th column of the channel
 matrix, computed as the ratio between the k-th element of the residual
 signal 
\begin_inset Formula $r$
\end_inset

 and the k-th diagonal element of the channel matrix 
\begin_inset Formula $\mathbf{H}$
\end_inset

.
 
\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\text{dist}$
\end_inset

: A vector of squared distances between the estimated transmitted symbol
 value 
\begin_inset Formula $a_{est}$
\end_inset

 and the constellation points in 
\begin_inset Formula $\mathbb{A}$
\end_inset

.
 
\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\boldsymbol{\hat{\theta}_{osic}}$
\end_inset

: The estimated transmitted symbol vector of length N.
 It is initialized as an empty vector and updated with the minimum-distance
 constellation point in each iteration of the loop.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{algorithm}[H] 
\backslash
caption{OSIC Detection Algorithm} 
\backslash
begin{algorithmic}[1] 
\backslash
Procedure{OSIC
\backslash
_Det}{$
\backslash
mathbf{y}$, $
\backslash
mathbf{H}$, $
\backslash
mathbb{A}$}     
\backslash
State $
\backslash
mathbf{r} 
\backslash
gets 
\backslash
mathbf{y}$     
\backslash
For{$k 
\backslash
gets N-1, N-2, 
\backslash
dots, 0$}         
\backslash
State $a_{est} 
\backslash
gets 
\backslash
frac{
\backslash
mathbf{r}[k]}{
\backslash
mathbf{H}[k, k]}$         
\backslash
State $
\backslash
text{dist} 
\backslash
gets |a_{est} - 
\backslash
mathbb{A}|^2$         
\backslash
State $
\backslash
hat{
\backslash
theta}_{osic}[k] 
\backslash
gets 
\backslash
arg
\backslash
min_{a 
\backslash
in 
\backslash
mathbb{A}} 
\backslash
text{dist}$         
\backslash
State $
\backslash
mathbf{r} 
\backslash
gets 
\backslash
mathbf{r} - 
\backslash
hat{
\backslash
theta}_{osic}[k] 
\backslash
cdot 
\backslash
mathbf{H}[:, k]$     
\backslash
EndFor     
\backslash
State 
\backslash
textbf{return} $
\backslash
hat{
\backslash
theta}_{osic}$ 
\backslash
EndProcedure 
\backslash
end{algorithmic} 
\backslash
end{algorithm} 
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The outer loop iterates through the columns of the channel matrix, which
 has a size of 
\begin_inset Formula $N$
\end_inset

.
 Therefore, the outer loop has a complexity of 
\begin_inset Formula $O(N)$
\end_inset

.
 Inside the outer loop, there's a calculation of squared distances between
 the estimated symbol and each constellation point.
 The constellation points have a size of 
\begin_inset Formula $|\mathbb{A}|$
\end_inset

.
 This operation has a complexity of 
\begin_inset Formula $O\left(|\mathbb{A}|\right)$
\end_inset

.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Since the squared distance calculation is inside the outer loop, the overall
 complexity of the OSIC_Det algorithm :
\end_layout

\begin_layout Standard

\size large
\begin_inset Formula 
\begin{equation}
O(N|\mathbb{A}|)\label{eq:BigO-Osic}
\end{equation}

\end_inset


\end_layout

\begin_layout Subsubsection
NearML
\begin_inset CommandInset label
LatexCommand label
name "subsec:NearML"

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The Near-ML detection algorithm algorithms as a tree search with nodes represent
ing constellation points and depth equal to the number of transmitters.
 It computes distances between received signals and candidate symbols, selecting
 M best candidates at each level for pruning.
 By backtracking and updating accumulated distances, it maintains the M
 best candidates and performs additional pruning when necessary.
 The algorithm ultimately selects the candidate with the minimum total distance,
 resulting in a near-optimal solution with reduced search space and good
 detection performance.
\end_layout

\begin_layout Standard

\size large
For the Near Maximum Likelihood (Near-ML) detection algorithm, the goal
 is to estimate the transmitted symbols, denoted by 
\begin_inset Formula $\hat{\theta}_{NML}$
\end_inset

, given the received signal 
\begin_inset Formula $\boldsymbol{Y}$
\end_inset

, channel matrix 
\begin_inset Formula $\boldsymbol{H}$
\end_inset

, and the constellation points 
\begin_inset Formula $\boldsymbol{\mathbb{A}}$
\end_inset

.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
\begin_inset Formula $\boldsymbol{M}$
\end_inset

: The number of best candidates to be stored at each level of the tree search.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
\begin_inset Formula $QRM$
\end_inset

: 
\begin_inset Formula $\boldsymbol{|\mathbb{A}|}$
\end_inset

.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
\begin_inset Formula $a_{est}$
\end_inset

: The temporary estimation of the transmitted symbol at a specific level,
 calculated as the received signal divided by the corresponding channel
 coefficient.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
\begin_inset Formula $d$
\end_inset

: The distance between the temporary estimation 
\begin_inset Formula $a_{est}$
\end_inset

 and the constellation points.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
\begin_inset Formula $d_{min}$
\end_inset

: The minimum total distance found so far, used for pruning.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
\begin_inset Formula $d_{total}$
\end_inset

: The total distance of each candidate, used to find the best candidates.
 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
\begin_inset Formula $d_{minf}$
\end_inset

: The minimum total distance found at the end of the tree search, used to
 determine the best candidate.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
\begin_inset Formula $s_{est3}$
\end_inset

: The reordered detected symbols according to the original index.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
\begin_inset Formula $index[k]$
\end_inset

: The original index of the detected symbols.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{algorithm}[H] 
\backslash
caption{Near Maximum Likelihood Detection} 
\backslash
begin{algorithmic}[1] 
\backslash
Procedure{NearML}{$
\backslash
boldsymbol{y_p}$, $
\backslash
boldsymbol{H}$, $
\backslash
boldsymbol{
\backslash
mathbb{A}}$, $M$}     
\backslash
State Initialize tree search, set $nt$ as the number of columns of $
\backslash
boldsymbol{H}$, and set $QRM = |
\backslash
mathbb{A}|$     
\backslash
State Initialize variables, tensors, and arrays     
\backslash
State Compute the distances at level $nt$: $a_{est} = 
\backslash
frac{y_p[nt - 1]}{H[nt - 1, nt - 1]}$, $d = |a_{est} - 
\backslash
mathbb{A}|^2$     
\backslash
State Sort the distances and initialize the parent nodes and parent received
 signals     
\backslash
For{$n$ in range($QRM$)}         
\backslash
For{$k$ in range($nt-1$, $0$, $-1$)}             
\backslash
State Compute the distances at level $k$: $a_{est} = 
\backslash
frac{y_p[k - 1]}{H[k - 1, k - 1]}$, $d = |a_{est} - 
\backslash
mathbb{A}|^2$             
\backslash
State Sort the distances and update the best candidates             
\backslash
State Perform pruning: check if $d_{min} > d_{total}$             
\backslash
If{pruning condition met}                 
\backslash
State Skip the remaining branches and move to the next subtree         
    
\backslash
EndIf         
\backslash
EndFor         
\backslash
State Store the $M$ best candidates         
\backslash
State Update the minimum total distance: $d_{min} = 
\backslash
min(d_{total})$         
\backslash
If{a new tree is opened}             
\backslash
State Check the pruning condition: $d_{min} > d_{p}$             
\backslash
State Reset the skip flag if needed         
\backslash
EndIf     
\backslash
EndFor     
\backslash
State Determine the vector with the minimum distance: $d_{minf} = 
\backslash
min(d_{total})$     
\backslash
State Reorder the detected symbols according to the original index: $
\backslash
hat{
\backslash
theta}_{
\backslash
text{NearML}}[index[k]] = s_{est3}[k]$ 
\backslash
EndProcedure 
\backslash
end{algorithmic} 
\backslash
end{algorithm} 
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Based on the provided NearML code, the time complexity can be analyzed by
 considering the nested loops and the operations inside them.
 The outer loop iterates 
\begin_inset Formula $QRM$
\end_inset

 times, where 
\begin_inset Formula $QRM$
\end_inset

 is the number of constellation symbols (denoted as 
\begin_inset Formula $|𝔸|$
\end_inset

).
 Inside this loop, there is another loop that iterates nt times, where 
\begin_inset Formula $nt$
\end_inset

 represents the number of columns in the channel matrix 
\begin_inset Formula $\boldsymbol{H}$
\end_inset

 which is 
\begin_inset Formula $N$
\end_inset

.
 Within the inner loop, there are operations that take 
\begin_inset Formula $M$
\end_inset

 and 
\begin_inset Formula $QRM$
\end_inset

 time.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Therefore, the overall time complexity of the NearML algorithm can be approximat
ed as :
\end_layout

\begin_layout Standard

\size large
\begin_inset Formula 
\begin{equation}
O\left(|\mathbb{A}|N\left(M+|\mathbb{A}|\right)\right)\simeq O\left(|\mathbb{A}|^{2}NM\right)\label{eq:BigONearML}
\end{equation}

\end_inset


\end_layout

\begin_layout Subsection
\paragraph_spacing onehalf
\noindent

\size large
The Roadmap to 6G – AI Empowered Wireless Networks 
\begin_inset CommandInset citation
LatexCommand cite
key "The_Roadmap_to_6G"
literal "false"

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The integration of AI technologies in communication networks holds the potential
 for a more efficient and reliable future for 6G and beyond.
 
\color blue
Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:6GRoadMap"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
 illustrates the increasing presence of network machine learning across
 various network areas each year.
 The figure illustrates an ideal timeline of AI advances in the telecom
 area.
 The "intelligent PHY layer" paradigm, with its ability to self-learn and
 self-optimize, ensures that the system remains efficient and reliable despite
 various hardware and channel effects.
 Sometimes, the hardware referred to includes low-cost devices that may
 not be well fine-tuned but are commonly used.
 This AI-driven approach aims to adapt and optimize communication systems
 even when operating with less-than-ideal hardware components.
 This model leverages AI technologies to enhance communication efficiency
 and performance, and can autonomously learn and enhance performance through
 the integration of cutting-edge sensing and data-gathering tools.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Transfer learning can be used to get around the need for system redesign
 due to hardware heterogeneity for various hardware configurations.
 This approach adjusts the neural network weights to work with custom hardware
 architecture, regardless of the training on floating point or fixed point
 backpropagation.
 Therefore, network architecture is more crucial than numeric resolution
 in contrast to traditional methods.
 In the image bellow, a roadmap is presented that depicts the expected evolution
 of deep learning in the coming years.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Papers/RoadMap6G .png
	lyxscale 40
	scale 40

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Roadmap showing the evolution of deep learning models in telecom and justifying
 our research.
 
\begin_inset CommandInset label
LatexCommand label
name "fig:6GRoadMap"

\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "The_Roadmap_to_6G"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
\paragraph_spacing onehalf
\noindent

\size large
An Introduction to Deep Learning for the Physical Layer 
\begin_inset CommandInset citation
LatexCommand cite
key "Intro_DL_Physical_Layer"
literal "false"

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
It is explained detailed overview of neural networks and their application
 to channel equations, with formal mathematical description included.
 The article describes the formal structure of feed-forward neural networks,
 as well as some applications of convolutional neural networks, that was
 described in the first section.
 It also introduces autoencoders for end-to-end communication systems and
 proposes the idea that an autoencoder can be used to characterize a complete
 channel as shown in 
\color blue
Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Autoencoder-as-Channel"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
.
 What's remarkable about this approach is that it can be extended to channel
 models and loss functions for which the optimal solutions are unknown,
 making it highly versatile.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Papers/ChannelAutoencoder.png

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Autoencoder as Channel 
\size large

\begin_inset CommandInset label
LatexCommand label
name "fig:Autoencoder-as-Channel"

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "Intro_DL_Physical_Layer"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
In addition, the authors use adversarial networks to manage multiple transmitter
-receiver pairs with competing capacity.
 Although the Multiple-Input Multiple-Output (MIMO) scenario is not currently
 implemented, it could be a promising area for future work.
 Finally, the authors also discuss modulation classification, which involves
 using Convolutional Neural Networks (CNNs) to automatically detect the
 modulation scheme used in a communication process.
\end_layout

\begin_layout Subsubsection
\paragraph_spacing onehalf
\noindent
Autoencoder 
\begin_inset CommandInset citation
LatexCommand cite
key "autoencoderBasis"
literal "false"

\end_inset

 
\begin_inset CommandInset label
LatexCommand label
name "subsec:Autoencoder"

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
An autoencoder is a type of artificial neural network used primarily for
 unsupervised learning tasks, such as dimensionality reduction, feature
 extraction, and data compression.
 It is designed to learn efficient representations of input data by encoding
 and decoding the data through a neural network architecture.
 The primary goal of an autoencoder is to reconstruct the input data with
 the highest possible accuracy while learning a compact and meaningful represent
ation of the data.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The architecture of an autoencoder can be likened to a communication system,
 consisting of two main components: the encoder, which acts as the transmitter,
 and the decoder, which serves as the receiver.
 The encoder's responsibility is to compress the input data into a lower-dimensi
onal representation, similar to the role of a transmitter in a communication
 system.
 This compressed representation, often referred to as the latent space or
 bottleneck, is then sent through the channel.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
On the other hand, the decoder, which is analogous to the receiver in a
 communication system, takes the lower-dimensional representation from the
 channel and attempts to reconstruct the original input data.
 In essence, the autoencoder architecture mirrors the basic structure of
 a communication system, with the encoder and decoder functioning as transmitter
 and receiver, respectively.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The communication rate of this system is 
\begin_inset Formula $R=\frac{k}{n}$
\end_inset

 [bit/channel use], where 
\begin_inset Formula $k=log_{2}(M).$
\end_inset

In the notation (n,k), the system is able to send one of 
\begin_inset Formula $M=2^{k}$
\end_inset

 messages (i.e., k bits) through n channel uses.
 The communication channel is characterized by the conditional probability
 density function 
\begin_inset Formula $p(Y|x)$
\end_inset

, where 
\begin_inset Formula $y∈Rn$
\end_inset

 represents the received signal.
 After receiving 
\begin_inset Formula $\boldsymbol{Y}$
\end_inset

, the receiver applies a transformation 
\begin_inset Formula $g:\mathbb{R}^{n}→M$
\end_inset

 to generate the estimate 
\begin_inset Formula $\boldsymbol{ŝ}$
\end_inset

 of the transmitted message 
\begin_inset Formula $\boldsymbol{s}$
\end_inset

.
 As final loss function it is used cross entropy loss, which is mention
 in 
\color blue
section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Cross-Entropy-Loss"
plural "false"
caps "false"
noprefix "false"

\end_inset

 
\end_layout

\begin_layout Subsection
\paragraph_spacing onehalf
\noindent

\size large
Recent Advances in Neural Network Techniques For Channel Equalization:A
 Comprehensive Survey 
\begin_inset CommandInset citation
LatexCommand cite
key "Recent_Advances_in_Neural_Network_Techniques_for_Channel_Equalization"
literal "false"

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
This paper provides an overview of various channel equalization methods,
 including the Multilayer Perceptron (MLP) equalizer, Functional Link Artificial
 Neural Network (FLANN) equalizer, Chebyshev Neural Network (NN) equalizer,
 and Radial Basis Function NN (RBFNN) equalizer.
 Additionally, it presents a literature review and application of Recursive
 Neural Network (RNN) and Fuzzy Neural Network equalizers.
\end_layout

\begin_layout Subsubsection
FLANN
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
The primary difference between FLANN hardware and MLP configuration is that
 the nonlinear mapping replaces only the input, output, and hidden layers.
 This mapping uses a non-linear function to transform the input vector,
 mapping it to a higher-dimensional space.
 The expansion function, called the functional link, is typically a polynomial
 function of the input variables.
 In our final experiments, we explored the concept of searching for equalization
 in a higher-dimensional space, but did not utilize the polynomial function
 approach.
\end_layout

\begin_layout Subsubsection
RBF
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Radial basis functions (RBFs) are a type of basis function used in function
 approximation and machine learning algorithms.
 RBFs are a class of functions that depend only on the distance from the
 center of the function, and their output decreases as the distance from
 the center increases.
 Gaussian RBF: This function takes the form of 
\begin_inset Formula $e^{(-r^{2}/2)}$
\end_inset

, where r is the Euclidean distance from the center of the function.
 This RBF is widely used in machine learning and function approximation
 algorithms due to its smoothness and symmetry.
\end_layout

\begin_layout Subsubsection
RNN
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
The article concludes by stating that Recurrent Neural Networks (RNNs) generally
 outperform feed-forward neural networks (FNNs) and other methods.
 RNNs approximate a finite impulse response (IIR) filter, whereas other
 methods approximate a finite impulse response (FIR) filter.
 It is worth noting that IIR filters are known to be unstable, but recent
 advances in neural networks, such as LSTM, GRU, and Transformers, have
 been developed to overcome this limitation 
\end_layout

\begin_layout Subsubsection
Overview and Insights
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
Recurrent Neural Networks (RNNs) 
\begin_inset CommandInset citation
LatexCommand cite
key "RNN_LSTM"
literal "false"

\end_inset

 are the most effective solutions for BER performance.
 RNNs have made significant advancements over the years, leading to the
 emergence of powerful tools like Sequence to Sequence 
\begin_inset CommandInset citation
LatexCommand cite
key "seq_to_seq"
literal "false"

\end_inset

, which can handle longer sequences with the Attention mechanism.
 This development allows the model to weigh different parts of the input
 sequence based on their relevance to the current decoding step, improving
 interpretability of the model's predictions.
 Next this models has an evolution on transformers 
\begin_inset CommandInset citation
LatexCommand cite
key "transformer"
literal "false"

\end_inset

 models, which had emerged as an alternative, relying solely on self-attention
 to process input sequences, leading to greater parallelization during training
 and reduced computational complexity compared to RNN-based models.
 However, it's important to note that the best results found in this research
 are based on an outdated evolution of sequential models.
 The latest research on transformers and attention mechanisms will be presented
 to explain these advancements and show readers how to merge the latest
 advances in signal equalization and deep learning to create new state-of-the-ar
t models.
 
\color blue
Figure 10
\color inherit
 shows an evolution of sequential networks to illustrate how outdated RNNs
 are.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Networks/TimeLineEvolution.jpg
	lyxscale 20
	scale 28

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
From RNN to Image Transformers
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection

\size large
Neuronal
\size default
 networks 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Neural networks are a type of artificial intelligence system designed to
 mimic the functioning of the human brain.
 They consist of interconnected nodes, or "neurons," which are capable of
 processing information and making decisions based on that information.
 These networks are usually organized into layers, with each layer containing
 a different number of neurons.
 The input layer receives input from the external environment, while the
 output layer produces the final result or decision based on that input.
 The layers in between the input and output layers are called hidden layers,
 and they perform various intermediate calculations and processing tasks.
 Neural networks are trained using large amounts of data, allowing them
 to learn and make predictions or decisions based on that data.
 
\end_layout

\begin_layout Subsubsection
Linear Layer 
\begin_inset CommandInset label
LatexCommand label
name "subsec:Linear-Layer"

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
A linear layer in a neural network is a type of layer that applies a linear
 transformation to the input data.
 This transformation can be represented by a 
\series bold
matrix
\series default
 of weights, denoted as 
\begin_inset Formula $\boldsymbol{W_{n}}$
\end_inset

 ,and a biases 
\series bold
vector
\series default
, denoted as 
\begin_inset Formula $\boldsymbol{b_{n}}$
\end_inset

, which are learned during the training process.
 The subscript 
\begin_inset Formula $\boldsymbol{n}$
\end_inset

 refers to the nth layer.
 The output of a linear layer is calculated by performing a matrix and vector
 product between the input data 
\begin_inset Formula $\boldsymbol{X_{n-1}}$
\end_inset

 and the weights 
\begin_inset Formula $\boldsymbol{W_{n}}$
\end_inset

 as well as adding the biases.
 
\end_layout

\begin_layout Standard

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{X_{n}=W_{n}X_{n-1}+b_{n}}\label{eq:41}
\end{equation}

\end_inset


\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\boldsymbol{W_{n}}$
\end_inset

weight matrix at layer n.
\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\boldsymbol{b_{n}}$
\end_inset

 bias at layer n
\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\boldsymbol{X_{n-1}}$
\end_inset

Input or last layer data
\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\boldsymbol{X_{n}}$
\end_inset

 Output data
\end_layout

\begin_layout Standard

\size large
\color blue
Figure 11 
\color inherit
gives the idea that inputs are vectors, and the neural network can produce
 an output based on a linear relationship that depends on the weights and
 bias.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Diagrams/NN_eq.png
	lyxscale 70
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Output as Y and input as X.
 Vector matrix representation of system.
 Desing done with manim 
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Backpropagation 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
The layer aims to optimize the weight parameters to align with a target
 known as the ground truth.
 The error, denoted by 
\begin_inset Formula $E$
\end_inset

, is calculated as the difference between the predicted output (
\begin_inset Formula $\boldsymbol{\hat{X}}$
\end_inset

) and the actual target output (
\begin_inset Formula $\boldsymbol{X_{n}}$
\end_inset

), where 
\begin_inset Formula $n$
\end_inset

 is the index of the sample in the dataset.
 To optimize the weights, the backpropagation algorithm will be employed,
 which is a widely used technique in the field of artificial neural networks
 for training by adjusting the inter-neuron weights.
\begin_inset Formula 
\begin{equation}
\boldsymbol{Err=\hat{X}-X_{n}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
This method analyzes the error rate in relation to the weights and inputs.
 As we adjust our trainable parameters, {
\begin_inset Formula $\boldsymbol{W_{n}}$
\end_inset

, 
\begin_inset Formula $\boldsymbol{b_{n}}$
\end_inset

}, the error will change accordingly.
 The goal is to minimize the error, or to find a point where the error gradient
 is zero.
\begin_inset CommandInset citation
LatexCommand cite
key "Goodfellow-et-al-2016"
literal "false"

\end_inset


\end_layout

\begin_layout Standard

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{\nabla W=\frac{\partial E}{X_{n\text{+1}}}X_{n-1}^{T}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{\nabla X_{n-1}=W_{n}^{T}\frac{\partial E}{X_{n\text{+1}}}}
\end{equation}

\end_inset


\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\boldsymbol{\nabla W}$
\end_inset

Gradient of weights.
 This gradient represents the multivariable discrete differentiation.
 
\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\boldsymbol{\nabla X_{n-1}}$
\end_inset

Gradient of a sample before better known as input.
 
\end_layout

\begin_layout Subsubsection
Learning rate
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
When training a neural network, the weights 
\begin_inset Formula $\boldsymbol{W_{n}}$
\end_inset

 and bias terms 
\begin_inset Formula $\boldsymbol{b_{n}}$
\end_inset

 are updated iteratively using an optimization algorithm such as gradient
 descent.
 The learning rate 
\begin_inset Formula $\gamma$
\end_inset

 is a hyperparameter that plays a crucial role in this process by determining
 the size of the update step applied to the weights and biases at each iteration.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The learning rate 
\begin_inset Formula $\gamma$
\end_inset

 is a scalar value that is multiplied by the gradient of the loss function
 with respect to the weights of the network.
 This gradient provides information about the direction and magnitude of
 the weight update required to minimize the loss function.
 A smaller learning rate leads to smaller updates and slower convergence,
 while a larger learning rate results in larger updates and faster convergence.

\size default
 
\begin_inset CommandInset citation
LatexCommand cite
key "learningrate"
literal "false"

\end_inset

 
\end_layout

\begin_layout Standard

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{W_{n}}=\boldsymbol{W_{n-1}}-\gamma\boldsymbol{\nabla W}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{b_{n}}=\boldsymbol{b_{n-1}}-\gamma\boldsymbol{\frac{\partial E}{X_{n}}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
If the learning rate is set too low, the optimization process may become
 stuck in a local minimum or local maximum.
 A local minimum is a point in the optimization landscape where the cost
 function has a lower value than the surrounding points, but is not the
 global minimum.
 A local maximum is a point where the cost function has a higher value than
 the surrounding points, but is not the global maximum.
 This can lead to suboptimal performance or even failure of the optimization
 process.
 On the other hand, if the learning rate is set too high, the optimization
 process may oscillate or diverge, also leading to suboptimal performance.
 It is important to choose an appropriate learning rate for the optimization
 process in order to avoid these problems.
\end_layout

\begin_layout Subsubsection
Activation functions 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Activation functions are used in neural networks to introduce non-linearity
 into the network.
 This is important because many real-world problems are non-linear in nature
 and a neural network with only linear functions would not be able to model
 such problems accurately.
 Activation functions allow the network to learn more complex patterns in
 the data and improve the accuracy of the network.
 They also help to prevent the network from becoming stuck in a local minimum
 or plateau during training.
 
\color blue
Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Actfunctions"
plural "false"
caps "false"
noprefix "false"

\end_inset

 
\color black
shows the most common activation functions.
 
\color inherit
The most widely used activation functions in neural networks include the
 sigmoid, hyperbolic tangent (tanh), and rectified linear unit (ReLU) functions.
 The sigmoid function transforms any input value into a range from 0 to
 1, while the tanh function adjusts input values to fall within the -1 to
 1 range.
 The ReLU (Rectified Linear Unit) function operates linearly, setting all
 negative input values to 0 and retaining all positive input values in their
 initial form.
 
\begin_inset CommandInset citation
LatexCommand cite
key "ActivationFunctions"
literal "false"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/ActivationFunctions.png
	lyxscale 10
	scale 10

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Activation function.
 (a) Sigmoid, (b) tanh, (c) ReLU.
 
\begin_inset CommandInset label
LatexCommand label
name "fig:Actfunctions"

\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "ActivationFunctionsImages"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
However, the traditional activation functions pose some challenges when
 it comes to embedded devices.
 They often involve computationally expensive operations such as exponentiation,
 division, and floating-point arithmetic.
 These operations can significantly increase the processing time and power
 consumption, making them less attractive for resource-constrained embedded
 systems.
 To address these concerns, researchers have proposed hardened versions
 of activation functions.
 Hardened activation functions are designed to be computationally less demanding
 while maintaining similar performance to their traditional counterparts.
 Examples of hardened activation functions include the binary step function,
 Hardtahn 
\color blue
Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Hardtanh(red)-and-Tanh(blue)"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
, or Hardsigmoid.
 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
These hardened activation functions enable faster neural network computations
 while still delivering similar results, with the Hardtanh function being
 the most used for this research that can be described as follows:
\end_layout

\begin_layout Standard

\size large
\begin_inset Formula 
\begin{equation}
hardtanh(x)=\begin{cases}
-1, & \text{if }x<-1\\
x, & \text{if }-1\le x\le1\\
1, & \text{if }x>1
\end{cases}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Hardtanh.png
	lyxscale 25
	scale 25

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Hardtanh(red) and Tanh(blue) 
\begin_inset CommandInset label
LatexCommand label
name "fig:Hardtanh(red)-and-Tanh(blue)"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Loss functions
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
A loss function is often defined as a scalar function of the model's parameters,
 the input data, and the true output.
 It quantifies how well the model is able to fit the data, and it's commonly
 used to evaluate the performance of different models and to select the
 best one.
 In terms of estimators, a loss function can be seen as a measure of how
 well the estimator is able to estimate the true parameter.
 The goal of training a machine learning model is to find the sub-optimal
 set of parameters that minimize the loss function.
 There are different types of loss functions, each one is suitable for different
 types of problems.
 There are various types of loss functions, each tailored to specific types
 of problems.
 For example, in a regression problem, the mean squared error (MSE), as
 mentioned in section 
\color blue

\begin_inset CommandInset ref
LatexCommand eqref
reference "subsec:MSE"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
 , is a commonly used loss function.
 Conversely, in classification problems, the cross-entropy loss is often
 employed.
 Due to its significance, we will delve deeper into the cross-entropy loss
 in the following section, discussing how it operates within the context
 of deep learning.
\end_layout

\begin_layout Subsubsection
Cross Entropy Loss
\begin_inset CommandInset label
LatexCommand label
name "subsec:Cross-Entropy-Loss"

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Previously, we have discussed the Mean Squared Error (MSE) in the context
 of estimators.
 However, there is another cost function, known as the cross-entropy loss,
 which can be utilized for evaluating models in the context of classification
 problems.
 Prior to elaborating on the cross-entropy loss, it is imperative to also
 discuss the softmax function.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The softmax function is a mathematical technique which transforms a vector
 of real numbers into a probability distribution over the classes.
 The output of the softmax function is a vector of values between 0 and
 1 that sum up to 1, which can be interpreted as probabilities.
 The softmax function is employed in this context as it provides a means
 to convert the output, or scores, of the model into a probability distribution
 that represents the uncertainty of the model's predictions.
 Additionally, the softmax function ensures that the probability of each
 class falls within the range of 0 and 1, and that the sum of all class
 probabilities is 1, which is a necessary requirement for a probability
 distribution.
 Given an input vector of size 
\begin_inset Formula $K$
\end_inset

 where 
\begin_inset Formula $z_{i}$
\end_inset

 represents each element taken from this vector,
\color blue
 Figure 14
\color inherit
 illustrates how the values are mapped from real values to probabilities
 using the formula depicted inside the box.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/softmax.png
	lyxscale 40
	scale 40

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Softmax used to map real numbers to probabilty distribution.
\begin_inset CommandInset label
LatexCommand label
name "fig:Softmax"

\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "softmax"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
After obtaining the softmax output probabilities, a comparison is made between
 these probabilities and an ideal output.
 This comparison is measured using the cross-entropy loss function, which
 evaluates the dissimilarity between the predicted and true probability
 distributions.
 One notable advantage of this function is its ease of computation and different
iation, which makes it well-suited for optimization algorithms based on
 gradients.
 The objective of the training process is to minimize the KL(Kullback-Leibler)
 divergence.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
D_{KL}(P||Q)=\sum P(i)log\frac{P(i)}{Q(i)}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
In this equation, 
\begin_inset Formula $D_{KL}(P∣∣Q)$
\end_inset

 represents the KL divergence between two probability distributions 
\begin_inset Formula $P$
\end_inset

 and 
\begin_inset Formula $Q$
\end_inset

, where 
\begin_inset Formula $P$
\end_inset

 is the true distribution and 
\begin_inset Formula $Q$
\end_inset

 is the approximating distribution.
 The double vertical bars (
\begin_inset Formula $||$
\end_inset

) in the notation denote "divergence between" the two distributions.
 The KL divergence is widely used in information theory and machine learning
 to evaluate the dissimilarity between two distributions.
 It is important to note that the Kullback-Leibler (KL) divergence is not
 symmetric.
 In other words, the KL divergence between distributions P and Q, denoted
 as 
\begin_inset Formula $D_{KL}(P∣∣Q)$
\end_inset

, is not equal to the KL divergence between 
\begin_inset Formula $Q$
\end_inset

 and 
\begin_inset Formula $P$
\end_inset

, denoted as 
\begin_inset Formula $D_{KL}(Q∣∣P)$
\end_inset

.
 The asymmetry of the KL divergence implies that it should not be regarded
 as a true distance metric in the strict mathematical sense.
 Instead, it serves as a measure of dissimilarity between two probability
 distributions.
 This characteristic is also reflected in its alternative name, relative
 entropy.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The KL divergence plays a crucial role in determining which class is more
 probable.
 The predicted class distribution, denoted by 
\begin_inset Formula $P(Y∣x_{i};θ)$
\end_inset

, is influenced by the parameters 
\begin_inset Formula $θ$
\end_inset

, while the true class distribution is represented by 
\begin_inset Formula $P^{*}(Y∣x_{i})$
\end_inset

.
 Where 
\begin_inset Formula $x_{i}$
\end_inset

 are 
\begin_inset Formula $z_{i}$
\end_inset

values transformed by the softmax.
 Both of these distributions are taken into account when assessing the dissimila
rity between 
\begin_inset Formula $P(Y∣x_{i};θ)$
\end_inset

 and 
\begin_inset Formula $P^{*}(Y∣x_{i})$
\end_inset

 .
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
D_{KL}(P^{*}(Y|x_{i})||P(Y|x_{i};\theta)=\sum P^{*}(Y|x_{i})log\frac{P^{*}(Y|x_{i})}{P(Y|x_{i};\theta)}
\end{equation}

\end_inset

Rewriting the logarithm as two individual sections, we can observe that
 the left part of the equation below does not depend on the 
\begin_inset Formula $\theta$
\end_inset

 parameter.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\sum\underbrace{P^{*}(Y|x_{i})log(P^{*}(Y|x_{i}))}_{\text{Independent of }\theta}-P^{*}(Y|x_{i})P(Y|x_{i};\theta)
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
And then we aim to make both distributions as similar as possible using
 the best estimator.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\text{argmin}D_{KL}(P^{*}||P)\equiv\underset{\theta}{\text{argmin}}-\sum_{y}P^{*}(Y|x_{i})P(Y|x_{i};\theta)
\end{equation}

\end_inset


\end_layout

\begin_layout Standard

\size large
Where 
\begin_inset Formula $P^{*}=P^{*}(Y∣x_{i})$
\end_inset

 and 
\begin_inset Formula $P=P(Y∣x_{i};θ)$
\end_inset


\end_layout

\begin_layout Subsection
Convolutional Neuronal Networks 
\begin_inset CommandInset label
LatexCommand label
name "subsec:CNN"

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Convolutional neural networks (CNNs) type of network excel at feature extraction
, which is a critical aspect of their success in various applications, especiall
y in image recognition and computer vision tasks.
 Feature extraction is the process of identifying and extracting relevant
 patterns or features from raw data, helping the model to discern and recognize
 important characteristics within the input.
 The network is composed of multiple layers, including 
\series bold
convolutional layers
\series default
, 
\series bold
activation layers
\series default
, 
\series bold
pooling layers 
\series default
and
\series bold
 linear layers
\series default
.
 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The convolutional layers apply a set of filters to the input data, where
 each filter is a small matrix of weights.
 This ones are used to identify features in the data such as 
\series bold
edges
\series default
, 
\series bold
textures
\series default
, and 
\series bold
shapes
\series default
, specifically, we will be utilizing these layers to extract the relationship
 of intercarrier symbol interference (ISI) and to perform dimensionality
 reduction.
 
\begin_inset CommandInset citation
LatexCommand cite
key "Conv1"
literal "false"

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "Goodfellow-et-al-2016"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\size large
The 
\series bold
activation layers
\series default
 or activation functions introduce non-linearity to the network, allowing
 it to learn complex representations of the input data.
 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\size large
The 
\series bold
pooling layers
\series default
 reduce the spatial dimensions of the data, which helps to reduce overfitting
 and computational cost.
\end_layout

\begin_deeper
\begin_layout Itemize
\paragraph_spacing onehalf

\size large
Max pooling is used to pick the feature with the highest activation in a
 small region of the input feature map
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\size large
Average pooling is used to reduce the spatial size of the input data by
 taking the average of the values of a small region of the input feature
 map.
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Diagrams/Max_pool_avg_pool.jpg
	lyxscale 40
	scale 20

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Average and max pooling
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Itemize
\noindent
\align block

\series bold
\size large
Linear layers
\series default
 classify the features extracted by the convolutional layers into the desired
 output.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent
\align block

\size large
It should be noted that what is commonly referred to as 'convolution' in
 the context of convolutional neural networks (CNNs) is actually a cross-correla
tion operation, denoted with symbol 
\begin_inset Formula $\bigstar$
\end_inset

 and convolution usually is used 
\begin_inset Formula $\boldsymbol{*}$
\end_inset

.
 The term 'convolution' is used only for convention purposes.
 The basic concept behind cross-correlation is to take a small matrix, referred
 to as a kernel or filter, and slide it over the input data (such as an
 image or audio signal).
 At each position, the kernel is multiplied element-wise with the underlying
 data, and the results are summed to produce a single output value, referred
 to as a feature map.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Diagrams/Conv2d_Kernel.jpg
	lyxscale 30
	scale 25

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Caption Standard

\begin_layout Plain Layout
Basic cross-correlation operation
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The output of the convolution operation is a feature map, where each element
 in the feature map is computed as follows:
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
Y_{ij}=\sum_{a,b}K_{ab}\circ I_{i+a,j+b}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Where kernel(a,b) is the value of the filter at position (a,b), input(i+a,j+b)
 is the value of the input at position (i+a,j+b) and output(i,j) is the
 output value at position (i,j)
\end_layout

\begin_layout Subsubsection
Channels
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
A channel refers to a specific feature or dimension of the input data.
 For example, in the case of image data, a channel can represent a color
 channel such as red, green, or blue.
 These channels are used to extract different features of the input image,
 and they are processed separately by the CNN.
 In our case study, we can use channels as a division between the real and
 imaginary parts, or for feature extraction of intercarrier symbol interference
 (ISI).
 We can have N channels as input and M channels as output, depending on
 how many features we want to deal with.
 In the image below, we show a case of 3 channel input and two channel output,
 also with a bias term.
\size default

\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/ConvolutionExpansion.png
	lyxscale 50
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Convolutional Neural Network with 3-channel Input and 2-channel Output,
 including bias term
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
A Generalized View of Linear Layers through Convolutional Neural Networks
\end_layout

\begin_layout Standard

\size large
Let's take a more detailed look at the math, given the following terms.
\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $j$
\end_inset

 input channels with
\begin_inset Formula $X_{j}$
\end_inset

 matrices
\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $d$
\end_inset

 ouput channels 
\begin_inset Formula $Y_{d}$
\end_inset

matrices and this ones an output size of 
\begin_inset Formula $X_{j}-K_{ij}$
\end_inset


\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $K_{ij}$
\end_inset

 kernels,where 
\begin_inset Formula $i$
\end_inset

 maps to 
\begin_inset Formula $Y_{d}$
\end_inset

 and 
\begin_inset Formula $j$
\end_inset

 to 
\begin_inset Formula $X_{j}$
\end_inset


\end_layout

\begin_layout Itemize
\noindent
\align block

\size large
\begin_inset Formula $\bigstar$
\end_inset

 cross-correlation
\end_layout

\begin_layout Standard

\size large
\begin_inset Formula 
\begin{equation}
Y_{d}=B_{d}+\sum_{j=1}^{n}X_{j}\bigstar K_{ij}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
We can think of the matrices as individual blocks and visualize them in
 the image below.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Conv2dGeneralization.png
	lyxscale 40
	scale 60

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset Formula $Y_{d}$
\end_inset

 output given kernels
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Finally, with the use of abstraction, we can further simplify the problem
 by representing it as a generalized version of tensors.
 The internal tensor is given by the sum of the cross-correlations between
 X channels and kernels.
 In a more general perspective, this can be viewed as the inner product
 
\begin_inset Formula $\langle.\rangle$
\end_inset

 of two tensors.
\end_layout

\begin_layout Standard

\size large
\begin_inset Formula 
\begin{equation}
Y=B+\langle K,X\rangle
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/MetaDense.png
	lyxscale 50
	scale 70

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Higher dimensionality abstract version
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
It's worth noting that when we consider a kernel of 1 dimension and an input
 of 1 channel, we can see that a dense layer is just a specific case of
 a 2D convolutional layer (Conv2D).
 Just as 
\begin_inset CommandInset ref
LatexCommand formatted
reference "eq:41"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 
\end_layout

\begin_layout Subsection
\paragraph_spacing onehalf
\noindent

\size large
MobileNet 
\begin_inset CommandInset citation
LatexCommand cite
key "MobileNet"
literal "false"

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
Addressing the issue of efficiency, the traditional MobileNet achieves its
 high performance through the use of depthwise separable convolutions.
 This technique, which combines depthwise convolution and pointwise convolution,
 allows the model to maintain high accuracy.
 In terms of time complexity, MobileNet has a lower multiplications compared
 to regular 
\color blue

\begin_inset CommandInset ref
LatexCommand nameref
reference "subsec:CNN"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
.
 This results in faster inference times and lower memory requirements,as
 its name says usefull for mobile applications, also include embbeded system
 applications for edge computing.
 It is important to mention that MobileNet's efficiency comes at the cost
 of slightly lower accuracy compared to conventional CNNs.
\end_layout

\begin_layout Subsubsection
Depthwise Separable Convolution
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Standard convolution operations can be slow to perform due to the number
 of multiplications required.
 An alternative method called depth-wise separable convolution can be used
 to speed up the process.
 This method breaks down the convolution process into two parts: depthwise
 convolution and pointwise convolution.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Let us briefly review the fundamental concepts of convolution on an input
 volume.
 Let's take an input volume 
\begin_inset Formula $F$
\end_inset

 with dimensions 
\begin_inset Formula $D_{F}\times D_{F}\times M$
\end_inset

, where 
\begin_inset Formula $D_{F}$
\end_inset

 represents the width and height of the input volume and 
\begin_inset Formula $M$
\end_inset

 is the number of input channels.
 In the case of a color image, 
\begin_inset Formula $M$
\end_inset

 would be equal to 3 for the R, G, and B channels.
 We perform convolution on a kernel 
\begin_inset Formula $K$
\end_inset

, which has dimensions 
\begin_inset Formula $D_{k}\times D_{k}\times M$
\end_inset

.
 The output will be in the shape of 
\begin_inset Formula $D_{G}\times D_{G}\times1$
\end_inset

.
 When we apply 
\begin_inset Formula $N$
\end_inset

 kernels to the input, we obtain an output volume 
\begin_inset Formula $G$
\end_inset

 with dimensions 
\begin_inset Formula $D_{G}\times D_{G}\times N$
\end_inset

 as seen in 
\color blue
Figure 20
\color inherit
.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Papers/TraditionalConv.png
	lyxscale 50
	scale 63

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Traditional convolution
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
In a traditional convolution, filters are applied across all input channels
 and their values are combined in a single step.
 However, in depthwise separable convolution, this process is split into
 two stages as seen in 
\color blue
Figure 21
\color inherit
 and 
\color blue
Figure 22
\color inherit
.
 The first stage is depthwise convolution, which applies convolution to
 a single input channel at a time.
 To perform depthwise convolution, we use filters or kernels 
\begin_inset Formula $K$
\end_inset

, which are of shape 
\begin_inset Formula $D_{K}\times D_{K}\times1$
\end_inset

.
 Here, 
\begin_inset Formula $D_{K}$
\end_inset

 is the width and height of the square kernel, and it has a depth of 1 because
 this convolution is only applied to a single channel.
 Therefore, we require 
\begin_inset Formula $M$
\end_inset

 such 
\begin_inset Formula $D_{K}\times D_{K}\times1$
\end_inset

 kernels over the entire input volume 
\begin_inset Formula $F$
\end_inset

, where 
\begin_inset Formula $F$
\end_inset

 has a shape 
\begin_inset Formula $D_{F}\times D_{F}\times M$
\end_inset

.
 For each of these 
\begin_inset Formula $M$
\end_inset

 convolutions, we get an output of 
\begin_inset Formula $D_{G}\times D_{G}\times1$
\end_inset

 in shape.
 By stacking these outputs together, we obtain an output volume 
\begin_inset Formula $G$
\end_inset

 of shape 
\begin_inset Formula $D_{G}\times D_{G}\times M$
\end_inset

, which marks the end of the first phase, that is, the end of depthwise
 convolution.
 The number of multiplications in the depthwise convolution phase is obtained
 by applying these multiplications to all 
\begin_inset Formula $M$
\end_inset

 input channels separately, with each channel having its own kernel.
 Therefore, the total number of multiplications in this phase is:
\end_layout

\begin_layout Standard

\size large
\begin_inset Formula 
\begin{equation}
DW=M\times D_{G}{}^{2}\times D_{k}{}^{2}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Papers/DepthwiseConv.png
	lyxscale 70
	scale 70

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Depthwise convolution
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Pointwise convolution refers to a 
\begin_inset Formula $1\times1$
\end_inset

 convolution operation applied to each of the output channels generated
 by the depthwise convolution.
 In this step, the input is a volume of shape 
\begin_inset Formula $D_{G}\times D_{G}\times M$
\end_inset

, where 
\begin_inset Formula $M$
\end_inset

 is the number of output channels generated by the depthwise convolution.
 The filter used for this operation, denoted as KPC, has a shape of 
\begin_inset Formula $1\times1\times M$
\end_inset

, which means that it is applied across all 
\begin_inset Formula $M$
\end_inset

 output channels.
 The resulting output has the same width and height as the input 
\begin_inset Formula $D_{G}\times D_{G}$
\end_inset

, and the number of output channels can be controlled by using 
\begin_inset Formula $N$
\end_inset

 filters.
 Therefore, the final output volume of the depthwise separable convolution
 has a shape of 
\begin_inset Formula $D_{G}\times D_{G}\times N$
\end_inset

.
 And hence, the number of multiplications for one instance of convolution
 is 
\begin_inset Formula $M$
\end_inset

.
 This is applied to the entire output of the first phase, which has a width
 and height of 
\begin_inset Formula $D_{G}$
\end_inset

.
 So the total number of multiplications for this kernel is 
\begin_inset Formula $D_{G}\times D_{G}\times M$
\end_inset

.
 So for some 
\begin_inset Formula $N$
\end_inset

 kernels, we'll have this multiplications :
\end_layout

\begin_layout Standard

\size large
\begin_inset Formula 
\begin{equation}
PW=N\times D_{G}\times D_{G}\times M
\end{equation}

\end_inset


\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center

\size large
\begin_inset Graphics
	filename Imagenes/Papers/Pointwise.png
	lyxscale 70
	scale 70

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout

\size large
Pointwise convolution
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Hence, the total multiplication count is the sum of multiplication counts
 in the depthwise and pointwise convolution stages.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
Total=DW+PW=M\times D_{G}{}^{2}\times D_{k}{}^{2}+N\times D_{G}\times D_{G}\times M
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
Total=M\times D_{G}^{2}(D_{K}^{2}+N)
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
We can compare the computational efficiency of standard convolution with
 depthwise convolution by computing their ratio.
 This ratio is obtained by summing the reciprocal of the depth of the output
 volume, denoted as 
\begin_inset Formula $N$
\end_inset

, and the reciprocal of the squared dimensions of the kernel, denoted as
 
\begin_inset Formula $D_{k}$
\end_inset

.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\frac{DepthWise}{Standard}=\frac{M\times D_{G}^{2}(D_{K}^{2}+N)}{N\times D_{G}^{2}\times D_{k}^{2}\times M}=\frac{1}{N}+\frac{1}{D_{k}^{2}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
To better understand this, let's take an example.
 Suppose the output feature volume 
\begin_inset Formula $N$
\end_inset

 is 1024, and the kernel size is 3, which means 
\begin_inset Formula $D_{K}$
\end_inset

 is 3.
 Plugging these values into the equation, we obtain a ratio of 0.112.
 This indicates that standard convolution requires 9 times more multiplications
 than depthwise separable convolution.
 This significant difference in computational power can have a considerable
 impact on the performance and efficiency of convolutional neural networks.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{table}[htbp] 
\backslash
centering 
\backslash
caption{Depthwise Separable vs Full Convolution MobileNet} 
\backslash
label{tab:my-table} 
\backslash
begin{tabular}{|l|c|c|c|} 
\backslash
hline 
\backslash
textbf{Model} & 
\backslash
textbf{ImageNet Accuracy} & 
\backslash
textbf{Mult-Adds (Million)} & 
\backslash
textbf{Parameters (Million)} 
\backslash

\backslash
 
\backslash
hline Conv MobileNet & 71.7
\backslash
% & 4866 & 29.3 
\backslash

\backslash
 
\backslash
hline MobileNet & 70.6
\backslash
% & 569 & 4.2 
\backslash

\backslash
 
\backslash
hline 
\backslash
end{tabular} 
\backslash
end{table} 
\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
MobileNetV3 
\begin_inset CommandInset citation
LatexCommand cite
key "MobilenetV3"
literal "false"

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "subsec:MobileNetV3"

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
The MobileNetV3 architecture uses a combination of depthwise separable convoluti
ons, linear bottlenecks, and other optimizations to reduce the number of
 parameters and computational complexity while maintaining high accuracy.
 It also includes new design elements, such as dynamic activation functions
 and network architecture search techniques, to improve performance on a
 variety of tasks.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{table}[h] 
\backslash
centering 
\backslash
caption{MobileNet architectures} 
\backslash
label{tab:mobilenet} 
\backslash
begin{tabular}{|c|c|c|c|} 
\backslash
hline 
\backslash
textbf{Model} & 
\backslash
textbf{Input Resolution} & 
\backslash
textbf{FLOPS} & 
\backslash
textbf{Parameters} 
\backslash

\backslash
 
\backslash
hline MobileNet v1 & 224x224 & 569 M & 4.2 million 
\backslash

\backslash
 
\backslash
hline MobileNet v2 & 224x224 & 300 M & 3.4 million 
\backslash

\backslash
 
\backslash
hline MobileNet v3 & 224x224 & 219 M & 5.4 million 
\backslash

\backslash
 
\backslash
hline 
\backslash
end{tabular} 
\backslash
end{table}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
FLOPS stands for "Floating Point Operations Per Second".
 It is a measure of a computer's performance based on the number of floating
 point operations (such as additions, subtractions, multiplications, and
 divisions) it can perform in a second.
 It is commonly used to measure the performance of computer processors or
 the computational requirements of machine learning models.
\end_layout

\begin_layout Subsubsection
Reduced complexity for activation functions
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
One of the key components of his low computational cost is the implementation
 of hardsigmoid and hardswish function seen in 
\color blue
Figure 23
\color inherit
, which is quite similar that we done with hardtanh but with other activation
 function type.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
hswish[x]=x\frac{RELU6(x+3)}{6}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Papers/hardsigmoid.png

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Hard functions 
\begin_inset CommandInset citation
LatexCommand cite
key "MobilenetV3"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard

\size large
These functions are integrated into the final stage of MobileNet to serve
 as more efficient functions.
 
\color blue
Figure 24
\color inherit
 shows the most efficiente stages of mobileNet V3.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Papers/LastMobileNetv3.png

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Last section optimized 
\begin_inset CommandInset citation
LatexCommand cite
key "MobilenetV3"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
\paragraph_spacing onehalf
\noindent

\size large
A Novel OFDM Equalizer for Large Doppler Shift Channel through Deep Learning
 
\begin_inset CommandInset citation
LatexCommand cite
key "ZeroForcingEqNN"
literal "false"

\end_inset

 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset CommandInset label
LatexCommand label
name "subsec:A-Novel-OFDM"

\end_inset

This articles describes the neural architecture called Cascaded Net (CN)
 for equalization in OFDM systems.
 The use of a zero-forcing preprocessor aims to prevent the network from
 getting stuck in a saddle point or local minimum point.
 The CN neural architecture is designed to address the equalization problem
 in OFDM systems with Rayleigh fading and large Doppler shifts.
 By cascading a deep trainable network behind a zero-forcing preprocessor,
 the CN architecture achieves superior performance in comparison to traditional
 equalization methods.
 In 
\color blue
Figure 25
\color inherit
, blocks of equalizers and their proposed preprocessing stages can be appreciate
d.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Papers/ZeroForcePreprocess.png
	lyxscale 50
	scale 40

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Deep learning equalizer with prepocesing stage.
 
\size large

\begin_inset CommandInset citation
LatexCommand cite
key "ZeroForcingEqNN"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
As they are performing frequency domain equalization, their base equation
 is the same as ours.
 
\begin_inset Formula $\boldsymbol{Y=HX+W}$
\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The Cascade net is defined as follows.
 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\hat{\boldsymbol{X_{0}=(H^{H}H)^{-1}H^{H}Y}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{Z}_{i}=\boldsymbol{W}_{i}\left[\begin{array}{c}
\boldsymbol{H^{H}}\boldsymbol{Y}_{i}\\
\hat{\boldsymbol{X}_{i}}\\
\boldsymbol{H}^{H}\boldsymbol{H}\hat{\boldsymbol{X}_{i}}
\end{array}\right]+\boldsymbol{B}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\hat{\boldsymbol{X}_{i+1}}=\phi(\boldsymbol{Z}_{i})
\end{equation}

\end_inset


\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\size large
Where 
\begin_inset Formula $\boldsymbol{W}_{i}$
\end_inset

 and 
\begin_inset Formula $\boldsymbol{B}_{i}$
\end_inset

 represents weights and bias as trainnable parameters.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\size large
\begin_inset Formula $\boldsymbol{X}_{i}$
\end_inset

 Input vector
\end_layout

\begin_layout Itemize
\begin_inset Formula $\left[\begin{array}{c}
\boldsymbol{H^{H}}\boldsymbol{Y}_{i}\\
\hat{\boldsymbol{X}_{i}}\\
\boldsymbol{H}^{H}\boldsymbol{H}\hat{\boldsymbol{X}_{i}}
\end{array}\right]$
\end_inset

 
\size large
Vertical concatenation of the vectors.
 
\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\phi$
\end_inset

 Activation function
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\size large
\begin_inset Formula $\boldsymbol{Z_{i}}$
\end_inset

Resulting output of network
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\phi=tanh\left(\frac{\boldsymbol{X_{i}}}{|t_{i}|}\right)
\end{equation}

\end_inset


\end_layout

\begin_layout Itemize
\begin_inset Formula $\boldsymbol{t}_{i}$
\end_inset


\size large
trainable normalization factor
\end_layout

\begin_layout Standard

\size large
In the context of hardware design, the term 'cascade' refers to the process
 of concatenating multiple hardware instances one after the other to create
 a larger system or to perform a more complex function.
 
\color blue
Figure 26
\color inherit
 illustrates how this is done with layers of a neural network.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Papers/CascaNet.png
	lyxscale 50
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Cascade Net 
\size large

\begin_inset CommandInset citation
LatexCommand cite
key "ZeroForcingEqNN"
literal "false"

\end_inset


\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "Preprocesing"

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Their loss function or estimator is based on the Euclidean distance, with
 a logarithmic regularization of outliers and the objective of minimizing
 the distance between points.
 They accumulate the total estimation for each layer i and finally sum it
 up.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
loss=\sum_{i=1}^{L}log(i)||\boldsymbol{X}-\hat{\boldsymbol{X}}||
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
To deal with complex matrix number they make a reformulation in the matrix
 as shown in 
\color blue
Figure 27
\color inherit
.
 Where 
\begin_inset Formula $\mathfrak{R}$
\end_inset

is the real part and 
\begin_inset Formula $\mathfrak{I}$
\end_inset

 the imaginary part for vector 
\begin_inset Formula $\boldsymbol{Y}$
\end_inset

 and 
\begin_inset Formula $\boldsymbol{X}$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center

\size large
\begin_inset Graphics
	filename Imagenes/Papers/ComplexMatrix.png
	lyxscale 50
	scale 70

\end_inset


\size default

\begin_inset Caption Standard

\begin_layout Plain Layout
Matrix reformulation 
\size large

\begin_inset CommandInset citation
LatexCommand cite
key "ZeroForcingEqNN"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
\paragraph_spacing onehalf
\noindent

\size large
A Survey of Complex-Valued Neural Networks 
\begin_inset CommandInset citation
LatexCommand cite
key "A_Survey_of_Complex_valued_nueronal_Netoworks"
literal "false"

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
\begin_inset CommandInset label
LatexCommand label
name "subsec:A-Survey-of"

\end_inset

This writing provides a comprehensive description of a novel loss function
 and the requisite adaptations needed to facilitate backpropagation in complex
 networks.
 Additionally, the paper demonstrates how to preprocess data, activation
 functions, and cost functions, which can be valuable for conducting experiments
 with complex data or complex neural networks.
\end_layout

\begin_layout Subsubsection
Normalize unitary circle
\end_layout

\begin_layout Standard

\size large
When examining data in the complex plane, the initial step is to address
 normalization.
 Normalization is achieved by dividing the data by its absolute maximum,
 resulting in all points being contained within a unitary circle.
 
\begin_inset CommandInset label
LatexCommand label
name "subsec:Normalize-unitary-circle"

\end_inset


\end_layout

\begin_layout Standard

\size large
\begin_inset Formula 
\begin{equation}
f(z)=\frac{z}{max(|z|)}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard

\size large
\color blue
Figure 28 
\color inherit
demonstrates how a complex network can handle polar segmentation, and how
 weights and biases can be used to define a vector in the complex plane.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Papers/ComplexCircle.png

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
A Geometric Interpretation of Segmentation and Function Evaluation in the
 Complex Plane.
 
\begin_inset CommandInset citation
LatexCommand cite
key "A_Survey_of_Complex_valued_nueronal_Netoworks"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Activation functions
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The hyperbolic tangent is an example of a fully complex activation function
 and has been utilized in 
\begin_inset CommandInset citation
LatexCommand cite
key "tanh_complex"
literal "false"

\end_inset

.
 It is apparent that singularities in the output may arise due to values
 on the imaginary axis.
 To prevent an explosion of values, it is necessary to appropriately scale
 the inputs, which mention in the normalization in the section above.
 According to some researchers, imposing the strict constraint of requiring
 the activation function to be holomorphic may not be necessary and outpus
 similar results of real functions shown in
\color blue
 Figure 29.

\color inherit
 A holomorphic function is a complex-valued function of a complex variable
 that is complex differentiable at every point within its domain.
 In other words, a function 
\begin_inset Formula $f(z)$
\end_inset

 is holomorphic at a point 
\begin_inset Formula $\boldsymbol{z}$
\end_inset

 if the limit of the difference quotient of 
\begin_inset Formula $f(z)$
\end_inset

 as 
\begin_inset Formula $\boldsymbol{z}$
\end_inset

 approaches that point exists and is independent of the path of approach.
 Therefore, for a basic implementation, we should split the evaluation into
 real and imaginary parts as separate sections to activate the values.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Papers/tanhcomplex.png

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Complex function separate for each real and imaginary part.
 
\begin_inset CommandInset citation
LatexCommand cite
key "Survey_Complex_valued_NN"
literal "false"

\end_inset

 
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Loss functions
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
One approach to dealing with the error is to take the complex magnitude
 of the differences between the estimator and the ground truth.
 Given 
\begin_inset Formula $d\in\mathbb{C}^{N}$
\end_inset

(ground truth) and 
\begin_inset Formula $o\in\mathbb{C}^{N}$
\end_inset

(estimated output), the error denoted as 
\begin_inset Formula $e=d-o$
\end_inset

.
 It can be calculated the complex mean square loss in a non-negative scalar.
 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
L(e)=\sum_{k=0}^{N-1}|e_{k}|^{2}=\sum_{k=0}^{N-1}e_{k}\overline{e_{k}}\label{eq:MSECOMPLEX}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
If we take a polar approach where 
\begin_inset Formula $d=re^{i\phi}$
\end_inset

 and 
\begin_inset Formula $o=\hat{r}e^{i\hat{\phi}}$
\end_inset

, we can convert the error into a log function to bring points closer and
 cancel the exponentials.
 Rewritten in this way, the equation becomes:
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
(e_{log}):=\sum_{k=0}^{N-1}e_{k}\overline{e_{k}}=\sum_{k=0}^{N-1}(log(o_{k})-log(d_{k}))*\overline{((log(o_{k})-log(d_{k})))}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\align center

\size large
\begin_inset Formula $log\left(\frac{o_{k}}{d_{k}}\right)*\overline{log\left(\frac{o_{k}}{d_{k}}\right)}=log\left(\frac{\hat{r}e^{i\hat{\phi}}}{re^{i\phi}}\right)*log\left(\frac{\hat{r}e^{-i\hat{\phi}}}{re^{-i\phi}}\right)=log\left(\frac{\hat{r}}{r}e^{i(\hat{\phi}-\phi)}\right)*log\left(\frac{\hat{r}}{r}e^{-i(\hat{\phi}+\phi)}\right)$
\end_inset


\end_layout

\begin_layout Standard
\align center

\size large
\begin_inset Formula $\left[log(\frac{\hat{r}}{r})+log\left(e^{i(\hat{\phi}-\phi)}\right)\right]*\left[log(\frac{\hat{r}}{r})+log\left(e^{-i(\hat{\phi}-\phi)}\right)\right]=$
\end_inset


\end_layout

\begin_layout Standard
\align center

\size large
\begin_inset Formula $\left[log(\frac{\hat{r}}{r})+i(\hat{\phi}-\phi)\right]*\left[log(\frac{\hat{r}}{r})-i(\hat{\phi}-\phi)\right]=$
\end_inset


\end_layout

\begin_layout Standard
\align left

\size large
Multiply out the terms 
\end_layout

\begin_layout Standard
\align center

\size large
\begin_inset Formula $log^{2}(\frac{\hat{r}}{r})+i(\hat{\phi}-\phi)log(\frac{\hat{r}}{r})-i(\hat{\phi}-\phi)log(\frac{\hat{r}}{r})-i^{2}(\hat{\phi}-\phi)^{2}$
\end_inset


\end_layout

\begin_layout Standard
\align left

\size large
Simplify
\end_layout

\begin_layout Standard
\align center

\size large
\begin_inset Formula $log^{2}(\frac{\hat{r}}{r})+(\hat{\phi}-\phi)^{2}$
\end_inset


\end_layout

\begin_layout Standard
\align left

\size large
We multiply the angle and radius by 0.5 in the loss function to give them
 equal importance since both are equally significant for the loss.
 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
Loss(e_{log})=\frac{1}{2}\left(log\left[\frac{\hat{r}}{r}\right]^{2}+\left[\hat{\phi}-\phi\right]^{2}\right)\label{eq:65}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The obtained representation of magnitude and phase within the loss function
 offers potential advantages, particularly in the context of the polar estimatio
n approach.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newpage
\end_layout

\end_inset


\end_layout

\begin_layout Section
Transformers
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Transformers have gained immense relevance due to their exceptional performance
 in natural language processing (NLP) tasks such as machine translation
 and sentiment analysis.
 They have also proven valuable in recommendation systems, time series forecasti
ng, speech recognition, and scientific research, including protein folding
 prediction.
 Transformers' versatility in capturing complex patterns and dependencies
 makes them applicable to a wide range of machine learning tasks beyond
 NLP.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
One of the significant advantages of transformers is their ability to capture
 long-range dependencies and effectively model sequences.
 One of this thesis hypothesis suggests that by considering the context
 and relationships between symbols over long distances, transformers have
 the potential to mitigate the impact of inter-symbol interference (ISI)
 and enhance the overall performance of systems.
 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
First, we examined the main paper that discusses the building blocks of
 transformers.
 Subsequently, we delved into the internal workings of these blocks.
 Having analyzed the individual components, we proceeded to explore the
 concept of the image transformer and how transformers can be utilized to
 learn spatial relations.
\end_layout

\begin_layout Subsection
\paragraph_spacing onehalf
\noindent

\size large
Attention Is All You Need 
\begin_inset CommandInset citation
LatexCommand cite
key "transformer"
literal "false"

\end_inset

 
\begin_inset CommandInset label
LatexCommand label
name "subsec:Attention-Is-All"

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
"Attention is All You Need" is a research paper published by Google in 2017
 that introduced the Transformer model, a neural network architecture for
 sequence-to-sequence modeling.
 The Transformer model is designed to handle variable-length sequences of
 input data and generate variable-length output sequences, making it particularl
y useful for tasks such as machine translation and natural language processing.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The Transformer model differs from previous neural network architectures
 by relying solely on attention mechanisms for input and output processing,
 eliminating the need for recurrent
\begin_inset CommandInset citation
LatexCommand cite
key "RNN_LSTM"
literal "false"

\end_inset

 and convolutional layers
\begin_inset CommandInset citation
LatexCommand cite
key "Conv1"
literal "false"

\end_inset

.
 The attention mechanism
\begin_inset CommandInset citation
LatexCommand cite
key "Attention"
literal "false"

\end_inset

 allows the model to focus on different parts of the input sequence when
 generating the output sequence, making it more accurate and efficient than
 previous models.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
In an autoregressive mode in the context of an autoencoder, the decoder
 network is designed to generate the output sequence one element at a time,
 based on the previously generated elements.
 In other words, the decoder network takes the previous elements of the
 output sequence as input and generates the next element of the sequence.
 This is in contrast to a non-autoregressive mode, where the decoder network
 generates the entire output sequence at once, without considering the previousl
y generated elements.
\end_layout

\begin_layout Subsubsection
Encoder Decoder
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Transformer model consists of an encoder and a decoder.
 The encoder processes the input sequence, using multi-head attention and
 position encoding to create a fixed-length representation of the input.
 The decoder then generates the output sequence, using multi-head attention
 and position encoding to attend to the input representation and generate
 each output token.
 The model is trained using maximum likelihood estimation, where the goal
 is to minimize the cross-entropy loss between the predicted output sequence
 and the ground truth.
 In
\color blue
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Transformer"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
, all the elements, including masks, multi-head attention, and feed-forward
 components, are observed to be brought together.
 These elements are organized into blocks of cascaded Encoders and Decoders,
 which is why the presence of 'Nx' notation indicating N blocks can be seen.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Papers/TransformerEncodeDecode.png
	lyxscale 50
	scale 70

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Transformer with encoder and decoder sections 
\begin_inset CommandInset label
LatexCommand label
name "fig:Transformer"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
In the transformer diagram, "Nx" is typically used to represent the number
 of encoder-decoder layers in the model.
 For example, a transformer model with 6 encoder layers and 6 decoder layers
 might be represented as "Nx=6" in the diagram.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The output of the Transformer model is a sequence of tokens, which can be
 interpreted as a sequence of words, or other discrete units depending on
 the task at hand.
 These tokens can be further processed by other components of a larger system,
 such as a language model or a downstream task-specific model.
\end_layout

\begin_layout Subsubsection
Embedding
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The embedding refers to the process of representing 
\series bold
discrete input
\series default
 tokens as 
\series bold
continuous vectors
\series default
 that can be processed by the model.
 This is achieved using an embedding layer, which maps each input token
 to a high-dimensional 
\begin_inset Formula $\mathbb{R}^{N}$
\end_inset

 vector in a learned embedding space.
 Words cannot be represented as numbers directly.
 Normally, numerical data is transformed into a discrete representation,
 but in order to process it through a transformer network, these discrete
 representations need to be mapped to a continuous vector space using an
 embedding layer.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The input size of an embedding layer is typically the size of the vocabulary
 
\begin_inset Formula $|A|$
\end_inset

, i.e., the number of unique tokens that the model can expect to encounter
 in the input.
 For example, if the vocabulary size is 10,000, then the input size of the
 embedding layer would be 10,000.
 The output size of the embedding layer is determined by the desired dimensional
ity of the embedding space 
\begin_inset Formula $\mathbb{R}^{M}$
\end_inset

, which is a hyperparameter that can be tuned by the model developer.
 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Normally, each word is assigned a unique index, and this index corresponds
 to a row in the embedding matrix.
 To obtain the embedding vector for a word, we retrieve the corresponding
 row from the matrix and multiply it by each element in row to get the new
 vector 
\begin_inset Formula $V$
\end_inset

.

\color blue
 Figure 31
\color inherit
 shows how words are encoded into a value and passed through an embedding
 layer to finally be mapped into a vector.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Networks/EmbbededLayer.jpg
	lyxscale 30
	scale 40

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Embbeded Matrix
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The embedding layer allows the model to capture the semantic relationships
 between different input tokens, and enables it to perform tasks such as
 language modeling and machine translation.
 Is typically followed by positional encoding, which adds information about
 the position of each input token in the sequence.
 Together, the embedding and positional encoding components provide a way
 for the model to process variable-length input sequences of discrete tokens
 in an efficient and effective manner.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Let X be an input sequence of length T, where each element 
\begin_inset Formula $x_{i}$
\end_inset

 is an integer representing the 
\begin_inset Formula $i$
\end_inset

-th token in the vocabulary.
 Let 
\begin_inset Formula $E$
\end_inset

 be a learned embedding matrix of size
\begin_inset Formula $V\times d$
\end_inset

, where 
\begin_inset Formula $V$
\end_inset

 is the size of the vocabulary and 
\begin_inset Formula $d$
\end_inset

 is the dimension of the embedding space.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The embedding layer can be defined as follows:
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\text{E}(X)=[\text{e}_{1},\text{e}_{2},\dots,\text{e}_{T}]
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Positional encoding can be added to the embeddings as follows:
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\text{E'}(X)=[\text{e'}_{1},\text{e'}_{2},\dots,\text{e'}_{T}]
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
where 
\begin_inset Formula $\text{e'}_{i}=\text{e}_{i}+\text{PE}_{i}$
\end_inset

, and 
\begin_inset Formula $\text{PE}_{i}$
\end_inset

 is the 
\begin_inset Formula $i$
\end_inset

-th row of a learned positional encoding matrix of size 
\begin_inset Formula $T\times d$
\end_inset

.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The resulting embeddings 
\begin_inset Formula $\text{E'}(X)$
\end_inset

 are continuous vectors in a high-dimensional embedding space that can be
 processed by the transformer model.
\end_layout

\begin_layout Subsubsection
Multihead attention
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
One of the key components of the Transformer model is multi-head attention.
 Multi-head attention allows the model to attend to different parts of the
 input sequence simultaneously, by splitting the input data into multiple
 representations and computing attention on each of them.
 This allows the model to capture complex relationships between different
 parts of the input sequence, and enables it to handle long sequences more
 efficiently.
 In multi-head attention mechanism of a transformer model, the input sequence
 is split into multiple vectors (heads), and each of these vectors is processed
 independently.
 The attention mechanism then operates on these vectors to compute weighted
 combinations that represent different aspects of the input sequence.The
 multi-head attention mechanism consists of three linear transformations:
 Query, Key, and Value as shown in 
\color blue
Figure 32
\color inherit
.
 These transformations are learned parameters that are used to compute the
 attention scores and weights for each head.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Papers/Attention.png
	scale 120

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Attention respect to input vectors 
\begin_inset CommandInset citation
LatexCommand cite
key "singh2020multihead"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
Query: This transformation takes the current decoder state as input and
 maps it to a query vector.
 The query vector is used to compute the similarity between the decoder
 state and each of the key vectors.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
Key: This transformation takes the encoder output as input and maps it to
 a key vector.
 The key vector is used to compute the similarity between the decoder state
 and each of the query vectors.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
Value: This transformation takes the encoder output as input and maps it
 to a value vector.
 The value vector is used to compute the weighted sum of the encoder output,
 based on the attention weights calculated from the query and key vectors.
\end_layout

\begin_layout Standard

\size large
In 
\color blue
Figure 33
\color inherit
, it is shown how the Query, Key, and Value are concatenated using Linear
 layers.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Papers/Multihead.png
	scale 80

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Caption Standard

\begin_layout Plain Layout
Multihead attention 
\begin_inset CommandInset citation
LatexCommand cite
key "transformer"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Let 
\begin_inset Formula $Q$
\end_inset

, 
\begin_inset Formula $K$
\end_inset

, and 
\begin_inset Formula $V$
\end_inset

 be the query, key, and value matrices, respectively, for one head of the
 multi-head attention mechanism.
 Let 
\begin_inset Formula $d_{k}$
\end_inset

 be the dimension of the key vectors, and let 
\begin_inset Formula $d_{v}$
\end_inset

 be the dimension of the value vectors.
 Let 
\begin_inset Formula $h$
\end_inset

 be the number of heads.
 and 
\begin_inset Formula $W$
\end_inset

 values in the equations you've provided are learned weight matrices in
 a Transformer model used for multi-head self-attention mechanism.
 Then, the multi-head attention mechanism can be defined as follows:
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align center

\size large
\begin_inset Formula 
\begin{equation}
MultiHead(Q,K,V)=Concat(head_{1},\ldots,headh_{h})W^{O}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align left

\size large
where
\end_layout

\begin_layout Standard
\align center

\size large
\begin_inset Formula $\text{head}_{i}=\text{Attention}(QW_{i}^{Q},KW_{i}^{K},VW_{i}^{V})$
\end_inset

 and
\end_layout

\begin_layout Standard
\align center

\size large
\begin_inset Formula $\ensuremath{W_{i}^{Q}\in\mathbb{R}^{d{model}\times d_{k}}}$
\end_inset

,
\begin_inset Formula $\ensuremath{W_{i}^{K}\in\mathbb{R}^{d_{model}\times d_{k}}}$
\end_inset

,
\begin_inset Formula $\ensuremath{W_{i}^{V}\in\mathbb{R}^{d_{model}\times d_{v}}}$
\end_inset

and 
\begin_inset Formula $\ensuremath{W^{O}\in\mathbb{R}^{hd_{v}\times d_{model}}}$
\end_inset

 are learned weight matrices.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The Attention function can be defined as follows:
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align center

\size large
\begin_inset Formula 
\begin{equation}
Attention(Q,K,V)=softmax(\frac{QK^{T}}{\sqrt{d_{k}}}+Mask)V
\end{equation}

\end_inset


\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $W^{O}$
\end_inset

 weight Output, 
\begin_inset Formula $W^{Q}$
\end_inset

 weight Query, 
\begin_inset Formula $W^{K}$
\end_inset

 weight Key, 
\begin_inset Formula $W^{V}$
\end_inset

weight Value.
 
\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $d_{k}$
\end_inset

 is the dimensionality of the key.
 The division operation 
\begin_inset Formula $\frac{QK^{T}}{\sqrt{d_{k}}}$
\end_inset

 is the scaling operation.
 It's used because for large values of 
\begin_inset Formula $d_{k}$
\end_inset

, the dot product grows large in magnitude, pushing the softmax function
 into regions where it has extremely small gradients.
 To counteract this effect, we scale the dot product by 
\begin_inset Formula $\sqrt{d_{k}}$
\end_inset

.
\end_layout

\begin_layout Itemize

\size large
A mask matrix is a method used to prevent certain elements in the input
 from attending to others.
 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The head and self-attention mechanisms are better illustrated in 
\color blue
Figure 34
\color inherit
.
 As depicted, the input embedded vectors x are mapped by weights and utilized
 within the context of the self-attention mechanism.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Papers/Dot product.png
	lyxscale 40
	scale 40

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Self attention dot product 
\begin_inset CommandInset citation
LatexCommand cite
key "singh2020multihead"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Mask
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
In multi-head attention mechanism of a transformer model, a mask is a binary
 matrix that is used to selectively prevent certain elements of the input
 sequence from being attended to by the model.
 As can be appreciated in
\color blue
 Figure 35
\color inherit
, the attention weights matrix is filtered and certain values are set to
 zero using a mask.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Papers/Mask.png
	scale 60

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Mask example
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard

\size large
There are two types of masks commonly used in the transformer model: padding
 masks and sequence masks.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\size large
Padding masks: These masks are used to ignore padding tokens in the input
 sequence, which are added to ensure that all input sequences are of the
 same length.
 Padding tokens have no semantic meaning and should not be attended to by
 the model.
 A padding mask is a binary matrix that has a value of 0 for padding tokens
 and 1 for all other tokens.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\size large
Sequence masks: These masks are used to ensure that each position in the
 output sequence can only attend to positions that have already been processed.
 This is important for tasks such as language modeling, where the model
 is trained to predict the next word in a sequence based on the previous
 words.
 A sequence mask is a binary matrix that has a value of 0 for all future
 positions in the sequence and 1 for all other positions.
 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Masks are applied to the attention mechanism by adding them to the attention
 weights before computing the weighted sum of the input sequence.
 The mask ensures that certain elements of the input sequence are not attended
 to by the model, which can improve the accuracy and efficiency of the model.
\end_layout

\begin_layout Subsubsection
Overview and Insights
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
In the equalization stage, the Transformer architecture can be applied to
 cancel Inter-Symbol Interference (ISI) using attention mechanisms, as the
 data is sequential and can be interpreted symbol by symbol.
 However, positional encoding may be lost when treating continuous data,
 which poses a challenge.
 Furthermore, the Transformer architecture outputs symbols instead of continuous
 values, necessitating a mechanism to discretize the received data Y and
 apply a token for each position, treating equalization as a machine translation.
\end_layout

\begin_layout Subsection
\paragraph_spacing onehalf
\noindent

\size large
An image is worth 16x16 words 
\begin_inset CommandInset citation
LatexCommand cite
key "dosovitskiy2020image"
literal "false"

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "subsec:An-image-is"

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
The Vision Transformer is a deep learning architecture that is specifically
 designed for image classification tasks.
 Unlike traditional Convolutional Neural Networks (CNNs) that use convolutional
 layers to extract features from images, the ViT uses self-attention mechanisms
 to capture relationships between different parts of the image.
 In 
\color blue
Figure 36
\color inherit
, the architecture is depicted, which takes a sequence of patches as input,
 where each patch represents a small square region of the image.
 The input is then flattened and passed to an encoder, as illustrated in
 the figure.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Papers/pasted1.png
	lyxscale 80
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Basic example of image splitting in a grid for automatic fungi recognition.
 
\begin_inset CommandInset citation
LatexCommand cite
key "visionTransformer"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
These patches are then flattened and passed through a linear projection
 layer to obtain a sequence of embeddings, which are then fed into a series
 of transformer encoder layers.
 The transformer encoder layers use self-attention mechanisms to model the
 relationships between the different patches in the input sequence.
 This allows the ViT to capture long-range dependencies between different
 parts of the image, which is particularly useful for image classification
 tasks where the spatial relationship between different parts of the image
 is important.
 It takes as input an image and outputs a class label or a set of class
 probabilities, based on the features extracted from the image.
\end_layout

\begin_layout Subsubsection
\paragraph_spacing onehalf
\noindent
The Grid 
\begin_inset CommandInset label
LatexCommand label
name "subsec:The-Grid"

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The "16x16 words" phrase refers to the fact that the input image is divided
 into a grid of 16x16 patches, each of which is treated as a "word" in the
 input sequence.
 This means that the ViT processes the image as a sequence of 256 patches,
 each represented by an embedding, instead of as a single 2D array of pixel
 values.
 Nevertheless, there exists a trade-off between grid size and computational
 complexity, since larger grids necessitate additional memory and processing
 power for training.
 
\color blue
Figure 37
\color inherit
 illustrates an image that is divided into 14 x 14 grids.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Papers/VITexample-transformed.png
	lyxscale 30
	scale 15

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Vision transforrmer example of 14X14 
\begin_inset CommandInset citation
LatexCommand cite
key "CollabVIT"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newpage
\end_layout

\end_inset


\end_layout

\begin_layout Section
Methodology
\end_layout

\begin_layout Subsection
General description
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
In
\color blue
 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Dataset"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
 the signal channels dataset utilized for training the models is explained.
 This is followed by an explanation of Bit Error Rate (BER) in 
\color blue

\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Signal-quality-metrics"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
.
 BER and BLER are the most common metrics used to measure equalization performan
ce.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
In 
\color blue

\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Software-Platform"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
 the focus is on the explanation of how software reusability simplifies
 the development of new neural networks by eliminating the necessity of
 building all components from scratch.
 This approach allows for a more efficient process by enabling developers
 to concentrate solely on network implementation.
 To showcase the network's time performance in terms of software, the concept
 of FLOPs is introduced at the end of the subsection in 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:FLOPS"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 It serves as a measure to demonstrate the computational efficiency of the
 network.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Once the platform is explained, the models are presented, beginning with
 the Golden Model in 
\color blue

\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Golden-Model"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
.
 Subsequently, the neuronal network implementations developed for this research
 are introduced in sections 
\color blue

\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:PhaseNet"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
 through 
\color blue

\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:GridNet"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
.
 In the case of 
\color blue

\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:PhaseNet"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
 it is explained how preprocesing is done in subsection 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Effective-Techniques-for"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 It is worth noting that preprocessing plays a vital role in achieving favorable
 results for neural networks in equalization task.
 For a more comprehensive understanding of the relationship between Section
 2 and Section 3, please refer to the provided table, which offers further
 insights.
\end_layout

\begin_layout Standard
\begin_inset Float table
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="6" columns="3">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Network
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
State of Art
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Description
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
PhaseNet
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset CommandInset ref
LatexCommand eqref
reference "subsec:Linear-Layer"
plural "false"
caps "false"
noprefix "false"

\end_inset

,
\begin_inset CommandInset ref
LatexCommand eqref
reference "subsec:A-Novel-OFDM"
plural "false"
caps "false"
noprefix "false"

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Correcting phase of complex recieved values
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
PolarNet
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset CommandInset ref
LatexCommand eqref
reference "subsec:Linear-Layer"
plural "false"
caps "false"
noprefix "false"

\end_inset

,
\begin_inset CommandInset ref
LatexCommand eqref
reference "subsec:A-Novel-OFDM"
plural "false"
caps "false"
noprefix "false"

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Correcting phase and magnitude of complex received values.
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
ComplexNet
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset CommandInset ref
LatexCommand eqref
reference "subsec:A-Survey-of"
plural "false"
caps "false"
noprefix "false"

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Nueronal networks with comlex numbers
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
MobileNet
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset CommandInset ref
LatexCommand eqref
reference "subsec:CNN"
plural "false"
caps "false"
noprefix "false"

\end_inset

,
\begin_inset CommandInset ref
LatexCommand eqref
reference "subsec:MobileNetV3"
plural "false"
caps "false"
noprefix "false"

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Converting a channel into an image using an optimized CNN 
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
GridNet
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset CommandInset ref
LatexCommand eqref
reference "subsec:Attention-Is-All"
plural "false"
caps "false"
noprefix "false"

\end_inset


\begin_inset CommandInset ref
LatexCommand eqref
reference "subsec:The-Grid"
plural "false"
caps "false"
noprefix "false"

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Treating the IQ plane as an image.
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Methodology and State of Art
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Simulation Parameters
\end_layout

\begin_layout Subsubsection
V2V
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The 802.11p standard is utilized for V2V communication, where it is assumed
 that the cyclic prefix (CP) has been removed from the channel, leaving
 only the payload and channel in frequency domain.
 The final channel size is maintained at 48x48.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{table}[H] 
\backslash
centering 
\backslash
caption{Simulation parameters} 
\backslash
begin{tabular}{|c|c|} 
\backslash
hline 
\backslash
textbf{Parameter} & 
\backslash
textbf{Value} 
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

Number of OFDM subcarriers  & $N = 64$  
\backslash

\backslash
 
\backslash
hline 
\end_layout

\begin_layout Plain Layout

Number of data subcarriers  & $N_d = 48$ 
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

Bandwidth  & $BW = 10MHz$ 
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

Samples in the cyclic prefix   & $CP = 16$ 
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

Sampling time  & $T_s = 100ns$ 
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

Symbol period  & $T_{OFDM} = 8 
\backslash
mu s$ 
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

Data modulation  & QPSK,16-QAM 
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

Channel model & 
\backslash
parbox{5cm}{Exponentially decaying,
\backslash

\backslash
 Rayleigh fading 
\backslash

\backslash
 $spread = 0.4
\backslash
mu s$, 
\backslash

\backslash
 $f_D=1Khz$} 
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

velocity & $v=100 km/h$ 
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

Channel estimation & Perfect channel knowledge 
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout


\backslash
end{tabular} 
\backslash
end{table}
\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
EVA model
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The EVA channel model is designed to represent a severe vehicular environment
 compared to some of its counterparts and it is a 3GPP standard 
\begin_inset CommandInset citation
LatexCommand cite
key "LTE"
literal "false"

\end_inset

.
 This model is commonly used in OFDM-based systems.
 The term 'vehicular' signifies that this model is primarily used for scenarios
 where the receiver, like a mobile device in a car, is in a fast-moving
 environment.
 Key features of the EVA model include high Doppler shifts, multipath fading,
 and delay spread.
 These characteristics necessitate the use of equalizers and channel estimators
 that can rapidly adapt to changing channel conditions.
 Moreover, multipath fading can cause both constructive and destructive
 interference, creating fast fluctuations in the signal's power.
 Lastly, delay spread results in inter-symbol interference (ISI) over the
 frame.
 The following tables present common values associated with this model.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{table}[H] 
\backslash
centering 
\backslash
caption{Power Delay Profile (PDP) of the EVA model} 
\backslash
begin{tabular}{|c|c|c|} 
\backslash
hline 
\backslash
textbf{Tap Number} & 
\backslash
textbf{Relative Delay ($
\backslash
mu s$)} & 
\backslash
textbf{Average Power (dB)} 
\backslash

\backslash
 
\backslash
hline 1 & 0.0 & 0.0 
\backslash

\backslash
 
\backslash
hline 2 & 30.0 & -1.5 
\backslash

\backslash
 
\backslash
hline 3 & 150.0 & -1.4 
\backslash

\backslash
 
\backslash
hline 4 & 310.0 & -3.6 
\backslash

\backslash
 
\backslash
hline 5 & 370.0 & -0.6 
\backslash

\backslash
 
\backslash
hline 6 & 710.0 & -9.1 
\backslash

\backslash
 
\backslash
hline 7 & 1090.0 & -7.0 
\backslash

\backslash
 
\backslash
hline 8 & 1730.0 & -12.0 
\backslash

\backslash
 
\backslash
hline 9 & 2510.0 & -16.9 
\backslash

\backslash
 
\backslash
hline 
\backslash
end{tabular} 
\backslash
end{table}
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Dataset
\begin_inset CommandInset label
LatexCommand label
name "subsec:Dataset"

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
This project has a dataset of 20,000 channel realizations, each with a size
 of 48x48.
 The dataset is divided into two groups of 10,000: the first group consists
 of Line-of-Sight (LOS) channel realizations, and the second group consists
 of Non-Line-of-Sight (NLOS) channel realizations, as depicted in 
\color blue
Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Channels"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
.
 Each value in the matrix is a complex number with a format of complex128,
 float64 for the real and imaginary parts.
 The data is stored in the .mat format, which is commonly used for storing
 variables on disk from Matlab code.
 However, the dataset is used in Python using the Scipy library.
 To ensure robust predictions, the LOS and NLOS channels have been shuffled,
 with one group following the other.
 As neural networks typically do not work well with complex numbers, the
 real and imaginary parts of the channels have been separated into two channels
 in an image.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Channels/NLOS_Channel_log_view.png
	lyxscale 70
	scale 50

\end_inset


\begin_inset Graphics
	filename Imagenes/Channels/LOS_Channel_log_view.png
	lyxscale 70
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
A comparison of LOS and NLOS channel magnitud in a log scale representation.
 
\begin_inset CommandInset label
LatexCommand label
name "fig:Channels"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Bit error rate perfomance analysis 
\begin_inset CommandInset label
LatexCommand label
name "subsec:Signal-quality-metrics"

\end_inset


\end_layout

\begin_layout Subsubsection
SNR
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
SNR 
\begin_inset CommandInset label
LatexCommand label
name "subsec:SNR"

\end_inset

stands for Signal-to-Noise Ratio which contrasts the strength of the signal
 with the strength of the noise.
 The most common way to measure it is in decibels (dB).
 In general, higher numbers indicate a better specification because there
 is a greater ratio of useful information (the signal) to unwanted data
 (the noise).
 Given this source 
\begin_inset CommandInset citation
LatexCommand cite
key "PythonModulation"
literal "false"

\end_inset

, it can be explained how the noise is calculated for noise simulation with
 the requirement of a certain SNR in dB.
\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent

\size large
Firstly, a vector 
\begin_inset Quotes eld
\end_inset


\begin_inset Formula $\boldsymbol{s}$
\end_inset


\begin_inset Quotes erd
\end_inset

 that represents the signal transmitted over a communication channel is
 considered.
 The objective is to derive a vector 
\begin_inset Quotes eld
\end_inset


\begin_inset Formula $\boldsymbol{r}$
\end_inset


\begin_inset Quotes erd
\end_inset

 that represents the signal received at the receiver after passing through
 the Additive White Gaussian Noise (AWGN), this noise type is described
 in 
\begin_inset CommandInset citation
LatexCommand cite
key "papoulis2002probability"
literal "false"

\end_inset

.
 The level of noise introduced by the AWGN channel is determined by the
 provided Signal-to-Noise Ratio (SNR), and it is denoted as 
\begin_inset Quotes eld
\end_inset


\begin_inset Formula $\boldsymbol{\gamma}$
\end_inset


\begin_inset Quotes erd
\end_inset

\SpecialChar endofsentence

\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent

\size large
The length of the vector 
\begin_inset Quotes eld
\end_inset


\begin_inset Formula $\boldsymbol{s}$
\end_inset


\begin_inset Quotes erd
\end_inset

 is denoted by 
\begin_inset Formula $\boldsymbol{N}$
\end_inset

.
 The signal power of the vector 
\begin_inset Quotes eld
\end_inset


\begin_inset Formula $\boldsymbol{s}$
\end_inset


\begin_inset Quotes erd
\end_inset

 can be expressed as follows:
\end_layout

\begin_deeper
\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
\begin_inset Formula 
\begin{equation}
P_{signal}=\frac{1}{N}\sum_{i=0}^{N-1}|s_{i}|^{2}
\end{equation}

\end_inset


\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent

\size large
If we have a complex IQ value 
\begin_inset Formula $s_{i}=a_{i}+jb_{i}$
\end_inset

, the modulus or magnitude of 
\begin_inset Formula $s_{i}$
\end_inset

 can be represented by 
\begin_inset Formula $|s_{i}|=\sqrt{a_{i}^{2}+b_{i}^{2}}$
\end_inset

, where a and b are real numbers.
\end_layout

\end_deeper
\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent

\size large
To compute the power spectral density of the noise vector 
\begin_inset Quotes eld
\end_inset


\begin_inset Formula $\boldsymbol{n}$
\end_inset


\begin_inset Quotes erd
\end_inset

, we use the following equation:
\end_layout

\begin_deeper
\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
\begin_inset Formula 
\begin{equation}
N_{o}=\frac{P_{signal}}{\gamma}=P_{signal}10^{-\frac{SNR_{dB}}{10}}
\end{equation}

\end_inset


\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent

\size large
Where 
\begin_inset Formula $\gamma=10^{\frac{SNR_{dB}}{10}}$
\end_inset

 is the SNR in dB to linear scale
\end_layout

\end_deeper
\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent

\size large
Assuming a complex IQ plane for all digital modulations, the noise variance
 (noise power) required for generating Gaussian random noise can be expressed
 as follows:
\end_layout

\begin_deeper
\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
\begin_inset Formula 
\begin{equation}
\sigma^{2}=\frac{N_{0}}{2}\label{eq:GuassianSigma}
\end{equation}

\end_inset


\end_layout

\end_deeper
\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent

\size large
Then, the Gaussian random noise vector 
\begin_inset Quotes eld
\end_inset


\begin_inset Formula $\boldsymbol{n}$
\end_inset


\begin_inset Quotes erd
\end_inset

 of length 
\begin_inset Formula $N$
\end_inset

 is generated, with its samples drawn from a Gaussian distribution having
 a mean of zero and a standard deviation shown by 
\color blue

\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:GuassianSigma"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
.
\end_layout

\begin_deeper
\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
\begin_inset Formula 
\begin{equation}
f(x)=\begin{cases}
\sigma\mathcal{N}_{N}(0,1), & \text{if \ensuremath{s} is real}\\
\frac{\sigma}{\sqrt{2}}\left[\mathcal{N}_{N}(0,1)+j\mathcal{N}_{N}(0,1)\right], & \text{if \ensuremath{s} is complex}
\end{cases}
\end{equation}

\end_inset


\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent

\size large
Here, 
\begin_inset Formula $\boldsymbol{\mathcal{N}_{N}(0,1)}$
\end_inset

 represents the white Gaussian noise vector with a mean of 0 and a standard
 deviation of 1.
\end_layout

\end_deeper
\begin_layout Subsubsection
BER
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset CommandInset label
LatexCommand label
name "subsec:BER"

\end_inset

The transmission of data is not always error-free.
 Bit errors may occur due to various factors such as noise, interference,
 distortion, and fading.
 Bit Error Rate (BER) is a common metric used to quantify the quality of
 a digital communication system by measuring the frequency of bit errors.
 BER is defined as the ratio of the number of erroneous bits to the total
 number of transmitted bits.
 It is usually expressed in terms of power, as the probability of error
 is dependent on the signal-to-noise ratio (SNR) and the channel conditions.
 The BER can be empirically represented as follows:
\end_layout

\begin_layout Standard

\size large
\begin_inset Formula 
\begin{equation}
BER=\frac{N_{err}}{N_{tot}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
where 
\begin_inset Formula $N_{err}$
\end_inset

 is the number of erroneous bits and 
\begin_inset Formula $N_{tot}$
\end_inset

 is the total number of transmitted bits.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
A high BER indicates poor system performance, which can lead to loss of
 data, degraded audio or video quality, or even complete system failure.
 Therefore, the BER is used as a benchmark to ensure that the digital communicat
ion system meets the required performance specifications.
\end_layout

\begin_layout Subsubsection
BLER
\begin_inset CommandInset label
LatexCommand label
name "subsec:BLER"

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
To compare the estimated values 
\begin_inset Formula $\hat{\theta}$
\end_inset

 with the ground truth 
\begin_inset Formula $x$
\end_inset

, the frame is considered as a whole instead of comparing each bit individually.
 Specifically, the CRC 
\begin_inset CommandInset citation
LatexCommand cite
key "CRC"
literal "false"

\end_inset

 is computed over the entire frame for both the estimated values and the
 ground truth.
 If the CRC of the equalized frame matches the CRC of the ground truth,
 the frame is considered error-free.
 Otherwise, the frame is marked as incorrect, and the corresponding block
 is added to the Block Error Rate (BLER) count.
 The use of CRC32 ensures that collisions are avoided, as the number of
 possible blocks is much smaller than the number of possible CRC false positives.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{algorithm}[H] 
\backslash
caption{Block Error Rate Calculation with CRC} 
\backslash
label{alg:block_error_rate_crc} 
\backslash
begin{algorithmic}[1] 
\backslash
Require 
\backslash
Statex Input data is 48 blocks of 48 symbols 
\backslash
Statex $txbits$: array of transmitted blocks 
\backslash
Statex $rxbits$: array of received blocks 
\backslash
Statex $crc
\backslash
_func$: CRC function for generating CRC codes 
\backslash
Ensure 
\backslash
Statex $BLER$: Block Error Rate of the communication system 
\backslash
State $total
\backslash
_blocks 
\backslash
gets 48$ 
\backslash
State $bad
\backslash
_blocks 
\backslash
gets 0$ 
\backslash
For{$n 
\backslash
gets 0$ to $47$} 
\backslash
State $tx
\backslash
_crc 
\backslash
gets crc
\backslash
_func(txbits[n].tobytes())$ 
\backslash
State $rx
\backslash
_crc 
\backslash
gets crc
\backslash
_func(rxbits[n].tobytes())$ 
\backslash
If{$tx
\backslash
_crc 
\backslash
neq rx
\backslash
_crc$} 
\backslash
State $bad
\backslash
_blocks 
\backslash
gets bad
\backslash
_blocks + 1$ 
\backslash
EndIf 
\backslash
EndFor 
\backslash
State $BLER 
\backslash
gets bad
\backslash
_blocks / total
\backslash
_blocks$ 
\backslash
State 
\backslash
Return $BLER$ 
\backslash
end{algorithmic} 
\backslash
end{algorithm}
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Software 
\size large
Platform 
\begin_inset CommandInset label
LatexCommand label
name "subsec:Software-Platform"

\end_inset


\end_layout

\begin_layout Subsubsection
Data set
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
In the field of machine learning, data is typically split into three sets:
 training, validation, and testing.
\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf

\series bold
\size large
Training set
\series default
: The training set is a subset of the data used to train the model.
 The model uses the training data to learn the relationships between the
 input features and the target output.
 The model parameters are updated during the training process to minimize
 the prediction error.
\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent

\series bold
\size large
Validation set
\series default
: The validation set is a subset of the data used to evaluate the model
 during training.
 The purpose of the validation set is to ensure that the model is not overfittin
g to the training data.
 Overfitting occurs when the model is too complex and learns the noise in
 the training data instead of the underlying relationships.
 The model is evaluated on the validation set after each training epoch,
 and its performance is used to determine when to stop training or to adjust
 the model's hyperparameters.
\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent

\series bold
\size large
Testing set
\series default
: The testing set is a subset of the data used to evaluate the model's performan
ce after training.
 The model is never trained on the test set and its performance on the test
 set provides an estimate of its generalization performance to new, unseen
 data.
 The test set is used to determine the final accuracy of the model and its
 ability to make predictions on new data.
\end_layout

\begin_layout Subsubsection
Class design and documentation
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
To achieve code reusability, it is important to write modular and maintainable
 code that incorporates class inheritance and shared attributes.
 In order to further enhance the object-oriented programming (OOP) structure
 of our code, we implement the factory pattern.
 The factory pattern allows us to create multiple experiments with little
 changes but have the same base build and experiment structure, increasing
 code efficiency and reusability 
\begin_inset CommandInset citation
LatexCommand cite
key "DesignPatterns"
literal "false"

\end_inset

.
 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
This, combined with the PyTorch Lightning framework, has made the development
 process much easier and faster.
 PyTorch Lightning also offers tools for distributed training that can be
 used to scale the training of big models across several GPUs
\begin_inset CommandInset citation
LatexCommand cite
key "gpu-basic-training"
literal "false"

\end_inset

, TPUs 
\begin_inset CommandInset citation
LatexCommand cite
key "mnist-tpu-training"
literal "false"

\end_inset

, or machines.
 This tooling also facilitates the concept of batches, which involves having
 multiple realizations of the dataset in the format [BATCH, seq_len] or
 [BATCH, channel, height, width].
 By using batches, the training time is reduced and it becomes more manageable
 to handle large amounts of data.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Codigo/SoftwareDiagrams/networkdevelop.png
	lyxscale 50
	scale 28

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Software Architecture Diagram Planning 
\begin_inset CommandInset label
LatexCommand label
name "fig:Software-Architecture-Diagram"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
These are the main classes used in the software development:
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
Channel
\end_layout

\begin_deeper
\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
Loads a .mat file containing complex channel coefficient data and converts
 it into a numpy array.
 The class has a constructor __init__ that takes a Boolean parameter LOS
 (default value True) indicating whether to load the line-of-sight (LOS)
 or non-line-of-sight (NLOS) channel data.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
The Channel class has a single attribute con_list that is the numpy array
 containing the channel data.
 The class also defines a __getitem__ method that returns the channel data
 for a specific index in the array.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
The code also imports the scipy.io and numpy libraries and sets up the path
 to the directory containing the .mat files.
 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
Imports the Download_Mat_files function from the DownloadFiles module, and
 adds the path to the conf and tools directories to the Python path.
 
\end_layout

\end_deeper
\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
QAM
\series default
 
\end_layout

\begin_deeper
\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
This class QAM is used to generate QAM modulation schemes and perform demodulati
on on a complex symbol vector.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
The constructor initializes the QAM modulation scheme.
 It takes in the following parameters:
\end_layout

\begin_deeper
\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
num_symbols: The number of QAM symbols to generate.
 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
constelation: The size of the QAM constellation.
 Valid values are 4, 16, 32, and 64.
 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
cont_type: The type of constellation used.
 Valid values are "Data", "Unit_Pow", and "Norm".
 
\end_layout

\begin_deeper
\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
Data
\series default
: constelation as it is.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
Unit_Pow
\series default
: normalized power constelation
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
Norm
\series default
: Normalized constelation to max magnitud to 1 in the complex plane.
 
\end_layout

\end_deeper
\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
noise: Deprecated
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
noise_power: Deprecated
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
load_type: A flag indicating the type of loading.
 Valid values are "Complete" and "Alphabet".
 
\end_layout

\begin_deeper
\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
Complete
\series default
: This is used to get the complex plane data points
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
Alphabet
\series default
: Get the token values, which could be used to retrieve the symbols sent
 without having to put them in the complex domain.
\end_layout

\end_deeper
\end_deeper
\end_deeper
\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
Rx: 
\series default
This class is a PyTorch Dataset that generates a dataset for a communication
 channel.
 The channel is defined by a complex matrix 
\begin_inset Formula $\boldsymbol{H}$
\end_inset

, and QAM symbols are generated with specific parameters such as constellation
 size, constellation type, and load type.
 The dataset consists of a total of 20000 realizations, with each realization
 containing 48 QAM symbols.
 The class generates QAM symbols, generates a complex matrix 
\begin_inset Formula $\boldsymbol{H}$
\end_inset

, applies the channel to the symbols, and adds additive white Gaussian noise
 to the signal.
 The class also defines the AWGN method to add noise with a given SNR.
 The dataset can be loaded as batches using PyTorch's DataLoader.
 The class overloads the __getitem__ method to return the channel tensor
 and the corresponding transmitted tensor.
 The channel tensor is a 48x48x2 tensor of the real and imaginary parts
 of the complex matrix 
\begin_inset Formula $\boldsymbol{H}$
\end_inset

, and the transmitted tensor is either the QAM symbol bits or the QAM symbol
 complex values depending on the load type.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Codigo/UML/Classes_rx.png
	lyxscale 70
	scale 40

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Rx and their aggregated classes
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
RX_loader
\series default
: This class also splits the dataset into three parts for training, validation,
 and testing.
 The SNR_BER_TEST method of the class is used to calculate the bit error
 rate (BER) for different signal-to-noise ratio (SNR) values.
 This method uses the predict method of the trainer object to predict the
 values of the output of the model and then calculate the BER.
 Class also defines methods to calculate the output of the system given
 the input, including Get_Y, MSE_X, LMSE_X, and ZERO_X.
 These methods calculate the channel output, estimate the transmitted symbols,
 and perform equalization to reduce the effect of the channel on the received
 symbols.
 The class also defines a method to filter the data based on z-score.
\end_layout

\begin_deeper
\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
init
\series default
: Initializes the Rx_loader object with the specified batch size, QAM and
 loading type.
 It also loads the RX dataset and splits it into training, validation and
 testing sets.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
SNR_calc
\series default
: Calculates the signal-to-noise ratio (SNR) and bit error rate (BER) given
 the predicted output and the actual output.
 This is used for internal evaluation in the predict section of the Lightning
 API.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
SNR_BER_TEST:
\series default
 Performs an SNR-BER test by iterating through a range of SNR values and
 printing the BER for each value.
 It also saves the BER values to a CSV file.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
Get_Y:
\series default
 Takes in three arguments: 
\begin_inset Formula $\boldsymbol{H}$
\end_inset

 (channel tensor), 
\begin_inset Formula $\boldsymbol{X}$
\end_inset

 (transmitted symbol tensor), conj (boolean flag to indicate whether to
 take the complex conjugate of 
\begin_inset Formula $\boldsymbol{H}$
\end_inset

), and noise_activ (boolean flag to indicate whether to add noise to the
 received signal).
 It returns the received signal tensor 
\begin_inset Formula $\boldsymbol{Y}$
\end_inset

 of shape (batch_size, 48).
 
\end_layout

\begin_deeper
\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
If noise_activ is True
\series default
, it adds complex Gaussian noise to the received signal 
\begin_inset Formula $Y[i]$
\end_inset

.
 The noise power is computed as the ratio of the signal power to the signal-to-n
oise ratio (SNR) in decibels.
 The noise is generated using the PyTorch function torch.randn to create
 random Gaussian noise with zero mean and standard deviation of 
\begin_inset Formula $\sqrt{P_{n}/2}$
\end_inset

, where Pn is the noise power.
 More detail in 
\color blue

\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:SNR"
plural "false"
caps "false"
noprefix "false"

\end_inset


\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
If conj is True
\series default
, it takes the complex conjugate of 
\begin_inset Formula $\boldsymbol{H}$
\end_inset

 using the method 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newline
\end_layout

\end_inset

 conj().resolve_conj(), and performs matrix multiplication with Y[i].
 This helps in data preprocesing in section
\color blue
 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:A-Novel-OFDM"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
 more detail in 
\color blue

\begin_inset CommandInset ref
LatexCommand nameref
reference "Preprocesing"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
 image.
\end_layout

\end_deeper
\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
MSE_X
\series default
: Computes the minimum mean square error (MMSE) estimate of the transmitted
 signal 
\begin_inset Formula $\boldsymbol{X}$
\end_inset

 given the channel matrix 
\begin_inset Formula $\boldsymbol{H}$
\end_inset

 and received signal 
\begin_inset Formula $\boldsymbol{Y}$
\end_inset

.
 It returns a tensor of shape (batch_size, 48) of complex values.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
LMSE_X
\series default
: Computes the linear minimum mean square error (LMMSE) estimate of the
 transmitted signal 
\begin_inset Formula $\boldsymbol{X}$
\end_inset

 given the channel matrix 
\begin_inset Formula $\boldsymbol{H}$
\end_inset

, received signal 
\begin_inset Formula $\boldsymbol{Y}$
\end_inset

 and SNR.
 It returns a tensor of shape (batch_size, 48) of complex values.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
Chann_diag
\series default
: Extracts the diagonal of each channel matrix in the tensor and returns
 them as a tensor of shape (batch_size, 48) of complex values.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
ZERO_X
\series default
: The method starts by computing the diagonal elements of the channel tensor
 using the 
\series bold
Chann_diag
\series default
 method.
 This helper method extracts the diagonal of each matrix in the tensor and
 combines them into a new tensor.
 Next, the method applies Zero Forcing (ZF) equalization by dividing the
 received signal tensor Y by the diagonal tensor of the channel tensor chann.
 The output is an estimated signal tensor x_hat, which is a tensor of complex
 values with a shape of (batch_size, 48).
 The method returns this tensor as its output.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
filter_z_score
\series default
: Filters out outlier data points from the tensor based on the z-score.
 It returns a filtered tensor and the indices of the valid data points.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
filter_z_score_matrix
\series default
: Filters out outlier data points from the diagonal tensor of a batch of
 channel matrices based on the z-score.
 It returns a filtered tensor and the indices of the valid data points.
\end_layout

\begin_deeper
\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
The default value of the threshold parameter in the filter_z_score() method
 of the Rx_loader class is 1.96, which corresponds to a 95% confidence level
 assuming a normal distribution.
 This means that data points whose absolute z-score is greater than 1.96
 will be considered as outliers and filtered out.
 However, this value can be adjusted by the user based on their specific
 requirements.
\end_layout

\end_deeper
\end_deeper
\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Codigo/UML/Classes_data_loader.png
	lyxscale 70
	scale 40

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Rx Data Loader and usefull classes
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The Rx_loader class is implemented in all classes throughout the project
 for multiple experiments.
 The golden models also use this class because all final application classes
 inherit from this class and use the PyTorch Lightning framework to create
 powerful combinations between custom datasets and helper functions required
 for preprocessing.
\end_layout

\begin_layout Subsubsection
Generic Network Implementation
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The training_step and validation_step methods both call the common_step
 method, which contains the shared implementation between the two.
 This approach reduces code duplication and helps keep the implementation
 DRY (Don't Repeat Yourself)
\begin_inset CommandInset citation
LatexCommand cite
key "CleanCode"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The common_step method takes a batch of data and an optional flag to indicate
 whether the batch is being used for prediction.
 It then performs the 
\series bold
pre-processing
\series default
 of the data, which includes different strategies such as 
\color blue

\begin_inset CommandInset ref
LatexCommand nameref
reference "subsec:Zero-forcing-sec"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
, obtaining Y with its conjugate 
\color blue

\begin_inset CommandInset ref
LatexCommand eqref
reference "Preprocesing"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
, normalizing values 
\color blue

\begin_inset CommandInset ref
LatexCommand eqref
reference "subsec:Normalize-unitary-circle"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
, and filtering outliers by z-score
\color blue
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "subsec:Z-score"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
After the pre-processing is done, the method evaluates the model by computing
 the predicted output and comparing it with the target output.
 The 
\series bold
evaluation
\series default
 process involves passing the pre-processed data through the neural network
 model, which generates the predicted output.
 The predicted output is then compared with the target output using a loss
 function, which calculates the difference between them.
 The method returns the loss value, which is used for updating the model's
 parameters during training.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
By separating the common implementation from the specific training and validatio
n logic, we can easily reuse the same code for different stages of the training
 process, and focus on implementing the logic that is specific to each stage.
 This results in cleaner and more maintainable code, as well as faster developme
nt times.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Codigo/UML/GeneriNet.png
	lyxscale 70
	scale 40

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Generic Net
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
FLOPS 
\begin_inset CommandInset label
LatexCommand label
name "subsec:FLOPS"

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Now, having a software platform, it is crucial to measure its performance.
 FLOPS, which stands for "floating point operations per second," serves
 as a metric for assessing the computational performance of a computer or
 processor.
 It quantifies the number of floating point arithmetic operations that can
 be executed within a one-second timeframe.
 Floating point operations include addition, subtraction, multiplication,
 and division, as well as more complex operations like trigonometric functions,
 logarithms, and exponentials.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
FLOPS is commonly used as a benchmark for evaluating the performance of
 CPUs, GPUs, and other computing devices.
 It is often used in the context of high-performance computing, scientific
 simulations, and machine learning applications, where large amounts of
 data must be processed quickly.
 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
One approach to measuring FLOPS that we used in this work is to calculate
 the execution time and multiply it by the number of operations in each
 equalizer.
 This allows us to visualize the time complexity and efficiency of the equalizer
s.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
FLOPS\simeq\frac{1}{ExecTime}*Operations
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Performance variations in parallel algorithms stem from differences in design,
 implementation, and parallelism efficiency.
 Factors like memory access patterns, communication overhead, and load balancing
 also influence performance on multi-core systems.
 As a result, floating-point operation rates can change depending on algorithm
 effectiveness and work distribution among cores.
\end_layout

\begin_layout Subsection
Golden Model 
\begin_inset CommandInset label
LatexCommand label
name "subsec:Golden-Model"

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
In this project, the golden model serves as a benchmark for evaluating the
 performance of new models.
 The golden model is based on three equalizers: Least squares (LS), Linear
 Minimum Mean Squared Error (LMMSE), and zero forcing, which are discussed
 in more detail in sections
\color blue
 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:LS"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
, 
\color blue

\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:LMMSE"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
 , 
\color blue

\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Zero-forcing-sec"
plural "false"
caps "false"
noprefix "false"

\end_inset

 
\color inherit
of this document,respectively, and for the non-linear models there was implement
ed
\color blue
 
\begin_inset CommandInset ref
LatexCommand nameref
reference "subsec:OSIC"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
 and
\color blue
 
\begin_inset CommandInset ref
LatexCommand nameref
reference "subsec:NearML"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/Golden_4QAM.png
	lyxscale 40
	scale 55

\end_inset


\begin_inset Graphics
	filename Imagenes/Results/Golden_16QAM.png
	lyxscale 40
	scale 55

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Caption Standard

\begin_layout Plain Layout
Golden linear models plot QPSK and 16QAM
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
When evaluating the performance of a communication system, it is standard
 practice to plot both the Bit Error Rate
\color blue
 (
\begin_inset CommandInset ref
LatexCommand nameref
reference "subsec:BER"
plural "false"
caps "false"
noprefix "false"

\end_inset

) 
\color inherit
and Signal-to-Noise Ratio (SNR) on the same graph, with SNR on the x-axis
 and BER on the y-axis.
 BER measures the number of errors that occur in a transmitted data stream,
 relative to the total number of bits transmitted, while SNR measures the
 strength of the signal relative to the background noise.
 Comparing the BER and SNR values allows us to evaluate the system's performance
 under different levels of noise.To create a more representative view, it
 was decided to average the results of 5 tests and plot the average.
 Additionally, for each test, the SNR was incremented by a step of 2.
 Therefore, an interpolation was performed to smooth the curves.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/Golden/Results_Non_linear_Golden_Models_QPSK_-17_3_2023-11_36.png
	lyxscale 40
	scale 55

\end_inset


\begin_inset Graphics
	filename Imagenes/Results/Golden/Results_Non_linear_Golden_Models_-17_3_2023-11_32.png
	lyxscale 40
	scale 55

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Golden LMMSE and non-linear models plot QPSK and 16QAM
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Another metric we are using is the block error rate 
\color blue
(
\color inherit
 
\color blue

\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Signal-quality-metrics"
plural "false"
caps "false"
noprefix "false"

\end_inset

) 
\color black
which
\color inherit
 is a common metric used to measure the performance of digital communication
 systems, and it is an important factor in determining the quality of the
 transmission.
 A lower block error rate indicates that fewer errors are occurring during
 transmission and the communication system is performing better.
 A "block" is a fixed-length sequence of bits, and in a communication system,
 data is transmitted in these fixed-length blocks, for this case we built
 the blocks of 48 which is the same size as frame.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/BLER/Results_16QAM-10_3_2023-23_51.png
	lyxscale 70
	scale 70

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
16-QAM linear models BLER: LS, LMMSE, ZeroForcing
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Defining the Golden class, which takes the mode ("MSE"(LS), "LMSE", or "ZERO")
 as input and initializes the Rx_loader superclass with the given BATCHSIZE,
 QAM, and "Complete" load.
 Depending on the mode, the class sets the self.estimator attribute to the
 MSE_X, LMSE_X, or ZERO_X method.
 The class also defines the forward method, the configure_optimizers method,
 and the predict_step method, which calculates the bit error rate (BER)
 for a given batch of data.
 Finally, the class defines the predict_dataloader method, which returns
 the test_loader.
 In the main section of the script, a PyTorch Lightning Trainer object is
 instantiated.
 Finally, the SNR_BER_TEST method of the Golden object is called with the
 Trainer object and a file name for the output log.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/Golden/BLER/Results_Non_linear_Golden_Models_-17_3_2023-11_35.png
	lyxscale 70
	scale 70

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Golden LMMSE and non-linear models BLER 16QAM
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsection
\paragraph_spacing onehalf
\noindent
PhaseNet 
\begin_inset CommandInset label
LatexCommand label
name "subsec:PhaseNet"

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
This neural network corrects the distortion and restores the original phase
 given channel and noise.
 It can be used in applications such as phase modulation or PSK.
 However, the network encounters a problem when evaluating the error between
 the estimated and real values.
 When the estimated value is in the second quadrant of the complex plane
 and the real value is in the third quadrant, the error becomes quite large.
 This is because the error is measured as the difference in angles, and
 traversing the second, fourth, and third quadrants causes the error to
 increase significantly.
 It is important to note that angle values are usually represented within
 the range of 
\begin_inset Formula $-\pi$
\end_inset

 to 
\begin_inset Formula $\pi$
\end_inset

 in pytorch and numpy libraries.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Networks/ErrorAngle.png
	scale 80

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Angle error - Red represents high error and green represents smaller error.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
To address the issue of computing the error and achieving precise adjustment
 of the estimation, we adopted a new technique.
 This technique involves generating a complex number with a fixed radius
 of 1 and a variable angle.
 Since neural networks only output angles, we truncated the ground truth
 complex values to a radius of one.
 We used Euler's formula to construct this complex number in rectangular
 form, based only on the angle.
 Specifically, we used the output of the neural network, denoted as 
\begin_inset Formula $O(\boldsymbol{\hat{\theta}})$
\end_inset

, with a radius of one to build the complex number.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
O(\boldsymbol{\hat{\theta}})=e^{i\boldsymbol{\hat{\theta}}}=cos(\boldsymbol{\hat{\theta}})+i*sin(\boldsymbol{\hat{\theta}})
\end{equation}

\end_inset

By using this approach, we can concentrate solely on the phasors (angles)
 and keep a constant radius.
 We can objectively measure the difference between the complex value of
 the estimated and real values using the method of least squares.
 This method allows us to calculate the difference between two quadrants
 more accurately, resulting in better estimation correction.
 However, to avoid getting a complex error and obtain only a numerical error
 value, we calculate the mean squared error (MSE) separately for the real
 and imaginary parts.Furthermore, by limiting the radius to 1, the loss is
 bounded, preventing it from exploding and introducing a large error.
 This can help with the convergence of the neural network.
 The equation below shows the error measurement that was developed.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
MSE\left(\boldsymbol{\hat{\theta}}\right)=\frac{1}{2}\left(E\left[(cos(\boldsymbol{\hat{\theta}})-X_{real})^{2}\right]+E\left[(sin(\boldsymbol{\hat{\theta}})-X_{imag})^{2}\right]\right)\label{eq:62}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\align center

\size large
However this expresion can be rewriten and it can be expand each term as
 follows:
\end_layout

\begin_layout Standard
\align center

\size large
\begin_inset Formula $E\left[\cos^{2}(\boldsymbol{\hat{\theta}})\right]-2X_{\text{real}}E\left[\cos(\boldsymbol{\hat{\theta}})\right]+X_{\text{real}}^{2}+E\left[\sin^{2}(\boldsymbol{\hat{\theta}})\right]-2X_{\text{imag}}E\left[\sin(\boldsymbol{\hat{\theta}})\right]+X_{\text{imag}}^{2}$
\end_inset


\end_layout

\begin_layout Standard
\align center

\size large
We can simplify this by noting that:
\end_layout

\begin_layout Standard
\align center

\size large
\begin_inset Formula $E\left[\cos^{2}(\boldsymbol{\hat{\theta}})\right]+E\left[\sin^{2}(\boldsymbol{\hat{\theta}})\right]=E\left[\cos^{2}(\boldsymbol{\hat{\theta}})+\sin^{2}(\boldsymbol{\hat{\theta}})\right]=E\left[1\right]=1$
\end_inset


\end_layout

\begin_layout Standard
\align center

\size large
and
\end_layout

\begin_layout Standard
\align center

\size large
\begin_inset Formula $-2X_{\text{real}}E\left[\cos(\boldsymbol{\hat{\theta}})\right]-2X_{\text{imag}}E\left[\sin(\boldsymbol{\hat{\theta}})\right]=-2(X_{\text{real}}\cos(\boldsymbol{\hat{\theta}})+X_{\text{imag}}\sin(\boldsymbol{\hat{\theta}}))$
\end_inset


\end_layout

\begin_layout Standard
\align center

\size large
Substituting these simplifications back into the previous equation gives:
\end_layout

\begin_layout Standard
\align center

\size large
\begin_inset Formula $\frac{1}{2}\left(1-2(X_{\text{real}}\cos(\boldsymbol{\hat{\theta}})+X_{\text{imag}}\sin(\boldsymbol{\hat{\theta}}))+X_{\text{real}}^{2}+X_{\text{imag}}^{2}\right)$
\end_inset


\end_layout

\begin_layout Standard
\align center

\size large
which can be further simplified to:
\end_layout

\begin_layout Standard
\align center

\size large
\begin_inset Formula 
\begin{equation}
\frac{1}{2}\left((\cos(\boldsymbol{\hat{\theta}})-X_{\text{real}})^{2}+(\sin(\boldsymbol{\hat{\theta}})-X_{\text{imag}})^{2}\right)\label{eq63}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The final result is the same as the squared Euclidean distance, multiplied
 by a factor of 1/2.
 In complex form, it is represented by the squared magnitude of the difference
 between the complex numbers, which is equivalent to 
\color blue

\begin_inset CommandInset ref
LatexCommand formatted
reference "eq:MSECOMPLEX"
plural "false"
caps "false"
noprefix "false"

\end_inset

 
\color inherit
with a fixed radius of 1
\end_layout

\begin_layout Standard

\size large
\begin_inset Formula 
\begin{equation}
MSE\left(\boldsymbol{\hat{\theta}}\right)=|O(\boldsymbol{\hat{\theta}})-X|^{2}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard

\size large
Where 
\begin_inset Formula $|.|$
\end_inset

 is the magnitud of the complex number.
\end_layout

\begin_layout Subsubsection
Effective Techniques for Improving Model Generalization 
\begin_inset CommandInset label
LatexCommand label
name "subsec:Effective-Techniques-for"

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
In the field of machine learning, it is important to ensure that the models
 we build are able to accurately and effectively make predictions on new
 data.
 However, it is common for models to suffer from issues such as overfitting
 or poor generalization to new data.
 In this section, we will explore three techniques that can be used to improve
 the performance of machine learning models: 
\series bold
regularization
\series default
, 
\series bold
normalization
\series default
, and 
\series bold
standardization
\series default
.
 By properly applying these techniques, we can mitigate the risks of overfitting
 and improve the ability of our models to generalize to new data.
 
\begin_inset CommandInset citation
LatexCommand cite
key "Regularization_Bisong,Normalization_layers,standarization"
literal "false"

\end_inset


\end_layout

\begin_layout Subsubsection
Regularization
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Reegularization works by adding a penalty term to the objective function
 that the model is trying to minimize.
 This penalty term discourages the model from learning relationships that
 are too complex, and encourages it to learn simpler relationships that
 generalize better.
 There are several methods for regularization, including 
\begin_inset CommandInset citation
LatexCommand cite
key "Goodfellow-et-al-2016"
literal "false"

\end_inset

:
\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf

\size large
L1 Lasso regularization: This method adds a penalty term to the cost function
 that is proportional to the absolute value of the weights.
\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf

\size large
L2 Ridge regularization: This method adds a penalty term to the cost function
 that is proportional to the square of the weights.
\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf

\size large
Dropout regularization: This method randomly sets a fraction of the weights
 in the model to zero during training, which helps to prevent overfitting
 by reducing the number of parameters in the model.
 Dropout is only applied during the training process, and all neurons are
 available during evaluation.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
In two-dimensional space, the L1 regularization term takes the shape of
 a diamond centered at the origin because it represents the sum of absolute
 values of the weights.The L2 regularization term takes the shape of a circle
 centered at the origin because it represents the sum of the squared values
 of the weights.
 This can be better appreciated in 
\color blue
Figure 38.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename trasasdenivelRegularization.png
	lyxscale 50
	scale 60

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Level sets of the loss function and L1,L2 regularization 
\begin_inset CommandInset citation
LatexCommand cite
key "regimage"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\align block

\size large
To implement regularization, you can modify the cost function of the model
 to include the regularization term.
 For example, in L2 regularization, the cost function would be modified
 to include the sum of the squares of the weights, as shown in the following
 equation:
\end_layout

\begin_layout Standard

\size large
\begin_inset Formula 
\begin{equation}
J(W)=\frac{\lambda}{2}||w||^{2}=\frac{\lambda}{2}\sum_{j=1}^{m}w_{j}^{2}
\end{equation}

\end_inset


\end_layout

\begin_layout Itemize

\size larger
\begin_inset Formula $\lambda$
\end_inset

 
\size large
regularization parameter
\end_layout

\begin_layout Itemize

\size larger
\begin_inset Formula $J(W)$
\end_inset

 
\size large
Weight regularization
\end_layout

\begin_layout Subsubsection
Normalization 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Data is scaled using a process called normalization to give it a unit norm
 (or length).
 This is frequently done to improve the data's suitability for particular
 machine learning algorithms, such as those that use gradient descent or
 have a set range for acceptable input data.
 When comparing various features, normalization can also be used to scale
 down the data to a common scale.
 Data normalization methods include min-max normalization, mean normalization,
 and z-score normalization.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Normalization of complex numbers involves dividing a complex number by its
 magnitude (or absolute value) to obtain a complex number with a magnitude
 of 1.
 This is typically done to simplify calculations and make it easier to compare
 complex numbers.
 The normalized form of a complex number is often written as 
\begin_inset Formula $ẑ=\frac{z}{|\boldsymbol{v}|}$
\end_inset

, where 
\begin_inset Formula $z$
\end_inset

 is the original complex number and 
\begin_inset Formula $ẑ$
\end_inset

 is the normalized form and 
\begin_inset Formula $|\boldsymbol{v}|$
\end_inset

 is the max magnitud of the entire vector of the complex numbers.
 Normalization of complex numbers is useful in many applications, including
 signal processing and control systems, where it is often necessary to compare
 complex numbers on an equal footing.
 
\begin_inset CommandInset citation
LatexCommand cite
key "ComplexnumbersNN"
literal "false"

\end_inset


\end_layout

\begin_layout Standard

\size large
\begin_inset Formula 
\begin{equation}
ẑ_{i}=\frac{z_{i}}{|\boldsymbol{v}|}
\end{equation}

\end_inset


\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $|\boldsymbol{v}|$
\end_inset

 Maximum magnitud of the vector
\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\mathsf{z}$
\end_inset

 Input value
\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $ẑ$
\end_inset

 Normalized value
\end_layout

\begin_layout Subsubsection
Standarization 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
Standardization is a method used in machine learning to transform the values
 of a feature or set of features to a standard scale.
 The standard scale is typically defined as having a mean of 0 and a standard
 deviation of 1.
 Standardization is often used as a preprocessing step before training a
 model, as it can help to improve the performance and convergence of the
 model.
 Standardization can be useful when the features in the dataset have different
 scales or units, as it can help to bring them onto a common scale and make
 it easier for the model to learn from the data.
 Standardization can be applied to both real and complex-valued data.
\end_layout

\begin_layout Standard

\size large
\begin_inset Formula 
\begin{equation}
\hat{z_{i}}=\frac{z_{i}-\mu}{\sigma}
\end{equation}

\end_inset


\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\boldsymbol{\mu}$
\end_inset

 Mean of the data
\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\boldsymbol{\sigma}$
\end_inset

 Standard deviation of the data
\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\mathsf{\boldsymbol{z}}$
\end_inset

 Input value
\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\boldsymbol{ẑ}$
\end_inset

 Standarized value
\end_layout

\begin_layout Subsubsection
Z-score
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The Z-score,
\begin_inset CommandInset label
LatexCommand label
name "subsec:Z-score"

\end_inset

 also known as standard score, is a statistical measure that indicates how
 many standard deviations an observation or data point is from the mean
 of a data set.
 It is used to standardize data and compare individual observations to a
 population or sample mean.
 The magnitude of the z-score represents how far away the data point is
 from the mean in terms of standard deviations.
 It helps us to remove outliers and make our trainning stage more stable.
 Outliers are data points that are significantly different from the other
 data points in the data set and can skew statistical analyses or machine
 learning models.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
To identify outliers using z-score, we first calculate the z-score for each
 data point in the data set.
 We can then set a threshold z-score value, usually between 2 and 3, beyond
 which any data point is considered an outlier.
 Data points that have a z-score above the threshold are identified as outliers
 and can be removed from the data set.
 This can help to improve the accuracy and reliability of our results or
 predictions.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
z_{i}=\frac{x_{i}-\mu}{\sigma}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
We use the z-score to filter outliers with a desired level of confidence,
 which is typically set at 95%.
 This corresponds to a z-score of 1.96, which means that approximately 95%
 of the data points would fall within the confidence interval.
 The 95% confidence level is frequently employed as a standard level of
 confidence in statistical analyses, as depicted in 
\color blue
Figure 39.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/ConfidenceInterval.png
	lyxscale 70
	scale 70

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
95% Confidence interval 
\begin_inset CommandInset citation
LatexCommand cite
key "z_score_drawing"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
In this project, we used the z-score to assess the dispersion of each block
 of 48 symbols.
 The aim was to ensure that the symbols in each block were within the required
 confidence interval and that the relations between the symbols were not
 too dispersed.
 By using the z-score, we were able to analyze the standard deviation of
 the symbols in each block and identify any blocks that fell outside the
 desired range.
 It is worth noting that the received symbols in this project were subject
 to distortions and interference resulting from the communication channel
 and environmental noise.
 This made it imperative to carefully assess the dispersion of each block
 of symbols in order to identify and correct any errors in the transmission.
\end_layout

\begin_layout Subsubsection
Preprocesing
\end_layout

\begin_layout Standard
\noindent
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{table}[h] 
\backslash
centering 
\backslash
caption{Preprocessing flags PhaseNet} 
\backslash
label{tab:preprocessing} 
\backslash
begin{tabular}{|c|c|} 
\backslash
hline 
\backslash
textbf{Preprocessing} & 
\backslash
textbf{Enable} 
\backslash

\backslash
 
\backslash
hline Conjugate & True 
\backslash

\backslash
 
\backslash
hline Z-score & True 
\backslash

\backslash
 
\backslash
hline  Zero-Forcing & False 
\backslash

\backslash
 
\backslash
hline 
\backslash
end{tabular} 
\backslash
end{table}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Based on the experimentation, it can be concluded that preprocessing plays
 a crucial role in enabling the neural network to converge successfully.
 As demonstrated in the paper 
\shape italic
A Novel OFDM Equalizer for Large Doppler Shift Channel through Deep Learning
\shape default
\color blue
 
\begin_inset CommandInset ref
LatexCommand vpageref
reference "subsec:A-Novel-OFDM"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
, preprocessing helped to achieve a successful outcome.
 In this network, our first preprocessing stage is to multiply 
\begin_inset Formula $\boldsymbol{Y}$
\end_inset

 by the Hermitian transpose of the channel, 
\begin_inset Formula $\boldsymbol{H^{H}Y}$
\end_inset

.
 This results in 
\begin_inset Formula $\boldsymbol{H^{H}Y}$
\end_inset

 being the input to the network.
 Next, we apply a z-score filter 
\begin_inset CommandInset ref
LatexCommand vpageref
reference "subsec:Z-score"
plural "false"
caps "false"
noprefix "false"

\end_inset

 with a 95% confidence interval to eliminate outliers.
 Finally, we normalize angles from -pi to pi to -1 to 1.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Codigo/UML/PhasNet.png
	lyxscale 70
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Preprocesing Stages
\begin_inset CommandInset label
LatexCommand label
name "fig:PreprocesPhaseNet"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Parameters 
\end_layout

\begin_layout Standard
\begin_inset CommandInset label
LatexCommand label
name "Table4"

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{table}[H]   
\backslash
centering   
\backslash
caption{Number of Parameters in the PyTorch nn.Sequential block}   
\backslash
label{tab:PhaseNetTable}   
\backslash
begin{tabular}{|l|l|l|}     
\backslash
hline     
\backslash
textbf{Layer} & 
\backslash
textbf{Output Shape} & 
\backslash
textbf{Number of Parameters} 
\backslash

\backslash
     
\end_layout

\begin_layout Plain Layout


\backslash
hline     nn.Linear(48, 240, bias=True) & (batch
\backslash
_size, 240) & (48 + 1) * 240 = 11,760 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline     nn.Hardtanh() & (batch
\backslash
_size, 240) & 0 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline     nn.Linear(240, 720, bias=True) & (batch
\backslash
_size, 720) & 2 * 240$^2$ + 2 * 240 = 346,320 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline     nn.Linear(720, 240, bias=True) & (batch
\backslash
_size, 240) & 4 * 240$^2$ + 2 * 240 = 1,388,160 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline     nn.Hardtanh() & (batch
\backslash
_size, 240) & 0 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline     nn.Linear(240, 48, bias=True) & (batch
\backslash
_size, 48) & (240 + 1) * 48 = 11,568 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline     
\backslash
multicolumn{2}{|r|}{
\backslash
textbf{Total}} & 
\backslash
textbf{1,757,808 = 13.39 MB} 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline   
\backslash
end{tabular} 
\backslash
end{table} 
\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Hyperparameters
\end_layout

\begin_layout Standard

\size large
SNR stands for Signal-to-Noise Ratio during training.
 This value is applicable to all networks.
 During testing, the SNR is subjected to varying values.

\size default
 
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{table}[H]   
\backslash
centering   
\backslash
caption{Hyperparameters}   
\backslash
label{tab:hyperparams}   
\backslash
begin{tabular}{|l|l|}     
\backslash
hline     
\backslash
textbf{Hyperparameter} & 
\backslash
textbf{Value} 
\backslash

\backslash
 
\backslash
hline     BATCHSIZE & 10 
\backslash

\backslash
 
\backslash
hline     QAM & 16 
\backslash

\backslash
 
\backslash
hline     NUM
\backslash
_EPOCHS & 2 
\backslash

\backslash
 
\backslash
hline     INPUT
\backslash
_SIZE & 48 
\backslash

\backslash
 
\backslash
hline     HIDDEN
\backslash
_SIZE & 240 
\backslash

\backslash
 
\backslash
hline     LEARNING
\backslash
_RATE & 8e-5 
\backslash

\backslash
 
\backslash
hline     CONJ & True 
\backslash

\backslash
 
\backslash
hline  SNRdB & 35 
\backslash

\backslash
 
\backslash
hline 
\backslash
end{tabular} 
\backslash
end{table} 
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
PolarNet
\begin_inset CommandInset label
LatexCommand label
name "subsec:PolarNet"

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The Polar_Net consists of two networks: PhaseNet, which we've seen before,
 and a new network called Mag_net.
 The Polar_Net is an integration of these two as pretrained networks.
 Since we're already familiar with PhaseNet, let's now focus on describing
 MagNet.
\end_layout

\begin_layout Subsubsection
MagNet Preprocesing and loss function
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The architecture of MagNet is quite similar to that of Polar_Net, but with
 fewer parameters in the hidden layer.
 As a result, we won't go into as much detail about the layer architecture.
 However, we'll still pay close attention to the preprocessing stage.
 Unlike PhaseNet, MagNet doesn't use the Hermitian transpose of the channel.
 Instead, it uses the diagonal of the channel to perform zero forcing equalizati
on as a preprocessing step 
\color blue

\begin_inset CommandInset ref
LatexCommand eqref
reference "subsec:Zero-forcing-sec"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
.
 Next, a z-score filter is applied, followed by complex normalization by
 absolute.
 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The loss function for MagNet remains quite simple, let 
\begin_inset Formula $O(\hat{\theta})$
\end_inset

 be the output of the network, which approximates the magnitude of the ground
 truth, and the magnitude of a complex number is denoted by 
\begin_inset Formula $|.|$
\end_inset

, the folowing error is given: 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
MSE(\hat{\theta})=E\left[\left(O(\boldsymbol{\hat{\theta}})-|\boldsymbol{\theta}|\right)^{2}\right]
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
To put it another way, the network produces its output in terms of the magnitude
 of the complex numbers.
 Then, for the loss function, the absolute value of the complex value of
 the ground truth is taken.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Codigo/UML/MagNet.png
	lyxscale 70
	scale 60

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
MagNet Preprocesing
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Magnet Parameters 
\begin_inset CommandInset label
LatexCommand label
name "subsec:Magnet-Parameters"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{table}[h]   
\backslash
centering   
\backslash
caption{Number of Parameters in the PyTorch nn.Sequential block}   
\backslash
label{tab:num_params}   
\backslash
begin{tabular}{|l|l|l|}     
\backslash
hline     
\backslash
textbf{Layer} & 
\backslash
textbf{Output Shape} & 
\backslash
textbf{Number of Parameters} 
\backslash

\backslash
     
\backslash
hline     
\end_layout

\begin_layout Plain Layout

nn.Linear(48, 120, bias=True) & (batch
\backslash
_size, 120) & (48 + 1) * 120 = 5,880 
\backslash

\backslash
     
\backslash
hline     
\end_layout

\begin_layout Plain Layout

nn.Hardtanh() & (batch
\backslash
_size, 120) & 0 
\backslash

\backslash
     
\backslash
hline     
\end_layout

\begin_layout Plain Layout

nn.Linear(120, 240, bias=True) & (batch
\backslash
_size, 240) & 2 * 120$^2$ + 2 * 120 = 29,040 
\backslash

\backslash
     
\backslash
hline     
\end_layout

\begin_layout Plain Layout

nn.Linear(240, 120, bias=True) & (batch
\backslash
_size, 120) & 4 * 120$^2$ + 2 * 120 = 57,840 
\backslash

\backslash
     
\backslash
hline
\end_layout

\begin_layout Plain Layout

nn.Hardtanh() & (batch
\backslash
_size, 120) & 0 
\backslash

\backslash
     
\backslash
hline     
\end_layout

\begin_layout Plain Layout

nn.Linear(120, 48, bias=True) & (batch
\backslash
_size, 48) & (120 + 1) * 48 = 5,856 
\backslash

\backslash
     
\backslash
hline     
\end_layout

\begin_layout Plain Layout


\backslash
multicolumn{2}{|r|}{
\backslash
textbf{Total}} & 
\backslash
textbf{98,716 = 789.7 KB} 
\backslash

\backslash
     
\backslash
hline   
\backslash
end{tabular} 
\backslash
end{table} 
\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
MagNet Hyperparameters
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{table}[H] 
\backslash
centering 
\backslash
caption{Hyperparameters} 
\backslash
label{tab:hyperparams} 
\backslash
begin{tabular}{|l|l|} 
\backslash
hline 
\backslash
textbf{Hyperparameter} & 
\backslash
textbf{Value} 
\backslash

\backslash
 
\backslash
hline BATCHSIZE & 10 
\backslash

\backslash
 
\backslash
hline QAM & 16 
\backslash

\backslash
 
\backslash
hline NUM
\backslash
_EPOCHS & 10 
\backslash

\backslash
  
\backslash
hline INPUT
\backslash
_SIZE & 48 
\backslash

\backslash
 
\backslash
hline HIDDEN
\backslash
_SIZE & 120 
\backslash

\backslash
 
\backslash
hline LEARNING
\backslash
_RATE & 5e-5 
\backslash

\backslash
 
\backslash
hline SNRdB & 25 
\backslash

\backslash
 
\backslash
hline 
\backslash
end{tabular} 
\backslash
end{table}
\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
All Together
\end_layout

\begin_layout Standard
The final size of the network is the sum of the Magnet parameters and the
 Phase parameters, which is approximately 
\series bold
0.753 MB + 13.39 MB = 14.143 MB
\series default
.
 The reason why Magnet has fewer parameters is that more parameters in the
 magnitude can lead to overfitting and the network may not generalize well
 with new data.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Codigo/UML/PolarNet.png
	lyxscale 70
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Overview of PolarNet
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Complex Net
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
This network was motivated in the paper A Survey of Complex-Valued Neural
 Networks 
\color blue

\begin_inset CommandInset ref
LatexCommand vpageref
reference "subsec:A-Survey-of"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color black
.
 The main idea is to investigate the use of complex-valued neural networks
 and attempt to reduce the number of network parameters.
 However, this approach may increase the time complexity due to the need
 for complex number operations between each layer.
 Additionally, we aim to utilize state-of-the-art loss functions proposed
 in mathematical formulas 
\color blue

\begin_inset CommandInset ref
LatexCommand formatted
reference "eq:MSECOMPLEX"
plural "false"
caps "false"
noprefix "false"

\end_inset

 
\color black
and 
\color blue

\begin_inset CommandInset ref
LatexCommand formatted
reference "eq:65"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color black
.Finally, for preprocessing, the hermitian transpose and normalization steps
 are applied.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Codigo/UML/ComplexUML.png
	lyxscale 70
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Complex Network Implementation
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Codigo/UML/ComplexNet.png
	lyxscale 70
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Complex Preprocesing
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\color black
In the upcoming subsections, we will explain the components required to
 construct a complex network.
 
\end_layout

\begin_layout Subsubsection
Apply Complex 
\begin_inset CommandInset label
LatexCommand label
name "subsec:Apply-Complex"

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
One of the key components of layers in this stage is the apply_complex functions
 which is part of the complexLinear layers.
 The apply_complex(fr, fi, input, dtype = torch.complex128) function takes
 as input the real and imaginary parts of the weights fr and fi, the input
 tensor input, and a data type dtype for the output tensor.
 It applies a complex-valued linear transformation to the input tensor,
 given by the expression:
\end_layout

\begin_layout Standard

\size large
\begin_inset Formula 
\begin{equation}
Re(z)=Re(fr)*Re(x)-Im(fi)*Im(x)
\end{equation}

\end_inset


\end_layout

\begin_layout Standard

\size large
\begin_inset Formula 
\begin{equation}
Im(z)=Re(fi)*Re(x)+Im(fr)*Im(x)
\end{equation}

\end_inset


\end_layout

\begin_layout Subsubsection
\paragraph_spacing onehalf
\noindent
Complex Linear
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
The ComplexLinear(in_features, out_features) class defines a custom PyTorch
 module for a complex-valued linear layer.
 It has two attributes: fc_r is a standard PyTorch Linear module that applies
 a linear transformation to the real part of the input, and fc_i is another
 Linear module that applies a linear transformation to the imaginary part
 of the input.
 The forward(input) method of this module applies the complex-valued linear
 transformation separately to the real and imaginary parts of the input
 tensor using the apply_complex function.
\end_layout

\begin_layout Subsubsection
\paragraph_spacing onehalf
\noindent
Hardtanh Complex
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
The HardTahn_complex class defines a custom PyTorch module for a complex-valued
 hard tanh activation function.
 It has two attributes: hard_real is a standard PyTorch Hardtanh module
 that applies the hard tanh function to the real part of the input tensor,
 and hard_imag is another Hardtanh module that applies the hard tanh function
 to the imaginary part of the input tensor.
 The forward(input) method of this module applies the hard tanh function
 separately to the real and imaginary parts of the input tensor, and then
 combines them into a complex-valued tensor using torch.float64 and the +1j*
 syntax to create a complex number.
 
\end_layout

\begin_layout Subsubsection
Parameters 
\begin_inset CommandInset label
LatexCommand label
name "subsec:Complex-Net-Param"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{table}[H] 
\backslash
centering 
\backslash
begin{tabular}{|l|l|l|l|} 
\backslash
hline 
\backslash
textbf{Layer} & 
\backslash
textbf{Input Size} & 
\backslash
textbf{Output Size} & 
\backslash
textbf{Number of Parameters} 
\backslash

\backslash
 
\backslash
hline Linear 1 & 48 & 120 & 11,520 
\backslash

\backslash
 
\backslash
hline HardTanh 1 & 120 & 120 & 0 
\backslash

\backslash
 
\backslash
hline Linear 2 & 120 & 240 & 138,240 
\backslash

\backslash
 
\backslash
hline Linear 3 & 240 & 240 & 115,440 
\backslash

\backslash
 
\backslash
hline Linear 4 & 240 & 120 & 57,720 
\backslash

\backslash
 
\backslash
hline HardTanh 2 & 120 & 120 & 0 
\backslash

\backslash
 
\backslash
hline Linear 5 & 120 & 240 & 138,240 
\backslash

\backslash
 
\backslash
hline Linear 6 & 240 & 48 & 23,088 
\backslash

\backslash
 
\backslash
hline Total & 48 & 48 & 484,248 = 3.87 MB 
\backslash

\backslash
 
\backslash
hline 
\backslash
end{tabular} 
\backslash
caption{Number of parameters in the complex network.} 
\backslash
end{table} 
\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
HyperParameters
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{table}[h] 
\backslash
centering 
\backslash
begin{tabular}{|l|l|} 
\backslash
hline 
\backslash
textbf{Parameter} & 
\backslash
textbf{Value} 
\backslash

\backslash
 
\backslash
hline Batch Size & 50 
\backslash

\backslash
 
\backslash
hline QAM & 16 
\backslash

\backslash
 
\backslash
hline Number of Epochs & 100 
\backslash

\backslash
 
\backslash
hline Learning Rate & 0.00001 
\backslash

\backslash
 
\backslash
hline SNRdB & 40 
\backslash

\backslash
 
\backslash
hline 
\backslash
end{tabular} 
\backslash
caption{Values for network hyperparameters.} 
\backslash
end{table} 
\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Loss functions
\end_layout

\begin_layout Standard

\size large
In the experiments, we evaluate the performance of the complex network using
 both custom loss functions
\size default
 
\size large
\color blue

\begin_inset CommandInset ref
LatexCommand formatted
reference "eq:MSECOMPLEX"
plural "false"
caps "false"
noprefix "false"

\end_inset

 
\color black
and 
\color blue

\begin_inset CommandInset ref
LatexCommand formatted
reference "eq:65"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color black
.

\color inherit
 The results of these experiments are presented in the next section.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Networks/ComplexLoss.png
	lyxscale 70
	scale 70

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Loss functions code
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsection
MobileNet zeroForcing
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
We conducted experiments with this network to study how well 
\color blue

\begin_inset CommandInset ref
LatexCommand nameref
reference "subsec:CNN"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
 can be developed in signal equalization in the state of art 
\color blue

\begin_inset CommandInset ref
LatexCommand nameref
reference "subsec:Autoencoder"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
.
 However, we opted to employ the efficient architecture of MobileNet as
 our network's goal is to improve the effectiveness of the zero-forcing
 method for communication channels.
 Given the relative simplicity of the zero-forcing algorithm, we determined
 that the 
\color blue

\begin_inset CommandInset ref
LatexCommand nameref
reference "subsec:MobileNetV3"
plural "false"
caps "false"
noprefix "false"

\end_inset

 
\color inherit
architecture was well-suited for our purposes.
 Its time efficiency and competence relative to zero-forcing made it a suitable
 choice.
 However, in the presence of noise in the channel data, the conventional
 zero-forcing approach may not be effective as it does not consider noise
 in its nature.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The channel is initially a 1x48x48 matrix, but it must be transformed into
 a single vector of length 1x48 for the zero-forcing approach to be applicable.
 Thus, this implementation employs two modified MobileNets to process the
 channel data.
 One network is responsible for extracting the absolute value of the channel
 matrix, while the other network extracts the angle matrix of the channel.
 Notably, the first and last layers were modified to fit the specific problem.
 In the image below, they are marked in red.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/MobileNetCustom.png
	lyxscale 70
	scale 70

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Ilustartion of mobileNet customized for our target problem
\begin_inset CommandInset label
LatexCommand label
name "fig:Ilustartion-of-mobileNet"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The models used in this project were taken from the PyTorch framework, so
 there was no need to test their functionality.
 We did not use pre-trained weights and instead trained the models from
 scratch.
 Thanks to the GPU, we were able to train the models faster.

\size default
 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The idea behind this is to replicate the process of traditional zero-forcing
 
\begin_inset Formula $\boldsymbol{\frac{Y}{H}}$
\end_inset

, where the channel matrix is represented by 
\begin_inset Formula $\boldsymbol{H}$
\end_inset

 and the received signal is represented by 
\begin_inset Formula $\boldsymbol{Y=HX+n}$
\end_inset

.
 In this process, we estimate the channel using the equation:
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{\hat{X}=\frac{Y}{\hat{\theta}}}
\end{equation}

\end_inset

 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
where 
\begin_inset Formula $\boldsymbol{\hat{\theta}}$
\end_inset

 represents the output of the model.
 However, as we want the estimator values to be in the range of 
\begin_inset Formula $0<\hat{\boldsymbol{\theta}}<1$
\end_inset

, we need to rearrange the estimation equation as follows:
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\hat{X}=Y*\hat{\boldsymbol{\theta}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
As we are working with polar coordinates, we should note that when multiplying
 two phasors, their amplitudes are multiplied, and their angles are added
 together.
 So basically net compensate the distorted phasor 
\begin_inset Formula $Y$
\end_inset

 and estimation equations has this form:
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
O(\hat{\theta})=Y_{mag}*\hat{\theta_{mag}}\angle\hat{\theta}_{angle}+Y_{angle}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard

\size large
Finally the MSE loss between this estimated 
\begin_inset Formula $O(\hat{\theta})$
\end_inset

 and the true value is given this form.
 
\end_layout

\begin_layout Standard

\size large
\begin_inset Formula 
\begin{equation}
MSE(\hat{\theta})=E\left[\left(O(\boldsymbol{\hat{\theta}})-\boldsymbol{\theta}\right)^{2}\right]
\end{equation}

\end_inset


\end_layout

\begin_layout Subsubsection
\paragraph_spacing onehalf
\noindent
Software Implementation 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
In the common_step method, the input data is processed by the Predesigned
 Model network, which is a pre-trained MobileNetv3 network that is modified
 to fit the problem.
 The output of the network is passed through two separate layers: one layer
 for the magnitude and one layer for the angle of the signal.
 The angle layer is used to estimate the phase shift of the received signal.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
It's worth noting that the channel is treated as an image of two channels,
 one for the real and the other for the imaginary part.
 In the software implementation, a complex128 channel of 1 channel is built,
 and then the absolute and angle of this 1 channel matrix is taken to feed
 both mobile nets.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
In this code implementation, the channel magnitude is normalized to the
 maximum magnitude of 1.
 This normalization is done after building the 
\begin_inset Formula $\boldsymbol{Y}$
\end_inset

, to avoid altering the results of calculating the input signal.
 Then the z-score is computed, and outliers are filtered with a confidence
 interval of 99%.
 Finally, for the angle error calculation, the same ideas as in PolarNet
 are followed.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Codigo/UML/MobileNetForwar.png
	lyxscale 80
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
MobileNet Forward process
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Loss Function
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
For the loss function we face the same issue as PhaseNet regarding the calculati
on of angle errors.
 To avoid this problem, we adopt a similar solution, which involves fixing
 the radius to 1 and comparing the angles 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq63"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 So we end up with 3 evalautons for a single loss function.
 However, in this loss, we chose to emphasize the Phasor concept to make
 it more intuitive.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\begin_inset Formula 
\begin{equation}
Loss=\begin{array}{c}
\frac{1}{2}MSE(Y_{mag}*\hat{\theta_{mag}},x_{mag})+\\
\frac{1}{4}MSE\left(\left[1\angle\hat{\theta}_{angle}+Y_{angle}\right]_{real},\left[1\angle x_{angle}\right]_{real}\right)+\\
\frac{1}{4}MSE\left(\left[1\angle\hat{\theta}_{angle}+Y_{angle}\right]_{imag},\left[1\angle x_{angle}\right]_{imag}\right)
\end{array}
\end{equation}

\end_inset


\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf

\size large
The first term computes the MSE between the magnitudes of the estimated
 signal 
\begin_inset Formula $Y_{mag}*\hat{\theta_{mag}}$
\end_inset

 and the true signal magnitud 
\begin_inset Formula $\boldsymbol{X_{mag}}$
\end_inset

.
 Here, 
\begin_inset Formula $\boldsymbol{Y_{mag}}$
\end_inset

 is the magnitude of the received signal 
\begin_inset Formula $\boldsymbol{Y}$
\end_inset

, and 
\begin_inset Formula $\boldsymbol{\hat{\theta_{mag}}}$
\end_inset

 is the estimated magnitude given by network.
\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf

\size large
The second term computes the mean squared error (MSE) between the real component
s of the estimated phasor, with fixed radius plus phase correction, and
 the real value of the angle of x
\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf

\size large
The same as second term in loss, but with imaginary part.
 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The function also includes weighting factors for each term.
 The first term is weighted by 1/2, while the second and third terms are
 each weighted by 1/4.
\end_layout

\begin_layout Subsubsection
Parameters
\end_layout

\begin_layout Standard
MobileNetV3 model has about 2.24 million parameters in an efficient way.
 
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{table}[h] 
\backslash
centering 
\backslash
begin{tabular}{|c|c|c|} 
\backslash
hline 
\backslash
textbf{Name} & 
\backslash
textbf{Type} & 
\backslash
textbf{Params} 
\backslash

\backslash
 
\backslash
hline 0 & loss
\backslash
_f & MSELoss 
\backslash
_ 0 
\backslash

\backslash
 
\backslash
hline 1 & abs
\backslash
_net & PredesignedModel = 1.6 M 
\backslash

\backslash
 
\backslash
hline 2 & angle
\backslash
_net & PredesignedModel = 1.6 M 
\backslash

\backslash
 
\backslash
hline 3 & final
\backslash
_merge
\backslash
_abs & Sequential = 18.6 K 
\backslash

\backslash
 
\backslash
hline 4 & final
\backslash
_merge
\backslash
_ang & Sequential = 18.6 K 
\backslash

\backslash
 
\backslash
hline 
\backslash
multicolumn{2}{|c|}{
\backslash
textbf{Total size}} & 
\backslash
textbf{3.2 MB + 37.2 KB} 
\backslash

\backslash
 
\backslash
hline 
\backslash
end{tabular} 
\backslash
caption{Model architecture} 
\backslash
end{table} 
\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
HyperParameter
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{table}[h] 
\backslash
centering 
\backslash
begin{tabular}{|l|l|} 
\backslash
hline 
\backslash
textbf{Parameter} & 
\backslash
textbf{Value} 
\backslash

\backslash
 
\backslash
hline Batch Size & 50 
\backslash

\backslash
 
\backslash
hline Number of Epochs & 50 
\backslash

\backslash
 
\backslash
hline Learning Rate & 0.0001 
\backslash

\backslash
 
\backslash
hline SNRdB & 30 
\backslash

\backslash
 
\backslash
hline 
\backslash
end{tabular} 
\backslash
caption{Neural network hyperparameters} 
\backslash
label{tab:nn_params} 
\backslash
end{table}
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
\paragraph_spacing onehalf
GridNet 
\begin_inset CommandInset label
LatexCommand label
name "subsec:GridNet"

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
At the moment we were conducting this research, nothing had been done before
 with transformers and signal equalization.
 We are aware that transformers are a heavier network, but recent advances
 in Edge Computing TPU processors 
\begin_inset CommandInset citation
LatexCommand cite
key "coral2020accelerator"
literal "false"

\end_inset

 are making them a more feasible solution at a relatively low cost.
 While there is a paper called "Radio Transformer"
\begin_inset CommandInset citation
LatexCommand cite
key "RadioTransformer"
literal "false"

\end_inset

 in the state of the art, it is used for modulation recognition, not for
 signal equalization.
 Additionally, historically, this paper does not align with "Attention is
 All You Need" 
\begin_inset CommandInset citation
LatexCommand cite
key "transformer"
literal "false"

\end_inset

 paper since it was written in 2016, whereas "Attention is All You Need"
 was written in 2017.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
While we were initially inspired by the concept of an image being worth
 16x16 words 
\begin_inset CommandInset citation
LatexCommand cite
key "dosovitskiy2020image"
literal "false"

\end_inset

 as described in the state of the art 
\color blue

\begin_inset CommandInset ref
LatexCommand formatted
reference "subsec:An-image-is"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
, we took this idea further by considering the encoder and decoder for the
 original transformer design 
\color blue

\begin_inset CommandInset ref
LatexCommand formatted
reference "fig:Transformer"
plural "false"
caps "false"
noprefix "false"

\end_inset

 
\color inherit
.
 Additionally, we challenged the assumption that the grid must be based
 on Euclidean geometry and instead rethought the grid in terms of a polar
 geometry.
 This paradigm shift was justified by the fact that our best results were
 obtained using polar representation.
 Furthermore, polar representation results in a non-uniformly distributed
 grid, where values closer to the center are penalized more heavily.
 This is useful because, in the presence of additive white noise, values
 are not expected to be centered, but rather more commonly found towards
 the edges of the polar representation.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The main idea is to divide the complex plane into grids, with each grid
 slot considered as a bucket.
 When a received value 
\begin_inset Formula $\boldsymbol{Y_{i}}$
\end_inset

 arrives, it is placed in an incorrect bucket 
\begin_inset Formula $\boldsymbol{B_{i}},$
\end_inset

which is assigned a number 
\begin_inset Formula $\boldsymbol{A_{i}}$
\end_inset

.
 To train the network, we assign the ground truth value with its correct
 bucket number 
\begin_inset Formula $\boldsymbol{B_{j}}$
\end_inset

and calculate the maximum likelihood cost function between the estimation
 and ground truth , similar to correcting mistranslated text in a language
 task.
 Multihead attention improves Bucket calculation, because it takes care
 of the values passed before.
 In the context of signal processing, this attention mechanism helps to
 handle the ISI (Inter-Symbol Interference), which is a major challenge
 in dealing with a doubly dispersive 
\color blue

\begin_inset CommandInset ref
LatexCommand nameref
reference "subsec:Channel"
plural "false"
caps "false"
noprefix "false"

\end_inset

 .
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Finally, after predicting the bucket 
\begin_inset Formula $\boldsymbol{B_{j}},$
\end_inset

the value passes through the degrid process, which involves placing the
 value in the middle of the patch coordinates.
 This process helps to further equalize the value as it is forced to be
 placed in only this position or any other patch.
\end_layout

\begin_layout Subsubsection
\paragraph_spacing onehalf
Square Grid
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The encoding process involves binning the real and imaginary parts of the
 data into a set of discrete bins and mapping them onto a 2D grid.
 The decoding process reverses this process by mapping the values back to
 their original locations in the complex plane.
 The smallest number used for the grid is 4 because number 2 is reserved
 for the start of sentence token (<sos>) and 3 is reserved for the end of
 sentence token (<eos>), making it compatible with language models.
 The largest number corresponds to the number of bins used in the encoding
 process.
 In other words number of bins is the size of our alphabet.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Codigo/UML/SquareGrid.png
	lyxscale 70
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Class attibutes to do the grid with bins
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
step
\series default
: A float value that represents the step size for binning, from -.85 to .85.
 Note that step is for quadrant and not all plane.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
binsx
\series default
: A tensor that contains the bins for the real part of the data.
 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
binsy
\series default
: A tensor that contains the bins for the imaginary part of the data.
 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
binxy
\series default
: A tensor that contains a 2D bin index matrix for encoding.
 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
x_indices
\series default
: A tensor that stores the indices of the bins for the real part of the
 data.
 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
y_indices
\series default
: A tensor that stores the indices of the bins for the imaginary part of
 the data.
 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
indices_shape
\series default
: A tuple that stores the shape of the input data for encoding.
 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
real_decoded
\series default
: A tensor that stores the decoded values for the real part of the data.
 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
imag_decoded
\series default
: A tensor that stores the decoded values for the imaginary part of the
 data.
 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
decoded_shape
\series default
: A tuple that stores the shape of the input data for decoding.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Encoding Recipe: 
\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent

\size large
Loop over the binsx for the real and binsy for the imaginary parts, and
 check if the data value falls in the range of bin i and bin i+1.
\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent

\size large
Save all the values that fall in the bin as x_indices and y_indices.
 These indices behave more like coordinates for the matrix of binsxy.
\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent

\size large
Encoding is done by putting the indices in the binxy vector.
 The binxy vector returns a numerical token that represents the position
 of the complex plane.
\end_layout

\begin_layout Standard

\size large
Here's an elegant code implementation 
\end_layout

\begin_layout Standard

\size large
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
lstinputlisting[language=python,firstline=39, lastline=48]{Codigo/GridCode.py}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Networks/GridNet.png
	lyxscale 80
	scale 70

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Square grid enconding values with a step of 1/7 per cuadrant 
\begin_inset CommandInset label
LatexCommand label
name "fig:Square-grid"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Decoding Recipe: 
\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent

\size large
Loop over the binsxy matrix and create a mask of indices that correspond
 to the encoded values
\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent

\size large
Use the mask of indices to assign values from the binsx and binsy vectors
 to the corresponding real and imaginary decoded vectors.
 Add half a step to each value to place it in the center of the bin.
\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent

\size large
Build a complex number vector using the real and imaginary decoded vectors.
\end_layout

\begin_layout Standard

\size large
Here's an elegant code implementation 
\end_layout

\begin_layout Standard

\size large
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
lstinputlisting[language=python,firstline=64, lastline=76]{Codigo/GridCode.py}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The gridding step ensures that all possible values in the complex plane
 are now bounded by the alphabet size 
\begin_inset Formula $|\mathbb{A}|$
\end_inset

, which can be beneficial for neural networks even if it doesn't compromise
 the space between QAM points spacing.
 In the picture bellow we show some points that was enconded and decoded,
 and we appreciate how they are centered after decoding.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Networks/SquareGridDegrid.png
	lyxscale 50
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Points after encoding and decoding, shown in a centered position of the
 binxy
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Polar Grid
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The Polar Grid is quite similar to the number ordering of the Square Grid,
 as it starts with 4 as its initial number.
 However, in this code implementation, instead of having x and y bins, we
 will have radius and angle bins.
 One thing to note is that now we have two steps that can be totally independent
: one step for the radius and the other for the angle.
 In the Square Grid, the step was the same for both x and y coordinates.
 One main advantage of the polar grid is that we don't need to take care
 of the angle measurement error, as the encoding will handle it within the
 transformer.
 However, the polar grid uses more space with fewer patches compared to
 the square grid.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Codigo/UML/RadGrid.png
	lyxscale 70
	scale 70

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Class attributes for the Radial Grid
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
step_radius
\series default
: Steps between 0 and 1
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
step_angle
\series default
: Steps between 0 and 
\begin_inset Formula $\boldsymbol{\pi}$
\end_inset


\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
binsr
\series default
: Number of bins for radius
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
binsa
\series default
: Numbers of bins for angles
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
binra
\series default
: Combined Grid between radius and angle.
 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Encoding Recipe: 
\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent

\size large
Loop over the binsr for the radius and binsa for the angle, and check if
 the data value falls in the range of bin i and bin i+1.
\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent

\size large
Save all the values that fall in the bin as r_indices and a_indices.
 These indices behave more like coordinates for the matrix of binsra.
\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent

\size large
Encoding is done by putting the indices in the binra vector.
 The binra vector returns a numerical token that represents the position
 of the complex plane.
\end_layout

\begin_layout Standard

\size large
Here's an elegant code implementation 
\end_layout

\begin_layout Standard

\size large
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
lstinputlisting[language=python,firstline=38, lastline=49]{Codigo/RadGrid.py}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Networks/RadGrid.png
	lyxscale 80
	scale 80

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Radial Grid encoding values.
 Radius step = 0.25 and angle step = pi/6 
\begin_inset CommandInset label
LatexCommand label
name "fig:Radial-Grid-encoding"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Decoding Recipe: 
\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent

\size large
Loop over the binsra matrix and create a mask of indices that correspond
 to the encoded values
\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent

\size large
Use the mask of indices to assign values from the binsr and binsa vectors
 to the corresponding radius and angle decoded vectors.
 Add half a step to each value to place it in the center of the bin.
\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent

\size large
Build a complex number vector using the magnitud and phase decoded vectors.
\end_layout

\begin_layout Standard

\size large
Here's an elegant code implementation 
\end_layout

\begin_layout Standard

\size large
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
lstinputlisting[language=python,firstline=59, lastline=74]{Codigo/RadGrid.py}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Similarly to the square grid, the values in the polar grid are also centered
 in the grid during decoding, thus closing again the possible states of
 the points in the complex plane.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Networks/RadGridOriginalData.png
	lyxscale 50
	scale 57

\end_inset


\begin_inset Graphics
	filename Imagenes/Networks/RadGridOriginal_Decoded_Data.png
	lyxscale 50
	scale 57

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Points after encoding and decoding, shown in a centered position of the
 binra
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Data Augmentation for Improving Error Performance in PolarGrid 
\begin_inset CommandInset label
LatexCommand label
name "subsec:Data-Augmentation"

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Due to the superior ICI cancellation performance of Polar Net, some of the
 high SNR, had BER errors were reduced to zero.
 However, this does not indicate a perfect system; rather, it suggests that
 the error rate did not fail often enough across all of the samples.
 Therefore, we combined the validation set and training set to artificially
 augment the data and allow the system to fail more often.
 It is important to note that this step of merging the validation and testing
 set was carried out only after confirming that the network was functioning
 well with the established parameters.
 This decision does not affect the training stage in any way.
\end_layout

\begin_layout Subsubsection
Transformer implementation
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Our transformer implementation can handle both grids by simply changing
 a hyperparameter, which provides a generic interface for experimentation.
 For positional embedding, we use a logical sequence of numbers ranging
 from 0 to 48 positions.
 Although there were some experiments with the sin embedding, it did not
 work well for this task.
 We apply a padding mask to the source and pass it to the transformer.
 The transformer is not a custom implementation but rather a predefined
 block already available in PyTorch that contains an encoder and decoder.
 Note that we implemented a transformer from scratch during the study of
 this network, but we decided to use PyTorch's standard APIs instead.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The vocabulary size is determined based on the number of patches we have
 in the grid strategy.
 This means that the number of possible values that a patch can take in
 the grid is equal to the number of patches in the grid.
 For example, if we have a grid with 25 patches, then the vocabulary size
 is 25.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The loss function used in the training process is given by the cross-entropy
 
\color blue

\begin_inset CommandInset ref
LatexCommand formatted
reference "subsec:Cross-Entropy-Loss"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
.
 This is a commonly used loss function for multi-class classification tasks,
 such as image classification.
 Mathematically, the cross-entropy loss measures the distance between the
 predicted probability distribution and the true probability distribution.
 In the context of the grid encoding task, the predicted probability distributio
n is the distribution over the patches in the grid, and the true probability
 distribution is a one-hot vector representing the true patch in the grid.
 The figure 
\begin_inset CommandInset ref
LatexCommand formatted
reference "fig:Transformer"
plural "false"
caps "false"
noprefix "false"

\end_inset

 in the state of the art can be used to visualize the transformer architecture
 , at the right is placed the transformer decoder which its has output the
 output probabilities for symbol 
\begin_inset Formula $A_{i}$
\end_inset

 using the softmax function 
\begin_inset CommandInset ref
LatexCommand formatted
reference "fig:Softmax"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Codigo/UML/GridNet.png
	lyxscale 50
	scale 40

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
GridNet Workflow
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Autoregression in predicting mode
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Autoregression in a Transformer refers to the technique of feeding previously
 generated output tokens as input to the model in order to generate subsequent
 tokens.
 In other words, the model generates one token at a time, and each token
 is conditioned on the previously generated tokens.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
This autoregression technique is achieved in a Transformer through a process
 called self-attention.
 Self-attention allows the model to capture dependencies between different
 positions in the input sequence by weighing each input token's relevance
 to the current token being generated.
 During training, the model learns to attend to the most relevant tokens
 from the previous generated output, which in turn influences the distribution
 of probabilities over the vocabulary for the next token.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
In practice, autoregression in a Transformer involves a process called decoding,
 where the model generates tokens one at a time, starting with a special
 start-of-sequence <sos> token and continuing until a special end-of-sequence
 <eos> token is generated or a maximum sequence length is reached.
 The output tokens generated by the model at each decoding step are fed
 back as input to the model for the next step, creating a feedback loop
 that allows the model to incorporate information from previously generated
 tokens to generate subsequent ones.
\end_layout

\begin_layout Subsubsection
Noise in Trainning
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
This network is the only one that uses variable noise ratios during training
 to help the model generalize better.
 The noise varies each epoch and is determined by the following equation:
\end_layout

\begin_layout Standard

\size large
\begin_inset Formula 
\begin{equation}
SNR_{dB}=45-5(mod(Epoch,4))
\end{equation}

\end_inset


\end_layout

\begin_layout Subsubsection
Transformer hyperparameters
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
In this section, we first list the hyperparameters that directly affect
 the final parameter size of the model.
 Before we show the table, let's review the meaning of the parameters to
 better understand the hyperparameters table.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
Embedding_size
\series default
: the embedding size refers to the size of the vector that is used to represent
 each input token in the network.
 Each token in the input sequence is mapped to a high-dimensional vector
 of fixed size, which is called the embedding.
 The embedding captures the semantic meaning of the token in a continuous
 vector space, which can be learned by the network during training.
 In practice, the embedding size is often set to a value between 100 and
 1000, depending on the size of the input vocabulary and the complexity
 of the task
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
Num_heads
\series default
: Is a hyperparameter that controls the number of parallel self-attention
 mechanisms in the network.
 Self-attention is a mechanism that allows the model to weigh the importance
 of different positions in the input sequence when making a prediction.
 Self-attention is applied to the input sequence multiple times, with different
 linear projections of the input sequence used as inputs to each attention
 mechanism
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
Encoder and Decoder Layers
\series default
: The output of the encoder layer is a sequence of hidden representations
 that captures the relevant information from the input sequence.Both the
 encoder and decoder layers can be stacked multiple times to improve the
 quality of the feature representation and the final output sequence.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
Forward Expansion
\series default
: After performing multi-head attention on the input, the result is passed
 through a feedforward neural network (FFN) layer, which typically consists
 of two fully connected layers with a ReLU activation function in between,
 in our case was ever setup to GELU activation function.
 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
Dropout
\series default
: The dropout rate to apply during training to prevent overfitting.
 This value typically ranges between 0.1 and 0.3.
\end_layout

\begin_layout Standard

\size large
Other parameters, such as CONJ_ACTIVE, refer to the same preprocessing step
 of taking the conjugate of the channel 
\begin_inset Formula $\boldsymbol{H^{H}Y}$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{table}[h] 
\backslash
centering  
\backslash
begin{tabular}{|l|l|} 
\backslash
hline 
\backslash
textbf{Hyperparameters} & 
\backslash
textbf{Value} 
\backslash

\backslash
 
\backslash
hline BATCHSIZE & 100 
\backslash

\backslash
 
\backslash
hline QAM & 16 
\backslash

\backslash
 
\backslash
hline NUM
\backslash
_EPOCHS & 24 
\backslash

\backslash
 
\backslash
hline SNR & 45-25 
\backslash

\backslash
 
\backslash
hline CONJ
\backslash
_ACTIVE & True 
\backslash

\backslash
 
\backslash
hline NOISE & True 
\backslash

\backslash
 
\backslash
hline LEARNING
\backslash
_RATE & .0001 
\backslash

\backslash
 
\backslash
hline GRID & Square 
\backslash

\backslash
 
\backslash
hline STEP & 1/7 
\backslash

\backslash
 
\backslash
hline 
\backslash
end{tabular} 
\backslash
caption{Square GridNet hyperparameters} 
\backslash
label{tab:transformer_hyper} 
\backslash
end{table}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{table}[h] 
\backslash
centering  
\backslash
begin{tabular}{|l|l|} 
\backslash
hline 
\backslash
textbf{Hyperparameters} & 
\backslash
textbf{Value} 
\backslash

\backslash
 
\backslash
hline BATCHSIZE & 100 
\backslash

\backslash
 
\backslash
hline QAM & 16 
\backslash

\backslash
 
\backslash
hline NUM
\backslash
_EPOCHS & 13 
\backslash

\backslash
 
\backslash
hline SNR & 45-20 
\backslash

\backslash
 
\backslash
hline CONJ
\backslash
_ACTIVE & True 
\backslash

\backslash
 
\backslash
hline NOISE & True 
\backslash

\backslash
 
\backslash
hline LEARNING
\backslash
_RATE & .0001 
\backslash

\backslash
 
\backslash
hline GRID & Polar 
\backslash

\backslash
 
\backslash
hline STEP
\backslash
_RADIUS & 0.25 
\backslash

\backslash
 
\backslash
hline STEP
\backslash
_ANGLE & $
\backslash
pi/6$ 
\backslash

\backslash
 
\backslash
hline 
\backslash
end{tabular} 
\backslash
caption{Polar GridNet hyperparameters} 
\backslash
label{tab:transformer_hyper} 
\backslash
end{table}
\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Parameters
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{table}[H] 
\backslash
centering 
\backslash
begin{tabular}{|l|l|} 
\backslash
hline 
\backslash
textbf{Name} & 
\backslash
textbf{Value} 
\backslash

\backslash
 
\backslash
hline loss
\backslash
_f & CrossEntropyLoss 
\backslash

\backslash
 
\backslash
hline src
\backslash
_word
\backslash
_embedding & Embedding (101 K) 
\backslash

\backslash
 
\backslash
hline src
\backslash
_position
\backslash
_embedding & Embedding (25.6 K) 
\backslash

\backslash
 
\backslash
hline trg
\backslash
_word
\backslash
_embedding & Embedding (101 K) 
\backslash

\backslash
 
\backslash
hline trg
\backslash
_position
\backslash
_embedding & Embedding (25.6 K) 
\backslash

\backslash
 
\backslash
hline transformer & Transformer (44.1 M) 
\backslash

\backslash
 
\backslash
hline fc
\backslash
_out & Linear (102 K) 
\backslash

\backslash
 
\backslash
hline dropout & Dropout (0) 
\backslash

\backslash
 
\backslash
hline 
\backslash
multicolumn{2}{|l|}{Total params: 44.5 M} 
\backslash

\backslash
 
\backslash
multicolumn{2}{|l|}{Total estimated model params size (MB): 177.990} 
\backslash

\backslash
 
\backslash
hline 
\backslash
end{tabular} 
\backslash
caption{Square Grid Transformer Parameters} 
\backslash
label{tab:polar-grid-transformer-parameters} 
\backslash
end{table}
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{table}[H] 
\backslash
centering 
\backslash
begin{tabular}{|l|l|} 
\backslash
hline 
\backslash
textbf{Name} & 
\backslash
textbf{Value} 
\backslash

\backslash
 
\backslash
hline loss
\backslash
_f & CrossEntropyLoss 
\backslash

\backslash
 
\backslash
hline src
\backslash
_word
\backslash
_embedding & Embedding (26.1 K) 
\backslash

\backslash
 
\backslash
hline src
\backslash
_position
\backslash
_embedding & Embedding (25.6 K) 
\backslash

\backslash
 
\backslash
hline trg
\backslash
_word
\backslash
_embedding & Embedding (26.1 K) 
\backslash

\backslash
 
\backslash
hline trg
\backslash
_position
\backslash
_embedding & Embedding (25.6 K) 
\backslash

\backslash
 
\backslash
hline transformer & Transformer (69.3 M) 
\backslash

\backslash
 
\backslash
hline fc
\backslash
_out & Linear (26.2 K) 
\backslash

\backslash
 
\backslash
hline dropout & Dropout (0) 
\backslash

\backslash
 
\backslash
hline 
\backslash
multicolumn{2}{|l|}{Total params: 69.5 M} 
\backslash

\backslash
 
\backslash
multicolumn{2}{|l|}{Total estimated model params size (MB): 277.842} 
\backslash

\backslash
 
\backslash
hline 
\backslash
end{tabular} 
\backslash
caption{Polar Grid Transformer Parameters} 
\backslash
label{tab:polar-grid-transformer-parameters} 
\backslash
end{table}
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
To summarize, the Radial Grid prioritizes investing less in the vocabulary
 size and compensating for it by adjusting other hyperparameters such as
 multi-head attention and increasing the number of feedforward parameters
 in order to achieve better results.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newpage
\end_layout

\end_inset


\end_layout

\begin_layout Section
Results
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
In order to assess the effectiveness of various equalization methods, we
 performed a series of five experiments for each method in a consistent
 manner, and subsequently calculated the average of their results.
 This approach is based on the principles of Monte Carlo tests
\begin_inset CommandInset citation
LatexCommand cite
key "montecarlo"
literal "false"

\end_inset

, aiming to obtain representative statistics of the ensemble, rather than
 only smoothing out the curves.
 By conducting multiple experiments and averaging the outcomes, we can ensure
 a more reliable representation of each method's performance.
 Although the channel dataset remains constant, the transmitted information
 is described by a normal distribution with random data for each iteration.
 This also promotes the use of Monte Carlo techniques.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
In our research, we evaluated the performance of our method in both noisy
 and non-noisy scenarios across a wide range of signal-to-noise ratios (SNRs).
 The SNR range we considered was from 45 to 5, with a step of 2 between
 each SNR.
 By including SNRs below the typical operating range, we could assess the
 system's robustness to low signal levels.
 Although we did not implement a MIMO system in this study, high SNR values
 are also relevant for MIMO systems, and this evaluation could provide insight
 into their performance under different conditions.
 The same about high SNR values apply to the LOS channels.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
This comprehensive evaluation helped us to identify the strengths and weaknesses
 of each method and determine which methods are most effective in different
 scenarios.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Our performance metrics are the (Bit Error Rate)
\color blue
 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:BER"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
 and (Block Error Rate)
\color blue
 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:BLER"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
 , which have been explained in the theoretical framework.
 BER measures the ratio of incorrectly received bits to the total number
 of transmitted bits, while BLER measures the ratio of incorrectly received
 blocks to the total number of transmitted blocks.
 A lower value for both metrics indicates better performance of the system.
\end_layout

\begin_layout Subsection
Multiplications and Big O analysis
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Using execution time and source code analysis, we determined the FLOPS for
 each equalizer in this section and evaluated the model's complexity.
 We narrowed our focus to the multiplication operations exclusively in order
 to make our study more portable to other CPU architectures.
 The number of parameters was estimated through the source code analysis
 for the Big O notation analysis.
 Big O notation is a mathematical notation that expresses the upper bound
 of the growth rate of an algorithm in terms of its input size.
 It provides a way to express the worst-case time complexity of an algorithm
 in terms of a simple function of the input size, ignoring constant factors
 and lower-order terms.
 The efficiency and scalability of the algorithm can be analyzed through
 this analysis.
 A detailed description of the system specifications used for the time measureme
nt experiment is provided in the table below.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{table}[htbp]   
\backslash
centering   
\backslash
caption{Processor specifications}    
\backslash
begin{tabular}{|l|l|}     
\backslash
hline     
\backslash
textbf{Property} & 
\backslash
textbf{Value} 
\backslash

\backslash
  
\backslash
hline     Architecture & x86
\backslash
_64 
\backslash

\backslash
 
\backslash
hline    CPU op-mode(s) & 32-bit, 64-bit 
\backslash

\backslash
  
\backslash
hline   Address sizes & 43 bits physical, 48 bits virtual 
\backslash

\backslash
 
\backslash
hline    Byte Order & Little Endian 
\backslash

\backslash
 
\backslash
hline   CPU(s) & 16 
\backslash

\backslash
  
\backslash
hline   Model name & AMD Ryzen 7 3700X 8-Core Processor 
\backslash

\backslash
 
\backslash
hline    CPU family & 23 
\backslash

\backslash
 
\backslash
hline    Model & 113 
\backslash

\backslash
 
\backslash
hline     Thread(s) per core & 2 
\backslash

\backslash
 
\backslash
hline    Core(s) per socket & 8 
\backslash

\backslash
 
\backslash
hline     Frequency boost & enabled 
\backslash

\backslash
 
\backslash
hline    CPU max MHz & 4426.1709 
\backslash

\backslash
   
\backslash
hline  CPU min MHz & 2200.0000 
\backslash

\backslash
  
\backslash
hline   BogoMIPS & 7186.16 
\backslash

\backslash
  
\backslash
hline      
\backslash
end{tabular}   
\backslash
label{tab:processor_specs} 
\backslash
end{table}
\end_layout

\end_inset


\size large
 
\end_layout

\begin_layout Subsubsection
LMMSE
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Using equation 
\color blue

\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:LMMSE"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
 to invert the channel H requires the naive matrix inversion operation,
 which has a computational complexity of 
\begin_inset Formula $O(N^{3})$
\end_inset

 operations, where N is the matrix size 
\begin_inset CommandInset citation
LatexCommand cite
key "StrassenO3"
literal "false"

\end_inset

.
 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Similarly, the total number of internal complex multiplications involved
 in matrix multiplication is 
\begin_inset Formula $N^{3}$
\end_inset

.
 In the following table we will describe the total complex multiplications
 required.
 
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{table}[H] 
\backslash
centering 
\backslash
caption{Number of Operations by Type} 
\backslash
label{tab:operations}  
\backslash
begin{tabular}{|l|l|l|}  
\backslash
hline  
\backslash
textbf{Operation} &  
\backslash
textbf{No.
 Complex Mults} &  
\backslash
textbf{Big O} 
\backslash

\backslash
 
\backslash
hline $H^H$                       &   $0$   & $O(N^2)$ 
\backslash

\backslash
 
\backslash
hline $H^HH$                      & $48^3$ & $O(N^3)$ 
\backslash

\backslash
 
\backslash
hline $
\backslash
sigma I $                 &  $0 $  & $O(N)$
\backslash

\backslash
 
\backslash
hline $(H^HH+
\backslash
sigma I)^{-1}$      & $48^3$ & $O(N^3)$
\backslash

\backslash
  
\backslash
hline $(H^HH+
\backslash
sigma I)^{-1}H^H$   & $48^3$ & $O(N^3)$
\backslash

\backslash
  
\backslash
hline $(H^HH+
\backslash
sigma I)^{-1}H^HH$  & $48^3$ & $O(N^3)$
\backslash

\backslash
 
\backslash
hline $(H^HH+
\backslash
sigma I)^{-1}H^HHY$ & $48^2$ & $O(N^2)$
\backslash

\backslash
  
\backslash
hline 
\backslash
textbf{Total} & 
\backslash
textbf{552,960} & 
\backslash
textbf{$O(4N^3+3N^2+N)$}  
\backslash

\backslash
  
\backslash
hline 
\backslash
end{tabular} 
\backslash
end{table} 
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard

\size large
The time measurements in the code give an average time of 5.96e-02, which
 is equal to t = 59.6 ms.
 Therefore, the estimated FLOPS considering only the complex multiplications
 is calculated as follows:
\end_layout

\begin_layout Standard

\size large
\begin_inset Formula 
\begin{equation}
FLOPS\simeq\frac{552,960}{59.6ms}=9.27\times10^{6}
\end{equation}

\end_inset


\end_layout

\begin_layout Subsubsection
Zero Forcing
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
In the equation 
\color blue

\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:ZeroForcing"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
 we can describe this equalizer.
 This involves 48 extractions of diagonal elements and then an elementwise
 divison by each element of vector 
\begin_inset Formula $Y$
\end_inset

.
 This involves 48 multiplications of complex numbers.
 The time measurements in the code give an average time of 2.62e-03, which
 is equal to t = 2.62 ms.
 Therefore, the estimated FLOPS is calculated as follows:
\end_layout

\begin_layout Standard

\size large
\begin_inset Formula 
\begin{equation}
FLOPS\simeq\frac{48}{2.62ms}=18.320\times10^{3}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard

\size large
For the time complexity of this algorithm is conisdered a 
\begin_inset Formula $O(N)$
\end_inset

 
\begin_inset CommandInset label
LatexCommand label
name "OZeroForcing"

\end_inset

 complexity, because diagonal is size of N.

\size default
 
\end_layout

\begin_layout Subsubsection
PhaseNet
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The preprocesing stage for Phase Net shown in Figure 
\color blue

\begin_inset CommandInset ref
LatexCommand ref
reference "fig:PreprocesPhaseNet"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
 uses the Hermitian transpose multiplication with the received signal 
\begin_inset Formula $\boldsymbol{Y}$
\end_inset

 with an 
\begin_inset Formula $O(N^{2})$
\end_inset

 complexity.
 Next, we need to extract the phase of the rectangular form of the complex
 numbers, which involves an arctan function that is considered almost linear.
 For the network stage, based on 
\color black
Table 4 in 
\color blue

\begin_inset CommandInset ref
LatexCommand ref
reference "Table4"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
, we can visualize all the number of parameters implied in the networks,
 and each linear layer basically performs a matrix multiplication of weights
 times the last input.
 In the case of PhaseNet, there are 4 linear layers, which is equivalent
 to 
\begin_inset Formula $O(4N^{2})$
\end_inset

 plus the preprocesing is 
\begin_inset Formula $O(5N^{2})$
\end_inset

.
 Note that only normal products are involved here, not complex ones, which
 leads to a lower constant.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{table}[H]
\end_layout

\begin_layout Plain Layout


\backslash
centering
\end_layout

\begin_layout Plain Layout


\backslash
caption{Complexity of PhaseNet}
\end_layout

\begin_layout Plain Layout


\backslash
label{tab:phasenet_complexity}
\end_layout

\begin_layout Plain Layout


\backslash
begin{tabular}{|l|l|} 
\end_layout

\begin_layout Plain Layout


\backslash
hline  
\backslash
textbf{Preprocessing Stage} &  
\backslash
textbf{Complexity} 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline $H^HY$ & $O(N^2+N)$ 
\backslash

\backslash
          
\end_layout

\begin_layout Plain Layout


\backslash
hline $arctan$ & $O(N)$ 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline 
\backslash
multicolumn{2}{|c|}{Network Stage} 
\backslash

\backslash
          
\end_layout

\begin_layout Plain Layout


\backslash
hline 4 linear layers & $O(4N^2)$ 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline Total complexity including preprocessing & $O(5N^2+2N)$ 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout


\backslash
end{tabular}  
\backslash
end{table} 
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "BigOPhaseNet"

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
FLOPS\simeq\frac{1,761,808}{.119}=14.8\times10^{6}
\end{equation}

\end_inset


\end_layout

\begin_layout Subsubsection
\paragraph_spacing onehalf
PolarNet
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
This network has the same preprocessing as PhaseNet, plus additional zero
 forcing, with their corresponding Big O growth rates 
\color blue

\begin_inset CommandInset ref
LatexCommand nameref
reference "BigOPhaseNet"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
, 
\color blue

\begin_inset CommandInset ref
LatexCommand nameref
reference "OZeroForcing"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
, respectively.
 Additionally the network has MagnitudNet has the same preprocessing stage
 as PhaseNet, which results in a final growth rate of 
\begin_inset Formula $O(10N^{2}+2N)$
\end_inset

.
 Taken from the 
\color blue

\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Magnet-Parameters"
plural "false"
caps "false"
noprefix "false"

\end_inset

 
\color inherit
we finally calculate the FLOPS.
 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
FLOPS\simeq\frac{1,761,808+5,856}{.392}=4.5\times10^{6}
\end{equation}

\end_inset


\end_layout

\begin_layout Subsubsection
ComplexNet
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
This network deals with complex operations, and to make it portable with
 the gradients and machine learning environment, the "apply complex" function
 was needed, which can be seen in section
\color blue
 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Apply-Complex"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
 and results in a complexity of 
\begin_inset Formula $O(4N^{2})$
\end_inset

 per each linear complex layer.
 Based on Table 8 in
\color blue
 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Complex-Net-Param"
plural "false"
caps "false"
noprefix "false"

\end_inset

 
\color black
the network has 6 linear layers, plus the preprocessing (which involves
 complex conjugation) and leads to a final complexity of 
\begin_inset Formula $O(13N^{2})$
\end_inset

.
 Again, in Table 8, the number of parameters used in the FLOPS calculation
 can be found.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
FLOPS\simeq\frac{484,248}{.173}=2.7\times10^{6}
\end{equation}

\end_inset


\end_layout

\begin_layout Subsubsection
MobileNet
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The original MobileNet model has a time complexity of approximately 
\begin_inset Formula $O(n^{2.3})$
\end_inset

, MobileNetV2 has a time complexity of approximately 
\begin_inset Formula $O(N^{2})$
\end_inset

 and MobileNetV3 has a time complexity of approximately 
\begin_inset Formula $O(Nlog(N))$
\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "MobileNet,MobilenetV3"
literal "false"

\end_inset

.
 It's important to note that the actual runtime performance of MobileNet
 can also be affected by factors such as the hardware platform, software
 optimization, and batch size.
 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
For the final growth rate of our MobileNetV3 implementation, we modified
 the final layer with a linear layer, as shown in the Figure 
\color blue

\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Ilustartion-of-mobileNet"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
, and applied a pre-processing step using a Hermitian matrix, and the pointwise
 division to emulate zero-forcing
\color blue
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:ZeroForcing"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
, the network has a final time complexity of 
\begin_inset Formula $O(N^{2}+2N+Nlog(N))$
\end_inset

.
 To access all the number of parameters, we used a software API that iterated
 over all parameters and added up their total size to calculate it.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{algorithm}[H]  
\backslash
caption{Count Parameters}  
\backslash
label{alg:count_parameters}  
\backslash
begin{algorithmic}[1]  
\backslash
Function{count
\backslash
_parameters}{$model$}  
\backslash
State $total
\backslash
_parameters 
\backslash
gets 0$  
\backslash
For{$p$ 
\backslash
textbf{in} $model.parameters$}  
\backslash
If{$p.requires
\backslash
_grad$}  
\backslash
State $total
\backslash
_parameters 
\backslash
gets total
\backslash
_parameters + 
\backslash
text{numel}(p)$  
\backslash
EndIf  
\backslash
EndFor  
\backslash
State 
\backslash
textbf{return} $total
\backslash
_parameters$  
\backslash
EndFunction  
\backslash
end{algorithmic}  
\backslash
end{algorithm} 
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
FLOPS\simeq\frac{3,170,688}{.834}=3.801\times10^{6}
\end{equation}

\end_inset


\end_layout

\begin_layout Subsubsection
GridNet
\end_layout

\begin_layout Standard

\size large
Based on Algorithm 4 we can estimate the same for GrideNet versions.
 For the GridNet Square we have this FLOPS:
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
FLOPS\simeq\frac{67,773,587}{1.93}=35.11\times10^{6}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard

\size large
and for GridNet Polar is 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
FLOPS\simeq\frac{69,460,531}{2.5}=27.8\times10^{6}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The Transformer model, has a time complexity of 
\begin_inset Formula $O(N^{2})$
\end_inset

, where 
\begin_inset Formula $N$
\end_inset

 is the length of the input sequence.
 This is due to the self-attention mechanism, which computes a similarity
 score between each pair of tokens in the input sequence, resulting in an
 
\begin_inset Formula $N\times N$
\end_inset

 matrix.
 The computation of this matrix requires 
\begin_inset Formula $O(N^{2})$
\end_inset

 time.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
In addition to the self-attention mechanism, the Transformer also includes
 feedforward layers and normalization layers, but their time complexity
 is typically much lower than that of the self-attention mechanism.
 Therefore, the overall time complexity of the Transformer can be approximated
 as 
\begin_inset Formula $O(N^{2})$
\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "transformer"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
However, there are optimizations that can be applied to reduce the time
 complexity of the Transformer, such as restricting the maximum length of
 the input sequence or using approximate attention mechanisms.
 These optimizations can reduce the time complexity to
\begin_inset Formula $O(Nlog(N))$
\end_inset

 or even 
\begin_inset Formula $O(N)$
\end_inset

, but at the cost of reduced accuracy or increased memory usage.
 Adding the preprocing stage of grids which can be viewed on Figure 
\color blue

\begin_inset CommandInset ref
LatexCommand eqref
reference "fig:Square-grid"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
 and Figure 
\color blue

\begin_inset CommandInset ref
LatexCommand eqref
reference "fig:Radial-Grid-encoding"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
 with N cells denoted as 
\begin_inset Formula $|\mathbb{C}|$
\end_inset

 and the Hermitian Conjugate applied in other networks, the final complexity
 can be described as 
\begin_inset Formula $O(N^{2}+Nlog(N)+|\mathbb{C}|)$
\end_inset

.
\end_layout

\begin_layout Subsubsection
OSIC
\end_layout

\begin_layout Standard

\size large
Based on the analysis in subsection 
\color blue

\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:OSIC"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
 we end up with the big 
\begin_inset Formula $O$
\end_inset

 notation found in 
\color blue

\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:BigO-Osic"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
.
 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
Based on the algorithm in the same section 
\color blue

\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:OSIC"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
 we can make a table due to the short of algorithm looks like.
 
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{table}[H] 
\backslash
begin{tabular}{|l|c|c|c|} 
\backslash
hline 
\backslash
textbf{Operation} & 
\backslash
multicolumn{1}{l|}{
\backslash
textbf{Count (multiplications/additions)}} & 
\backslash
multicolumn{1}{l|}{
\backslash
textbf{Iterations}} & 
\backslash
multicolumn{1}{l|}{
\backslash
textbf{Total Operations}} 
\backslash

\backslash
 
\backslash
hline Element-wise subtraction (a
\backslash
_est - conste) & 16 & 48 & 768 
\backslash

\backslash
 
\backslash
hline Element-wise squaring & 16 & 48 & 768 
\backslash

\backslash
 
\backslash
hline Sorting (torch.argsort(sest2)) & $16 * 
\backslash
log_{2}(16)$ & 48 & $
\backslash
simeq$768 
\backslash

\backslash
 
\backslash
hline Scalar multiplication (sest[ind] * mag2) & 48 & 48 & 2304 
\backslash

\backslash
 
\backslash
hline Scalar addition & 48 & 48 & 2304 
\backslash

\backslash
 
\backslash
hline 
\backslash
end{tabular} 
\backslash
caption{Approximate number of products in the OSIC
\backslash
_Det function} 
\backslash
end{table} 
\end_layout

\end_inset


\end_layout

\begin_layout Standard

\size large
Total number of products (multiplications and additions) ≈ 48 * (16 + 16
 + (16 * log2(16)) + 48 + 48) = 9216
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
\begin_inset Formula 
\begin{equation}
FLOPS\simeq\frac{9216}{640\times10^{-3}}=14.4\times10^{3}
\end{equation}

\end_inset


\end_layout

\begin_layout Subsubsection
NearML
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Based on the analysis in subsection 
\color blue

\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:NearML"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
 we end up with the big O equation found in 
\color blue

\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:BigONearML"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 
\color inherit
Due to algorithm is more complex than OSIC we can aproach the numer of multiplic
ations as 
\begin_inset Formula $\text{\ensuremath{(\mathbb{A}}}N+N)L$
\end_inset

, with 
\begin_inset Formula $\mathbb{A}=16$
\end_inset

 and 
\begin_inset Formula $N=48$
\end_inset

 and 
\begin_inset Formula $L=4$
\end_inset

 branching levels 
\begin_inset Formula $\text{\ensuremath{(\mathbb{A}}}N+N)L=3264$
\end_inset

 .
 And finally with time 
\begin_inset Formula $t=640ms$
\end_inset

 let's calculate the total floating-point operations per seconds (FLOPS):
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
FLOPS\simeq\frac{3264}{7.35}\simeq444
\end{equation}

\end_inset


\end_layout

\begin_layout Subsubsection
Performance Analysis: FLOPs and Time Complexity Benchmark
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
This FLOPS value works like an estimate and should not be taken as definitive.
 One of the main advantages of deep learning techniques is that they are
 easy to parallelize, and FLOPS can be significantly reduceded.
 Big O notation is a mathematical notation used to describe the upper bound
 of the growth rate of a function or algorithm in terms of its input size.
 
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{table}[H] 
\backslash
centering 
\backslash
caption{FLOPS and Time Complexity} 
\backslash
label{tab:operations} 
\backslash
begin{tabular}{|l|l|l|} 
\end_layout

\begin_layout Plain Layout


\backslash
hline 
\backslash
textbf{Name} & 
\backslash
textbf{FLOPS} & 
\backslash
textbf{Big O Complexity} 
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

OSIC & $ 14.4
\backslash
times10^{3} $ & $O(N 
\backslash
times |
\backslash
mathbb{A}|) $  
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

NearML & $ 444 $ & $O(|
\backslash
mathbb{A}|
\backslash
times N
\backslash
times
\backslash
left(M+|
\backslash
mathbb{A}|
\backslash
right))$  
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

Zero Forcing & $18.320
\backslash
times10^{3}$ & $O(N)$ 
\backslash

\backslash
 
\backslash
hline 
\end_layout

\begin_layout Plain Layout

ComplexNet & $2.7
\backslash
times10^{6}$ & $O(13N^{2})$  
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

LMMSE & $9.27
\backslash
times10^{6}$ &  $O(4N^3+3N^2+N)$ 
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

MobileNet & $3.801
\backslash
times10^{6}$ &  $O(N^{2}+2N+Nlog(N))$
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

PolarNet & $2.7
\backslash
times10^{6}$ & $O(10N^{2}+2N)$
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

PhaseNet & $14.8
\backslash
times10^{6}$ & $O(5N^{2})$
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

GridNet Square & $35.11
\backslash
times10^{6}$ & $O(N^{2}+N*log(N)+|
\backslash
mathbb{C}|)$ 
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

GrideNet Polar & $27.8
\backslash
times10^{6}$ & $O(N^{2}+N*log(N)+|
\backslash
mathbb{C}|)$ 
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout


\backslash
end{tabular} 
\backslash
end{table}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/BigO.png
	lyxscale 70
	scale 70

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Big O Benchmark for 16QAM.
 Dotted red line is the case for N=48
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newpage
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
BER and BLER
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
To provide a detailed comparison of the BER and BLER values across different
 SNR values, we will analyze the results obtained from various methods.
 Firstly, we will compare the linear methods, followed by a comparison of
 the non-linear methods.
 This approach will provide a comprehensive view of both plots.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Neural networks are typically run in custom-built Python frameworks, as
 shown in 
\color blue
Figure
\color inherit
 
\color blue

\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Software-Architecture-Diagram"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
.
 This approach enables a consistent environment for each evaluation execution,
 where all BER and BLER values are obtained from a processed CSV file and
 then plotted using the Matplotlib Python library.
 The resulting visualizations provide an effective means of analyzing and
 interpreting the performance of these neural networks.
 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
In order to facilitate faster testing evaluations, the SNR values in the
 x-axis are incremented by a step of 2, ranging from 5 to 45 SNR.
 To generate smoother curves, a cubic interpolator is applied to the plotted
 data, which may introduce artifacts and hills in the curves.
 It should be emphasized that these undulations illustrate the overall trend
 of the results.
 To achieve completely smooth curves without valleys or hills, additional
 realizations may be required to have more realizations falling in this
 values.
 
\end_layout

\begin_layout Subsubsection
PhaseNet
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
In 
\color blue
Figure
\color inherit
 
\color blue

\begin_inset CommandInset ref
LatexCommand ref
reference "fig:66"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
 the PhaseNet model shows an upgrade of up to one order of magnitude.
 The model plateaus at 
\begin_inset Formula $10^{-5}$
\end_inset

 BER from 30db to higher values.
 This can be achieved due to the preprocessing stage, which sets all phase
 points to the closest points but with incorrect phase.
 This enables the networks to classify well between only four possible angle
 positions in the QPSK scneario.
 This turn allows the network to handle noise scenarios well and correct
 the ISI by comparing all values at the same time due to the parallel input
 nature with the feedforward linear layer described in 
\color blue

\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:41"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/PhaseNET/QPSK_vs_LMMSE_PhasNet.png
	lyxscale 70
	scale 80

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
QPSK BER : PhaseNet vs.
 LMMSE 
\begin_inset CommandInset label
LatexCommand label
name "fig:66"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Regarding the block errors in 
\color blue
Figure
\color inherit
 
\color blue

\begin_inset CommandInset ref
LatexCommand ref
reference "fig:67"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
 , the same gain of one order of magnitude is observed in the noisiest scenarios
, up to 25 dB.
 However, beyond this point, the model cannot infer any further relation
 between the points, and as a consequence, the BLER flattens out at 
\begin_inset Formula $BLER=9\times10^{-3}$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/BLER/Results_PhaseNet-10_3_2023-23_39.png
	lyxscale 80
	scale 80

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Caption Standard

\begin_layout Plain Layout
QPSK BLER : PhaseNet vs.
 LMMSE 
\begin_inset CommandInset label
LatexCommand label
name "fig:67"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
As seen in 
\color blue
Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:68"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
, the non-linear model exhibits similar linear growth in relation to lower
 SNR values, while PhaseNet follows a positive concave shape with an improvement
 of one order of magnitude.
 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
One positive aspect of the PhaseNet model is that the number of symbols
 for bigger PSK does not affect the time complexity of the networks.
 Only retraining is necessary, as only the number of symbols in the frame
 matters for the networks and the relative positions are learned.
 In fact, more constellation points lead to a more complex and less accurate
 precision.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/PhaseNET/BER_Non_linear_Golden vs PhaseNet_-17_3_2023-12_36.png
	lyxscale 80
	scale 80

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Caption Standard

\begin_layout Plain Layout
QPSK BER: PhaseNet vs.
 OSIC and NML 
\begin_inset CommandInset label
LatexCommand label
name "fig:68"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
In the case of BLER in 
\color blue
Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:69"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
, the non-linear equalizer exhibits similar performance, while PhaseNet
 performs one order of magnitude better on average.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/PhaseNET/BLER_Non_linear_Golden vs PhaseNet_-17_3_2023-12_36.png
	lyxscale 80
	scale 80

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
QPSK BLER: PhaseNet vs.
 OSIC and NML 
\begin_inset CommandInset label
LatexCommand label
name "fig:69"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
PolarNet
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
This network combines a 16-PSK PhaseNet equalization with an additional
 MagNet equalization.
 In this model, we assume that phase and magnitude are completely separate
 from each other, see in subsection 
\color blue

\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:PolarNet"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
 for more detail.
 One of the main reasons is to maintain a more modular architecture, which
 means that in a future implementation, it can be equalized a 16-PSK or
 16-QAM with almost the same processing stages.
 Another key feature is that each network is specialized, reducing the error
 to only its specific task.
 Therefore, in theory, this will make the error not influence each other.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Observing the graph below in 
\color blue
Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:70"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
, it can be seen that the model flattens at a BER of 
\begin_inset Formula $10^{-3}$
\end_inset

 at 30dB.
 The main reason for this result is that, since we used the Mean Squared
 Error (MSE) to correct the weights, smaller error values than 
\begin_inset Formula $10^{-3}$
\end_inset

 were not sufficient to modify the internal network weights.
 This leads to the model plateauing, where it reaches a point where it cannot
 improve any further.
 Also we keep in mind that this models has 
\begin_inset Formula $A^{2}$
\end_inset

 elements in comparison with QPSK, so curves will look closer to the golden
 models.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/PolarNet/Linear/Polar_16QAM.png
	lyxscale 70
	scale 80

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
16-QAM BER: PolarNet vs.
 LMMSE 
\begin_inset CommandInset label
LatexCommand label
name "fig:70"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Regarding the BLER in 
\color blue
Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:71"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
 , it is shown that the system can consistently equalize a certain quantity
 of blocks and prove that most of the errors are given from far away points
 in the constellation.
 However, in general, the network is capable of clustering the data points
 around their corresponding constellation points.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/PolarNet/Linear/Results_PolarNet-10_3_2023-23_36.png
	lyxscale 80
	scale 80

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
16-QAM BLER: PolarNet vs.
 LMMSE 
\begin_inset CommandInset label
LatexCommand label
name "fig:71"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Similarly in 
\color blue
Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:72"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
, the non-linear equalizers outperform the neural network in low noise scenarios
 with SNR values greater than 30 dB.
 This is because the neural network truncates error during the training
 stage and additional preprocessing stages may be necessary to achieve lower
 BER.
 To balance the trade-off between signal recognition over noise and overfitting,
 sacrificing performance beyond 30 dB may be necessary, unless alternative
 preprocessing stages, different from the Hermitian matrix, can be implemented.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/PolarNet/NonLinear/BER_Non_linear_Golden vs PolarNet_-17_3_2023-11_44.png
	lyxscale 80
	scale 80

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
16-QAM BER: PolarNet vs.
 OSIC and NML 
\begin_inset CommandInset label
LatexCommand label
name "fig:72"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Despite the model being truncated for a BLER of 35dB in 
\color blue
Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:73"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
 , the compromise is reasonable since the model outperforms the non-linear
 equalizers within a range of 15dB to 35dB.
 This suggests that most of the errors reported in the BER section are outliers.
 By centering the input values around the mean, neural networks can learn
 patterns in the data more effectively without being overly influenced by
 extreme values.
 Therefore, values closer to the mean can provide a balanced representation
 of the data and be well-suited for neural networks, in this case it can
 be seen in BLER plot.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/PolarNet/NonLinear/BLER_Non_linear_Golden vs PolarNet_-17_3_2023-11_44.png
	lyxscale 80
	scale 80

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Caption Standard

\begin_layout Plain Layout
16-QAM BLER: PolarNet vs.
 OSIC and NML 
\begin_inset CommandInset label
LatexCommand label
name "fig:73"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
ComplexNet
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
In complex net we try two different loss functions to traing the neuronal
 network.
 However, logarithmic polar loss in equation 
\color blue

\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:65"
plural "false"
caps "false"
noprefix "false"

\end_inset

 
\color inherit
was not as effective because it produced high loss numbers that were larger
 than 1, which slow network error convergence and make high jumps in the
 gradient.
 As a result, the network had difficulties updating its weights and optimizing
 its performance using this loss function.
 Bad optmization resuls in poor perfomance shown in 
\color blue
Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:74"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
.
 On the other hand, the complex MSE loss 
\color blue
(
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:MSECOMPLEX"
plural "false"
caps "false"
noprefix "false"

\end_inset

)
\color inherit
 was much more effective because its output values were lower than those
 of the initial loss functions.
 This made it easier for the networks to determine which parameters were
 good or not.
 By using an effective loss function, the network can optimize its performance
 and achieve higher accuracy in its predictions.
 This is particularly important in communication systems where accuracy
 and reliability are critical for successful operation.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/ComplexNet/ComplexNet.png
	lyxscale 70
	scale 80

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
16-QAM BER: ComplexNet with Two Losses vs.
 LMMSE 
\begin_inset CommandInset label
LatexCommand label
name "fig:74"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
In the BLER results in 
\color blue
Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig: 75"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
, we avoided plotting the ComplexNet Polar logarithmic loss because it performed
 poorly with a BLER of 1 across all blocks.
 On the other hand, Abs loss networks attempted to approximate the golden
 standard, but were not quite good enough.
 One of the main reasons for this is that the proposed methods in the state-of-t
he-art literature and the ones implemented in our research are not mature
 enough to help with the equalization task.
 As seen in 
\begin_inset CommandInset citation
LatexCommand cite
key "A_Survey_of_Complex_valued_nueronal_Netoworks"
literal "false"

\end_inset

, there are some assumptions about the activation functions in the complex
 plane.
 Additionally, we used automatic differentiation provided by the pytorch
 framework, which may have struggled with complex conjugation.
 Implementing a solution from complex differentiation can be challenging
 and may require a separate research project for someone with strong mathematica
l skills.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/BLER/Results_ComplexNet-10_3_2023-23_43.png
	lyxscale 80
	scale 80

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
16-QAM BLER: ComplexNet with Two Losses vs.
 LMMSE 
\begin_inset CommandInset label
LatexCommand label
name "fig: 75"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
In 
\color blue
Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:76"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
 complexNet performs marginally better than NML in situations with higher
 noise levels and is nearly identical to OSIC for values below 15dB.
 Intriguingly, the model's loss closely mirrors that of OSIC, indicating
 that the neural networks are attempting to generalize a solution similar
 to OSIC.
 The primary advantage of these neural networks is their greater parallelizabili
ty.
 Concerning time complexity, the network's growth is only dependent on the
 N scale and not the alphabet of symbols.
 Therefore, for larger QAM systems, this network may be a more suitable
 solution.
 It is recommended to conduct further testing with higher QAM constellations.
 However, higher QAM constelations is outside this research scope.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/ComplexNet/BER_Non_linear_Golden vs ComplexNet_-17_3_2023-12_31.png
	lyxscale 80
	scale 80

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Caption Standard

\begin_layout Plain Layout
16-QAM BER: ComplexNet vs.
 OSIC and NML 
\begin_inset CommandInset label
LatexCommand label
name "fig:76"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
For the BLER graph in 
\color blue
Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:77"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
 the model does not take into account whether the data is close to the mean
 or an outlier, as it faces difficulties in generalizing effectively.
 Consequently, the presence or absence of outliers in the data has little
 impact on the model's inherent error.
 This could be attributed to the error function, and as previously mentioned,
 the research on complex values for neural networks is still in its early
 stages.
 Therefore, it is reasonable to expect that the current state-of-the-art
 implementation may not be well-suited for this specific problem.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/ComplexNet/BLER_Non_linear_Golden vs ComplexNet_-17_3_2023-12_35.png
	lyxscale 80
	scale 80

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
16-QAM BLER: ComplexNet vs.
 OSIC and NML 
\begin_inset CommandInset label
LatexCommand label
name "fig:77"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
MobileNet
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Although MobileNet is not the most accurate convolutional neural network,
 it is still considered one of the fastest models in terms of processing
 speed and FLOPS among state-of-the-art methods.
 The main idea behind MobileNet is to provide channel compression into a
 vector seen in 
\color blue
Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Ilustartion-of-mobileNet"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
 and then perform zero forcing with the received signal, which offers a
 better solution than single zero forcing in subsection 
\color blue

\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Zero-forcing-sec"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
 , this because netowrk take in accounts noise and ISI.
 In 
\color blue
Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:78"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
 SNR values of 23 dB and below, it could be a viable option instead of zero
 forcing.
 In fact, it performs better than zero forcing in the range of 15 dB to
 25 dB, which is encouraging because it supports the hypothesis that it
 is essentially a zero-forcing method with noise consideration.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/MobileNEt/MobileNet_16QAM.png
	lyxscale 70
	scale 80

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
16-QAM BER: MobileNet vs.
 ZeroForcing 
\begin_inset CommandInset label
LatexCommand label
name "fig:78"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Due to its ability to account for noise, MobileNet can identify signals
 more accurately than single zero-forcing, resulting in a lower block error
 rate than the golden model until the model flattens at 30 dB as seen in
 
\color blue
Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:79"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
.
 It is important to note that MobileNet has a higher computational complexity
 than single zero-forcing.
 However, the lower block error rate achieved by MobileNet justifies the
 additional resources required for this equalization strategy.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/BLER/Results_MobileNet-10_3_2023-23_45.png
	lyxscale 80
	scale 80

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
16-QAM BLER: MobileNet vs.
 ZeroForcing 
\begin_inset CommandInset label
LatexCommand label
name "fig:79"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
In 
\color blue
Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:80"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
 SNR values below 30 dB, MobileNet can be a viable choice due to its lower
 computational complexity compared to non-linear models, while also achieving
 a better BER and exhibiting behavior similar to that of OSIC.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/MobileNEt/Non-lineal/BER/Results_Zero_Non_linear_Golden vs MobileNet_-17_3_2023-11_53.png
	lyxscale 80
	scale 80

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
16-QAM BER: MobileNet vs.
 Zero forcing, OSIC and NML 
\begin_inset CommandInset label
LatexCommand label
name "fig:80"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The block error rate is quite good for values lower than 30dB as seen in
 
\color blue
Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:81"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
, which can be attributed to the intelligent zero-forcing approach that
 effectively cancels the Intersymbol Interference (ISI), resulting in an
 improved BLER.
 This helps to ensure data integrity is maintained as much as possible.
 One potential future strategy could involve using this network as a preprocessi
ng step to feed data into other advanced networks, further enhancing their
 performance.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/MobileNEt/Non-lineal/BLER/Results_Zero_Non_linear_Golden vs MobileNet_-17_3_2023-11_54.png
	lyxscale 80
	scale 80

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
16-QAM BLER: MobileNet vs.
 Zero forcing, OSIC and NML 
\begin_inset CommandInset label
LatexCommand label
name "fig:81"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
GridNet Square
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
We experimented with different grid steps for GridNet Square and found 1/7
 to be the best, shown in Figure 
\color blue

\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Square-grid"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
.
 More cells provide higher resolution but lower noise tolerance, leading
 to overfitting.
 Larger steps group noisy points in the same or nearby cells, beneficial
 in noisy scenarios.
 Limited cells require small sizes to avoid overlap in QAM constelation.
 In general, the BER results for the tested method were significantly worse
 than the golden model LMMSE, showing a difference of one order of magnitude
 as seen in 
\color blue
Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:82"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/GridNet/Results_GridNetSquare-13_3_2023-11_47.png
	lyxscale 80
	scale 80

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
16-QAM BER: GridNet Square Grid vs LMMSE 
\begin_inset CommandInset label
LatexCommand label
name "fig:82"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The Blocks error metrics are not performing as expected at high SNR levels,
 as the model truncates at 35dB as seen in 
\color blue
Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:83"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
, and cannot utilize additional information provided by the grid.
 One of the main reasons for the poor performance is that all points in
 the grid have equal weighting and relevance, leading to position uncertainty.
 To address this issue, the polarGrid was developed, where points near the
 center are closer together and weighted differently from border points.
 This design reduces uncertainty and provides a more accurate position perspecti
ve, as seen in Figure
\color blue
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Radial-Grid-encoding"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/BLER/Results_GridNetSquare-11_3_2023-0_24.png
	lyxscale 80
	scale 80

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
16-QAM BLER: GridNet Square Grid vs.
 LMMSE 
\begin_inset CommandInset label
LatexCommand label
name "fig:83"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Regarding the non-linear models, all the results are parallel to each other.
 In 
\color blue
Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:84"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
 the performance of GridNet Square Grid can be considered an intermediate
 trade-off between OSIC and NML in terms of BER/SNR performance.
 Compared to NML, GridNet Square offers the main advantage of faster performance
 and the possibility of parallel processing in some sections.
 These features make it a good candidate for practical applications.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/GridNet/Square/BER_Non_linear_Golden vs GridNetSquare_-17_3_2023-11_46.png
	lyxscale 80
	scale 80

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
16-QAM BER: GridNet Square Grid MobileNet vs.OSIC and NML 
\begin_inset CommandInset label
LatexCommand label
name "fig:84"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Overall
\color blue
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:85"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
 shows that the non-linear methods outperform GridNet Square by one order
 of magnitude in terms of block error rate (BLER).
 However, in terms of bit error rate (BER), the degridding process used
 in GridNet Square narrows the noise by converting the grid patch to a complex
 point in the constellation and placing the calculated value in a fixed
 position based on the grid.
 This results in a slightly lower BER due to the reduced and discrete possible
 values.
 However, it is important to note that this process does not guarantee the
 integrity of the blocks and reduce block presicion.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/GridNet/Square/BLER_Non_linear_Golden vs GridNetSquare_-17_3_2023-11_46.png
	lyxscale 80
	scale 80

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
16-QAM BLER: GridNet Square Grid MobileNet vs.OSIC and NML 
\begin_inset CommandInset label
LatexCommand label
name "fig:85"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
GridNet Polar
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
In 
\color blue
Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:86"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
 gridNet with a polar grid achieved the best performance between 25 dB and
 45 dB, demonstrating that the attention mechanisms with varying cell sizes
 weighted more towards the center effectively reduced inter-symbol interference
 (ISI).
 However, below 25 dB, the model struggled to handle the noise and performed
 similarly to LMMSE.
 We trained the model with noise levels ranging from 25 dB to 45 dB, and
 the image below supports our hypothesis that the optimal equalization occurs
 within this range.
 Although providing mores noise ranges in the trainning may appear to improve
 performance, it would cause the network to learn more about noise than
 relevant data, resulting in worse performance.
 The network's best BER was observed in the scenario with the highest noise
 level of 5 dB.
 This result is particularly noteworthy since there were enough BER to support
 a statistically robust analysis, providing confidence that the result was
 not an artifact.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/GridNet/Polar/BER/Results_LMMSE vs GridNetPolar_-22_3_2023-10_35.png
	lyxscale 80
	scale 80

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
16-QAM BER: GridNet Polar Grid vs LMMSE 
\begin_inset CommandInset label
LatexCommand label
name "fig:86"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Polar Grid exhibits one of the lowest block error rates (BLER) for high
 signal-to-noise ratio (SNR) values between 33 dB and 45 dB in 
\color blue
Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:87"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
.
 The autoregression attention mechanisms employed by the transformer model
 are effective in capturing the relationship between the first and last
 values, which reduces inter-symbol interference (ISI) and leads to better
 performance.
 However, at lower SNR values, the noise starts to impact the network's
 attention mechanisms, causing the BLER to increase exponentially over testing
 data outside of the noise levels used in training.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/GridNet/Polar/BLER/Results_LMMSE vs GridNetPolar_-22_3_2023-10_41.png
	lyxscale 80
	scale 80

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
16-QAM BLER: GridNet Polar Grid vs LMMSE 
\begin_inset CommandInset label
LatexCommand label
name "fig:87"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
OSIC and PolarGrid operate similarly, utilizing attention mechanisms and
 grids to achieve superior performance at high signal-to-noise ratio (SNR)
 values as shown in 
\color blue
Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:88"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
.
 Comparing the non-linear models, it can be seen that OSIC yields the same
 bit error rate (BER) in certain low SNR ranges.
 However, for the lowest SNR, GridNet outperforms OSIC.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/GridNet/Polar/BER/Results_GrinNetPolar vs OSIC and NML_-22_3_2023-12_49.png
	lyxscale 80
	scale 80

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
16-QAM BER: GridNet Polar Grid MobileNet vs.OSIC and NML 
\begin_inset CommandInset label
LatexCommand label
name "fig:88"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
In 
\color blue
Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:89"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
 the block error rate (BLER) graph shows that the models perform better
 at higher signal-to-noise ratio (SNR) values above 25 dB.
 However, for lower SNR values, both non-linear methods perform better.
 Nonetheless, GridNet is faster than NML and represents a promising implementati
on option with a small performance sacrifice for low SNR scenarios.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/GridNet/Polar/BLER/Results_GrinNetPolar vs OSIC and NML_-22_3_2023-12_50.png
	lyxscale 80
	scale 80

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
16-QAM BLER: GridNet Polar Grid MobileNet vs.OSIC and NML 
\begin_inset CommandInset label
LatexCommand label
name "fig:89"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
GridNet Both
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
PolarGrid has the potential to use fewer parameters because the number of
 patches reduces the alphabet size employed by the transformer, resulting
 in a smaller data model.
 While there is at least one order of magnitude difference between PolarGrid
 and SquareGrid in terms of bit error rate (BER), SquareGrid exhibits more
 consistent and predictable BER/SNR slope, whereas PolarNet shows rapid
 BER growth over a short range of SNR values as shown in 
\color blue
Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:90"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
, which can sometimes be undesirable, particularly if the communication
 system operates within this range.
 On a positive note, neither of the grids performs worse than NML, which
 has the highest BER.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/GridNet/BOTH/BER/GridNetBoth.png
	lyxscale 80
	scale 80

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
16-QAM BER: GridNet, Polar and Square Grid vs LMMSE 
\begin_inset CommandInset label
LatexCommand label
name "fig:90"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
In the 
\color blue
Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:16-QAM-BER:-GridNet"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
 , it can be appreciated that SquareGrid behaves more similarly to NML for
 lower SNR values, while GridNetPolar works similarly to OSIC, with an improveme
nt for SNR values lower than 15 dB.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/GridNet/BOTH/BER/GridNetBoth_5_25.png
	lyxscale 80
	scale 80

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
16-QAM BER: GridNet, Polar and Square Grid vs LMMSE from 5dB to 27dB 
\begin_inset CommandInset label
LatexCommand label
name "fig:16-QAM-BER:-GridNet"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Regarding the block error rate (BLER) in 
\color blue
Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:92"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
 both methods perform well for signal-to-noise ratio (SNR) values higher
 than 25 dB.
 However, SquareGrid exhibits a slower growth rate than PolarNet between
 27 dB and 20 dB, and for lower SNR values, other non-linear methods achieve
 lower BLER values.
 One of the main drawbacks of these iterative methods is that they are less
 easily parallelizable compared to transformers, making the use of transformers
 a viable option despite the trade-off in BLER performance.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/GridNet/BOTH/BLER/GridNetBoth.png
	lyxscale 80
	scale 80

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Caption Standard

\begin_layout Plain Layout
16-QAM BLER: GridNet, Polar and Square Grid vs LMMSE 
\begin_inset CommandInset label
LatexCommand label
name "fig:92"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Square grid works better with lower SNR than the Polar grid.
 Basically both grids are a finnaly trade off between consisten noise mitigation
 or ISI cancelation.
 It can be taken a closer look for SNR range from 5dB to 25dB in 
\color blue
Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:93"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/GridNet/BOTH/BLER/GridNetBoth_5_25.png
	lyxscale 80
	scale 80

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
16-QAM BLER: GridNet, Polar and Square Grid vs LMMSE from 5dB to 30dB 
\begin_inset CommandInset label
LatexCommand label
name "fig:93"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Outlook of results
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The results presented in 
\color blue
Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:94"
plural "false"
caps "false"
noprefix "false"

\end_inset

, Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:95"
plural "false"
caps "false"
noprefix "false"

\end_inset

, Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:96"
plural "false"
caps "false"
noprefix "false"

\end_inset

 
\color black
and
\color blue
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:97"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
 are based on the visual and experimental representation of the Block Error
 Rate (BER) and Bit Error Rate (BLER) with different Signal-to-Noise Ratio
 (SNR) scenarios.
 The results provide valuable insights into the strengths and weaknesses
 of each equalization method and can inform the development of more effective
 equalization techniques for equalization task.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
PolarNet appears to perform well overall SNR values, with one of the best
 performances in the range between 15 dB to 25 dB for reducing bit errors.
 Additionally, it exhibits a smooth increase in BER, making its behavior
 well predictable, also has is an intermidiate term of complexity.
 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
MobileNet performs well for SNR values lower than 25 dB, with lower BER
 than all golden models and some networks such as GridNet Square.
 Additionally, it strikes a good balance between the number of parameters
 and time complexity, making it a good candidate for embedded applications.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
Complex is slightly better than NML and GridNetSquare for SNR values lower
 than 18 dB.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
GridNet Polar has the lower BER values from 27dB to 45dB.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/All/BER/Results_All equalization methods_-22_3_2023-11_15.png
	lyxscale 80
	scale 80

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Caption Standard

\begin_layout Plain Layout
16-QAM BER: All methods 
\begin_inset CommandInset label
LatexCommand label
name "fig:94"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
GridNet Square behaves similar to NML.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
MobileNet, PolarNet and ComplexNet converge to the NML model for the lowest
 SNR values, from 5dB to 15dB.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/All/BER/Results_All equalization methods_5_35.png
	lyxscale 80
	scale 80

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
16-QAM BER: All methods from 5dB to 27dB 
\begin_inset CommandInset label
LatexCommand label
name "fig:95"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
GridNetPolar performs well at high SNR, it degrades faster from 35dB to
 lower values, resulting in the worst BLER below 25dB.
 This means that while PolarGrid reduces bit errors, it consistently fails
 over the blocks.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
PolarNet outperforms all methods for SNR values lower than 30 dB, while
 also exhibiting the same growth relation with its BER metric.
 This mean a good outlier and noise handling for this Network.
 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
MobileNet shows promising results as an upgrade to the standard zero-forcing
 equalizer, handling with noise and ISI.
 This can be observed as it displays the second-best BLER plot among all
 the models.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
MobileNet exhibits a very close BER performance to PolarNet.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/All/BLER/Results_All equalization methods_-22_3_2023-11_19.png
	lyxscale 80
	scale 80

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Caption Standard

\begin_layout Plain Layout
16-QAM BLER: All methods from 5dB to 45dB 
\begin_inset CommandInset label
LatexCommand label
name "fig:96"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
Both GridNet are the first networks to reach the block error rate of 1.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
ComplexNet has better BLER than GridNet from 22dB to lower.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/All/BLER/Results_All equalization methods_14_30.png
	lyxscale 80
	scale 80

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
16-QAM BLER: All methods from 14dB to 30dB 
\begin_inset CommandInset label
LatexCommand label
name "fig:97"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newpage
\end_layout

\end_inset


\end_layout

\begin_layout Section
Conclusion
\end_layout

\begin_layout Subsection
Contributions
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
Compared to the state of art that use neural networks for signal equalization,
 we employed larger frame sizes and higher constellation points, such as
 16QAM.
 Typically, smaller frame sizes and lower constellation points, such as
 QPSK, are used:
\end_layout

\begin_deeper
\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
Larger frame sizes of 48
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
A channel of 48x48
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
Support up to 16QAM.
\end_layout

\end_deeper
\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
In order to help the neural network generalize better during the training
 stage, the z-score was utilized to reduce outliers.
 This approach was particularly necessary for the equalization task, as
 it prevented the neural network from having to adapt to all possible solutions
 and improved its ability to generalize effectively.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
PhaseNet
\series default
:
\end_layout

\begin_deeper
\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
Designed for PSK systems equalization.
 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
Generated the idea to use a unitary circle to exploit the concept of using
 distance as a metric of the phase, setting a constant radius of one but
 measuring the error distance based on how well the angle is estimated by
 the network.
 This avoids wrong angle measurements, which would result in an incorrect
 error being passed to the network.
 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
Network learns faster and generalizes better for phase prediction with the
 distance error metric.
\end_layout

\end_deeper
\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
PolarNet
\series default
: 
\end_layout

\begin_deeper
\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
A combination of PhaseNet and MagNet, which is an equalizer that separately
 deals with phase and magnitude error reduction and estimates them as separate
 values in a phasor manner.
 The idea behind this network is to make it more modular, as a system can
 work with either PSK equalization or QAM, depending on the requirement
 of the system.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
Combination of different preprocesing stages on for magnitud and another
 for phase.
 
\end_layout

\end_deeper
\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
ComplexNet
\series default
:
\end_layout

\begin_deeper
\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
First Implementation of complex of a feedforward neural network for OFDM
 equalization.
 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
Although it did not produce the best results for equalization, it opens
 new avenues for possible implementation and mathematical study to upgrade
 gradients and network evaluation, to make a better estimate of the ground
 truth.
\end_layout

\end_deeper
\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
MobileNet
\series default
:
\end_layout

\begin_deeper
\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
A network typically used for classification modified for our research, it
 was utilized for a regression task to simulate zero-forcing with known
 noise.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
Modification of the first and final layer to ensure the network fits with
 the data dimensionality.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
Using one of the most efficient convolutional neural networks for an equalizatio
n task, striking a balance between accuracy and time complexity
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
The network significantly reduced the BER and BLER with just one single
 vector of size 48 performing zero-forcing.
\end_layout

\end_deeper
\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
Identified a gap
\series default
 in the existing literature regarding the use of transformers in the signal
 processing scenario.
\end_layout

\begin_deeper
\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
Taking inspiration from image-to-image translation models, we implemented
 a square grid that divides the IQ plane into buckets.
 These buckets are a quantization of all infinite possible values in the
 plane into a reduced alphabet.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
Translated the uncorrected image given by the data, which had channel deformatio
n and noise, and recovered the image with the desired buckets based on the
 ground truth.
\end_layout

\end_deeper
\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
PolarGrid
\series default
 preprocessing stage in GridNet:
\end_layout

\begin_deeper
\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
Although existing square grids are commonly used for image processing in
 image transformers, the use of PolarGrid was unexplored before this research.
 Which is quite useful in this case, as our image represents the complex
 plane that can be analyzed in polar geometry.
\end_layout

\end_deeper
\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
GridNet
\series default
:
\end_layout

\begin_deeper
\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
The first transformer applied to signal equalization in the modulation scheme
 for OFDM.
\end_layout

\end_deeper
\begin_layout Subsection
Outlook
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
In this work, new networks for equalizing variant channels were presented.
 The proposed networks met the objectives by presenting the following advantages
:
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\size large
MobileNet and PolarGrid enable adequate mitigation of impairments caused
 by ISI and doppler effects.
 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\size large
PhaseNet, PolarNet, and ComplexNet allow for adequate noise reduction.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\size large
The networks time complexity can be parallelized without implementing complex
 architectures.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\size large
Except for ComplexNet, the networks outperform the non-linear classical
 methods OSCI and NML for lower SNR values.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\size large
PolarGridNet is proof that transformers can be used in the telecom industry
 with adequate preprocessing.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The following observations were made regarding the work presented in this
 study:
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\size large
Neural networks work better with closely spaced data points, hence a pre-process
ing stage plays a fundamental role.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\size large
Attention mechanisms assign weights to input data, enabling the model to
 focus on relevant information and reduce inter-symbol interference (ISI).
 However, in the presence of noise, this can cause attention mechanisms
 to fail in assigning correct weights, leading to a focus on irrelevant
 features and increased block error rate (BLER).
 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\size large
Variable SNR values work better for GridNet training, while constant SNR
 works better for the other models.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\size large
Training with low SNR values can result in the network learning noise patterns
 instead of accurately representing the signal.
 
\end_layout

\begin_deeper
\begin_layout Itemize
\paragraph_spacing onehalf

\size large
Our experiments showed that a minimum SNR value of 20dB is required for
 training.
\end_layout

\end_deeper
\begin_layout Itemize
\paragraph_spacing onehalf

\size large
All networks should be implemented in Python due to the GPU and TPU APIs
 support, which accelerates the training process.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\size large
The use of a larger dataset is recommended to increase the robustness of
 the network testing.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
In conclusion, the field of neural networks has seen tremendous advancements
 in recent years, with the development of more complex architectures, such
 as deep neural networks, convolutional neural networks, and transformers.
 It is essential to strike a balance between accuracy and memory footprint
 for signal equalization to avoid affecting data throughput.
 These advancements have led to significant improvements in the ability
 of neural networks to process complex data, including doubly dispersive
 channels.
 These developments have resulted in numerous practical applications, ranging
 from self-driving cars and drone flying to the development of new 6G technologi
es.
 However, despite the remarkable progress made in the field, there are still
 many challenges that need to be addressed, such as reducing noise overfitting,
 managing outliers, MIMO signal cleaning, and the need for more formal mathemati
cal descriptions of some network architectures.
 Further research is necessary to continue to advance the field and unlock
 the full potential of neural networks in the telecom area, which is an
 area that is just starting to show its potential.
\end_layout

\begin_layout Subsection
Future Work
\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent

\size large
Model quantization is a technique for reducing the memory footprint and
 computational cost of deep neural networks by converting the weights and
 activations of the network to a lower numerical precision format.
 While it can significantly reduce the memory and power requirements of
 neural networks, it can also lead to a loss of accuracy.
 Adjustments to the network architecture and training process are needed
 to ensure that the quantized network still achieves good performance.
 Google's Coral platform is an example of a system that uses model quantization
 for efficient inference, including a set of tools for quantizing and compressin
g neural network models to run on the Coral Edge TPU.
 Coral's quantization tools include both post-training and quantization-aware
 training methods, and are compatible with popular deep learning frameworks
 such as TensorFlow and PyTorch.
 
\begin_inset CommandInset citation
LatexCommand cite
key "coral2020accelerator"
literal "false"

\end_inset


\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent

\size large
One potential future work is to use the latest reinforcement learning algorithms
 to discover a matrix inversion algorithm.
 AlphaTensor is a well-known network that discovers many provably correct
 matrix multiplication algorithms that improve over existing algorithms
 in terms of the number of scalar multiplications, and is adaptable to different
 use-cases, including discovering algorithms for structured matrix multiplicatio
n and optimizing for actual runtime.
 The results demonstrate that the space of matrix multiplication algorithms
 is richer than previously thought, and AlphaTensor can efficiently search
 this space to discover novel algorithms that outperform human-designed
 ones on the same hardware.
 Therefore, a possible future direction could be to create an algorithm
 that outperforms existing ones and achieves a time complexity of almost
 
\begin_inset Formula $O(N^{2})$
\end_inset

 for matrix inversion.
\begin_inset CommandInset citation
LatexCommand cite
key "alphatensor"
literal "false"

\end_inset


\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent

\size large
Equalization in MIMO scenarios could be a potential candidate, as it involves
 classification tasks that are typically more effective with neural networks.
\begin_inset CommandInset citation
LatexCommand cite
key "DeepMimoOFDM"
literal "false"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newpage
\end_layout

\end_inset


\end_layout

\begin_layout Section
References
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset CommandInset bibtex
LatexCommand bibtex
btprint "btPrintCited"
bibfiles "Bibliography"
options "plain"

\end_inset


\end_layout

\begin_layout Standard

\end_layout

\begin_layout Standard

\end_layout

\begin_layout Standard

\end_layout

\begin_layout Standard

\end_layout

\end_body
\end_document
