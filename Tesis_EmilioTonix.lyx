#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\begin_preamble
\usepackage{helvet}
\renewcommand{\familydefault}{\sfdefault}
\usepackage{ragged2e}
\usepackage{blindtext}
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhead{}
\fancyhead[RO,LE]{Doubly dispersive channels equalization using deep learning techniques}
\fancyfoot[CO,RE]{Emilio Tonix}
\fancyfoot{}
\fancyfoot[LE,RO]{\thepage}
\fancyfoot[CO,RE]{Emilio Tonix}

\usepackage{listings}
\usepackage{xcolor}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}


\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}

\lstset{style=mystyle}
\end_preamble
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "Courier"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family rmdefault
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref true
\pdf_bookmarks true
\pdf_bookmarksnumbered false
\pdf_bookmarksopen false
\pdf_bookmarksopenlevel 1
\pdf_breaklinks false
\pdf_pdfborder true
\pdf_colorlinks false
\pdf_backref false
\pdf_pdfusetitle true
\papersize default
\use_geometry true
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 2.5cm
\topmargin 2.5cm
\rightmargin 2.5cm
\bottommargin 2.5cm
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Standard
\align center
\begin_inset Graphics
	filename Imagenes/Cinvestav_Logo-transformed.jpeg
	lyxscale 13
	scale 12

\end_inset


\end_layout

\begin_layout Standard
\align center

\size larger
Centro de Investigación y de Estudios Avanzados del I.P.N 
\end_layout

\begin_layout Standard
\align center

\size larger
Unidad Guadalajara 
\end_layout

\begin_layout Standard
\align center

\end_layout

\begin_layout Standard
\align center

\series bold
\size huge
\color black
Exploring Deep Learning Techniques for Equalizing Doubly Dispersive Channels
\end_layout

\begin_layout Standard

\series bold
\color white
.
\end_layout

\begin_layout Standard
\align center

\size larger
\color black
A thesis presented by:
\end_layout

\begin_layout Standard
\align center

\series bold
\size larger
\color black
Luis Emilio Tonix Gleason
\end_layout

\begin_layout Standard
\align center

\size larger
\color black
to obtain the degree of:
\end_layout

\begin_layout Standard
\align center

\series bold
\size larger
\color black
Master in Science
\end_layout

\begin_layout Standard
\align center

\size larger
\color black
in the subject of:
\end_layout

\begin_layout Standard
\align center

\series bold
\size larger
\color black
Electrical Engineering
\end_layout

\begin_layout Standard
\align center

\size larger
\color black
Thesis Advisors:
\end_layout

\begin_layout Standard
\align center

\series bold
\size larger
\color black
Dr.
 Ramón Parra Michel
\end_layout

\begin_layout Standard
\align center

\series bold
\size larger
\color black
Dr.
 Fernando Peña Campos
\end_layout

\begin_layout Standard
\align center

\end_layout

\begin_layout Standard
\align center

\series bold
\size larger
\color black
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill Guadalajara, Jalisco 
\backslash
today
\end_layout

\end_inset

 
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newpage
\end_layout

\end_inset


\end_layout

\begin_layout Section*
\noindent

\size huge
\color black
Acknowledgment 
\size large
\color inherit

\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newline
\end_layout

\end_inset

 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent
\align block

\size large
Thank you for reading this; I appreciate it.
 I'm expecting that your work will benefit greatly from this material.
 I won't hesitate to say that you might have done your job more effectively
 than I did.
 Progress in science is a way to skepticism and having the best information
 from multiple sources to meet your individual standards.
  
\end_layout

\begin_layout Standard

\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newpage
\end_layout

\end_inset


\end_layout

\begin_layout Section*

\size huge
Resumen 
\size large

\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newline
\end_layout

\end_inset

 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent
\align block

\size large
En la actualidad, la tecnología de redes de comunicación inalámbricas de
 alta movilidad está en constante evolución, y tiene aplicaciones en diversos
 ámbitos, tales como la seguridad vial, la conducción autónoma, el monitoreo
 remoto de vehículos, el vuelo de drones y los requisitos de 6G.
 Los transmisores RF, que se emplean en los sistemas de telecomunicaciones
 para transmitir información, codifican dicha información a través de la
 amplitud y la fase de una señal portadora, comúnmente conocida como datos
 IQ.
 Sin embargo, al viajar a través de un canal de alta movilidad, estos datos
 sufren distorsión, debido a la dispersión doble de dicho canal, lo que
 implica que las propiedades de la señal se ven afectadas por el desplazamiento,
 difusión en el tiempo y la frecuencia.
 Aunque existen algoritmos tradicionales que requieren ecualizadores iterativos
 complejos, que pueden ser lentos en términos de tiempo de ejecución pero
 precisos, también existen ecualizadores más sencillos, aunque menos precisos.
 En este trabajo se analizarán algunas soluciones basadas en redes neuronales,
 buscando un equilibrio entre la complejidad del tiempo y la precisión para
 hacer frente a este desafío.
 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newline
\end_layout

\end_inset

 
\end_layout

\begin_layout Standard
\align block

\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
Es posible afirmar que los algoritmos convencionales han demostrado ser
 eficaces en el desarrollo actual.
 Sin embargo, los recientes avances en redes neuronales han simplificado
 problemas que antes eran intratables, como el descifrado de secuencias
 de ADN o la creación de imágenes a partir de texto.
 En resumen, abordan con éxito problemas no lineales.
 El objetivo de este trabajo es imitar técnicas de ecualización conocidas
 con naturaleza lineal, como los ecualizadores MSE, LMMSE y no linealies
 como MAP.
 Durante las pruebas realizaremos un seguimiento de diferentes tamaños de
 constelaciones y tasas de error de bit en una variedad de situaciones de
 interferencia y ruido.
 Esperamos que la tasa de error de bits disminuya hasta, o funcione ligeramente
 mejor que, el modelo de oro, que son los ecualizadores mencionados previamente.
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newline
\end_layout

\end_inset

 
\end_layout

\begin_layout Standard
\align block

\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
Los últimos enfoques en investigación literaria demuestran la existencia
 de diversas estrategias que se aproximan a lograr una buena ecualización,
 aunque no registran todas las etapas de la ecualización basándose en métodos
 tradicionales.
 Por otro lado, se presentará una estrategia que incluso aborde condiciones
 más complicadas del canal, tales como canales de línea de vista o la falta
 de ella.
 Finalmente, pero no menos importante, se busca promover una mayor investigación
 en este campo prácticamente inexplorado por algunos equipos de comunicación.
\end_layout

\begin_layout Standard

\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newpage
\end_layout

\end_inset


\end_layout

\begin_layout Section*

\size huge
Abstract
\size large
 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newline
\end_layout

\end_inset

 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
Due to their primary uses in control, road safety, autonomous driving, remote
 monitoring of vehicles, drone flying, and 6G needs, the development of
 high-mobility wireless communication networks is cutting-edge technology.
 The RF broadcasts, which are used by telecommunications systems to transfer
 encoded information over the amplitude and phase of a carrier signal, are
 normally called IQ data.
 However, this data is distorted as it travels through a high mobility channel.
 High mobility channels are doubly dispersive, which means that the signal
 properties are mixed with some temporal frequency shifting and spreading.
 There are some traditional algorithms that may require complex iterative
 equalizers that can be slow in terms of execution time.
 However, there are also simpler equalizers that may not be as precise.
 In this work, we will investigate the use of neural network-based solutions
 and consider how we should balance time complexity and accuracy to meet
 this challenge.
 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newline
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
We can categorically assert that conventional algorithms continue to work
 well in the context of contemporary development.
 However, recent advances in neural networks have simplified problems that
 were previously intractable, such as deciphering DNA sequences or creating
 images from text.
 In short, they successfully tackle non-linear issues.
 The objective of this work is to mimic well-known equalization techniques
 with linear properties such as MSE and LMMSE, as well as non-linear techniques
 like MAP equalizers.
 We will evaluate how well the equalization performs under various noise
 conditions and with various bit-size encodings.
 We anticipate that the bit error rate will drop to, or perform slightly
 better than, the golden model, which are the aforementioned equalizers.
 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newline
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
According to literature studies, there are a few cutting-edge methodologies
 that approach this goal but fall short of fully documenting all of the
 steps of equalization.
 This article presents a method for dealing with more complex circumstances,
 such as line of sight or a lack of it.
 Lastly, we aim to encourage further research into this largely untapped
 area by some communication teams.
 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newline
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent
\align block

\end_layout

\begin_layout Standard

\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newpage
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset toc
LatexCommand tableofcontents

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newpage
\end_layout

\end_inset


\end_layout

\begin_layout Standard

\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
This chapter's main goal is to provide an overview of the technical facts
 and some of the current issues that prompted this study.
\end_layout

\begin_layout Subsection
Document organization
\end_layout

\begin_layout Standard

\size large
The structure of this document is as follows: 
\end_layout

\begin_layout Itemize

\series bold
\size large
Chapter 1 Theoretical Framework: 
\series default
Fundamental ideas and concepts behind the current project.
 Outlines the core concepts necessary to comprehend this study
\end_layout

\begin_layout Itemize

\series bold
\size large
Chapter 2 State of Art:
\series default
 Examines the existing literature on classical equalization methods and
 compares them to deep learning models.
 
\end_layout

\begin_layout Itemize

\series bold
\size large
Chapter 3 Present work:
\series default
 The present work includes the Python implementation of various models,
 to train and test different experiments, as well as an overview of the
 software architecture that makes this possible.
 The focus is on explainable deep learning models of Quadrature Amplitude
 Modulation (QAM) equalization based on neural networks, including the design
 of the proposed models.
 Additionally, the description, characteristics, and comparison with related
 work will also be discussed
\end_layout

\begin_layout Itemize

\series bold
\size large
Chapter 4 Results and Analysis:
\series default
 Explains the conception and execution of the idea, the experiments carried
 out, and the analysis of the outcomes.
 Here, we compare the BER (Bit Error Rate) graphs of our studied models.
\end_layout

\begin_layout Itemize

\series bold
\size large
Chapter 5 Conclusion and Outlook: 
\series default
The conclusions and potential future directions of this study are determined.
\end_layout

\begin_layout Subsection
\paragraph_spacing onehalf
Background
\end_layout

\begin_layout Standard

\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
It takes a lot of expertise in the field of communications to model different
 types of channels, account for various channel flaws, and create the best
 signaling and detecting systems that guarantee a reliable data flow.
 The design of transmit signals in communications enables simple analytical
 techniques for symbol detection for a range of channel and system models,
 including multipath, doppler spread, and white Gaussian noise (AWGN) over
 constellation symbol detection.
 
\begin_inset CommandInset citation
LatexCommand cite
key "aghvami2005channel"
literal "false"

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newline
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
One of the guiding principles of communication system design is the division
 of signal processing into a series of distinct blocks, each of which performs
 a clearly defined and isolated functions such as source or channel coding,
 modulation, channel estimation, and equalization.
 This strategy has made it possible for us to have the effective, adaptable,
 and controlled systems we have today, but it is not certain whether individuall
y tuned processing blocks will yield the best end-to-end performance 
\begin_inset CommandInset citation
LatexCommand cite
key "proakis2002communication"
literal "false"

\end_inset

.
 During implementation, we will also consider the abstraction of the other
 communication blocks and assume that the channel has already been estimated.
 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newline
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Diagrams/Typical_Block_Diagram.png
	lyxscale 50
	scale 40

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Typical communication system block diagram 
\begin_inset CommandInset citation
LatexCommand cite
key "ChannelDiagram"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
On the other hand, the design philosophy guiding the creation of the 6G
 architecture will be "AI native.", allowing the network to become intelligent,
 capable of solving individual stages of the channel, and able to self-learn
 and self-adapt in response to changing network dynamics 
\begin_inset CommandInset citation
LatexCommand cite
key "The_Roadmap_to_6G"
literal "false"

\end_inset

.
 It has been demonstrated that NNs are capable of approximating any function
 
\begin_inset CommandInset citation
LatexCommand cite
key "HORNIK1989359"
literal "false"

\end_inset

, and current research has demonstrated an astounding aptitude for algorithmic
 learning 
\begin_inset CommandInset citation
LatexCommand cite
key "8697857"
literal "false"

\end_inset

.
 Due to the challenge of defining real-world images or language with strict
 mathematical models, deep learning (DL) excels in fields like computer
 vision and natural language processing.
 For example, while it is now simple to develop DL algorithms that learn
 to complete this task with accuracy greater than that of humans 
\begin_inset CommandInset citation
LatexCommand cite
key "Surpassing_Human_Level_Performance"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Despite this, we assume that the DL applications we evaluate in this thesis
 are a useful and insightful way to fundamentally rethink the problem of
 communications network design, and they show promise for performance improvemen
ts in complex communications scenarios that are difficult to describe with
 tractable mathematical models.
 Finally, we will look for the equalization stage, which, if it is seen
 in the diagram above, fits on the channel decoder.
 
\end_layout

\begin_layout Subsection
OFDM
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
Orthogonal Frequency Division Multiplexing (OFDM) is a digital communication
 technique that divides the available bandwidth into a large number of narrowban
d subcarriers, and transmits data by modulating the subcarriers with symbols.
 OFDM is widely used in wireless and wired communication systems, such as
 Wi-Fi, LTE, and DOCSIS.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent
\align block

\size large
The basic blocks of an OFDM system are:
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Diagrams/OFDM_typical.png
	lyxscale 50
	scale 40

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
OFDM basic diagram 
\begin_inset CommandInset citation
LatexCommand cite
key "OFDMdiagram"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Itemize

\series bold
\size large
Binary sequence
\series default
: This block generates the data to be transmitted.
 The data is usually a sequence of bits.
\end_layout

\begin_layout Itemize
\align block

\series bold
\size large
QAM mapping
\series default
: Bits are grouped into blocks called symbols usally named as alphabet 
\begin_inset Formula $\boldsymbol{\mathbb{A}}$
\end_inset

.
 We have a set of bits 
\begin_inset Formula $2^{\mathbb{A}}$
\end_inset

 grouped inside the alphabet.
 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\align block

\series bold
\size large
IFFT block
\series default
: This block applies an Inverse Fast Fourier Transform (IFFT) to the modulated
 symbols, dividing them into a set of subcarriers.
\end_layout

\begin_layout Itemize
\align block

\series bold
\size large
Cyclic prefix
\series default
: Helps OFDM symbols to reduce inter-symbol interference.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
At regular intervals, the transmitter inserts recognizable symbols known
 as "pilots" into the transmitted signal.
 These pilots are selected to have a known value and to be separated from
 one another by a given number of symbols.
 By comparing the known transmission symbols to the received symbols, the
 receiver can then utilize the pilots to estimate the channel.
 This may lower the system's data throughput.
 Subsequently, the equalizer performs channel equalization using the coefficient
s obtained by the estimator, to reduce the distortions caused by the communicati
on channel in the received data.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Since we have been provided with a dataset that contains previously estimated
 channels, we will not prioritize the channel estimation component of this
 project.
 Rather, in order to minimize errors and impairments at the receiver and
 to transmit the symbols as accurately as possible, we will focus on canceling
 the effects of the received, but well-known, channel during the communication
 process.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
We are entering a new research area as we attempt to generalize the pseudo
 inverse of the channel to cancel its effects.
 It is well known that the matrix inverse is not a continuous function,
 as some matrices may not have an inverse or may be singular.
 However, we are using a subset of invertible matrices to mitigate this
 issue, and also considering realistic physical phenomena.
 Additionally, we must grapple with the numerical instability of the matrix
 inverse, as well as the use of complex numbers in a neural network.
\end_layout

\begin_layout Subsubsection
Advantages and Disadvantages in OFDM
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
The advantages offered by OFDM systems in broadband systems are as follows
 
\begin_inset CommandInset citation
LatexCommand cite
key "ofdm_book"
literal "false"

\end_inset

:
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\align block

\series bold
\size large
High spectral efficiency
\series default
: OFDM can transmit a large amount of data over a wide frequency band by
 dividing the available bandwidth into multiple narrowband subcarriers.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\align block

\series bold
\size large
Robustness to channel impairments
\series default
: OFDM is less sensitive to frequency-selective fading and interference
 than other multiplexing techniques, making it well-suited for use in wireless
 communication systems.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\align block

\series bold
\size large
Ease of implementation
\series default
: OFDM can be implemented using simple digital signal processing techniques,
 making it relatively easy to design and implement.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
Some disadvantages of OFDM include:
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\align block

\series bold
\size large
High peak-to-average power ratio
\series default
: OFDM signals have a high peak-to-average power ratio, which can cause
 problems in power amplifier systems and limit the range of the transmitted
 signal.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\align block

\series bold
\size large
Sensitivity to timing errors: 
\series default
OFDM is sensitive to timing errors, which can cause inter-symbol interference
 and reduce the performance of the system.
\end_layout

\begin_layout Itemize

\series bold
\size large
Sensitivity to Doppler spread:
\series default
 Doppler spread causes interference between the subcarriers.
\end_layout

\begin_layout Subsection
QAM and IQ data
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
QAM (Quadrature Amplitude Modulation) is a type of digital modulation that
 encodes data onto a carrier signal by modulating the amplitude and phase
 of the signal.
 It is commonly used in digital communication systems to transmit digital
 data over analog channels.
 IQ data refers to the in-phase and quadrature components of a complex-valued
 signal.
 In digital communication systems, the IQ data is typically used to represent
 the amplitude and phase of the modulated carrier signal.
 It's ussualy represented with complex numbers in an alphabet 
\begin_inset Formula $\mathbb{A}\in\mathbb{C}^{n}$
\end_inset

.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Diagrams/16QAM.png
	lyxscale 20
	scale 20

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Caption Standard

\begin_layout Plain Layout
16-QAM constellation 
\begin_inset CommandInset citation
LatexCommand cite
key "wiki_16qam"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\size large
 In the field of communication systems, a QAM constellation refers to a
 graphical representation of the symbol points in an alphabet on the complex
 plane.
 Each point represents a specific combination of the in-phase and quadrature
 components of the modulated signal.
 The number of points in the constellation is determined by the number of
 possible combinations of in-phase and quadrature values, which is in turn
 determined by the number of bits per symbol used in the QAM modulation
 scheme.
 For instance, in a 16-QAM constellation, there are 16 symbol points arranged
 in a square grid, with each point corresponding to 4 bits of data.
 The distance between points in the constellation serves as an indicator
 of the signal-to-noise ratio required for reliable transmission of the
 data.
 It is common for QAM constellations to utilize gray code for assigning
 the symbol points in a manner that minimizes the error rate.
 However, this is not the only method that can be employed for this purpose
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/QAM_noise.jpg
	lyxscale 80
	scale 50

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
QPSK and 16 QAM with noise and phase displacement 
\begin_inset CommandInset citation
LatexCommand cite
key "QAMwithNoise"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
SNR
\end_layout

\begin_layout Standard
A signal-to-noise ratio contrasts the strength of the signal with the strength
 of the noise.
 The most common way to measure it is in decibels (dB).
 In general, higher numbers indicate a better specification because there
 is a greater ratio of useful information (the signal) to unwanted data
 (the noise).
 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
SNR=\frac{P_{signal}}{P_{noise}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
P_{signal}=\sum|s|^{2}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\noindent
For realistic simulations, noise is typically an AWGN, which is useful.
 In order to simulate bit error rates, AWGN can generate appropriate power
 levels.
 Typically, noise power is determined by its variance 
\begin_inset Formula $\boldsymbol{\sigma^{2}}$
\end_inset

, which in simulations is used as follows
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\sigma^{2}=10^{\frac{SNR}{10}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard

\end_layout

\begin_layout Subsection
Channel
\size large
 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newline
\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Dispersion and doubly dispersion
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
Dispersion, in the context of radio communication systems, refers to the
 spreading out of a signal over a range of frequencies or wavelengths as
 it travels through a medium, such as air.
 This phenomenon can lead to distortion of the signal and negatively impact
 the performance of the communication system.
 There are various factors that can contribute to dispersion, including
 the distance the signal travels, the presence of obstacles or reflections,
 and the frequency of the signal.
 Techniques such as equalization, adaptive modulation, and error correction
 codes can be used to mitigate the effects of dispersion.
 A doubly dispersive channel is a type of communication channel that exhibits
 dispersion in two dimensions, such as time and frequency.
 This means that the signals transmitted through the channel are spread
 out in both time and another aspect, such as frequency or spatial dimensions.
 
\begin_inset CommandInset citation
LatexCommand cite
key "rappaport2002wireless"
literal "false"

\end_inset


\end_layout

\begin_layout Subsubsection
Multipath fading and doppler shift
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent
\align block

\size large
A multipath fading channel is a type of wireless communication channel that
 experiences fading of the transmitted signal due to multiple paths of the
 signal between the transmitter and receiver.
 This can occur when the signal reflects off of obstacles such as buildings
 or terrain, or when it is refracted by the atmosphere.
 Multiple paths of the transmitted signal can cause constructive and destructive
 interference at the receiver, resulting in rapid fluctuations in the received
 signal strength.
 This can cause the signal to fade in and out, which can affect the quality
 and reliability of the communication.
 
\begin_inset CommandInset citation
LatexCommand cite
key "balanis_2012"
literal "false"

\end_inset

.
 We begin with the ray-tracing technique and make advantage of the physical
 geometry of the propagation environment to create a deterministic model
 of the wireless channel.
 The delay of a signal refers to the time it takes for the signal to travel
 from the transmitter to the receiver, and the Doppler shift of a signal
 refers to the frequency shift of the signal due to the relative motion
 between the transmitter and receiver.
\size default

\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Diagrams/Propagation.png
	lyxscale 50
	scale 30

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Caption Standard

\begin_layout Plain Layout
Delay multipath 
\begin_inset CommandInset citation
LatexCommand cite
key "hong_thaj_viterbo_2022"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard

\series bold
\size larger
\begin_inset Formula 
\begin{equation}
\boldsymbol{\mathbf{r(t)=g_{1}s(t-\tau_{1})+g_{2}s(t-\tau_{2})}}
\end{equation}

\end_inset


\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\mathbf{r(t)}$
\end_inset

 recieved signal
\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\mathbf{g_{n}}$
\end_inset

 baseband equivalent complex gain(attenuation)
\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\mathbf{\boldsymbol{\tau_{1}=\frac{r_{1}}{c}}}$
\end_inset

 where c is the speed of light
\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\mathbf{\boldsymbol{\tau_{2}=\frac{(r_{2}+r_{3})}{c}}}$
\end_inset

 delay in reflected path
\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\boldsymbol{\mathbf{\tau_{2}-\tau_{1}}}$
\end_inset

 delay spread
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
In wireless communication, the Doppler shift can cause changes in the frequency
 of a signal as it travels from the transmitter to the receiver.
 This can happen when the transmitter or receiver (or both) are moving relative
 to each other, causing the frequency of the signal to shift.
 The Doppler shift can affect the performance of a wireless communication
 system by causing changes in the signal-to-noise ratio and the signal-to-interf
erence ratio, which can degrade the quality of the signal and make it more
 difficult to detect and decode.
\begin_inset CommandInset citation
LatexCommand cite
key "marsland2013radio"
literal "false"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Diagrams/DopplerBasic.png
	lyxscale 50
	scale 40

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Doppler shifts due to the different angles of arrival 
\begin_inset CommandInset citation
LatexCommand cite
key "hong_thaj_viterbo_2022"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard

\size larger
\begin_inset Formula 
\begin{equation}
\boldsymbol{\mathbf{r(t)=g_{1}e^{j2\pi\nu_{1}(t-\tau_{1})}s(t-\tau_{1})+g_{2}e^{j2\pi\nu_{2}(t-\tau_{2})}s(t-\tau_{2})}}
\end{equation}

\end_inset


\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\mathbf{\boldsymbol{\nu_{1}=\frac{v}{c}f_{c}}}$
\end_inset

 LOS doppler shift
\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\mathbf{\boldsymbol{\nu_{1}=\frac{v*cos(\theta)}{c}f_{c}}}$
\end_inset

 doppler shift in reflected path
\end_layout

\begin_layout Standard
\align block

\size large
We can generalize for time dependent function the gain as follows: 
\end_layout

\begin_layout Standard

\size larger
\begin_inset Formula 
\begin{equation}
\boldsymbol{\mathbf{g(\tau_{i},t)=g_{i}e^{j2\pi\nu_{i}(t-\tau_{i})}}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent
\align block

\size large
Therefore impulse time-frequency response of channel at fixed time t, can
 be obtained by taking fourier transform along the delay dimension of 
\begin_inset Formula $\mathbf{\boldsymbol{g(\tau,t)}}$
\end_inset


\end_layout

\begin_layout Standard

\size larger
\begin_inset Formula 
\begin{equation}
\mathbf{\boldsymbol{H(f,t)=\int g(\tau,t)e^{-j2\pi f\tau}d\tau}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent
\align block

\size large
A time-frequency channel is a type of communication channel that is characterize
d by time-varying frequency-selective fading.
 This means that the channel experiences changes in its frequency response
 over time, resulting in variations in the amplitude and phase of the signals
 transmitted through it.
 Because a channel is assumed to have a slow time-varying function of t,
 we refer to this phenomenon as having a wide sense of being stationary.
 
\begin_inset CommandInset citation
LatexCommand cite
key "rappaport2002wireless"
literal "false"

\end_inset


\end_layout

\begin_layout Subsubsection
Wide sense stationary
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
A wide sense stationary (WSS) process is a stochastic process in which the
 mean and the autocorrelation function of the process do not change over
 time.
 As a result, the process' statistical characteristics, such as the mean,
 variance, and autocorrelation, remain consistent across time.
 In signal processing and telecommunications, WSS processes are frequently
 used to simulate signals that are stationary over a period of time.
 A generalization of strictly stationary processes, or processes in which
 the mean and auto-correlation function are constant over time, are WSS
 processes.
 
\begin_inset CommandInset citation
LatexCommand cite
key "papoulis2002probability"
literal "false"

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent
\align block

\size large
A wide sense stationary (WSS) process can be described by the following
 equations:
\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent
\align block

\size large
The mean of the process is constant over time, and can be represented by
 the equation:
\end_layout

\begin_deeper
\begin_layout Standard

\size large
\begin_inset Formula 
\begin{equation}
\mathbf{\boldsymbol{E[X(t)]=\mu}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard

\size large
Where 
\begin_inset Formula $\boldsymbol{E[X(t)]}$
\end_inset

 is the expected value of the process at time t, and 
\begin_inset Formula $\boldsymbol{μ}$
\end_inset

 is the constant mean of the process.
\end_layout

\end_deeper
\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent
\align block

\size large
The autocovariance of the process, which is a measure of the correlation
 between two points in time, is also constant over time, and can be represented
 by the equation:
\end_layout

\begin_deeper
\begin_layout Standard

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{R_{X}(t1,t2)=E[(X(t_{1})-\mu)(X(t_{2})-\mu)]=R(t_{1}-t_{2})}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
Where
\begin_inset Formula $\boldsymbol{R_{X}(t_{1},t_{2})}$
\end_inset

is the autocovariance of the process at times t1 and t2, and 
\begin_inset Formula $\boldsymbol{R(t_{1}-t_{2})}$
\end_inset

 is the autocovariance function of the process, which is a function of the
 time difference between t1 and t2
\end_layout

\end_deeper
\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent
\align block

\size large
The autocorrelation function of the process, which is a measure of the correlati
on between two points in time, is also constant over time, and can be represente
d by the equation
\end_layout

\begin_deeper
\begin_layout Standard

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{r_{X}(t1,t2)=\frac{R_{X}(t_{1},t_{2})}{\sqrt{R_{X}(t_{1},t_{1})R_{X}(t_{2},t_{2})}}=r(t_{1}-t_{2})}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
Where 
\begin_inset Formula $\mathbf{r_{X}(t_{1},t_{2})}$
\end_inset

 is the autocorrelation function of the process at times t1 and t2, and
 
\begin_inset Formula $\boldsymbol{r(t_{1}-t_{2})}$
\end_inset

 is the autocorrelation function of the process, which is a function of
 the time difference between t1 and t2.
\end_layout

\end_deeper
\begin_layout Subsection
Equalization
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
A telecom channel equalizer is a device or algorithm used in telecommunications
 systems to compensate for distortion or other impairments in a communication
 channel.
 The equalizer uses signal processing techniques to estimate the characteristics
 of the channel, such as the impulse response or the frequency response,
 and then applies a correction to the transmitted signal to counteract the
 effects of the channel on the received signal.
 This can improve the performance of the communication system by reducing
 errors and increasing the data rate or signal-to-noise ratio.
 Bluetooth, WiFi, IOT, drones, V2V, wireless broadband, and satellite communicat
ions are just a few of the everyday applications they can be used for.
 
\begin_inset CommandInset citation
LatexCommand cite
key "goldsmith_2005"
literal "false"

\end_inset

 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newline
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Diagrams/Equalizer_Basic.jpg
	lyxscale 30
	scale 15

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Basic Equalizer
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Our goal is to develop an equalizer based on deep learning techniques and
 research how it performs in terms of timing and memory complexity.
 We take as a reference the classical methods that manage a good bit error
 rate, and we will take them as a golden model of accuracy.
 
\end_layout

\begin_layout Subsubsection
MSE
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
MSE equalization, or minimum mean square error equalization, is a technique
 used in digital communication systems to improve the performance of a channel
 by reducing the mean square error (MSE) between the transmitted and received
 signals.
 This equalization is a widely used technique in digital communication systems,
 as it can provide significant improvements in the performance of the channel
 by reducing the effects of noise, interference, and other impairments.
 It is often used in combination with other techniques, such as error correction
 and modulation, to further improve the overall performance of the communication
 system.
\begin_inset CommandInset citation
LatexCommand cite
key "proakis2002communication"
literal "false"

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align center

\size larger
\begin_inset Formula 
\begin{equation}
\boldsymbol{MSE=E[(x-y)^{2}]}
\end{equation}

\end_inset


\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\align block

\size large
\begin_inset Formula $\boldsymbol{x}$
\end_inset

 is the transmitted signal 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\align block

\size large
\begin_inset Formula $\boldsymbol{y}$
\end_inset

 is the received signal.
\end_layout

\begin_layout Subsubsection
MMSE
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
Since MMSE equalization is a linear equalization technique, the transmitted
 signal is first adjusted using a linear filter before being sent across
 the channel.
 By choosing the proper filter coefficients for the linear filter, the purpose
 of MMSE equalization is to reduce the MSE between the sent and received
 signals.
 The MMSE criteria, which stipulates that the filter coefficients should
 be set to minimize the MSE between the sent and received signals, may be
 used to compute the filter coefficients.
 The equation below can be used to do this: 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align center

\size larger
\begin_inset Formula 
\begin{equation}
\boldsymbol{H=\frac{E[xy]}{E[x^{2}]}}
\end{equation}

\end_inset


\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\align block

\size large
\begin_inset Formula $\boldsymbol{H}$
\end_inset

 is the filter coefficient.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\align block

\size large
\begin_inset Formula $\boldsymbol{x}$
\end_inset

 is the transmitted signal.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\align block

\size large
\begin_inset Formula $\boldsymbol{y}$
\end_inset

 is the received signal.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
It is possible to modify the sent signal before it is transmitted across
 the channel by using the weights determined values in the linear filter.
 The signal is modified and provided by: 
\end_layout

\begin_layout Standard

\size larger
\begin_inset Formula 
\begin{equation}
\boldsymbol{\hat{x}=Hx}
\end{equation}

\end_inset


\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\boldsymbol{\hat{x}}$
\end_inset

 is the adjusted signal and x is the original transmitted signal.
\end_layout

\begin_layout Subsubsection
LS
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
Least squares (LS) equalization is a linear equalization method that aims
 to minimize the mean squared error (MSE) between the estimated and the
 transmitted symbols.
 The noise component of x is disregarded by the LS (Least-Squares) equalizer,
 which treats it as a deterministic variable.
 A linear filter 
\begin_inset Formula $\boldsymbol{W}$
\end_inset

 that minimize the mean square error between 
\begin_inset Formula $\boldsymbol{\hat{x}}$
\end_inset

 and 
\begin_inset Formula $\boldsymbol{Hx}$
\end_inset

.
 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
The argmin function is a mathematical function that returns the indices
 of the minimum values of a given array or matrix.
 It is often used in optimization problems, where it is used to find the
 values of the variables that minimize some objective function.
\begin_inset CommandInset citation
LatexCommand cite
key "argmin_reference"
literal "false"

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size larger
\begin_inset Formula 
\begin{equation}
\boldsymbol{W_{Ls}=argmin||\hat{x}-Hx||^{2}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
With the solution in the Moore-Penrose pseudoinverse 
\begin_inset Formula $\boldsymbol{H^{+}}$
\end_inset

.The Moore-Penrose pseudoinverse is often used to solve linear least squares
 problems, which involve finding the values of variables that minimize the
 sum of the squares of the residuals (the differences between the observed
 values and the values predicted by the model).
 It can also be used to compute a "best fit" solution for systems of linear
 equations that do not have a unique solution.
 
\begin_inset CommandInset citation
LatexCommand cite
key "strang2019linear"
literal "false"

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size larger
\begin_inset Formula 
\begin{equation}
\boldsymbol{H^{+}=(H^{H}H)^{-1}H^{H}}
\end{equation}

\end_inset


\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\boldsymbol{H}$
\end_inset

 Channel matrix
\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\boldsymbol{H^{+}}$
\end_inset

Moore-Penrose pseudoinverse 
\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\boldsymbol{H^{H}}$
\end_inset

 Hermiatian transpose matrix.
 Complex square matrix that is equal to its own conjugate transpose
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
Its resistance to noise makes it appealing in a variety of communication
 systems, however because the noise component is ignored, it cannot operate
 satisfactorily with low SNR (signal to noise ratio).
 
\end_layout

\begin_layout Subsubsection
LMMSE
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
A form of linear filter called the Linear Minimum Mean Squared Error (LLMSE)
 Equalizer seeks to reduce the mean squared error (MSE) between the actual
 signal 
\begin_inset Formula $\boldsymbol{x}$
\end_inset

 and an estimation of the signal 
\begin_inset Formula $\boldsymbol{\hat{x}}$
\end_inset

.
 Incorporating second-order statistics of the data and the noise and treating
 the noise as a random variable allows it to achieve this.
 Compared to the Least Squares (LS) algorithm, this can perform better when
 there is low signal-to-noise ratio (SNR).
 To put it another way, the LLMSE equalization is a method that can be applied
 to restore precision to a signal that has been distorted by noise, especially
 when the noise level is high.
 When there is a low signal-to-noise ratio (SNR) and a significant quantity
 of noise in the signal, it performs exceptionally well.
\end_layout

\begin_layout Standard

\size larger
\begin_inset Formula 
\begin{equation}
\boldsymbol{W_{LMMSE}=argminE||x-\hat{x}||^{2}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
This equation consider AWGN (Additive White Gaussian Noise) with variance
 
\begin_inset Formula $\boldsymbol{\sigma^{2}}$
\end_inset

.
 It is called "white" because it has a flat power spectral density, meaning
 that it has equal power at all frequencies.
 It is called "additive" because it can be added to a signal without changing
 its distribution.
 
\end_layout

\begin_layout Standard

\size larger
\begin_inset Formula 
\begin{equation}
\boldsymbol{W_{LMMSE}=(H^{H}H+\sigma^{2}I)^{-1}H^{H}}
\end{equation}

\end_inset


\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\boldsymbol{\sigma^{2}}$
\end_inset

 variance of AWGN
\end_layout

\begin_layout Subsubsection
Pros and Cons
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
As we can see in the previous methods, the calculation of the equalization
 matrices is mainly based on finding the pseudo-inverse of certain matrix
 factors.
 However, directly solving for the inverse of the matrix can be computationally
 complex 
\begin_inset Formula $O(N^{3})$
\end_inset

 and, in addition, numerically unstable.
 This occurs if the matrix has a very small determinant, in which case the
 true solution may be subject to large perturbations.
 This will lead to a very complicated circuit architecture for numerical
 calculation.
\end_layout

\begin_layout Subsection

\size large
Neuronal
\size default
 networks
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Neural networks are a type of artificial intelligence system designed to
 mimic the functioning of the human brain.
 They consist of interconnected nodes, or "neurons," which are capable of
 processing information and making decisions based on that information.
 These networks are usually organized into layers, with each layer containing
 a different number of neurons.
 The input layer receives input from the external environment, while the
 output layer produces the final result or decision based on that input.
 The layers in between the input and output layers are called hidden layers,
 and they perform various intermediate calculations and processing tasks.
 Neural networks are trained using large amounts of data, allowing them
 to learn and make predictions or decisions based on that data.
 In this study case, the data consists of realistic channel realizations.
\end_layout

\begin_layout Subsubsection
Linear Layer
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
A linear layer in a neural network is a type of layer that applies a linear
 transformation to the input data.
 This transformation can be represented by a 
\series bold
matrix
\series default
 of weights, denoted as 
\size larger

\begin_inset Formula $\boldsymbol{W_{n}}$
\end_inset


\size large
 ,and a biases 
\series bold
vector
\series default
, denoted as
\size larger
 
\begin_inset Formula $\boldsymbol{b_{n}}$
\end_inset


\size large
, which are learned during the training process.
 The subscript 
\size larger

\begin_inset Formula $\boldsymbol{n}$
\end_inset


\size large
 refers to the nth layer.
 The output of a linear layer is calculated by performing a matrix and vector
 product between the input data 
\size larger

\begin_inset Formula $\boldsymbol{X_{n-1}}$
\end_inset

 
\size large
and the weights 
\size larger

\begin_inset Formula $\boldsymbol{W_{n}}$
\end_inset


\size large
 as well as adding the biases.
 
\end_layout

\begin_layout Standard

\size larger
\begin_inset Formula 
\begin{equation}
\boldsymbol{X_{n}=W_{n}X_{n-1}+b_{n}}
\end{equation}

\end_inset


\end_layout

\begin_layout Itemize

\size larger
\begin_inset Formula $\boldsymbol{W_{n}}$
\end_inset


\size large
weight matrix at layer n.
\end_layout

\begin_layout Itemize

\size larger
\begin_inset Formula $\boldsymbol{b_{n}}$
\end_inset

 
\size large
bias at layer n
\end_layout

\begin_layout Itemize

\size larger
\begin_inset Formula $\boldsymbol{X_{n-1}}$
\end_inset


\size large
Input or last layer data
\end_layout

\begin_layout Itemize

\size larger
\begin_inset Formula $\boldsymbol{X_{n}}$
\end_inset

 
\size large
Output data
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Diagrams/NN_eq.png
	lyxscale 70
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Output as Y and input as X.
 Vector matrix representation of system.
 Desing done with manim
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Backpropagation 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
The goal of the layer is to optimize the weights parameters so that they
 fit a target referred to as the ground truth.
 The error, denoted by E, is calculated as the difference between the predicted
 output (
\begin_inset Formula $\hat{X}$
\end_inset

) and the actual target output (
\begin_inset Formula $X_{n}$
\end_inset

).
 To achieve this, we will utilize the backpropagation algorithm, which is
 a common method in the field of artificial neural networks for training
 the network by adjusting the weights between neurons in the network.
 
\size larger

\begin_inset Formula 
\begin{equation}
\boldsymbol{Err=\hat{X}-X_{n}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
This method analyzes the error rate in relation to the weights and inputs.
 As we adjust our trainable parameters, {
\size larger

\begin_inset Formula $\boldsymbol{W_{n}}$
\end_inset


\size large
, 
\size larger

\begin_inset Formula $\boldsymbol{b_{n}}$
\end_inset


\size large
}, the error will change accordingly.
 The goal is to minimize the error, or to find a point where the error gradient
 is zero.
\begin_inset CommandInset citation
LatexCommand cite
key "Goodfellow-et-al-2016"
literal "false"

\end_inset


\end_layout

\begin_layout Standard

\size larger
\begin_inset Formula 
\begin{equation}
\boldsymbol{\nabla W=\frac{\partial E}{X_{n\text{+1}}}\times X_{n-1}^{T}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard

\size larger
\begin_inset Formula 
\begin{equation}
\boldsymbol{\nabla X_{n-1}=W_{n}^{T}\times\frac{\partial E}{X_{n\text{+1}}}}
\end{equation}

\end_inset


\end_layout

\begin_layout Itemize

\size larger
\begin_inset Formula $\boldsymbol{\nabla W}$
\end_inset


\size large
Gradient of weights.The gradient is a multi-variable generalization of the
 derivative.
\end_layout

\begin_layout Subsubsection
Learning rate
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
During the process of updating the weights, the learning rate is a hyperparamete
r that determines the size of the update step applied during the training
 of a neural network..
 It is a scalar value that is used to multiply the gradient of the loss
 function with respect to the weights of the network during gradient descent.
 The learning rate determines how fast the weights of the network are updated
 during training.
 A smaller learning rate results in slower updates, while a larger learning
 rate results in faster updates.
 The learning rate is typically set manually, and finding the optimal learning
 rate for a given problem is an important aspect of training a neural network.

\size default
 
\begin_inset CommandInset citation
LatexCommand cite
key "learningrate"
literal "false"

\end_inset

 
\end_layout

\begin_layout Standard

\size larger
\begin_inset Formula 
\begin{equation}
\boldsymbol{W_{n}=W_{n}-\gamma\nabla W}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard

\size larger
\begin_inset Formula 
\begin{equation}
\boldsymbol{b_{n}=b_{n}-\gamma\frac{\partial E}{X_{n}}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
If the learning rate is set too low, the optimization process may become
 stuck in a local minimum or local maximum.
 A local minimum is a point in the optimization landscape where the cost
 function has a lower value than the surrounding points, but is not the
 global minimum.
 A local maximum is a point where the cost function has a higher value than
 the surrounding points, but is not the global maximum.
 This can lead to suboptimal performance or even failure of the optimization
 process.
 On the other hand, if the learning rate is set too high, the optimization
 process may oscillate or diverge, also leading to suboptimal performance.
 It is important to choose an appropriate learning rate for the optimization
 process in order to avoid these problems.
\end_layout

\begin_layout Subsubsection
Basic code implementation
\end_layout

\begin_layout Standard

\size large
Although it may seem difficult to implement the code, it is actually quite
 simple as it involves encapsulating the results of the previous layer's
 calculations.
\end_layout

\begin_layout Standard

\size large
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
lstinputlisting[language=python]{Codigo/Linear.py}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
And a basic implmentation of the Linear Class.
\end_layout

\begin_layout Standard

\size large
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
lstinputlisting[language=python]{Codigo/TestLinear.py}
\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Activation functions 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Activation functions are used in neural networks to introduce non-linearity
 into the network.
 This is important because many real-world problems are non-linear in nature
 and a neural network with only linear functions would not be able to model
 such problems accurately.
 Activation functions allow the network to learn more complex patterns in
 the data and improve the accuracy of the network.
 They also help to prevent the network from becoming stuck in a local minimum
 or plateau during training.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/ActivationFunctions.png
	lyxscale 10
	scale 10

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Activation function.
 (a) Sigmoid, (b) tanh, (c) ReLU.
 
\begin_inset CommandInset citation
LatexCommand cite
key "ActivationFunctionsImages"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The most popular activation functions in neural networks are the sigmoid
 function, the hyperbolic tangent (tanh) function, and the rectified linear
 unit (ReLU) function.
 The sigmoid function maps any input value to a range between 0 and 1, while
 the tanh function maps input values to the range between -1 and 1.
 The ReLU function is a linear function that maps all negative input values
 to 0 and all positive input values to their original value.
\begin_inset CommandInset citation
LatexCommand cite
key "ActivationFunctions"
literal "false"

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
However, there are "hardened" versions of activation functions that can
 be evaluated computationally faster yet produce similar results.
 Examples of these include hardtanh and hardsigmoid.
 The Hardtanh function is defined as: 
\end_layout

\begin_layout Standard

\size larger
\begin_inset Formula 
\begin{equation}
\boldsymbol{hardtanh(x)=\begin{cases}
-1, & \text{if }x<-1\\
x, & \text{if }-1\le x\le1\\
1, & \text{if }x>1
\end{cases}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Hardtanh.png
	lyxscale 25
	scale 25

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Hardtanh(red) and Tanh(blue)
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Effective Techniques for Improving Model Generalization
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
In the field of machine learning, it is important to ensure that the models
 we build are able to accurately and effectively make predictions on new
 data.
 However, it is common for models to suffer from issues such as overfitting
 or poor generalization to new data.
 In this section, we will explore three techniques that can be used to improve
 the performance of machine learning models: 
\series bold
regularization
\series default
, 
\series bold
normalization
\series default
, and 
\series bold
standardization
\series default
.
 By properly applying these techniques, we can mitigate the risks of overfitting
 and improve the ability of our models to generalize to new data.
 
\begin_inset CommandInset citation
LatexCommand cite
key "Regularization_Bisong,Normalization_layers,standarization"
literal "false"

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\shape italic
\size large
\emph on
\bar under
\color black
Our data set, which includes doubly dispersive channels of a complex nature,
 requires extra attention.
 We will use distorted vectors or inverse matrices, which can result in
 numerical instability, as our ground truth.
 These extra precautions will help to guarantee the process' success.
 Ignoring these recommendations may result in unsatisfactory outcomes, as
 the neural network may not generalize as well and may perform poorly.
 
\begin_inset CommandInset citation
LatexCommand cite
key "ComplexnumbersNN"
literal "false"

\end_inset


\end_layout

\begin_layout Subsubsection
Regularization
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
Regularization is a technique used in machine learning to prevent overfitting.
 Overfitting occurs when a model is overly complex and captures the noise
 in the training data, rather than the underlying relationships.
 This results in poor generalization to new data.
 Regularization works by adding a penalty term to the objective function
 that the model is trying to minimize.
 This penalty term discourages the model from learning relationships that
 are too complex, and encourages it to learn simpler relationships that
 generalize better.
 There are several methods for regularization, including 
\begin_inset CommandInset citation
LatexCommand cite
key "Goodfellow-et-al-2016"
literal "false"

\end_inset

:
\end_layout

\begin_layout Enumerate
\align block

\size large
L1 regularization: This method adds a penalty term to the cost function
 that is proportional to the absolute value of the weights.
\end_layout

\begin_layout Enumerate
\align block

\size large
L2 regularization: This method adds a penalty term to the cost function
 that is proportional to the square of the weights.
\end_layout

\begin_layout Enumerate
\align block

\size large
Dropout regularization: This method randomly sets a fraction of the weights
 in the model to zero during training, which helps to prevent overfitting
 by reducing the number of parameters in the model.
 Dropout is only applied during the training process, and all neurons are
 available during evaluation.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename trasasdenivelRegularization.png
	lyxscale 50
	scale 60

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Level sets of the loss function and L1,L2 regularization 
\begin_inset CommandInset citation
LatexCommand cite
key "regimage"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
To implement regularization, you can modify the cost function of the model
 to include the regularization term.
 For example, in L2 regularization, the cost function would be modified
 to include the sum of the squares of the weights, as shown in the following
 equation:
\end_layout

\begin_layout Standard

\size larger
\begin_inset Formula 
\begin{equation}
\boldsymbol{J(W)=\frac{\lambda}{2}||w||^{2}=\frac{\lambda}{2}\sum_{j=1}^{m}w_{j}^{2}}
\end{equation}

\end_inset


\end_layout

\begin_layout Itemize

\size larger
\begin_inset Formula $\boldsymbol{\lambda}$
\end_inset

 
\size large
regularization parameter
\end_layout

\begin_layout Itemize

\size larger
\begin_inset Formula $\boldsymbol{J(W)}$
\end_inset

 
\size large
Cost function
\end_layout

\begin_layout Subsubsection
Normalization 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Data is scaled using a process called normalization to give it a unit norm
 (or length).
 This is frequently done to improve the data's suitability for particular
 machine learning algorithms, such as those that use gradient descent or
 have a set range for acceptable input data.
 When comparing various features, normalization can also be used to scale
 down the data to a common scale.
 Data normalization methods include min-max normalization, mean normalization,
 and z-score normalization.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\series bold
\size large
Normalization of complex numbers
\series default
 involves dividing a complex number by its magnitude (or absolute value)
 to obtain a complex number with a magnitude of 1.
 This is typically done to simplify calculations and make it easier to compare
 complex numbers.
 The normalized form of a complex number is often written as ẑ = z/|v|,
 where z is the original complex number and ẑ is the normalized form and
 |v| is the max magnitud of the entire vector of the complex numbers.
 Normalization of complex numbers is useful in many applications, including
 signal processing and control systems, where it is often necessary to compare
 complex numbers on an equal footing.
 
\begin_inset CommandInset citation
LatexCommand cite
key "ComplexnumbersNN"
literal "false"

\end_inset


\end_layout

\begin_layout Standard

\size larger
\begin_inset Formula 
\begin{equation}
\boldsymbol{ẑ=\frac{z}{|v|}}
\end{equation}

\end_inset


\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\boldsymbol{|v|}$
\end_inset

 Maximum magnitud of the vector
\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\mathsf{\boldsymbol{z}}$
\end_inset

 Input value
\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\boldsymbol{ẑ}$
\end_inset

 Normalized value
\end_layout

\begin_layout Subsubsection
Standarization 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
Standardization is a method used in machine learning to transform the values
 of a feature or set of features to a standard scale.
 The standard scale is typically defined as having a mean of 0 and a standard
 deviation of 1.
 Standardization is often used as a preprocessing step before training a
 model, as it can help to improve the performance and convergence of the
 model.
 Standardization can be useful when the features in the dataset have different
 scales or units, as it can help to bring them onto a common scale and make
 it easier for the model to learn from the data.
 Standardization can be applied to both real and complex-valued data.
\end_layout

\begin_layout Standard

\size larger
\begin_inset Formula 
\begin{equation}
\boldsymbol{\hat{z}=\frac{z-\mu}{\sigma}}
\end{equation}

\end_inset


\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\boldsymbol{\mu}$
\end_inset

 Mean of the data
\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\boldsymbol{\sigma}$
\end_inset

 Standard deviation of the data
\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\mathsf{\boldsymbol{z}}$
\end_inset

 Input value
\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\boldsymbol{ẑ}$
\end_inset

 Standarized value
\end_layout

\begin_layout Subsection
Convolutional Neuronal Networks
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
A convolutional neural network (CNN) is a type of deep learning neural network
 that is primarily used for image and video recognition.
 It is designed to process data that has a grid-like topology, such as an
 image.
 The network is composed of multiple layers, including 
\series bold
convolutional layers
\series default
, 
\series bold
activation layers
\series default
, 
\series bold
pooling layers 
\series default
and
\series bold
 linear layers
\series default
.
 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The convolutional layers apply a set of filters to the input data, where
 each filter is a small matrix of weights.
 This ones are used to identify features in the data such as 
\series bold
edges
\series default
, 
\series bold
textures
\series default
, and 
\series bold
shapes
\series default
, specifically, we will be utilizing these layers to extract the relationship
 of intercarrier symbol interference (ISI) and to perform dimensionality
 reduction.
 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\size large
The 
\series bold
activation layers
\series default
 or activation functions introduce non-linearity to the network, allowing
 it to learn complex representations of the input data.
 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\size large
The 
\series bold
pooling layers
\series default
 reduce the spatial dimensions of the data, which helps to reduce overfitting
 and computational cost.
\end_layout

\begin_deeper
\begin_layout Itemize
\paragraph_spacing onehalf

\size large
Max pooling is used to pick the feature with the highest activation in a
 small region of the input feature map
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\size large
Average pooling is used to reduce the spatial size of the input data by
 taking the average of the values of a small region of the input feature
 map.
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Diagrams/Max_pool_avg_pool.jpg
	lyxscale 40
	scale 20

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Average and max pooling
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Itemize
\noindent
\align block

\series bold
\size large
Linear layers
\series default
 classify the features extracted by the convolutional layers into the desired
 output.
\end_layout

\begin_layout Standard
\noindent
\align block

\size large
It should be noted that what is commonly referred to as 'convolution' in
 the context of convolutional neural networks (CNNs) is actually a cross-correla
tion operation, denoted with symbol 
\begin_inset Formula $\mathbf{\bigstar}$
\end_inset

 and convolution usually is used 
\begin_inset Formula $\boldsymbol{*}$
\end_inset

.
 The term 'convolution' is used only for convention purposes.
 The basic concept behind cross-correlation is to take a small matrix, referred
 to as a kernel or filter, and slide it over the input data (such as an
 image or audio signal).
 At each position, the kernel is multiplied element-wise with the underlying
 data, and the results are summed to produce a single output value, referred
 to as a feature map.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Diagrams/Conv2d_Kernel.jpg
	lyxscale 30
	scale 25

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Caption Standard

\begin_layout Plain Layout
Basic cross-correlation operation
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
The output of the convolution operation is a feature map, where each element
 in the feature map is computed as follows:
\end_layout

\begin_layout Standard

\size larger
\begin_inset Formula 
\begin{equation}
\boldsymbol{Y_{ij}=\sum K_{ab}\circ I_{i+a,j+b}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Where kernel(a,b) is the value of the filter at position (a,b), input(i+a,j+b)
 is the value of the input at position (i+a,j+b) and output(i,j) is the
 output value at position (i,j)
\end_layout

\begin_layout Subsubsection
Channels
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
A channel refers to a specific feature or dimension of the input data.
 For example, in the case of image data, a channel can represent a color
 channel such as red, green, or blue.
 These channels are used to extract different features of the input image,
 and they are processed separately by the CNN.
 In our case study, we can use channels as a division between the real and
 imaginary parts, or for feature extraction of intercarrier symbol interference
 (ISI).
 We can have N channels as input and M channels as output, depending on
 how many features we want to deal with.
 In the image below, we show a case of 3 channel input and two channel output,
 also with a bias term.
\size default

\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/ConvolutionExpansion.png
	lyxscale 50
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Convolutional Neural Network with 3-channel Input and 2-channel Output,
 including bias term
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
A Generalized View of Linear Layers through Convolutional Neural Networks
\end_layout

\begin_layout Standard

\size large
Let's take a more detailed look at the math, given the following terms.
\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\boldsymbol{j}$
\end_inset

 input channels with
\begin_inset Formula $\boldsymbol{X_{j}}$
\end_inset

 matrices
\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\boldsymbol{d}$
\end_inset

 ouput channels 
\begin_inset Formula $\boldsymbol{Y_{d}}$
\end_inset

matrices and this ones an output size of 
\begin_inset Formula $\boldsymbol{X_{j}-K_{ij}}$
\end_inset


\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\boldsymbol{K_{ij}}$
\end_inset

 kernels,where 
\begin_inset Formula $\boldsymbol{i}$
\end_inset

 maps to 
\begin_inset Formula $\boldsymbol{Y_{d}}$
\end_inset

 and 
\begin_inset Formula $\boldsymbol{j}$
\end_inset

 to 
\begin_inset Formula $\boldsymbol{X_{j}}$
\end_inset


\end_layout

\begin_layout Itemize
\noindent
\align block

\size large
\begin_inset Formula $\mathbf{\bigstar}$
\end_inset

 cross-correlation
\end_layout

\begin_layout Standard

\size larger
\begin_inset Formula 
\begin{equation}
\boldsymbol{Y_{d}=B_{d}+\sum_{j=1}^{n}X_{j}\bigstar K_{ij}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
We can think of the matrices as individual blocks and visualize them in
 the image below.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Conv2dGeneralization.png
	lyxscale 40
	scale 60

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset Formula $Y_{d}$
\end_inset

 output given kernels
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Finally, with the use of abstraction, we can further simplify the problem
 by representing it as a generalized version of tensors.
 The internal tensor is given by the sum of the cross-correlations between
 X channels and kernels.
 In a more general perspective, this can be viewed as the inner product
 of two tensors.
\end_layout

\begin_layout Standard

\size larger
\begin_inset Formula 
\begin{equation}
\boldsymbol{Y=B+\langle K,X\rangle}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/MetaDense.png
	lyxscale 50
	scale 70

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Higher dimensionality abstract version 
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
It's worth noting that when we consider a kernel of 1 dimension and an input
 of 1 channel, we can see that a dense layer is just a specific case of
 a 2D convolutional layer (Conv2D).
 Just as equation (15) and figure (8)
\end_layout

\begin_layout Subsection
Motivation
\end_layout

\begin_layout Subsection
Objectives
\end_layout

\begin_layout Subsubsection
General Objective
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
We should analyze and test different techniques of neural networks applied
 to frequency channel equalization, which is commonly used in OFDM.
 The NN models will be based on existing equalizers with well-known equations.
\end_layout

\begin_layout Subsubsection
Particular Objective
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
Our objective is to equalize a double dispersive channel, also known as
 a frequency-time channel and intercarrier symbol interference (ISI) through
 the utilization of various neural network strategies.
 These strategies will focus on specific stages of the existing equalization
 process.
 We aim to leverage the non-linearity of neural networks and employ techniques
 such as dimensionality expansion and reduction.
 Our aim is to recover QAM and PSK constellation symbols that have been
 distorted by a channel with both line-of-sight (LOS) and non-line-of-sight
 (NLOS) conditions, plus Gaussian noise.
 Our ultimate goal is to achieve a bit error rate (BER) comparable to that
 of the "golden models" or to reduce the computational complexity of current
 methods.
\end_layout

\begin_layout Section
State of Art
\end_layout

\begin_layout Section
Present work
\end_layout

\begin_layout Section
Results and Analysis
\end_layout

\begin_layout Section
Conclusion and Outlook
\end_layout

\begin_layout Subsection
Future Work
\end_layout

\begin_layout Section
References
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset CommandInset bibtex
LatexCommand bibtex
btprint "btPrintCited"
bibfiles "Bibliography"
options "plain"

\end_inset


\end_layout

\begin_layout Standard

\end_layout

\begin_layout Standard

\end_layout

\begin_layout Standard

\end_layout

\begin_layout Standard

\end_layout

\begin_layout Standard

\end_layout

\end_body
\end_document
