#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\begin_preamble
\usepackage{helvet}
\renewcommand{\familydefault}{\sfdefault}
\usepackage{ragged2e}
\usepackage{blindtext}
\usepackage{fancyhdr}
\usepackage{algorithm}
\usepackage{algpseudocode}
\pagestyle{fancy}
\fancyhead{}
\fancyhead[RO,LE]{Doubly dispersive channels equalization using deep learning techniques}
\fancyfoot[CO,RE]{Emilio Tonix}
\fancyfoot{}
\fancyfoot[LE,RO]{\thepage}
\fancyfoot[CO,RE]{Emilio Tonix}

\usepackage{listings}
\usepackage{xcolor}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}


\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}

\lstset{style=mystyle}
\end_preamble
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "Courier"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family rmdefault
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref true
\pdf_bookmarks true
\pdf_bookmarksnumbered false
\pdf_bookmarksopen false
\pdf_bookmarksopenlevel 1
\pdf_breaklinks false
\pdf_pdfborder true
\pdf_colorlinks false
\pdf_backref false
\pdf_pdfusetitle true
\papersize default
\use_geometry true
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 2.5cm
\topmargin 2.5cm
\rightmargin 2.5cm
\bottommargin 2.5cm
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Standard
\align center
\begin_inset Graphics
	filename Imagenes/Cinvestav_Logo-transformed.jpeg
	lyxscale 13
	scale 12

\end_inset


\end_layout

\begin_layout Standard
\align center

\size larger
Centro de Investigación y de Estudios Avanzados del I.P.N 
\end_layout

\begin_layout Standard
\align center

\size larger
Unidad Guadalajara 
\end_layout

\begin_layout Standard
\align center

\end_layout

\begin_layout Standard
\align center

\series bold
\size huge
\color black
Exploring Deep Learning Techniques for Equalizing Doubly Dispersive Channels
\end_layout

\begin_layout Standard

\series bold
\color white
.
\end_layout

\begin_layout Standard
\align center

\size larger
\color black
A thesis presented by:
\end_layout

\begin_layout Standard
\align center

\series bold
\size larger
\color black
Luis Emilio Tonix Gleason
\end_layout

\begin_layout Standard
\align center

\size larger
\color black
to obtain the degree of:
\end_layout

\begin_layout Standard
\align center

\series bold
\size larger
\color black
Master in Science
\end_layout

\begin_layout Standard
\align center

\size larger
\color black
in the subject of:
\end_layout

\begin_layout Standard
\align center

\series bold
\size larger
\color black
Electrical Engineering
\end_layout

\begin_layout Standard
\align center

\size larger
\color black
Thesis Advisors:
\end_layout

\begin_layout Standard
\align center

\series bold
\size larger
\color black
Dr.
 Ramón Parra Michel
\end_layout

\begin_layout Standard
\align center

\series bold
\size larger
\color black
Dr.
 Fernando Peña Campos
\end_layout

\begin_layout Standard
\align center

\end_layout

\begin_layout Standard
\align center

\series bold
\size larger
\color black
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill Guadalajara, Jalisco 
\backslash
today
\end_layout

\end_inset

 
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newpage
\end_layout

\end_inset


\end_layout

\begin_layout Section*
\noindent

\size huge
\color black
Acknowledgment 
\size large
\color inherit

\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newline
\end_layout

\end_inset

 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent
\align block

\size large
Thank you for reading this; I appreciate it.
 I'm expecting that your work will benefit greatly from this material.
 I won't hesitate to say that you might have done your job more effectively
 than I did.
 Progress in science is a way to skepticism and having the best information
 from multiple sources to meet your individual standards.
  
\end_layout

\begin_layout Standard

\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newpage
\end_layout

\end_inset


\end_layout

\begin_layout Section*

\size huge
Resumen 
\size large

\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newline
\end_layout

\end_inset

 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent
\align block

\size large
En la actualidad, la tecnología de redes de comunicación inalámbricas de
 alta movilidad está en constante evolución, y tiene aplicaciones en diversos
 ámbitos, tales como la seguridad vial, la conducción autónoma, el monitoreo
 remoto de vehículos, el vuelo de drones y los requisitos de 6G.
 Los transmisores RF, que se emplean en los sistemas de telecomunicaciones
 para transmitir información, codifican dicha información a través de la
 amplitud y la fase de una señal portadora, comúnmente conocida como datos
 IQ.
 Sin embargo, al viajar a través de un canal de alta movilidad, estos datos
 sufren distorsión, debido a la dispersión doble de dicho canal, lo que
 implica que las propiedades de la señal se ven afectadas por el desplazamiento,
 difusión en el tiempo y la frecuencia.
 Aunque existen algoritmos tradicionales que requieren ecualizadores iterativos
 complejos, que pueden ser lentos en términos de tiempo de ejecución pero
 precisos, también existen ecualizadores más sencillos, aunque menos precisos.
 El propósito de este trabajo es examinar diversas soluciones basadas en
 redes neuronales para la tarea de equalización en el procesamiento de señales.
 El enfoque principal es encontrar un equilibrio óptimo entre la complejidad
 temporal de la solución y su rendimiento en la tarea de equalización.
 Para lograr este objetivo, se seguirá una metodología que involucra la
 evaluación de una serie de redes neuronales organizadas desde las más sencillas
 hasta las más complejas.
 Cada red neuronal será evaluada en términos de su rendimiento y complejidad
 para compararlas adecuadamente y determinar los compromisos necesarios
 para su implementación.
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newline
\end_layout

\end_inset

 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
Es posible afirmar que los algoritmos convencionales han demostrado ser
 eficaces en la tarea de equalización en esquemas de modulación como LTE
 y Wi-Fi.
 Sin embargo, los recientes avances en redes neuronales han simplificado
 problemas que antes eran intratables, como el descifrado de secuencias
 de ADN o la creación de imágenes a partir de texto.
 En resumen, abordan con éxito problemas no lineales.
 El objetivo de este trabajo es imitar técnicas de ecualización conocidas
 con naturaleza lineal, como los ecualizadores Zero Forcing, MSE, LMMSE
 y no lineales como OSIC y NearML.
 Durante las pruebas que se realizaron, se hizo un seguimiento de diversos
 tamaños de constelaciones y tasas de error de bits en una variedad de situacion
es con interferencia y ruido.
 En los resultados de la investigación experimental, se demostró que la
 tasa de error de bits(BER) y la tasa de bloques (BLER) disminuyó y se acercó
 o incluso superó los modelos de oro, que son los ecualizadores mencionados
 anteriormente.
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newline
\end_layout

\end_inset

 
\end_layout

\begin_layout Standard
\align block

\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
Los últimos enfoques en investigación literaria han demostrado diversas
 estrategias que se aproximan a lograr una buena ecualización con redes
 nueronales.
 Sin embargo, estos enfoques se basan en métodos tradicionales y no cubren
 todas las etapas de la ecualización, además de tener escenarios relativamente
 simples en comparación con el canal que se estudiará en este trabajo.
 Por lo tanto, se abordan incluso condiciones tales como canales de línea
 de vista o la falta de ella.
 Por último, pero no menos importante, la presentación de los métodos desarrolla
dos en esta investigación busca establecer un punto de partida para futuras
 investigaciones en un campo de la comunicación prácticamente inexplorado
 por algunos equipos.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newpage
\end_layout

\end_inset


\end_layout

\begin_layout Section*

\size huge
Abstract
\size large
 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newline
\end_layout

\end_inset

 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
Due to their primary uses in control, road safety, autonomous driving, remote
 monitoring of vehicles, drone flying, and 6G needs, the development of
 high-mobility wireless communication networks is cutting-edge technology.
 The RF broadcasts, which are used by telecommunications systems to transfer
 encoded information over the amplitude and phase of a carrier signal, are
 normally called IQ data.
 However, this data is distorted as it travels through a high mobility channel.
 High mobility channels are doubly dispersive, which means that the signal
 properties are mixed with some temporal frequency shifting and spreading.
 There are some traditional algorithms that may require complex iterative
 equalizers that can be slow in terms of execution time.
 However, there are also simpler equalizers that may not be as precise.
 The aim of this study is to investigate different neural network-based
 solutions for signal processing equalization.
 The primary objective is to achieve an optimal balance between the solution's
 temporal complexity and its performance in equalization.
 To attain this objective, we will follow a methodology that entails evaluating
 a range of neural networks arranged from simple to complex.
 Performance and complexity will be assessed for each neural network to
 facilitate a fair comparison and determine the required trade-offs for
 implementation.
 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
Conventional algorithms have demonstrated their effectiveness in the equalizatio
n task for modulation schemes like LTE and Wi-Fi.
 However, recent advances in neural networks have simplified problems that
 were previously intractable, such as deciphering DNA sequences or creating
 images from text.
 In short, they successfully tackle non-linear issues.
 The objective of this work is to mimic well-known equalization techniques
 with linear properties such as Zero Forcing, MSE, and LMMSE, as well as
 non-linear techniques like OSIC and NearML equalizers.
 Various constellation sizes and bit error rates were monitored during the
 tests conducted in various scenarios with interference and noise.
 The experimental results indicated that the bit error rate (BER) and block
 error rate (BLER) decreased and approached, or even exceeded, the gold
 standard models of equalizers mentioned earlier.
 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newline
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Recent studies in literature have proposed multiple strategies to achieve
 effective equalization with neuronal networks.
 However, these methods rely on traditional approaches and fail to cover
 all aspects of equalization, and their scenarios are relatively simpler
 than the channel under consideration in this work.
 As a result, we investigate conditions such as line of sight channels or
 their absence.
 Finally, this study aims to provide a starting point for future investigations
 in a field of communication that remains unexplored by some teams.
 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newline
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent
\align block

\end_layout

\begin_layout Standard
\begin_inset CommandInset toc
LatexCommand tableofcontents

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newpage
\end_layout

\end_inset


\end_layout

\begin_layout Standard

\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
This chapter's main goal is to provide an overview of the technical facts
 and some of the current issues that prompted this study.
\end_layout

\begin_layout Subsection
Document organization
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The structure of this document is as follows: 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\series bold
\size large
Chapter 1 Theoretical Framework: 
\series default
Fundamental ideas and concepts behind the current project.
 Outlines the core concepts necessary to comprehend this study
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\series bold
\size large
Chapter 2 State of Art:
\series default
 This section examines recent research on equalization using deep learning.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\series bold
\size large
Chapter 3 Methodology:
\series default
 This work presents a Python implementation of various models for training
 and testing different experiments, along with an overview of the software
 architecture that enables these experiments.
 The primary focus is on developing explainable deep learning models for
 Quadrature Amplitude Modulation (QAM) equalization using neural networks,
 including the design of the proposed models.
 Additionally, each network's features are described, such as preprocessing,
 number of parameters, hyperparameters, and references to the state-of-the-art
 that support certain development stages.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\series bold
\size large
Chapter 4 Results and Analysis:
\series default
 This section covers the conception and execution of our idea, the experiments
 conducted, and the analysis of the results.
 We provide a comparison of our studied models in graphs and tables, focusing
 on their bit error rate (BER), block error rate (BLER), floating-point
 operations per second (FLOPS), and complexity.
 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\series bold
\size large
Chapter 5 Conclusion and Outlook: 
\series default
A conclusion is drawn based on the results, contributions, and potential
 future directions of this study.
\end_layout

\begin_layout Subsection
\paragraph_spacing onehalf
Background
\end_layout

\begin_layout Standard

\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
It takes a lot of expertise in the field of communications to model different
 types of channels, account for various channel flaws, and create the best
 signaling and detecting systems that guarantee a reliable data flow.
 The design of transmit signals in communications enables simple analytical
 techniques for symbol detection for a range of channel and system models,
 including multipath, doppler spread, and white Gaussian noise (AWGN) over
 constellation symbol detection.
 
\begin_inset CommandInset citation
LatexCommand cite
key "aghvami2005channel"
literal "false"

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newline
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
One of the guiding principles of communication system design is the division
 of signal processing into a series of distinct blocks, each of which performs
 a clearly defined and isolated functions such as source or channel coding,
 modulation, channel estimation, and equalization.
 This strategy has made it possible for us to have the effective, adaptable,
 and controlled systems we have today, but it is not certain whether individuall
y tuned processing blocks will yield the best end-to-end performance 
\begin_inset CommandInset citation
LatexCommand cite
key "proakis2002communication"
literal "false"

\end_inset

.
 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newline
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Diagrams/Typical_Block_Diagram.png
	lyxscale 50
	scale 40

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Typical communication system block diagram 
\begin_inset CommandInset citation
LatexCommand cite
key "ChannelDiagram"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
While dividing signal processing into distinct blocks has been a guiding
 principle of communication system design, it is important to consider how
 this strategy might evolve in the future.
 With the development of 6G networks, there is a growing interest in creating
 an "AI-native" architecture that can self-learn and adapt to changing network
 dynamics.
 Adopting processing blocks capable of solving individual stages of the
 channel can potentially help us achieve better end-to-end performance in
 communication systems.
 
\begin_inset CommandInset citation
LatexCommand cite
key "The_Roadmap_to_6G"
literal "false"

\end_inset

.
 It has been demonstrated that NNs are capable of approximating any function
 
\begin_inset CommandInset citation
LatexCommand cite
key "HORNIK1989359"
literal "false"

\end_inset

, and current research has demonstrated an astounding aptitude for algorithmic
 learning 
\begin_inset CommandInset citation
LatexCommand cite
key "8697857"
literal "false"

\end_inset

.
 Due to the challenge of defining real-world images or language with strict
 mathematical models, deep learning (DL) excels in fields like computer
 vision and natural language processing.
 For example, while it is now simple to develop DL algorithms that learn
 to complete this task with accuracy greater than that of humans 
\begin_inset CommandInset citation
LatexCommand cite
key "Surpassing_Human_Level_Performance"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Machine learning is known to focus on non-linear solutions, which can explore
 more complex and better-fitting solutions.
 In this research, we will specifically focus on the equalization block
 using various proposed networks.
 It is assumed that other channel blocks will perform optimally, allowing
 us to focus solely on the equalization block.
 By doing this, we hope to gain insight into the performance of different
 network proposals and determine which one is best suited for the task of
 equalization.
\end_layout

\begin_layout Subsection
OFDM
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
Orthogonal Frequency Division Multiplexing (OFDM) is a digital communication
 technique that divides the available bandwidth into a large number of narrowban
d subcarriers and transmits data by modulating the subcarriers with symbols.
 OFDM is widely used in wireless and wired communication systems, such as
 Wi-Fi, LTE, and DOCSIS, which are described by well-known standards, as
 referenced follows 
\begin_inset CommandInset citation
LatexCommand cite
key "WiFi"
literal "false"

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "LTE"
literal "false"

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "docsis4"
literal "false"

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent
\align block

\size large
The basic blocks of an OFDM system are:
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Diagrams/OFDM_typical.png
	lyxscale 50
	scale 40

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
OFDM basic diagram 
\begin_inset CommandInset citation
LatexCommand cite
key "OFDMdiagram"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Itemize

\series bold
\size large
Binary sequence
\series default
: This block generates the data to be transmitted.
 The data is usually a sequence of bits.
\end_layout

\begin_layout Itemize
\align block

\series bold
\size large
QAM mapping
\series default
: Bits are grouped into blocks called symbols usally named as alphabet 
\begin_inset Formula $\boldsymbol{\mathbb{A}}$
\end_inset

.
 We have a set of bits 
\begin_inset Formula $2^{\mathbb{A}}$
\end_inset

 grouped inside the alphabet.
 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\align block

\series bold
\size large
IFFT block
\series default
: This block applies an Inverse Fast Fourier Transform (IFFT) to the modulated
 symbols, dividing them into a set of subcarriers.
\end_layout

\begin_layout Itemize
\align block

\series bold
\size large
Cyclic prefix
\series default
: Helps OFDM symbols to reduce inter-symbol interference.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
At regular intervals, the transmitter inserts recognizable symbols known
 as "pilots" into the transmitted signal.
 These pilots are selected to have a known value and to be separated from
 one another by a given number of symbols.
 This estimation involves analyzing the correlations between the received
 signal and the known pilot symbols, and then using this information to
 estimate the channel response.
 Using the estimated channel response, the receiver then performs channel
 equalization to remove the distortions caused by the communication channel
 from the received signal 
\begin_inset CommandInset citation
LatexCommand cite
key "ChannelEstimation1"
literal "false"

\end_inset

, and also there are more complex methods that can handle delay-time channel
 estimation in an efficient embbeded pilot 
\begin_inset CommandInset citation
LatexCommand cite
key "ChannelEstimation2"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The research team has already completed a project on channel estimation
 and equalization, using classical QR methods 
\begin_inset CommandInset citation
LatexCommand cite
key "QRGonzalo"
literal "false"

\end_inset

 and an FPGA
\begin_inset CommandInset citation
LatexCommand cite
key "FPGADef"
literal "false"

\end_inset

 implementation for the equalization stage.
 For this current research, our focus is solely on the equalization stage,
 and we will not prioritize the channel estimation component.
 Our goal is to cancel the effects of the well-known received channel during
 the communication process.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Our research is focused on the generalization of the pseudo-inverse using
 neural networks to cancel out channel effects.
 The pseudo-inverse is a well-known technique used to solve the problem
 of matrix inversion when the matrix is not invertible or is singular 
\begin_inset CommandInset citation
LatexCommand cite
key "strang2019linear"
literal "false"

\end_inset

.
 While the pseudo-inverse is a well-known technique used to solve the problem
 of matrix inversion, it's important to note that the matrix inverse is
 not always well-defined.
 In addition, numerical instability can also pose a challenge.
 To address these issues, we mainly use invertible matrices, and we also
 incorporate regularization methods to avoid singular matrices.
 This approach more accurately simulates real-world scenarios.
 Another aspect that our research addresses is the use of complex numbers
 in neural networks, which can add an additional layer of complexity to
 the problem.
\end_layout

\begin_layout Subsubsection
Advantages and Disadvantages in OFDM
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
The advantages offered by OFDM systems in broadband systems are as follows
 
\begin_inset CommandInset citation
LatexCommand cite
key "ofdm_book"
literal "false"

\end_inset

:
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\align block

\series bold
\size large
High spectral efficiency
\series default
: OFDM can transmit a large amount of data over a wide frequency band by
 dividing the available bandwidth into multiple narrowband subcarriers.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\align block

\series bold
\size large
Robustness to channel impairments
\series default
: OFDM is less sensitive to frequency-selective fading and interference
 than other multiplexing techniques, making it well-suited for use in wireless
 communication systems.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\align block

\series bold
\size large
Ease of implementation
\series default
: OFDM can be implemented using simple digital signal processing techniques,
 making it relatively easy to design and implement.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
Some disadvantages of OFDM include:
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\align block

\series bold
\size large
High peak-to-average power ratio
\series default
: OFDM signals have a high peak-to-average power ratio, which can cause
 problems in power amplifier systems and limit the range of the transmitted
 signal.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\align block

\series bold
\size large
Sensitivity to timing errors: 
\series default
OFDM is sensitive to timing errors, which can cause inter-symbol interference
 and reduce the performance of the system.
\end_layout

\begin_layout Itemize

\series bold
\size large
Sensitivity to Doppler spread:
\series default
 Doppler spread causes interference between the subcarriers.
\end_layout

\begin_layout Subsection
QAM and IQ data
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
QAM (Quadrature Amplitude Modulation) 
\begin_inset CommandInset label
LatexCommand label
name "subsec:QAM-and-IQ"

\end_inset

is a type of digital modulation that encodes data onto a carrier signal
 by modulating the amplitude and phase of the signal.
 It is commonly used in digital communication systems to transmit digital
 data over analog channels.
 IQ data refers to the in-phase and quadrature components of a complex-valued
 signal.
 In digital communication systems, the IQ data is typically used to represent
 the amplitude and phase of the modulated carrier signal.
 It's ussualy represented with complex numbers in an alphabet 
\begin_inset Formula $\mathbb{A}\in\mathbb{C}^{n}$
\end_inset

.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Diagrams/16QAM.png
	lyxscale 20
	scale 20

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Caption Standard

\begin_layout Plain Layout
16-QAM constellation 
\begin_inset CommandInset citation
LatexCommand cite
key "wiki_16qam"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\size large
 In the field of communication systems, a QAM constellation refers to a
 graphical representation of the symbol points in an alphabet on the complex
 plane.
 Each point represents a specific combination of the in-phase and quadrature
 components of the modulated signal.
 The number of points in the constellation is determined by the number of
 possible combinations of in-phase and quadrature values, which is in turn
 determined by the number of bits per symbol used in the QAM modulation
 scheme.
 For instance, in a 16-QAM constellation, there are 16 symbol points arranged
 in a square grid, with each point corresponding to 4 bits of data.
 The distance between points in the constellation serves as an indicator
 of the signal-to-noise ratio required for reliable transmission of the
 data.
 It is common for QAM constellations to utilize gray code for assigning
 the symbol points in a manner that minimizes the error rate.
 However, this is not the only method that can be employed for this purpose
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/QAM_noise.jpg
	lyxscale 80
	scale 50

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
QPSK and 16 QAM with noise and phase displacement 
\begin_inset CommandInset citation
LatexCommand cite
key "QAMwithNoise"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
SNR
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
SNR 
\begin_inset CommandInset label
LatexCommand label
name "subsec:SNR"

\end_inset

stands for Signal-to-Noise Ratio which contrasts the strength of the signal
 with the strength of the noise.
 The most common way to measure it is in decibels (dB).
 In general, higher numbers indicate a better specification because there
 is a greater ratio of useful information (the signal) to unwanted data
 (the noise).
 Given this source 
\begin_inset CommandInset citation
LatexCommand cite
key "PythonModulation"
literal "false"

\end_inset

, it can be explained how the noise is calculated for noise simulation with
 the requirement of a certain SNR in dB.
\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent

\size large
Firstly, a vector 
\begin_inset Quotes eld
\end_inset


\begin_inset Formula $\boldsymbol{s}$
\end_inset


\begin_inset Quotes erd
\end_inset

 that represents the signal transmitted over a communication channel is
 considered.
 The objective is to derive a vector 
\begin_inset Quotes eld
\end_inset


\begin_inset Formula $\boldsymbol{r}$
\end_inset


\begin_inset Quotes erd
\end_inset

 that represents the signal received at the receiver after passing through
 the Additive White Gaussian Noise (AWGN), this noise type is described
 in 
\begin_inset CommandInset citation
LatexCommand cite
key "papoulis2002probability"
literal "false"

\end_inset

.
 The level of noise introduced by the AWGN channel is determined by the
 provided Signal-to-Noise Ratio (SNR), and it is denoted as 
\begin_inset Quotes eld
\end_inset


\begin_inset Formula $\boldsymbol{\gamma}$
\end_inset


\begin_inset Quotes erd
\end_inset

\SpecialChar endofsentence

\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent

\size large
The length of the vector 
\begin_inset Quotes eld
\end_inset


\begin_inset Formula $\boldsymbol{s}$
\end_inset


\begin_inset Quotes erd
\end_inset

 is denoted by 
\begin_inset Formula $\boldsymbol{N}$
\end_inset

.
 The signal power of the vector 
\begin_inset Quotes eld
\end_inset


\begin_inset Formula $\boldsymbol{s}$
\end_inset


\begin_inset Quotes erd
\end_inset

 can be expressed as follows:
\end_layout

\begin_deeper
\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{P_{signal}=\frac{1}{N}\sum_{i=0}^{N-1}|s_{i}|^{2}}
\end{equation}

\end_inset


\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent

\size large
If we have a complex IQ value 
\begin_inset Formula $\boldsymbol{s_{i}=a_{i}+jb_{i}}$
\end_inset

, the modulus or magnitude of 
\begin_inset Formula $\boldsymbol{s_{i}}$
\end_inset

 can be represented by 
\begin_inset Formula $\boldsymbol{|s_{i}|=\sqrt{a_{i}^{2}+b_{i}^{2}}}$
\end_inset

, where a and b are real numbers.
\end_layout

\end_deeper
\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent

\size large
To compute the power spectral density of the noise vector 
\begin_inset Quotes eld
\end_inset


\begin_inset Formula $\boldsymbol{n}$
\end_inset


\begin_inset Quotes erd
\end_inset

, we use the following equation:
\end_layout

\begin_deeper
\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{N_{o}=\frac{P_{signal}}{\gamma}=P_{signal}\times10^{-\frac{SNR_{dB}}{10}}}
\end{equation}

\end_inset


\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent

\size large
Where 
\begin_inset Formula $\boldsymbol{\boldsymbol{\gamma}=10^{\frac{SNR_{dB}}{10}}}$
\end_inset

 is the SNR in dB to linear scale
\end_layout

\end_deeper
\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent

\size large
Assuming a complex IQ plane for all digital modulations, the noise variance
 (noise power) required for generating Gaussian random noise can be expressed
 as follows:
\end_layout

\begin_deeper
\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{\sigma^{2}=\frac{N_{0}}{2}}
\end{equation}

\end_inset


\end_layout

\end_deeper
\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent

\size large
Then, the Gaussian random noise vector 
\begin_inset Quotes eld
\end_inset


\begin_inset Formula $\boldsymbol{n}$
\end_inset


\begin_inset Quotes erd
\end_inset

 of length 
\begin_inset Formula $\boldsymbol{N}$
\end_inset

 is generated, with its samples drawn from a Gaussian distribution having
 a mean of zero and a standard deviation as calculated using the last equation.
\end_layout

\begin_deeper
\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{f(x)=\begin{cases}
\sigma\times\mathcal{N}_{N}(0,1), & \text{if \ensuremath{s} is real}\\
\sigma\times\left[\mathcal{N}_{N}(0,1)+j*\mathcal{N}_{N}(0,1)\right], & \text{if \ensuremath{s} is complex}
\end{cases}}
\end{equation}

\end_inset


\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent

\size large
Here, 
\begin_inset Formula $\boldsymbol{\mathcal{N}_{N}(0,1)}$
\end_inset

 represents the white Gaussian noise vector with a mean of 0 and a standard
 deviation of 1
\end_layout

\end_deeper
\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent

\size large
Lastly, the generated noise vector is added to the original signal 
\begin_inset Formula $\boldsymbol{s}$
\end_inset

.
\end_layout

\begin_deeper
\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{r=s+n}
\end{equation}

\end_inset


\end_layout

\end_deeper
\begin_layout Subsubsection
BER
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
In digital communication systems, 
\begin_inset CommandInset label
LatexCommand label
name "subsec:BER"

\end_inset

the transmission of data is not always error-free.
 Bit errors may occur due to various factors such as noise, interference,
 distortion, and fading.
 Bit Error Rate (BER) is a common metric used to quantify the quality of
 a digital communication system by measuring the probability of bit errors.
 BER is defined as the ratio of the number of erroneous bits to the total
 number of transmitted bits.
 It is usually expressed in terms of power, as the probability of error
 is dependent on the signal-to-noise ratio (SNR) and the channel conditions.
 The BER can be mathematically represented as follows:
\end_layout

\begin_layout Standard

\size large
\begin_inset Formula 
\begin{equation}
\mathsf{\boldsymbol{BER=\frac{N_{err}}{N_{tot}}}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
where 
\begin_inset Formula $N_{err}$
\end_inset

 is the number of erroneous bits and 
\begin_inset Formula $N_{tot}$
\end_inset

 is the total number of transmitted bits.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The bit error rate (BER) can be defined in terms of the probability of error
 (POE).
 The POE can be calculated using three other variables: the error function
 (erf), the energy per bit (Eb), and the noise power spectral density (No).
\end_layout

\begin_layout Itemize

\size large
The error function,
\begin_inset Formula $\mathrm{erf}(x)=\frac{2}{\sqrt{\pi}}\int_{0}^{x}e^{-t^{2}}dt$
\end_inset

, is used to calculate the POE, and its value depends on the modulation
 method used in the communication system.
 
\end_layout

\begin_layout Itemize

\size large
The energy per bit, 
\begin_inset Formula $Eb$
\end_inset

, is a measure of the signal strength and can be calculated by dividing
 the carrier power by the bit rate.
 
\end_layout

\begin_layout Itemize

\size large
The noise power spectral density, No, is a measure of the noise present
 in the communication channel and is typically expressed in units of power
 per Hz.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
By using these three variables, the POE can be calculated, and thus the
 BER can be expressed in terms of POE.
 This provides a measure of the communication system's performance that
 takes into account both the strength of the signal and the noise present
 in the channel.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\mathbf{POE=\frac{1}{2}(1-erf)\sqrt{\frac{E_{b}}{N_{o}}}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The BER is a critical parameter for evaluating the performance of a digital
 communication system.
 A high BER indicates poor system performance, which can lead to loss of
 data, degraded audio or video quality, or even complete system failure.
 Therefore, the BER is used as a benchmark to ensure that the digital communicat
ion system meets the required performance specifications.
\end_layout

\begin_layout Subsubsection
BLER 
\begin_inset CommandInset label
LatexCommand label
name "subsec:BLER"

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Block Error Rate (BLER) is a measure of the reliability of a communication
 system or a data transmission system by blocks.
 BLER is defined as the ratio of the number of blocks of data received with
 errors to the total number of blocks of data transmitted.
 It is commonly used in wireless communication systems, where the transmission
 of data can be affected by various factors such as fading, interference,
 and noise.
 In such systems, BLER is often used to evaluate the performance of the
 system and to determine the optimal operating parameters such as power,
 coding, and modulation schemes.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\boldsymbol{BLER=\frac{BlockErrCount}{TotalBlocks}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
To check for errors in a block of data, a cyclic redundancy check (CRC)
 is often used 
\begin_inset CommandInset citation
LatexCommand cite
key "CRC"
literal "false"

\end_inset

.
 Given the estimated values and the ground truth, instead of comparing bit
 by bit, a set of symbols is taken, and a CRC is calculated for a given
 chunk of the data.
 If the CRC of the equalized chunk is equal to the real value, there are
 no errors.
 However, if the CRC differs, the chunk is marked as incorrect, and it is
 added to the BLER count.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{algorithm}[ht] 
\backslash
caption{Block Error Rate Calculation with CRC} 
\backslash
label{alg:block_error_rate_crc} 
\backslash
begin{algorithmic}[1] 
\backslash
Require 
\backslash
Statex Input data is 48 blocks of 48 symbols 
\backslash
Statex $txbits$: array of transmitted blocks 
\backslash
Statex $rxbits$: array of received blocks 
\backslash
Statex $crc
\backslash
_func$: CRC function for generating CRC codes 
\backslash
Ensure 
\backslash
Statex $BLER$: Block Error Rate of the communication system 
\backslash
State $total
\backslash
_blocks 
\backslash
gets 48$ 
\backslash
State $bad
\backslash
_blocks 
\backslash
gets 0$ 
\backslash
For{$n 
\backslash
gets 0$ to $47$} 
\backslash
State $tx
\backslash
_crc 
\backslash
gets crc
\backslash
_func(txbits[n].tobytes())$ 
\backslash
State $rx
\backslash
_crc 
\backslash
gets crc
\backslash
_func(rxbits[n].tobytes())$ 
\backslash
If{$tx
\backslash
_crc 
\backslash
neq rx
\backslash
_crc$} 
\backslash
State $bad
\backslash
_blocks 
\backslash
gets bad
\backslash
_blocks + 1$ 
\backslash
EndIf 
\backslash
EndFor 
\backslash
State $BLER 
\backslash
gets bad
\backslash
_blocks / total
\backslash
_blocks$ 
\backslash
State 
\backslash
Return $BLER$ 
\backslash
end{algorithmic} 
\backslash
end{algorithm}
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
\paragraph_spacing onehalf
Channel
\size large
 
\begin_inset CommandInset label
LatexCommand label
name "subsec:Channel"

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newline
\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Dispersion and doubly dispersion
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Time delay dispersion is a measure of the variation in the arrival times
 of a signal's components caused by transmission through a communication
 channel.
 It is a type of distortion that can occur in wireless communication systems
 and is due to the differences in the propagation paths taken by different
 parts of the transmitted signal.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Time delay dispersion can cause inter-symbol interference (ISI) in digital
 communication systems, which can lead to errors in the received signal.
 To mitigate the effects of time delay dispersion, techniques such as equalizati
on, adaptive modulation, and error correction codes can be used.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
A doubly dispersive channel is a type of communication channel that exhibits
 dispersion in two dimensions, such as time and frequency, or time and spatial
 dimensions.
 This means that the signals transmitted through the channel are spread
 out in both dimensions, which can cause additional distortion and complexity
 in the communication system.
 To overcome the challenges of a doubly dispersive channel, advanced techniques
 such as joint equalization and channel estimation can be employed.
 
\begin_inset CommandInset citation
LatexCommand cite
key "rappaport2002wireless"
literal "false"

\end_inset


\end_layout

\begin_layout Subsubsection
Multipath fading and doppler shift
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
A multipath fading channel is a type of wireless communication channel that
 experiences fading of the transmitted signal due to multiple paths of the
 signal between the transmitter and receiver.
 This can occur when the signal reflects off of obstacles such as buildings
 or terrain, or when it is refracted by the atmosphere.
 Multiple paths of the transmitted signal can cause constructive and destructive
 interference at the receiver, resulting in rapid fluctuations in the received
 signal strength.
 This can cause the signal to fade in and out, which can affect the quality
 and reliability of the communication.
 
\begin_inset CommandInset citation
LatexCommand cite
key "balanis_2012"
literal "false"

\end_inset

.
 We begin with the ray-tracing technique and make advantage of the physical
 geometry of the propagation environment to create a deterministic model
 of the wireless channel.
 The delay of a signal refers to the time it takes for the signal to travel
 from the transmitter to the receiver, and the Doppler shift of a signal
 refers to the frequency shift of the signal due to the relative motion
 between the transmitter and receiver.
\size default

\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Diagrams/Propagation.png
	lyxscale 50
	scale 30

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Caption Standard

\begin_layout Plain Layout
Delay multipath 
\begin_inset CommandInset citation
LatexCommand cite
key "hong_thaj_viterbo_2022"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard

\series bold
\size larger
\begin_inset Formula 
\begin{equation}
\boldsymbol{\mathbf{r(t)=g_{1}s(t-\tau_{1})+g_{2}s(t-\tau_{2})}}
\end{equation}

\end_inset


\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\mathbf{r(t)}$
\end_inset

 recieved signal
\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\mathbf{g_{n}}$
\end_inset

 baseband equivalent complex gain(attenuation)
\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\mathbf{\boldsymbol{\tau_{1}=\frac{r_{1}}{c}}}$
\end_inset

 where c is the speed of light
\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\mathbf{\boldsymbol{\tau_{2}=\frac{(r_{2}+r_{3})}{c}}}$
\end_inset

 delay in reflected path
\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\boldsymbol{\mathbf{\tau_{2}-\tau_{1}}}$
\end_inset

 delay spread
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
In wireless communication, the Doppler shift can cause changes in the frequency
 of a signal as it travels from the transmitter to the receiver.
 This can happen when the transmitter or receiver (or both) are moving relative
 to each other, causing the frequency of the signal to shift.
 The Doppler shift can affect the performance of a wireless communication
 system by causing changes in the signal-to-noise ratio and the signal-to-interf
erence ratio, which can degrade the quality of the signal and make it more
 difficult to detect and decode.
\begin_inset CommandInset citation
LatexCommand cite
key "marsland2013radio"
literal "false"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Diagrams/DopplerBasic.png
	lyxscale 50
	scale 40

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Doppler shifts due to the different angles of arrival 
\begin_inset CommandInset citation
LatexCommand cite
key "hong_thaj_viterbo_2022"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard

\size larger
\begin_inset Formula 
\begin{equation}
\boldsymbol{\mathbf{r(t)=g_{1}e^{j2\pi\nu_{1}(t-\tau_{1})}s(t-\tau_{1})+g_{2}e^{j2\pi\nu_{2}(t-\tau_{2})}s(t-\tau_{2})}}
\end{equation}

\end_inset


\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\mathbf{\boldsymbol{\nu_{1}=\frac{v}{c}f_{c}}}$
\end_inset

 LOS doppler shift
\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\mathbf{\boldsymbol{\nu_{1}=\frac{v*cos(\theta)}{c}f_{c}}}$
\end_inset

 doppler shift in reflected path
\end_layout

\begin_layout Standard
\align block

\size large
We can generalize for time dependent function the gain as follows: 
\end_layout

\begin_layout Standard

\size larger
\begin_inset Formula 
\begin{equation}
\boldsymbol{\mathbf{g(\tau_{i},t)=g_{i}e^{j2\pi\nu_{i}(t-\tau_{i})}}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent
\align block

\size large
Therefore impulse time-frequency response of channel at fixed time t, can
 be obtained by taking fourier transform along the delay dimension of 
\begin_inset Formula $\mathbf{\boldsymbol{g(\tau,t)}}$
\end_inset


\end_layout

\begin_layout Standard

\size larger
\begin_inset Formula 
\begin{equation}
\mathbf{\boldsymbol{H(f,t)=\int g(\tau,t)e^{-j2\pi f\tau}d\tau}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent
\align block

\size large
A time-frequency channel is a type of communication channel that is characterize
d by time-varying frequency-selective fading.
 This means that the channel experiences changes in its frequency response
 over time, resulting in variations in the amplitude and phase of the signals
 transmitted through it.
 Because a channel is assumed to have a slow time-varying function of t,
 we refer to this phenomenon as having a wide sense of being stationary.
 
\begin_inset CommandInset citation
LatexCommand cite
key "rappaport2002wireless"
literal "false"

\end_inset


\end_layout

\begin_layout Subsubsection
Wide sense stationary
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
A wide sense stationary (WSS) process is a stochastic process in which the
 mean and autocorrelation function of the process do not change over time.
 As a result, the process exhibits statistical properties that are time-invarian
t, such as the mean, variance, and autocorrelation.
\end_layout

\begin_layout Standard
\align block

\size large
In signal processing and telecommunications, WSS processes are often used
 because they have simpler mathematical properties compared to strict sense
 stationary (SSS) processes.
 This simplification makes them easier to analyze and work with, which allows
 for more efficient modeling and simulation of communication systems.
\end_layout

\begin_layout Standard
\align block

\size large
WSS processes are a generalization of strictly stationary processes, which
 are processes in which the mean and autocorrelation function are constant
 over time.
 WSS processes relax this constraint and allow for some degree of variability
 in the mean and autocorrelation function while still maintaining time-invariant
 statistical properties.
 
\begin_inset CommandInset citation
LatexCommand cite
key "papoulis2002probability"
literal "false"

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent
\align block

\size large
A wide sense stationary (WSS) process can be described by the following
 equations:
\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent
\align block

\size large
The mean of the process is constant over time, and can be represented by
 the equation:
\end_layout

\begin_deeper
\begin_layout Standard

\size large
\begin_inset Formula 
\begin{equation}
\mathbf{\boldsymbol{E[X(t)]=\mu}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard

\size large
Where 
\begin_inset Formula $\boldsymbol{E[X(t)]}$
\end_inset

 is the expected value of the process at time t, and 
\begin_inset Formula $\boldsymbol{μ}$
\end_inset

 is the constant mean of the process.
\end_layout

\end_deeper
\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent
\align block

\size large
The autocovariance of the process, which is a measure of the correlation
 between two points in time, is also constant over time, and can be represented
 by the equation:
\end_layout

\begin_deeper
\begin_layout Standard

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{R_{X}(t1,t2)=E[(X(t_{1})-\mu)(X(t_{2})-\mu)]=R(t_{1}-t_{2})}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
Where
\begin_inset Formula $\boldsymbol{R_{X}(t_{1},t_{2})}$
\end_inset

is the autocovariance of the process at times t1 and t2, and 
\begin_inset Formula $\boldsymbol{R(t_{1}-t_{2})}$
\end_inset

 is the autocovariance function of the process, which is a function of the
 time difference between t1 and t2
\end_layout

\end_deeper
\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent
\align block

\size large
The autocorrelation function of the process, which is a measure of the correlati
on between two points in time, is also constant over time, and can be represente
d by the equation
\end_layout

\begin_deeper
\begin_layout Standard

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{r_{X}(t1,t2)=\frac{R_{X}(t_{1},t_{2})}{\sqrt{R_{X}(t_{1},t_{1})R_{X}(t_{2},t_{2})}}=r(t_{1}-t_{2})}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
Where 
\begin_inset Formula $\mathbf{r_{X}(t_{1},t_{2})}$
\end_inset

 is the autocorrelation function of the process at times t1 and t2, and
 
\begin_inset Formula $\boldsymbol{r(t_{1}-t_{2})}$
\end_inset

 is the autocorrelation function of the process, which is a function of
 the time difference between t1 and t2.
\end_layout

\end_deeper
\begin_layout Subsection
Estimators
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
An estimator is a statistical function that maps an observation to an estimate
 of a parameter of the signal being observed, normally known as 
\begin_inset Formula $\hat{\boldsymbol{\theta}}$
\end_inset

 .It is a mathematical function that takes the data, usually in the form
 of a sample, and produces an estimate of an unknown parameter of the underlying
 probability distribution.
 It's important to note that the quality of an estimator is usually measured
 by some metric such as Mean Squared Error (MSE), Mean Absolute Error (MAE)
 or Likelihood that indicates how well the estimator is able to estimate
 the true parameter 
\begin_inset CommandInset citation
LatexCommand cite
key "MSE_MMSE"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
In the context of estimation theory, there are two key concepts to understand:
 posterior estimators and biased/unbiased estimators.
\begin_inset CommandInset citation
LatexCommand cite
key "statiticsbook"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\series bold
\size large
Posterior estimator
\series default
: Is a method of estimating a parameter by incorporating prior knowledge
 or belief about the parameter's distribution.
 This prior information is combined with the observed data to derive a posterior
 distribution for the parameter.
 The posterior distribution represents our updated belief about the parameter
 after considering the observed data.
 The estimator is then derived from this posterior distribution.
 The posterior estimator can be the mean, median, or mode of the posterior
 distribution, depending on the specific problem and desired properties
 of the estimator.
 Let's denote the parameter of interest as 
\begin_inset Formula $\boldsymbol{𝜃}$
\end_inset

 and the observed data as 
\begin_inset Formula $X$
\end_inset

.
 Bayes' theorem can be written as
\end_layout

\begin_deeper
\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{P(\theta|X)=\frac{P(X|\theta)*P(\theta)}{P(x)}}
\end{equation}

\end_inset


\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\size large
\begin_inset Formula $\boldsymbol{P(𝜃|X)}$
\end_inset

 is the posterior distribution of the parameter 
\begin_inset Formula $\boldsymbol{𝜃}$
\end_inset

 given the data 
\begin_inset Formula $\boldsymbol{X}$
\end_inset

.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\size large
\begin_inset Formula $\boldsymbol{P(X|𝜃)}$
\end_inset

 is the likelihood of observing the data 
\begin_inset Formula $\boldsymbol{X}$
\end_inset

 given the parameter 
\begin_inset Formula $\boldsymbol{𝜃}$
\end_inset

.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\size large
\begin_inset Formula $\boldsymbol{P(𝜃)}$
\end_inset

 is the prior distribution of the parameter 
\begin_inset Formula $\boldsymbol{𝜃}$
\end_inset

, representing our beliefs about 
\begin_inset Formula $\boldsymbol{𝜃}$
\end_inset

 before observing the data.
 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\size large
\begin_inset Formula $\boldsymbol{P(X)}$
\end_inset

 is the marginal likelihood of the data, which can be thought of as a normalizat
ion constant.
\end_layout

\end_deeper
\begin_layout Itemize
\paragraph_spacing onehalf

\series bold
\size large
Biased estimator:
\series default
 Is an estimator whose expected value does not equal the true value of the
 parameter being estimated.
 In other words, the estimator consistently overestimates or underestimates
 the true parameter value.
 Bias can be due to the estimator's functional form, the presence of outliers
 in the data, or other factors that systematically affect the estimator.
\end_layout

\begin_deeper
\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{Bias\left(\hat{\theta}\right)=E\left(\hat{\theta}\right)-𝜃}
\end{equation}

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
\paragraph_spacing onehalf

\series bold
\size large
Unbiased estimator:
\series default
 On average, the estimator provides an accurate estimate of the parameter.
 However, it's important to note that an unbiased estimator can still have
 a large variance, which means that individual estimates can be far from
 the true parameter value.
\end_layout

\begin_deeper
\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{E\left(\hat{\theta}\right)=\theta}
\end{equation}

\end_inset


\end_layout

\end_deeper
\begin_layout Subsubsection
MSE 
\begin_inset CommandInset label
LatexCommand label
name "subsec:MSE"

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
Mean squared error (MSE) is a widely used performance metric in estimation
 theory to evaluate the accuracy of an estimator.
 It measures the average of the squared differences between the estimated
 values and the true parameter values.
 In other words, MSE quantifies the difference between the estimator and
 the true parameter value, considering both the bias and the variance of
 the estimator.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align center

\size larger
\begin_inset Formula 
\begin{equation}
\boldsymbol{MSE(\hat{\theta})=E[(\hat{\theta}-\theta)^{2}]}
\end{equation}

\end_inset


\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\align block

\size large
\begin_inset Formula $\boldsymbol{\theta}$
\end_inset

 is the transmitted signal with the original values
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\align block

\size large
\begin_inset Formula $\boldsymbol{\hat{\theta}}$
\end_inset

 is the predicted values of the received signal.
\end_layout

\begin_layout Standard

\size large
However, reducing the MSE involves managing the trade-off between bias and
 variance.
 This trade-off can be more clearly seen when the MSE is decomposed into
 the sum of the squared bias and the variance, we can better visualize the
 idea rewritting the formula 
\begin_inset CommandInset citation
LatexCommand cite
key "statiticsbook"
literal "false"

\end_inset

: 
\end_layout

\begin_layout Standard

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{MSE(\hat{\theta})=E\left\{ \left[\left(\hat{\theta}-E\left(\hat{\theta}\right)\right)+\left(E\left(\hat{\theta}\right)-\theta\right)\right]^{2}\right\} =var(\hat{\theta})+\left(E\left(\hat{\theta}\right)-\theta\right)^{2}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{MSE(\hat{\theta})=var(\hat{\theta})+Bias^{2}(\theta)}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The bias-variance trade-off refers to the challenge of finding an estimator
 that minimizes both bias and variance.
 In practice, this trade-off means that an estimator with low bias may have
 high variance, while an estimator with low variance may have high bias.
 The goal is to find the optimal balance between bias and variance, resulting
 in the lowest MSE and the best overall estimator performance.
\end_layout

\begin_layout Subsubsection
Bias and variance in Deep Learning
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
In the context of deep learning models, including neural networks, bias
 refers to the error introduced by approximating a real-world problem with
 a simplified model, while variance represents the model's sensitivity to
 small fluctuations in the training data.
 A neural network with a high bias tends to produce simpler models that
 may not capture the true underlying relationship between inputs and outputs,
 resulting in underfitting.
 On the other hand, a network with high variance tends to overfit the training
 data, capturing noise and being sensitive to small changes in the input
 data.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
In supervised learning with neural networks, the goal is to find the right
 balance between bias and variance to achieve good generalization performance
 on unseen data.
 This can be achieved by selecting the appropriate network architecture,
 using regularization techniques, and fine-tuning hyperparameters.
\end_layout

\begin_layout Subsection
Equalization
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
A telecom channel equalizer is a device or algorithm used in telecommunications
 systems to compensate for distortion or other impairments in a communication
 channel.
 The equalizer uses signal processing techniques to estimate the characteristics
 of the channel, such as the impulse response or the frequency response,
 and then applies a correction to the transmitted signal to counteract the
 effects of the channel on the received signal.
 This can improve the performance of the communication system by reducing
 errors and increasing the data rate or signal-to-noise ratio.
 Bluetooth, WiFi, IOT, drones, V2V, wireless broadband, and satellite communicat
ions are just a few of the everyday applications they can be used for.
 
\begin_inset CommandInset citation
LatexCommand cite
key "goldsmith_2005"
literal "false"

\end_inset

 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newline
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Diagrams/Equalizer_Basic.jpg
	lyxscale 30
	scale 15

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Basic Equalizer
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Our goal is to develop an equalizer based on deep learning techniques and
 research how it performs in terms of timing and memory complexity.
 We take as a reference the classical methods that manage a good bit error
 rate, and we will take them as a golden model of accuracy.
 
\end_layout

\begin_layout Subsubsection
OFDM Time-Frequency Input-Output Relationship
\begin_inset CommandInset label
LatexCommand label
name "subsec:OFDM-Time-Frequency-Input-Output"

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The goal of this section is to provide a formal description of the key component
s used in the upcoming estimation sections, and provide and introduction
 about what estimation is looking for.
 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The transmitted and received frequency symbol blocks 
\begin_inset Formula $\boldsymbol{x,y\in\mathbb{C}^{N\times1}}$
\end_inset

 respectively, are obtained by computing the N-point discrete Fourier transform
 (DFT) of the time-domain blocks s and r 
\begin_inset Formula $\boldsymbol{s,r\in\mathbb{R}^{N\times1}}$
\end_inset

.
 We denote the N-point DFT as 
\begin_inset Formula $\boldsymbol{F_{N}}$
\end_inset

 and is expressed as follows:
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{F}_{N}=\begin{bmatrix}1 & 1 & 1 & \dots & 1\\
1 & w_{0} & w_{0}^{2} & \dots & w_{0}^{N-1}\\
1 & w_{0}^{2} & w_{0}^{4} & \dots & w_{0}^{2(N-1)}\\
\vdots & \vdots & \vdots & \ddots & \vdots\\
1 & w_{0}^{M-1} & w_{0}^{2(M-1)} & \dots & w_{0}^{(N-1)^{2}}
\end{bmatrix}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
where 
\begin_inset Formula $w_{0}=e^{-\frac{2\pi i}{N}}$
\end_inset

.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
In the time domain, the received signal, 
\begin_inset Formula $\boldsymbol{r(t)}$
\end_inset

, is given by the convolution of the transmitted signal, 
\begin_inset Formula $\boldsymbol{s(t)}$
\end_inset

, and the channel impulse response, 
\begin_inset Formula $\boldsymbol{h(t)}$
\end_inset

, plus the noise, 
\begin_inset Formula $\boldsymbol{n(t)}$
\end_inset

:
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{r=s(t)*h(t)+n(t)}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
To analyze the system in the frequency domain, the DFT is applied to the
 received signal, transmitted signal, and noise:
\end_layout

\begin_layout Standard
\align center

\size large
\begin_inset Formula $\boldsymbol{y=F_{N}\times r}$
\end_inset


\end_layout

\begin_layout Standard
\align center

\size large
\begin_inset Formula $\boldsymbol{x=F_{N}\times s}$
\end_inset


\end_layout

\begin_layout Standard
\align center

\size large
\begin_inset Formula $\boldsymbol{n=F_{N}\times n(t)}$
\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
When transforming from the time domain to the frequency domain, the linear
 convolution operation in the time domain is converted into circular convolution.
 Thus, the relationship between the transmitted signal and the received
 signal in the frequency domain can be expressed as:
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align center

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{Y=H⊙X}
\end{equation}

\end_inset

 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Each element of this relationship can be developed as follows:
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align center

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{y_{c}[n]=(x[n]\circledast h[n])_{n}=\sum_{m=0}^{N-1}x[m]h[(n-m)modN]}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
where 
\begin_inset Formula $H$
\end_inset

 is the channel frequency response, which is the DFT of the channel impulse
 response, 
\begin_inset Formula $h(t):$
\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{H=F_{N}h(t)}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\boldsymbol{H}=\begin{bmatrix}h_{(0)(0)} & 0 & \dots & h_{(0)(t-1)}\\
h_{(1)(0)} & h_{(1)(1)} & \dots & h_{(1)(t-1)}\\
\vdots & \vdots & \ddots & \vdots\\
0 & h_{(d-1)(0)} & \dots & h_{(d-1)(t-1)}
\end{bmatrix}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Here, 
\begin_inset Formula $d$
\end_inset

 represents the number of delays (i.e., the length of the channel impulse
 response), and 
\begin_inset Formula $t$
\end_inset

 represents the number of time samples in the OFDM symbol.
 Each element of the matrix is represented as 
\begin_inset Formula $h_{(delay)(time)}$
\end_inset

, where delay and time represent the indices of the corresponding delay
 and time samples, respectively.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
To mitigate the effect of Inter-Symbol Interference (ISI) caused by circular
 convolution, a Cyclic Prefix (CP) is added to the transmitted signal before
 transmission.
 This helps maintain orthogonality between subcarriers and minimize ISI.
 After adding the CP and assuming that the CP length is greater than or
 equal to the channel impulse response length, the circular convolution
 becomes equivalent to linear convolution, and the relationship between
 the frequency-domain components becomes
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{y=Hx+n}\label{eq:eq27}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
where 
\begin_inset Formula $\boldsymbol{y}$
\end_inset

, 
\begin_inset Formula $\boldsymbol{x}$
\end_inset

, and 
\begin_inset Formula $\boldsymbol{n}$
\end_inset

 are vectors of length 
\begin_inset Formula $\boldsymbol{N}$
\end_inset

, and 
\begin_inset Formula $\boldsymbol{H}$
\end_inset

 is an 
\begin_inset Formula $\boldsymbol{N\times N}$
\end_inset

 complex-valued matrix that represents the channel effects on the transmitted
 signal.
 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The objective of the receiver is to estimate the transmitted signal 
\begin_inset Formula $\boldsymbol{x}$
\end_inset

 from the received signal 
\begin_inset Formula $\boldsymbol{y}$
\end_inset

, which can be done by applying an inverse channel matrix to the received
 signal.
 This can be expressed as:
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{\hat{x}=H^{-1}y}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
However, the inverse channel matrix may not always exist or may be difficult
 to compute, especially in the presence of noise and channel distortions.
 Therefore, various signal processing techniques such as equalization, filtering
, and error correction codes are used to improve the accuracy and reliability
 of the transmitted signal estimation.
 These techniques involve manipulating the received signal Y to extract
 the transmitted signal x and minimize the effects of noise and channel
 distortions.
\end_layout

\begin_layout Subsubsection
Zero forcing
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The Zero Forcing Equalizer (ZFE)
\begin_inset CommandInset label
LatexCommand label
name "subsec:Zero-forcing"

\end_inset

 is a technique used in communication systems to reduce the impact of intersymbo
l interference (ISI), caused by the presence of multiple signal paths in
 a communication channel.
 Although the ZFE is effective, it has some limitations, such as being susceptib
le to noise and unable to handle certain types of channel distortions.
 Nevertheless, it can improve the performance of communication systems in
 specific scenarios.
 Given the section above in 
\color blue

\begin_inset CommandInset ref
LatexCommand nameref
reference "eq:eq27"
plural "false"
caps "false"
noprefix "false"

\end_inset

 
\color inherit
as the Input-Output relation.
 The main diagonal of the channel matrix H is taken and divided by recieved
 signal.
 This matrix is already in the frequency domain.
 To extract the main diagonal of the channel matrix the "diag(H)" operation
 is used.
\begin_inset Formula 
\begin{equation}
\boldsymbol{H_{\text{diag}}}=\text{diag}(\boldsymbol{H})=diag\left(\begin{bmatrix}h_{11} & 0 & \dots & 0\\
0 & h_{22} & \dots & 0\\
\vdots & \vdots & \ddots & \vdots\\
0 & 0 & \dots & h_{NN}
\end{bmatrix}\right)=\left(\begin{array}{c}
h_{11}\\
h_{22}\\
\vdots\\
\vdots\\
h_{NN}
\end{array}\right)
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Ideally, if the off-diagonal elements of the channel matrix H are relatively
 small, the channel matrix can be approximated by its main diagonal.
 Then, after diagonal division the estimated transmitted symbols can be
 expressed as 
\begin_inset Formula $\boldsymbol{\hat{\theta}\simeq x+\frac{n}{diag(H)}}$
\end_inset

, where n is the noise vector and diag(H) is the main diagonal of the channel
 matrix H.
 In the equations bellow the estimator is shown.
 
\end_layout

\begin_layout Standard
\align center

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{\hat{\theta}=y\circ\div diag(H)=\left(Hx+w\right)\circ\div diag(H)}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Where 
\begin_inset Formula $\boldsymbol{\circ\div}$
\end_inset

 represents the elementwise division.
 
\end_layout

\begin_layout Standard
\noindent

\size large
Based on the paper
\begin_inset CommandInset citation
LatexCommand cite
key "ZeroForcingEqNN"
literal "false"

\end_inset

, we will use zero forcing as a preprocessing stage for some of our experiments.
\end_layout

\begin_layout Subsubsection
LS
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Least squares (LS)
\begin_inset CommandInset label
LatexCommand label
name "subsec:LS"

\end_inset

 equalization is a linear equalization method that aims to minimize the
 mean squared error (MSE) between the estimated and the transmitted symbols.
 The goal of the least squares equalization is to find an estimate of the
 transmitted signal, 
\begin_inset Formula $\boldsymbol{\hat{\theta}}$
\end_inset

, that minimizes the mean squared error (MSE) between the received signal
 and the predicted received signal.
 To achieve this, we define the error vector 
\begin_inset Formula $\boldsymbol{e}$
\end_inset

 as the difference between the received signal and the predicted received
 signal based on the estimated transmitted signal 
\begin_inset Formula $\boldsymbol{e}=\boldsymbol{y}-\boldsymbol{H\theta},$
\end_inset

where 
\begin_inset Formula $\boldsymbol{\theta=x}$
\end_inset

.
 The objective is to minimize the mean squared error (MSE) 
\begin_inset CommandInset citation
LatexCommand cite
key "statiticsbook"
literal "false"

\end_inset

:
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{\text{J(\ensuremath{\theta)}}=E\left(\lVert\boldsymbol{e}\rVert_{2}^{2}\right)=E\left(\lVert\boldsymbol{y}-\boldsymbol{H\theta}\rVert_{2}^{2}\right)=\left(y-H\theta\right)^{T}\left(y-H\theta\right)}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
where 
\begin_inset Formula $\boldsymbol{\lVert\cdot\rVert_{2}}$
\end_inset

 indicates the 2-norm (Euclidean norm).
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
With the solution in the Moore-Penrose pseudoinverse 
\begin_inset Formula $\boldsymbol{H^{+}}$
\end_inset

.The Moore-Penrose pseudoinverse is often used to solve linear least squares
 problems, which involve finding the values of variables that minimize the
 sum of the squares of the residuals (the differences between the observed
 values and the values predicted by the model).
 It can also be used to compute a "best fit" solution for systems of linear
 equations that do not have a unique solution.
 
\begin_inset CommandInset citation
LatexCommand cite
key "strang2019linear"
literal "false"

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{H^{+}=(H^{H}H)^{-1}H^{H}}
\end{equation}

\end_inset


\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\size large
\begin_inset Formula $\boldsymbol{H}$
\end_inset

 Channel matrix
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\size large
\begin_inset Formula $\boldsymbol{H^{+}}$
\end_inset

Moore-Penrose pseudoinverse 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\size large
\begin_inset Formula $\boldsymbol{H^{H}}$
\end_inset

 Hermiatian transpose matrix.
 Complex square matrix that is equal to its own conjugate transpose
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Finally the estimator is:
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{\hat{\theta}=(H^{H}H)^{-1}H^{H}\theta}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Its resistance to noise makes it appealing in a variety of communication
 systems, however because the noise component is ignored, it cannot operate
 satisfactorily with low SNR (signal to noise ratio).
 The unbiasedness of the equalizer depends on the specific equalization
 problem and the assumptions made about the channel and noise characteristics,
 and the variance of the least squares equalization method quantifies the
 uncertainty in the estimated transmitted signal due to the presence of
 noise in the received signal.
 A higher variance implies a greater degree of uncertainty in the equalized
 signal.
\end_layout

\begin_layout Subsubsection
MMSE
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
MMSE equalization is a linear equalization technique that aims to minimize
 the mean squared error between the transmitted signal and its estimate.
 The MMSE equalizer balances the trade-off between bias and variance, unlike
 the zero-forcing equalizer, which focuses solely on eliminating intersymbol
 interference (ISI) without considering the noise amplification.
 MMSE equalization can be thought of as a compromise between the desire
 to eliminate ISI (which could introduce bias) and the need to limit noise
 amplification (which affects variance).
 The objective of MMSE equalization can be expressed as:
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{MMSE=min(E[(\hat{\theta}-\theta)^{2}])}
\end{equation}

\end_inset


\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\size large
\begin_inset Formula $\boldsymbol{\theta}$
\end_inset

 is the transmitted signal.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\size large
\begin_inset Formula $\boldsymbol{\hat{\theta}}$
\end_inset

 is the estimated signal.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Mathematically, the MMSE estimator is defined as 
\begin_inset Formula $\boldsymbol{\hat{\theta}_{MMSE}=E[\theta|y]}$
\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Here, 
\begin_inset Formula $\boldsymbol{\hat{\theta}_{MMSE}}$
\end_inset

 is the estimate of the transmitted signal 
\begin_inset Formula $\boldsymbol{\theta}$
\end_inset

 given the received signal
\begin_inset Formula $\boldsymbol{y}$
\end_inset

.
 The MMSE estimator computes the conditional expectation of 
\begin_inset Formula $\boldsymbol{\theta}$
\end_inset

 given the observed signal 
\begin_inset Formula $\boldsymbol{y}$
\end_inset

.
 This means that the MMSE estimator takes into account both the prior informatio
n about 
\begin_inset Formula $\boldsymbol{\theta}$
\end_inset

 and the likelihood of observing 
\begin_inset Formula $\boldsymbol{y}$
\end_inset

 given 
\begin_inset Formula $\boldsymbol{\theta}$
\end_inset

.
\end_layout

\begin_layout Subsubsection
LMMSE 
\size large

\begin_inset CommandInset label
LatexCommand label
name "subsec:LMMSE"

\end_inset

 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The Linear Minimum Mean Squared Error (LMMSE) estimator is a linear version
 of the MMSE estimator.
 While the MMSE estimator can be nonlinear, the LMMSE estimator restricts
 itself to linear functions of the observed data.
 The goal of the LMMSE estimator is to find a linear estimate of the transmitted
 signal that minimizes the mean squared error between the transmitted signal
 and its linear estimate, given the received signal.
 Compared to the Least Squares (LS) algorithm, this can perform better when
 there is low signal-to-noise ratio (SNR).
 To put it another way, the LMMSE equalization is a method that can be applied
 to restore precision to a signal that has been distorted by noise, especially
 when the noise level is high.
 When there is a low signal-to-noise ratio (SNR) and a significant quantity
 of noise in the signal, it performs exceptionally well.
 Mathematically, the LMMSE estimator is defined as:
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{\hat{\theta}_{LMMSE}=E[\theta]+C_{\theta y}C_{yy}^{-1}(y-E[y])}
\end{equation}

\end_inset


\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\size large
\begin_inset Formula $\boldsymbol{E[\theta]}$
\end_inset

 is the prior expectation of the transmitted signal.
 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\size large
\begin_inset Formula $\boldsymbol{C_{\theta y}}$
\end_inset

 is the cross-covariance matrix between the transmitted signal and the received
 signal.
 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\size large
\begin_inset Formula $\boldsymbol{C_{yy}}$
\end_inset

 is the covariance matrix of the received signal.
 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\size large
\begin_inset Formula $\boldsymbol{E[y]}$
\end_inset

 is the prior expectation of the received signal.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The LMMSE estimator seeks to find a linear estimate of 
\begin_inset Formula $\boldsymbol{\theta}$
\end_inset

 given the received signal 
\begin_inset Formula $\boldsymbol{y}$
\end_inset

:
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{\hat{\theta}_{LMMSE}=Wy}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
where 
\begin_inset Formula $\boldsymbol{W}$
\end_inset

 is the LMMSE equalizer matrix.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Using the LMMSE estimator definition 
\begin_inset Formula $\boldsymbol{\hat{\theta}_{LMMSE}}$
\end_inset

, we can derive the LMMSE equalizer matrix W:
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{W=C_{\theta y}C_{yy}^{-1}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
We know that the covariance matrix of 
\begin_inset Formula $\boldsymbol{y}$
\end_inset

, 
\begin_inset Formula $\boldsymbol{C_{yy}}$
\end_inset

, is given by:
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{C_{yy}=HC_{\theta\theta}H^{H}+\sigma^{2}I}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
where
\begin_inset Formula $\boldsymbol{C_{\theta\theta}}$
\end_inset

 is the covariance matrix of 
\begin_inset Formula $\boldsymbol{\theta}$
\end_inset

, and 
\begin_inset Formula $\boldsymbol{H^{H}}$
\end_inset

 denotes the conjugate transpose (Hermitian) of the matrix 
\begin_inset Formula $\boldsymbol{H}$
\end_inset

.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Now, we need to find the cross-covariance matrix between 
\begin_inset Formula $\boldsymbol{\theta}$
\end_inset

 and 
\begin_inset Formula $\boldsymbol{y}$
\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{C_{\theta y}=E[(\theta-E[\theta])(y-E[\theta])^{H}]=E[\theta y^{H}]=C_{\theta\theta}H^{H}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Assuming that the transmitted symbols are uncorrelated with equal power,
 we have
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{C_{\theta\theta}=E[\theta\theta^{H}]=\rho I}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
where
\begin_inset Formula $\boldsymbol{\rho}$
\end_inset

 is the average symbol power, and for simplicity we keep at unitary power.
 Substituting back the elements from Eq.
 37, we obtain the final estimation equation.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{W=H(HH^{H}+\sigma^{2}I)^{-1}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{\hat{\theta}_{LMMSE}=(H^{H}H+\sigma^{2}I)^{-1}H^{H}}\boldsymbol{\theta}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
This equation consider AWGN (Additive White Gaussian Noise) with variance
 
\begin_inset Formula $\boldsymbol{\sigma^{2}}$
\end_inset

.
 It is called "white" because it has a flat power spectral density, meaning
 that it has equal power at all frequencies.
 It is called "additive" because it can be added to a signal without changing
 its distribution.
 
\end_layout

\begin_layout Subsubsection
Pros and Cons
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
In conclusion, as demonstrated by the previously discussed methods, the
 computation of equalization matrices primarily relies on finding the pseudo-inv
erse of certain matrix factors.
 However, directly solving for the inverse of the matrix can be both computation
ally costly 
\begin_inset Formula $\boldsymbol{O(N^{3})}$
\end_inset

 and numerically unstable.
 This instability arises when the matrix has a very small determinant, which
 may cause the true solution to be susceptible to large perturbations.
 Consequently, this leads to a complex circuit architecture for numerical
 calculations.
 On the other hand, these methods are linear and will have a very predictable
 behavior over noise conditions and BER.
 As an alternative, neural networks offer a promising approach to address
 these challenges in signal equalization.
 They can adaptively learn the underlying structure of the data and are
 capable of handling non-linear relationships, which may lead to more efficient
 and robust equalization techniques.
\end_layout

\begin_layout Subsection
Non-linear equalizers
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
NearML (Near Maximum Likelihood) and OSIC (Ordered Successive Interference
 Cancellation) are two non-linear signal equalization techniques used in
 digital communication systems to mitigate the challenges posed by signal
 distortions.
 These methods provide better symbol detection accuracy and overall system
 performance, making them invaluable tools in modern communication systems
 design.
 However, they compromise time complexity due to the iterative nature of
 their applications.
 In our research team, these methods have been previously applied in MATLAB
 for benchmarking purposes in the work titled 
\begin_inset Quotes eld
\end_inset

Evaluation of OFDM Systems With Virtual Carriers Over V2V Channels
\begin_inset Quotes erd
\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "Gonza"
literal "false"

\end_inset

.
 We needed to perform a coding language translation to Python in order to
 make a fairer metric comparison under the same conditions as all the other
 Equalization methods and Nueronal Networks.
 Additionally, there was a well-planned architecture to integrate these
 methods in an almost transparent manner.
 Additional information about the software architecture can be found in
 the methodology section.
\end_layout

\begin_layout Subsubsection
OSIC
\begin_inset CommandInset label
LatexCommand label
name "subsec:OSIC"

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Ordered Successive Interference Cancellation (OSIC) detection method.
 This method is used for detecting transmitted symbols from a received signal
 in digital communication systems.
 The function accepts four inputs: the received signal vector, the channel
 matrix, the constellation points, and the indices of the detected symbols.
 The function starts by initializing several variables needed for the algorithm.
 It then goes through each column of the channel matrix in reverse order.
 For each column, it estimates the corresponding transmitted symbol by dividing
 the received signal by the channel matrix value.
 Then, it calculates the squared distance between the estimated symbol and
 each constellation point.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The algorithm selects the constellation point with the smallest squared
 distance as the detected symbol and updates the received signal vector
 accordingly.
 This process helps to cancel the interference caused by previously detected
 symbols and improves the overall detection performance.
 Finally, the detected symbols are rearranged according to the given indices
 and stored in an output tensor.
 The function returns this tensor containing the estimated transmitted symbols.
\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\mathbf{y}$
\end_inset

: The received signal, which is a complex-valued column vector of length
 
\begin_inset Formula $\boldsymbol{N}$
\end_inset

.
 
\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\mathbf{H}$
\end_inset

: The channel matrix of size 
\begin_inset Formula $\boldsymbol{N\times N}$
\end_inset

, which represents the channel coefficients 
\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\mathbb{\boldsymbol{A}}$
\end_inset

: The set of constellation points, which represents the possible symbol
 values in the modulation scheme used for the transmitted signal.
 
\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\mathbf{r}$
\end_inset

: A temporary variable used for storing the residual signal during the algorithm.
 It is initialized as the received signal 
\begin_inset Formula $\mathbf{y}$
\end_inset

 and updated in each iteration of the loop.
 
\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\boldsymbol{k}$
\end_inset

: The loop index representing the current column of the channel matrix being
 considered.
 
\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\boldsymbol{a_{est}}$
\end_inset

: The estimated transmitted symbol value for the k-th column of the channel
 matrix, computed as the ratio between the k-th element of the residual
 signal 
\begin_inset Formula $\mathbf{r}$
\end_inset

 and the k-th diagonal element of the channel matrix 
\begin_inset Formula $\mathbf{H}$
\end_inset

.
 
\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\text{dist}$
\end_inset

: A vector of squared distances between the estimated transmitted symbol
 value 
\begin_inset Formula $a_{est}$
\end_inset

 and the constellation points in 
\begin_inset Formula $\mathbb{A}$
\end_inset

.
 
\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\boldsymbol{\hat{\theta}_{osic}}$
\end_inset

: The estimated transmitted symbol vector of length N.
 It is initialized as an empty vector and updated with the minimum-distance
 constellation point in each iteration of the loop.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{algorithm}[H] 
\backslash
caption{OSIC Detection Algorithm} 
\backslash
begin{algorithmic}[1] 
\backslash
Procedure{OSIC
\backslash
_Det}{$
\backslash
mathbf{y}$, $
\backslash
mathbf{H}$, $
\backslash
mathbb{A}$}     
\backslash
State $
\backslash
mathbf{r} 
\backslash
gets 
\backslash
mathbf{y}$     
\backslash
For{$k 
\backslash
gets N-1, N-2, 
\backslash
dots, 0$}         
\backslash
State $a_{est} 
\backslash
gets 
\backslash
frac{
\backslash
mathbf{r}[k]}{
\backslash
mathbf{H}[k, k]}$         
\backslash
State $
\backslash
text{dist} 
\backslash
gets |a_{est} - 
\backslash
mathbb{A}|^2$         
\backslash
State $
\backslash
hat{
\backslash
theta}_{osic}[k] 
\backslash
gets 
\backslash
arg
\backslash
min_{a 
\backslash
in 
\backslash
mathbb{A}} 
\backslash
text{dist}$         
\backslash
State $
\backslash
mathbf{r} 
\backslash
gets 
\backslash
mathbf{r} - 
\backslash
hat{
\backslash
theta}_{osic}[k] 
\backslash
cdot 
\backslash
mathbf{H}[:, k]$     
\backslash
EndFor     
\backslash
State 
\backslash
textbf{return} $
\backslash
hat{
\backslash
theta}_{osic}$ 
\backslash
EndProcedure 
\backslash
end{algorithmic} 
\backslash
end{algorithm} 
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The outer loop iterates through the columns of the channel matrix, which
 has a size of 
\begin_inset Formula $\boldsymbol{N}$
\end_inset

.
 Therefore, the outer loop has a complexity of 
\begin_inset Formula $\boldsymbol{O(N)}$
\end_inset

.
 Inside the outer loop, there's a calculation of squared distances between
 the estimated symbol and each constellation point.
 The constellation points have a size of 
\begin_inset Formula $\boldsymbol{|\mathbb{A}|}$
\end_inset

.
 This operation has a complexity of 
\begin_inset Formula $\boldsymbol{O\left(|\mathbb{A}|\right)}$
\end_inset

.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Since the squared distance calculation is inside the outer loop, the overall
 complexity of the OSIC_Det algorithm is 
\begin_inset Formula $\boldsymbol{O(N*|\mathbb{A}|)}$
\end_inset

.
\end_layout

\begin_layout Subsubsection
NearML
\begin_inset CommandInset label
LatexCommand label
name "subsec:NearML"

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The Near-ML detection algorithm functions as a tree search with nodes representi
ng constellation points and depth equal to the number of transmitters.
 It computes distances between received signals and candidate symbols, selecting
 M best candidates at each level for pruning.
 By backtracking and updating accumulated distances, it maintains the M
 best candidates and performs additional pruning when necessary.
 The algorithm ultimately selects the candidate with the minimum total distance,
 resulting in a near-optimal solution with reduced search space and good
 detection performance.
\end_layout

\begin_layout Standard

\size large
For the Near Maximum Likelihood (Near-ML) detection algorithm, the goal
 is to estimate the transmitted symbols, denoted by 
\begin_inset Formula $\boldsymbol{\hat{\theta}_{NML}}$
\end_inset

, given the received signal 
\begin_inset Formula $\boldsymbol{Y}$
\end_inset

, channel matrix 
\begin_inset Formula $\boldsymbol{H}$
\end_inset

, and the constellation points 
\begin_inset Formula $\boldsymbol{\mathbb{A}}$
\end_inset

.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
\begin_inset Formula $\boldsymbol{M}$
\end_inset

: The number of best candidates to be stored at each level of the tree search.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
\begin_inset Formula $\boldsymbol{QRM}$
\end_inset

: 
\begin_inset Formula $\boldsymbol{|\mathbb{A}|}$
\end_inset

.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
\begin_inset Formula $\boldsymbol{a_{est}}$
\end_inset

: The temporary estimation of the transmitted symbol at a specific level,
 calculated as the received signal divided by the corresponding channel
 coefficient.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
\begin_inset Formula $\boldsymbol{d}$
\end_inset

: The distance between the temporary estimation 
\begin_inset Formula $\boldsymbol{a_{est}}$
\end_inset

 and the constellation points.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
\begin_inset Formula $\boldsymbol{d_{min}}$
\end_inset

: The minimum total distance found so far, used for pruning.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
\begin_inset Formula $\boldsymbol{d_{total}}$
\end_inset

: The total distance of each candidate, used to find the best candidates.
 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
\begin_inset Formula $\boldsymbol{d_{minf}}$
\end_inset

: The minimum total distance found at the end of the tree search, used to
 determine the best candidate.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
\begin_inset Formula $\boldsymbol{s_{est3}}$
\end_inset

: The reordered detected symbols according to the original index.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
\begin_inset Formula $\boldsymbol{index[k]}$
\end_inset

: The original index of the detected symbols.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{algorithm}[H] 
\backslash
caption{Near Maximum Likelihood Detection} 
\backslash
begin{algorithmic}[1] 
\backslash
Procedure{NearML}{$
\backslash
boldsymbol{y_p}$, $
\backslash
boldsymbol{H}$, $
\backslash
boldsymbol{
\backslash
mathbb{A}}$, $M$}     
\backslash
State Initialize tree search, set $nt$ as the number of columns of $
\backslash
boldsymbol{H}$, and set $QRM = |
\backslash
mathbb{A}|$     
\backslash
State Initialize variables, tensors, and arrays     
\backslash
State Compute the distances at level $nt$: $a_{est} = 
\backslash
frac{y_p[nt - 1]}{H[nt - 1, nt - 1]}$, $d = |a_{est} - 
\backslash
mathbb{A}|^2$     
\backslash
State Sort the distances and initialize the parent nodes and parent received
 signals     
\backslash
For{$n$ in range($QRM$)}         
\backslash
For{$k$ in range($nt-1$, $0$, $-1$)}             
\backslash
State Compute the distances at level $k$: $a_{est} = 
\backslash
frac{y_p[k - 1]}{H[k - 1, k - 1]}$, $d = |a_{est} - 
\backslash
mathbb{A}|^2$             
\backslash
State Sort the distances and update the best candidates             
\backslash
State Perform pruning: check if $d_{min} > d_{total}$             
\backslash
If{pruning condition met}                 
\backslash
State Skip the remaining branches and move to the next subtree         
    
\backslash
EndIf         
\backslash
EndFor         
\backslash
State Store the $M$ best candidates         
\backslash
State Update the minimum total distance: $d_{min} = 
\backslash
min(d_{total})$         
\backslash
If{a new tree is opened}             
\backslash
State Check the pruning condition: $d_{min} > d_{p}$             
\backslash
State Reset the skip flag if needed         
\backslash
EndIf     
\backslash
EndFor     
\backslash
State Determine the vector with the minimum distance: $d_{minf} = 
\backslash
min(d_{total})$     
\backslash
State Reorder the detected symbols according to the original index: $
\backslash
hat{
\backslash
theta}_{
\backslash
text{NearML}}[index[k]] = s_{est3}[k]$ 
\backslash
EndProcedure 
\backslash
end{algorithmic} 
\backslash
end{algorithm} 
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Based on the provided NearML code, the time complexity can be analyzed by
 considering the nested loops and the operations inside them.
 The outer loop iterates 
\begin_inset Formula $\boldsymbol{QRM}$
\end_inset

 times, where 
\begin_inset Formula $\boldsymbol{QRM}$
\end_inset

 is the number of constellation symbols (denoted as 
\begin_inset Formula $\boldsymbol{|𝔸|}$
\end_inset

).
 Inside this loop, there is another loop that iterates nt times, where 
\begin_inset Formula $\boldsymbol{nt}$
\end_inset

 represents the number of columns in the channel matrix 
\begin_inset Formula $\boldsymbol{H}$
\end_inset

 which is 
\begin_inset Formula $\boldsymbol{N}$
\end_inset

.
 Within the inner loop, there are operations that take 
\begin_inset Formula $\boldsymbol{M}$
\end_inset

 and 
\begin_inset Formula $\boldsymbol{QRM}$
\end_inset

 time.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Therefore, the overall time complexity of the NearML algorithm can be approximat
ed as 
\begin_inset Formula $\boldsymbol{O\left(|𝔸|\times N\times\left(M+|𝔸|\right)\right)}\boldsymbol{\simeq O\left(|𝔸|^{2}\times N\times M\right)}$
\end_inset


\end_layout

\begin_layout Subsubsection
Conclusion 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\size large
Approach to symbol detection: 
\end_layout

\begin_deeper
\begin_layout Itemize
\paragraph_spacing onehalf

\size large
OSIC: This algorithm processes the received signal in a sequential manner,
 starting from the strongest to the weakest received symbol.
 It detects the strongest symbol first and then removes its interference
 from the received signal before detecting the next symbol.
 This process continues until all symbols are detected.
 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\size large
NearML: Is a tree search algorithm that explores all possible symbol combination
s and computes the distances between the received signal and candidate symbols.
 It then selects the candidate with the minimum total distance as the detected
 transmitted symbol.
 The algorithm employs pruning techniques to reduce the search space while
 still maintaining good detection performance.
\end_layout

\end_deeper
\begin_layout Itemize
\paragraph_spacing onehalf

\size large
Complexity: 
\end_layout

\begin_deeper
\begin_layout Itemize
\paragraph_spacing onehalf

\size large
OSIC: The complexity of the algorithm is relatively lower compared to NearML,
 as it processes the received signal in a sequential manner and does not
 require an exhaustive search of all possible symbol combinations.
 This makes OSIC faster and more suitable for real-time applications with
 lower computational resources.
 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\size large
NearML: The complexity of NearML is higher, as it involves an exhaustive
 search of all possible symbol combinations in the tree.
 However, the pruning techniques employed in the algorithm help reduce the
 search space and improve computational efficiency.
\end_layout

\end_deeper
\begin_layout Subsection

\size large
Neuronal
\size default
 networks
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Neural networks are a type of artificial intelligence system designed to
 mimic the functioning of the human brain.
 They consist of interconnected nodes, or "neurons," which are capable of
 processing information and making decisions based on that information.
 These networks are usually organized into layers, with each layer containing
 a different number of neurons.
 The input layer receives input from the external environment, while the
 output layer produces the final result or decision based on that input.
 The layers in between the input and output layers are called hidden layers,
 and they perform various intermediate calculations and processing tasks.
 Neural networks are trained using large amounts of data, allowing them
 to learn and make predictions or decisions based on that data.
 In this study case, the data consists of realistic channel realizations.
\end_layout

\begin_layout Subsubsection
Linear Layer
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
A linear layer in a neural network is a type of layer that applies a linear
 transformation to the input data.
 This transformation can be represented by a 
\series bold
matrix
\series default
 of weights, denoted as 
\size larger

\begin_inset Formula $\boldsymbol{W_{n}}$
\end_inset


\size large
 ,and a biases 
\series bold
vector
\series default
, denoted as
\size larger
 
\begin_inset Formula $\boldsymbol{b_{n}}$
\end_inset


\size large
, which are learned during the training process.
 The subscript 
\size larger

\begin_inset Formula $\boldsymbol{n}$
\end_inset


\size large
 refers to the nth layer.
 The output of a linear layer is calculated by performing a matrix and vector
 product between the input data 
\size larger

\begin_inset Formula $\boldsymbol{X_{n-1}}$
\end_inset

 
\size large
and the weights 
\size larger

\begin_inset Formula $\boldsymbol{W_{n}}$
\end_inset


\size large
 as well as adding the biases.
 
\end_layout

\begin_layout Standard

\size larger
\begin_inset Formula 
\begin{equation}
\boldsymbol{X_{n}=W_{n}X_{n-1}+b_{n}}
\end{equation}

\end_inset


\end_layout

\begin_layout Itemize

\size larger
\begin_inset Formula $\boldsymbol{W_{n}}$
\end_inset


\size large
weight matrix at layer n.
\end_layout

\begin_layout Itemize

\size larger
\begin_inset Formula $\boldsymbol{b_{n}}$
\end_inset

 
\size large
bias at layer n
\end_layout

\begin_layout Itemize

\size larger
\begin_inset Formula $\boldsymbol{X_{n-1}}$
\end_inset


\size large
Input or last layer data
\end_layout

\begin_layout Itemize

\size larger
\begin_inset Formula $\boldsymbol{X_{n}}$
\end_inset

 
\size large
Output data
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Diagrams/NN_eq.png
	lyxscale 70
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Output as Y and input as X.
 Vector matrix representation of system.
 Desing done with manim
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Backpropagation 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
The goal of the layer is to optimize the weights parameters so that they
 fit a target referred to as the ground truth.
 The error, denoted by E, is calculated as the difference between the predicted
 output (
\begin_inset Formula $\boldsymbol{\hat{X}}$
\end_inset

) and the actual target output (
\begin_inset Formula $\boldsymbol{X_{n}}$
\end_inset

), where 
\begin_inset Formula $n$
\end_inset

 is the index of the sample in the dataset.
 To achieve this, we will utilize the backpropagation algorithm, which is
 a common method in the field of artificial neural networks for training
 the network by adjusting the weights between neurons in the network.
 
\size larger

\begin_inset Formula 
\begin{equation}
\boldsymbol{Err=\hat{X}-X_{n}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
This method analyzes the error rate in relation to the weights and inputs.
 As we adjust our trainable parameters, {
\size larger

\begin_inset Formula $\boldsymbol{W_{n}}$
\end_inset


\size large
, 
\size larger

\begin_inset Formula $\boldsymbol{b_{n}}$
\end_inset


\size large
}, the error will change accordingly.
 The goal is to minimize the error, or to find a point where the error gradient
 is zero.
\begin_inset CommandInset citation
LatexCommand cite
key "Goodfellow-et-al-2016"
literal "false"

\end_inset


\end_layout

\begin_layout Standard

\size larger
\begin_inset Formula 
\begin{equation}
\boldsymbol{\nabla W=\frac{\partial E}{X_{n\text{+1}}}\times X_{n-1}^{T}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard

\size larger
\begin_inset Formula 
\begin{equation}
\boldsymbol{\nabla X_{n-1}=W_{n}^{T}\times\frac{\partial E}{X_{n\text{+1}}}}
\end{equation}

\end_inset


\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\boldsymbol{\boldsymbol{\times}}$
\end_inset

Matrix multiplication 
\end_layout

\begin_layout Itemize

\size larger
\begin_inset Formula $\boldsymbol{\nabla W}$
\end_inset


\size large
Gradient of weights.The gradient is a multi-variable generalization of the
 derivative.
\end_layout

\begin_layout Subsubsection
Learning rate
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
When training a neural network, the weights 
\begin_inset Formula $\boldsymbol{W_{n}}$
\end_inset

 and bias terms 
\begin_inset Formula $\boldsymbol{b_{n}}$
\end_inset

 are updated iteratively using an optimization algorithm such as gradient
 descent.
 The learning rate 
\begin_inset Formula $\gamma$
\end_inset

 is a hyperparameter that plays a crucial role in this process by determining
 the size of the update step applied to the weights and biases at each iteration.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The learning rate 
\begin_inset Formula $\gamma$
\end_inset

 is a scalar value that is multiplied by the gradient of the loss function
 with respect to the weights of the network.
 This gradient provides information about the direction and magnitude of
 the weight update required to minimize the loss function.
 A smaller learning rate leads to smaller updates and slower convergence,
 while a larger learning rate results in larger updates and faster convergence.

\size default
 
\begin_inset CommandInset citation
LatexCommand cite
key "learningrate"
literal "false"

\end_inset

 
\end_layout

\begin_layout Standard

\size larger
\begin_inset Formula 
\begin{equation}
\boldsymbol{W_{n}}=\boldsymbol{W_{n}}-\gamma\boldsymbol{\nabla W}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard

\size larger
\begin_inset Formula 
\begin{equation}
\boldsymbol{b_{n}}=\boldsymbol{b_{n}}-\gamma\boldsymbol{\frac{\partial E}{X_{n}}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
If the learning rate is set too low, the optimization process may become
 stuck in a local minimum or local maximum.
 A local minimum is a point in the optimization landscape where the cost
 function has a lower value than the surrounding points, but is not the
 global minimum.
 A local maximum is a point where the cost function has a higher value than
 the surrounding points, but is not the global maximum.
 This can lead to suboptimal performance or even failure of the optimization
 process.
 On the other hand, if the learning rate is set too high, the optimization
 process may oscillate or diverge, also leading to suboptimal performance.
 It is important to choose an appropriate learning rate for the optimization
 process in order to avoid these problems.
\end_layout

\begin_layout Subsubsection
Activation functions 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Activation functions are used in neural networks to introduce non-linearity
 into the network.
 This is important because many real-world problems are non-linear in nature
 and a neural network with only linear functions would not be able to model
 such problems accurately.
 Activation functions allow the network to learn more complex patterns in
 the data and improve the accuracy of the network.
 They also help to prevent the network from becoming stuck in a local minimum
 or plateau during training.
 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
However, the traditional activation functions pose some challenges when
 it comes to embedded devices.
 They often involve computationally expensive operations such as exponentiation,
 division, and floating-point arithmetic.
 These operations can significantly increase the processing time and power
 consumption, making them less attractive for resource-constrained embedded
 systems.
 To address these concerns, researchers have proposed hardened versions
 of activation functions.
 Hardened activation functions are designed to be computationally less demanding
 while maintaining similar performance to their traditional counterparts.
 Examples of hardened activation functions include the binary step function,
 RELU, Hardtahn, Hardsigmoid.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/ActivationFunctions.png
	lyxscale 10
	scale 10

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Activation function.
 (a) Sigmoid, (b) tanh, (c) ReLU.
 
\begin_inset CommandInset citation
LatexCommand cite
key "ActivationFunctionsImages"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The most widely used activation functions in neural networks include the
 sigmoid, hyperbolic tangent (tanh), and rectified linear unit (ReLU) functions.
 The sigmoid function transforms any input value into a range from 0 to
 1, while the tanh function adjusts input values to fall within the -1 to
 1 range.
 The ReLU function operates linearly, setting all negative input values
 to 0 and retaining all positive input values in their initial form.
 
\begin_inset CommandInset citation
LatexCommand cite
key "ActivationFunctions"
literal "false"

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
As we have seen before, there exist "hardened" variants of activation functions,
 such as hardtanh and hardsigmoid, that offer more efficient computational
 evaluations while maintaining comparable outcomes to their traditional
 counterparts.
 These hardened activation functions enable faster neural network computations
 while still delivering similar results, with the Hardtanh function being
 the most used for this research that can be described as follows:
\end_layout

\begin_layout Standard

\size larger
\begin_inset Formula 
\begin{equation}
\boldsymbol{hardtanh(x)=\begin{cases}
-1, & \text{if }x<-1\\
x, & \text{if }-1\le x\le1\\
1, & \text{if }x>1
\end{cases}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Hardtanh.png
	lyxscale 25
	scale 25

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Hardtanh(red) and Tanh(blue)
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Loss functions
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
A loss function is often defined as a scalar function of the model's parameters,
 the input data, and the true output.
 It quantifies how well the model is able to fit the data, and it's commonly
 used to evaluate the performance of different models and to select the
 best one.
 In terms of estimators, a loss function can be seen as a measure of how
 well the estimator is able to estimate the true parameter.
 The goal of training a machine learning model is to find the optimal set
 of parameters that minimize the loss function.
 There are different types of loss functions, each one is suitable for different
 types of problems.
 There are various types of loss functions, each tailored to specific types
 of problems.
 For example, in a regression problem, the mean squared error (MSE), as
 mentioned in section 
\color blue

\begin_inset CommandInset ref
LatexCommand eqref
reference "subsec:MSE"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
 , is a commonly used loss function.
 Conversely, in classification problems, the cross-entropy loss is often
 employed.
 Due to its significance, we will delve deeper into the cross-entropy loss
 in the following section, discussing how it operates within the context
 of deep learning.
\end_layout

\begin_layout Subsubsection
Cross Entropy Loss
\begin_inset CommandInset label
LatexCommand label
name "subsec:Cross-Entropy-Loss"

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Previously, we have discussed the Mean Squared Error (MSE) in the context
 of estimators.
 However, there is another cost function, known as the cross-entropy loss,
 which can be utilized for evaluating models in the context of classification
 problems.
 Prior to elaborating on the cross-entropy loss, it is imperative to also
 discuss the softmax function.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The softmax function is a mathematical technique which transforms a vector
 of real numbers into a probability distribution over the classes.
 The output of the softmax function is a vector of values between 0 and
 1 that sum up to 1, which can be interpreted as probabilities.
 The softmax function is employed in this context as it provides a means
 to convert the output, or scores, of the model into a probability distribution
 that represents the uncertainty of the model's predictions.
 Additionally, the softmax function ensures that the probability of each
 class falls within the range of 0 and 1 and that the sum of all class probabili
ties is 1, which is a necessary requirement for a probability distribution.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/softmax.png
	lyxscale 40
	scale 40

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Softmax used to map real numbers to probabilty distribution.
\begin_inset CommandInset label
LatexCommand label
name "fig:Softmax"

\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "softmax"
literal "false"

\end_inset

 
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
After the softmax output, it is measured by the cross-entropy loss function,
 which checks the dissimilarity between the predicted and true probability
 distributions.
 One of the many advantages of this function is that it is also easy to
 compute and differentiate, making it a suitable loss function for gradient-base
d optimization algorithms.
 The goal of the training process is to minimize the Kullback-Leibler divergence.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size larger
\begin_inset Formula 
\begin{equation}
\boldsymbol{D_{KL}(P||Q)=\sum P(i)log\frac{P(i)}{Q(i)}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard

\size large
In this equation, 
\begin_inset Formula $\boldsymbol{D_{KL}(P∣∣Q)}$
\end_inset

 represents the KL divergence between two probability distributions 
\begin_inset Formula $\boldsymbol{P}$
\end_inset

 and 
\begin_inset Formula $\boldsymbol{Q}$
\end_inset

, where 
\begin_inset Formula $\boldsymbol{P}$
\end_inset

 is the true distribution and 
\begin_inset Formula $\boldsymbol{Q}$
\end_inset

 is the approximating distribution.
 The double vertical bars (
\begin_inset Formula $\boldsymbol{||}$
\end_inset

) in the notation denote "divergence between" the two distributions.
 The KL divergence is widely used in information theory and machine learning
 to evaluate the dissimilarity between two distributions.
 It is important to note that the Kullback-Leibler (KL) divergence is not
 symmetric.
 In other words, the KL divergence between distributions P and Q, denoted
 as 
\begin_inset Formula $\boldsymbol{D_{KL}(P∣∣Q)}$
\end_inset

, is not equal to the KL divergence between 
\begin_inset Formula $\boldsymbol{Q}$
\end_inset

 and 
\begin_inset Formula $\boldsymbol{P}$
\end_inset

, denoted as 
\begin_inset Formula $\boldsymbol{D_{KL}(Q∣∣P)}$
\end_inset

.
 The asymmetry of the KL divergence implies that it should not be regarded
 as a true distance metric in the strict mathematical sense.
 Instead, it serves as a measure of dissimilarity between two probability
 distributions.
 This characteristic is also reflected in its alternative name, relative
 entropy.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The KL divergence plays a crucial role in determining which class is more
 probable.
 The predicted class distribution, denoted by 
\begin_inset Formula $P(y∣x_{i};θ)$
\end_inset

, is influenced by the parameters 
\begin_inset Formula $θ$
\end_inset

, while the true class distribution is represented by 
\begin_inset Formula $P∗(y∣x_{i})$
\end_inset

.
 Both of these distributions are taken into account when assessing the dissimila
rity between them.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size larger
\begin_inset Formula 
\begin{equation}
\boldsymbol{D_{KL}(P^{*}(y|x_{i})||P(y|x_{i};\theta)=\sum P^{*}(y|x_{i})log\frac{P^{*}(y|x_{i})}{P(y|x_{i};\theta)}}
\end{equation}

\end_inset


\size large
Rewriting the logarithm as two individual sections, we can observe that
 the left part of the equation below does not depend on the 
\begin_inset Formula $\theta$
\end_inset

 parameter.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size larger
\begin_inset Formula 
\begin{equation}
\boldsymbol{\sum\underbrace{P^{*}(y|x_{i})log(P^{*}(y|x_{i}))}_{\text{Independent of }\theta}-P^{*}(y|x_{i})P(y|x_{i};\theta)}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
And then we aim to make both distributions as similar as possible using
 the best estimator.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size larger
\begin_inset Formula 
\begin{equation}
\boldsymbol{\underset{\theta}{\text{argmin}}D_{KL}(P^{*}||P)\equiv\underset{\theta}{\text{argmin}}-\sum_{y}P^{*}(y|x_{i})P(y|x_{i};\theta)}
\end{equation}

\end_inset


\end_layout

\begin_layout Subsection
Effective Techniques for Improving Model Generalization
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
In the field of machine learning, it is important to ensure that the models
 we build are able to accurately and effectively make predictions on new
 data.
 However, it is common for models to suffer from issues such as overfitting
 or poor generalization to new data.
 In this section, we will explore three techniques that can be used to improve
 the performance of machine learning models: 
\series bold
regularization
\series default
, 
\series bold
normalization
\series default
, and 
\series bold
standardization
\series default
.
 By properly applying these techniques, we can mitigate the risks of overfitting
 and improve the ability of our models to generalize to new data.
 
\begin_inset CommandInset citation
LatexCommand cite
key "Regularization_Bisong,Normalization_layers,standarization"
literal "false"

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\shape italic
\size large
\emph on
\bar under
\color black
Our data set, which includes doubly dispersive channels of a complex nature,
 requires extra attention.
 We will use distorted vectors or inverse matrices, which can result in
 numerical instability, as our ground truth.
 These extra precautions will help to guarantee the process' success.
 Ignoring these recommendations may result in unsatisfactory outcomes, as
 the neural network may not generalize as well and may perform poorly.
 
\begin_inset CommandInset citation
LatexCommand cite
key "ComplexnumbersNN"
literal "false"

\end_inset


\end_layout

\begin_layout Subsubsection
Regularization
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
Regularization is a technique used in machine learning to prevent overfitting.
 Overfitting occurs when a model is overly complex and captures the noise
 in the training data, rather than the underlying relationships.
 This results in poor generalization to new data.
 Regularization works by adding a penalty term to the objective function
 that the model is trying to minimize.
 This penalty term discourages the model from learning relationships that
 are too complex, and encourages it to learn simpler relationships that
 generalize better.
 There are several methods for regularization, including 
\begin_inset CommandInset citation
LatexCommand cite
key "Goodfellow-et-al-2016"
literal "false"

\end_inset

:
\end_layout

\begin_layout Enumerate
\align block

\size large
L1 regularization: This method adds a penalty term to the cost function
 that is proportional to the absolute value of the weights.
\end_layout

\begin_layout Enumerate
\align block

\size large
L2 regularization: This method adds a penalty term to the cost function
 that is proportional to the square of the weights.
\end_layout

\begin_layout Enumerate
\align block

\size large
Dropout regularization: This method randomly sets a fraction of the weights
 in the model to zero during training, which helps to prevent overfitting
 by reducing the number of parameters in the model.
 Dropout is only applied during the training process, and all neurons are
 available during evaluation.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename trasasdenivelRegularization.png
	lyxscale 50
	scale 60

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Level sets of the loss function and L1,L2 regularization 
\begin_inset CommandInset citation
LatexCommand cite
key "regimage"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
To implement regularization, you can modify the cost function of the model
 to include the regularization term.
 For example, in L2 regularization, the cost function would be modified
 to include the sum of the squares of the weights, as shown in the following
 equation:
\end_layout

\begin_layout Standard

\size larger
\begin_inset Formula 
\begin{equation}
\boldsymbol{J(W)=\frac{\lambda}{2}||w||^{2}=\frac{\lambda}{2}\sum_{j=1}^{m}w_{j}^{2}}
\end{equation}

\end_inset


\end_layout

\begin_layout Itemize

\size larger
\begin_inset Formula $\boldsymbol{\lambda}$
\end_inset

 
\size large
regularization parameter
\end_layout

\begin_layout Itemize

\size larger
\begin_inset Formula $\boldsymbol{J(W)}$
\end_inset

 
\size large
Cost function
\end_layout

\begin_layout Subsubsection
Normalization 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Data is scaled using a process called normalization to give it a unit norm
 (or length).
 This is frequently done to improve the data's suitability for particular
 machine learning algorithms, such as those that use gradient descent or
 have a set range for acceptable input data.
 When comparing various features, normalization can also be used to scale
 down the data to a common scale.
 Data normalization methods include min-max normalization, mean normalization,
 and z-score normalization.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\series bold
\size large
Normalization of complex numbers
\series default
 involves dividing a complex number by its magnitude (or absolute value)
 to obtain a complex number with a magnitude of 1.
 This is typically done to simplify calculations and make it easier to compare
 complex numbers.
 The normalized form of a complex number is often written as ẑ = z/|v|,
 where z is the original complex number and ẑ is the normalized form and
 |v| is the max magnitud of the entire vector of the complex numbers.
 Normalization of complex numbers is useful in many applications, including
 signal processing and control systems, where it is often necessary to compare
 complex numbers on an equal footing.
 
\begin_inset CommandInset citation
LatexCommand cite
key "ComplexnumbersNN"
literal "false"

\end_inset


\end_layout

\begin_layout Standard

\size larger
\begin_inset Formula 
\begin{equation}
\boldsymbol{ẑ=\frac{z}{|v|}}
\end{equation}

\end_inset


\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\boldsymbol{|v|}$
\end_inset

 Maximum magnitud of the vector
\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\mathsf{\boldsymbol{z}}$
\end_inset

 Input value
\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\boldsymbol{ẑ}$
\end_inset

 Normalized value
\end_layout

\begin_layout Subsubsection
Standarization 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
Standardization is a method used in machine learning to transform the values
 of a feature or set of features to a standard scale.
 The standard scale is typically defined as having a mean of 0 and a standard
 deviation of 1.
 Standardization is often used as a preprocessing step before training a
 model, as it can help to improve the performance and convergence of the
 model.
 Standardization can be useful when the features in the dataset have different
 scales or units, as it can help to bring them onto a common scale and make
 it easier for the model to learn from the data.
 Standardization can be applied to both real and complex-valued data.
\end_layout

\begin_layout Standard

\size larger
\begin_inset Formula 
\begin{equation}
\boldsymbol{\hat{z}=\frac{z-\mu}{\sigma}}
\end{equation}

\end_inset


\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\boldsymbol{\mu}$
\end_inset

 Mean of the data
\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\boldsymbol{\sigma}$
\end_inset

 Standard deviation of the data
\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\mathsf{\boldsymbol{z}}$
\end_inset

 Input value
\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\boldsymbol{ẑ}$
\end_inset

 Standarized value
\end_layout

\begin_layout Subsubsection
Gradient clipping
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Gradient clipping is a technique used to prevent the gradients of a neural
 network from becoming too large during training.
 It is commonly used to mitigate the problem of exploding gradients, which
 can occur when the gradients become too large and cause the model's parameters
 to diverge.
 This means that if the gradient exceeds this threshold, it will be set
 to the threshold value.
 This effectively limits the size of the gradients and keeps them from becoming
 too large.
 
\begin_inset Formula $ $
\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{algorithm} 
\backslash
caption{Gradient Clipping} 
\end_layout

\begin_layout Plain Layout


\backslash
begin{algorithmic}[1] 
\end_layout

\begin_layout Plain Layout


\backslash
State threshold $
\backslash
gets$ max
\backslash
_norm 
\end_layout

\begin_layout Plain Layout


\backslash
For{each parameter p in the model}     
\end_layout

\begin_layout Plain Layout


\backslash
State $ 
\backslash
boldsymbol{g} 
\backslash
gets 
\backslash
frac{
\backslash
partial
\backslash
epsilon}{
\backslash
partial
\backslash
theta}$     
\end_layout

\begin_layout Plain Layout


\backslash
If{$
\backslash
left
\backslash
|
\backslash
boldsymbol{g}
\backslash
right
\backslash
| > threshold$}         
\end_layout

\begin_layout Plain Layout


\backslash
State $
\backslash
boldsymbol{g} 
\backslash
gets 
\backslash
frac{
\backslash
boldsymbol{g}}{
\backslash
left
\backslash
|grad
\backslash
right
\backslash
|} 
\backslash
times$ threshold     
\end_layout

\begin_layout Plain Layout


\backslash
EndIf     
\end_layout

\begin_layout Plain Layout


\backslash
State 
\end_layout

\begin_layout Plain Layout

update
\backslash
_parameter(p, grad) 
\end_layout

\begin_layout Plain Layout


\backslash
EndFor 
\end_layout

\begin_layout Plain Layout


\backslash
end{algorithmic} 
\end_layout

\begin_layout Plain Layout


\backslash
end{algorithm} 
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/GradiantClipping.png
	scale 70

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Gradient clipping
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Z-score
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The Z-score,
\begin_inset CommandInset label
LatexCommand label
name "subsec:Z-score"

\end_inset

 also known as standard score, is a statistical measure that indicates how
 many standard deviations an observation or data point is from the mean
 of a data set.
 It is used to standardize data and compare individual observations to a
 population or sample mean.
 The magnitude of the z-score represents how far away the data point is
 from the mean in terms of standard deviations.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
This method has its own section in our results due to its relevance.
 It helps us to remove outliers and make our results more stable.
 Outliers are data points that are significantly different from the other
 data points in the data set and can skew statistical analyses or machine
 learning models.
 Z-score can be used to identify and reduce outliers in a data set.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
To identify outliers using z-score, we first calculate the z-score for each
 data point in the data set.
 We can then set a threshold z-score value, usually between 2 and 3, beyond
 which any data point is considered an outlier.
 Data points that have a z-score above the threshold are identified as outliers
 and can be removed from the data set.
 This can help to improve the accuracy and reliability of our results or
 predictions.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{z=\frac{x_{i}-\mu}{\sigma}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
We use the z-score to filter outliers with a desired level of confidence,
 which is typically set at 95%.
 This corresponds to a z-score of 1.96, which means that approximately 95%
 of the data points would fall within the confidence interval.
 The 95% confidence level is commonly used in statistical analyses as a
 standard level of confidence
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/ConfidenceInterval.png
	lyxscale 70
	scale 70

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
95% Confidence interval 
\begin_inset CommandInset citation
LatexCommand cite
key "z_score_drawing"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Convolutional Neuronal Networks
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
During the research, we will need to work with channel matrices as inputs
 for neural networks.
 As these are matrices rather than vectors, we will discuss convolutional
 neural networks (CNNs), which are a type of deep learning neural network
 primarily used for image recognition and dimensional reduction.
 This type of network excel at feature extraction, which is a critical aspect
 of their success in various applications, especially in image recognition
 and computer vision tasks.
 Feature extraction is the process of identifying and extracting relevant
 patterns or features from raw data, helping the model to discern and recognize
 important characteristics within the input.
 The network is composed of multiple layers, including 
\series bold
convolutional layers
\series default
, 
\series bold
activation layers
\series default
, 
\series bold
pooling layers 
\series default
and
\series bold
 linear layers
\series default
.
 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The convolutional layers apply a set of filters to the input data, where
 each filter is a small matrix of weights.
 This ones are used to identify features in the data such as 
\series bold
edges
\series default
, 
\series bold
textures
\series default
, and 
\series bold
shapes
\series default
, specifically, we will be utilizing these layers to extract the relationship
 of intercarrier symbol interference (ISI) and to perform dimensionality
 reduction.
 
\begin_inset CommandInset citation
LatexCommand cite
key "Conv1"
literal "false"

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "Goodfellow-et-al-2016"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\size large
The 
\series bold
activation layers
\series default
 or activation functions introduce non-linearity to the network, allowing
 it to learn complex representations of the input data.
 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\size large
The 
\series bold
pooling layers
\series default
 reduce the spatial dimensions of the data, which helps to reduce overfitting
 and computational cost.
\end_layout

\begin_deeper
\begin_layout Itemize
\paragraph_spacing onehalf

\size large
Max pooling is used to pick the feature with the highest activation in a
 small region of the input feature map
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\size large
Average pooling is used to reduce the spatial size of the input data by
 taking the average of the values of a small region of the input feature
 map.
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Diagrams/Max_pool_avg_pool.jpg
	lyxscale 40
	scale 20

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Average and max pooling
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Itemize
\noindent
\align block

\series bold
\size large
Linear layers
\series default
 classify the features extracted by the convolutional layers into the desired
 output.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent
\align block

\size large
It should be noted that what is commonly referred to as 'convolution' in
 the context of convolutional neural networks (CNNs) is actually a cross-correla
tion operation, denoted with symbol 
\begin_inset Formula $\mathbf{\bigstar}$
\end_inset

 and convolution usually is used 
\begin_inset Formula $\boldsymbol{*}$
\end_inset

.
 The term 'convolution' is used only for convention purposes.
 The basic concept behind cross-correlation is to take a small matrix, referred
 to as a kernel or filter, and slide it over the input data (such as an
 image or audio signal).
 At each position, the kernel is multiplied element-wise with the underlying
 data, and the results are summed to produce a single output value, referred
 to as a feature map.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Diagrams/Conv2d_Kernel.jpg
	lyxscale 30
	scale 25

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Caption Standard

\begin_layout Plain Layout
Basic cross-correlation operation
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The output of the convolution operation is a feature map, where each element
 in the feature map is computed as follows:
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{Y_{ij}=\sum K_{ab}\circ I_{i+a,j+b}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Where kernel(a,b) is the value of the filter at position (a,b), input(i+a,j+b)
 is the value of the input at position (i+a,j+b) and output(i,j) is the
 output value at position (i,j)
\end_layout

\begin_layout Subsubsection
Channels
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
A channel refers to a specific feature or dimension of the input data.
 For example, in the case of image data, a channel can represent a color
 channel such as red, green, or blue.
 These channels are used to extract different features of the input image,
 and they are processed separately by the CNN.
 In our case study, we can use channels as a division between the real and
 imaginary parts, or for feature extraction of intercarrier symbol interference
 (ISI).
 We can have N channels as input and M channels as output, depending on
 how many features we want to deal with.
 In the image below, we show a case of 3 channel input and two channel output,
 also with a bias term.
\size default

\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/ConvolutionExpansion.png
	lyxscale 50
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Convolutional Neural Network with 3-channel Input and 2-channel Output,
 including bias term
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
A Generalized View of Linear Layers through Convolutional Neural Networks
\end_layout

\begin_layout Standard

\size large
Let's take a more detailed look at the math, given the following terms.
\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\boldsymbol{j}$
\end_inset

 input channels with
\begin_inset Formula $\boldsymbol{X_{j}}$
\end_inset

 matrices
\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\boldsymbol{d}$
\end_inset

 ouput channels 
\begin_inset Formula $\boldsymbol{Y_{d}}$
\end_inset

matrices and this ones an output size of 
\begin_inset Formula $\boldsymbol{X_{j}-K_{ij}}$
\end_inset


\end_layout

\begin_layout Itemize

\size large
\begin_inset Formula $\boldsymbol{K_{ij}}$
\end_inset

 kernels,where 
\begin_inset Formula $\boldsymbol{i}$
\end_inset

 maps to 
\begin_inset Formula $\boldsymbol{Y_{d}}$
\end_inset

 and 
\begin_inset Formula $\boldsymbol{j}$
\end_inset

 to 
\begin_inset Formula $\boldsymbol{X_{j}}$
\end_inset


\end_layout

\begin_layout Itemize
\noindent
\align block

\size large
\begin_inset Formula $\mathbf{\bigstar}$
\end_inset

 cross-correlation
\end_layout

\begin_layout Standard

\size larger
\begin_inset Formula 
\begin{equation}
\boldsymbol{Y_{d}=B_{d}+\sum_{j=1}^{n}X_{j}\bigstar K_{ij}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
We can think of the matrices as individual blocks and visualize them in
 the image below.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Conv2dGeneralization.png
	lyxscale 40
	scale 60

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset Formula $Y_{d}$
\end_inset

 output given kernels
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Finally, with the use of abstraction, we can further simplify the problem
 by representing it as a generalized version of tensors.
 The internal tensor is given by the sum of the cross-correlations between
 X channels and kernels.
 In a more general perspective, this can be viewed as the inner product
 of two tensors.
\end_layout

\begin_layout Standard

\size larger
\begin_inset Formula 
\begin{equation}
\boldsymbol{Y=B+\langle K,X\rangle}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/MetaDense.png
	lyxscale 50
	scale 70

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Higher dimensionality abstract version 
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
It's worth noting that when we consider a kernel of 1 dimension and an input
 of 1 channel, we can see that a dense layer is just a specific case of
 a 2D convolutional layer (Conv2D).
 Just as equation (15) and figure (8)
\end_layout

\begin_layout Subsection
FLOPS
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
FLOPS stands for "floating point operations per second." It is a measure
 of the computational performance of a computer or processor, and it indicates
 how many floating point arithmetic operations can be performed in one second.
 Floating point operations include addition, subtraction, multiplication,
 and division, as well as more complex operations like trigonometric functions,
 logarithms, and exponentials.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
FLOPS is commonly used as a benchmark for evaluating the performance of
 CPUs, GPUs, and other computing devices.
 It is often used in the context of high-performance computing, scientific
 simulations, and machine learning applications, where large amounts of
 data must be processed quickly.
 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
One approach to measuring FLOPS that we used in this work is to calculate
 the execution time and multiply it by the number of operations in each
 equalizer.
 This allows us to visualize the time complexity and efficiency of the equalizer
s.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\boldsymbol{FLOPS\simeq\frac{1}{ExecTime}*Operations}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Performance variations in parallel algorithms stem from differences in design,
 implementation, and parallelism efficiency.
 Factors like memory access patterns, communication overhead, and load balancing
 also influence performance on multi-core systems.
 As a result, floating-point operation rates can change depending on algorithm
 effectiveness and work distribution among cores.
\end_layout

\begin_layout Subsection
Objectives
\end_layout

\begin_layout Subsubsection
General Objective
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
We aim to analyze and test various neural network techniques for frequency
 channel equalization in OFDM systems.
 Our approach involves breaking the process into simpler and more complex
 tasks based on time complexity, delegating complex tasks like matrix inversion
 to neural networks while handling lighter tasks in a preprocessing stage.
 As matrix inversion is sensitive to initial conditions, our research will
 explore how neural networks can effectively address these challenges.
 Combining preprocessing methods such as 
\begin_inset Formula $\boldsymbol{H^{H}}$
\end_inset

 and zero forcing with the non-linearity of neural networks generally leads
 to better performance than classical equalization in terms of BER and BLER.
 We will evaluate this performance across various noise levels, ranging
 from 5dB to 45dB.
\end_layout

\begin_layout Subsubsection
Particular Objective
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
A double dispersive channel presents significant challenges for communication
 systems due to its frequency and time variations, noise, and intercarrier
 symbol interference (ISI).
 Our objective is to recover QAM and PSK constellation symbols that have
 been distorted by a channel with both line-of-sight (LOS) and non-line-of-sight
 (NLOS) conditions, while achieving a bit error rate (BER) and block error
 rate (BLER) that are comparable to established benchmarks known as "golden
 models." To achieve this, we explore a range of techniques, including linear
 methods such as Least Squares (LS), Linear Minimum Mean Square Error (LMMSE),
 and Zero Forcing, as well as non-linear techniques such as Ordered Successive
 Interference Cancellation (OSIC) and Near Maximum Likelihood (NearML).
 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
We begin our exploration in the field of deep learning with feedforward
 layers, followed by the integration of complex numbers in neuronal networks,
 then convolutional layers, and finally transformers.
 We aim to leverage the non-linearity of neural networks and explore a range
 of techniques, starting from simpler models that use linear layers and
 basic activation functions and then advancing to more sophisticated techniques
 involving complex numbers integrated into neural network architectures.
 To extract the most relevant information from the channel, we employ dimensiona
lity reduction using a Convolutional Neural Network (CNN) and a non-linear
 process.
 Furthermore, we examine the use of attention mechanisms to reduce intercarrier
 symbol interference (ISI).
 Finally, the FLOPS metric and time complexity will play an important role
 in benchmarking and conducting a relevant analysis of the situations in
 which neural networks can be used.
 This analysis will help to determine which neural network architecture
 is better suited to a given situation and to develop a better tradeoff
 between accuracy and computational complexity.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align block

\size large
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newpage
\end_layout

\end_inset


\end_layout

\begin_layout Section
State of Art
\end_layout

\begin_layout Subsection
Introduction
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
To support our research and development, we conducted a thorough study of
 several key papers, which we organized into different categories based
 on their relevance to the project.
 In the following sections, I will provide a brief overview of how each
 of these articles contributed to the development of our project.
 Please note that many papers in the literature deal with smaller input
 and channel sizes than the 48x48 size used in our research.
 It is possible that these studies were mostly focused on proofs of concepts
 or making results fit better.
 Nevertheless, we opted for a larger channel size to create a more realistic
 scenario for our research.
 So BER/SNR metrics should be based on the golden models rather than on
 these articles.
\end_layout

\begin_layout Subsection
\paragraph_spacing onehalf
\noindent

\size large
The Roadmap to 6G – AI Empowered Wireless Networks 
\begin_inset CommandInset citation
LatexCommand cite
key "The_Roadmap_to_6G"
literal "false"

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The integration of AI technologies in the communication network provides
 a promising future for efficient and reliable communication in 6G and beyond.
 The "intelligent PHY layer" paradigm, through its ability to self-learn
 and self-optimize, ensures that the system remains efficient and reliable
 despite the various hardware and channel effects.
 This model leverages AI technologies to enhance communication efficiency
 and performance, and can autonomously learn and enhance performance through
 the integration of cutting-edge sensing and data-gathering tools.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Hardware heterogeneity necessitates system redesign for different hardware
 settings, which can be overcome using transfer learning.
 This approach adjusts the neural network weights to work with custom hardware
 architecture, regardless of the training on floating point or fixed point
 backpropagation.
 Therefore, network architecture is more crucial than numeric resolution
 in contrast to traditional methods.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Papers/RoadMap6G.png
	lyxscale 50
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Roadmap showing the evolution of deep learning models in telecom and justifying
 our research 
\begin_inset CommandInset citation
LatexCommand cite
key "The_Roadmap_to_6G"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
In conclusion, we present a roadmap in the image above depicting the expected
 evolution of deep learning in the coming years.
 This image justifies the necessity of our research.
 The picture shows the progression of models from simpler to more intelligent
 systems, with the intelligence level displayed in circles on the right
 side of the image.
\end_layout

\begin_layout Subsection
\paragraph_spacing onehalf
\noindent

\size large
A Novel OFDM Equalizer for Large Doppler Shift Channel through Deep Learning
 
\begin_inset CommandInset citation
LatexCommand cite
key "ZeroForcingEqNN"
literal "false"

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset CommandInset label
LatexCommand label
name "subsec:A-Novel-OFDM"

\end_inset

This documentation describes the proposed neural architecture called Cascaded
 Net (CN) for equalization in OFDM systems.
 The use of a zero-forcing preprocessor aims to prevent the network from
 getting stuck in a saddle point or local minimum point.
 The CN neural architecture is designed to address the equalization problem
 in OFDM systems with Rayleigh fading and large Doppler shifts.
 By cascading a deep trainable network behind a zero-forcing preprocessor,
 the CN architecture achieves superior performance in comparison to traditional
 equalization methods.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Papers/ZeroForcePreprocess.png
	lyxscale 50
	scale 40

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Deep learning equalizer with prepocesing stage.
 
\size large

\begin_inset CommandInset citation
LatexCommand cite
key "ZeroForcingEqNN"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
As they are performing frequency domain equalization, their base equation
 is the same as ours.
 
\begin_inset Formula $\boldsymbol{Y=Hx+W}$
\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The Cascade net is defined as follows.
 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\hat{\boldsymbol{X_{0}=(H^{H}H)^{-1}H^{H}Y}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{z_{i}=w_{i}\left[\begin{array}{c}
H^{H}Y\\
\hat{X_{i}}\\
H^{H}H\hat{x_{i}}
\end{array}\right]+b_{i}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{\hat{X_{i+1}}=\phi(z_{i})}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Where 
\begin_inset Formula $\boldsymbol{w}$
\end_inset

 and 
\begin_inset Formula $\boldsymbol{b}$
\end_inset

 representes weights and bias as trainnable parameters.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{\phi=tanh\left(\frac{x}{|t_{i}|}\right)}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Papers/CascaNet.png
	lyxscale 50
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Cascade Net 
\size large

\begin_inset CommandInset citation
LatexCommand cite
key "ZeroForcingEqNN"
literal "false"

\end_inset


\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "Preprocesing"

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Their loss function or estimator is based on the Euclidean distance, with
 a logarithmic regularization of outliers and the objective of minimizing
 the distance between points.
 They accumulate the total estimation for each layer i and finally sum it
 up.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\mathbf{loss(X_{\theta}^{CN}(H,Y))=\sum_{i=1}^{L}log(i)||X-\hat{X||^{2}}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
To deal with complex matrix number they make a reformulation in the matrix
 as follows.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center

\size large
\begin_inset Graphics
	filename Imagenes/Papers/ComplexMatrix.png
	lyxscale 50
	scale 70

\end_inset


\size default

\begin_inset Caption Standard

\begin_layout Plain Layout
Matrix reformulation 
\size large

\begin_inset CommandInset citation
LatexCommand cite
key "ZeroForcingEqNN"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
BER perfomance
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The image below shows a benchmark of different equalizers, including ZF
 (Zero Forcing), PIC (Parallel Interference Cancellation), DET (Deep MIMO
 Detection Network)
\begin_inset CommandInset citation
LatexCommand cite
key "DeepMimoOFDM"
literal "false"

\end_inset

], and CN (Cascaded Net).
 The modulation they used in the experiment below is QPSK.
 and they assume that CSI is perfect.
 The receiver is trained off-line for the single-user system with fixed
 Doppler shift.
 If Subcarrier number 
\begin_inset Formula $N$
\end_inset

 is 32, 
\begin_inset Formula $f_{N}$
\end_inset

 equals to 0.16.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Papers/CascadeResults.png

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
QPSK equalization with different strategies in the paper 
\begin_inset CommandInset citation
LatexCommand cite
key "ZeroForcingEqNN"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent

\size large
Classical PIC methods perform well in low subcarrier frequency scenarios
 (
\begin_inset Formula $f_{N}$
\end_inset

 less than 0.1).
 However, their performance degrades significantly with an increase in subcarrie
r frequency due to significant error propagation, as stated in the first
 section.
\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent

\size large
Deep MIMO detection (Det) faces a flat error curve in high SNR scenarios.
\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent

\size large
Cascaded Net (CN) consistently performs well compared to Zero Forcing (ZF)
 and Det, which is in line with the argument made in the third section.
\end_layout

\begin_layout Subsubsection
\paragraph_spacing onehalf
\noindent
Performance Improvement Strategies for our solutions
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
As a conclusion, we have opted to use 
\begin_inset Formula $\boldsymbol{H^{H}Y}$
\end_inset

 instead of pure 
\begin_inset Formula $\boldsymbol{Y}$
\end_inset

 as an input for certain neural networks in our research.
 We have also implemented zero forcing as an additional preprocessing stage.
 These strategies have proven to be effective as they bring constellation
 points closer to one another, reducing the network's burden to equalize
 the signal to the ideal state, particularly when dealing with long distances
 between ideal point and recieved point.
 
\end_layout

\begin_layout Subsection
\paragraph_spacing onehalf
\noindent

\size large
Recent Advances in Neural Network Techniques For Channel Equalization:A
 Comprehensive Survey 
\begin_inset CommandInset citation
LatexCommand cite
key "Recent_Advances_in_Neural_Network_Techniques_for_Channel_Equalization"
literal "false"

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
This paper provides an overview of various channel equalization methods,
 including the Multilayer Perceptron (MLP) equalizer, Functional Link Artificial
 Neural Network (FLANN) equalizer, Chebyshev Neural Network (NN) equalizer,
 and Radial Basis Function NN (RBFNN) equalizer.
 Additionally, it presents a literature review and application of Recursive
 Neural Network (RNN) and Fuzzy Neural Network equalizers.
\end_layout

\begin_layout Subsubsection
FLANN
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
The primary difference between FLANN hardware and MLP configuration is that
 the nonlinear mapping replaces only the input, output, and hidden layers.
 This mapping uses a non-linear function to transform the input vector,
 mapping it to a higher-dimensional space.
 The expansion function, called the functional link, is typically a polynomial
 function of the input variables.
 In our final experiments, we explored the concept of searching for equalization
 in a higher-dimensional space, but did not utilize the polynomial function
 approach.
\end_layout

\begin_layout Subsubsection
RBF
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Radial basis functions (RBFs) are a type of basis function used in function
 approximation and machine learning algorithms.
 RBFs are a class of functions that depend only on the distance from the
 center of the function, and their output decreases as the distance from
 the center increases.
 Gaussian RBF: This function takes the form of 
\begin_inset Formula $e^{(-r^{2}/2)}$
\end_inset

, where r is the Euclidean distance from the center of the function.
 This RBF is widely used in machine learning and function approximation
 algorithms due to its smoothness and symmetry.
\end_layout

\begin_layout Subsubsection
RNN
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
The article concludes by stating that Recurrent Neural Networks (RNNs) generally
 outperform feed-forward neural networks (FNNs) and other methods.
 RNNs approximate a finite impulse response (IIR) filter, whereas other
 methods approximate a finite impulse response (FIR) filter.
 It is worth noting that IIR filters are known to be unstable, but recent
 advances in neural networks, such as LSTM, GRU, and Transformers, have
 been developed to overcome this limitation 
\end_layout

\begin_layout Subsubsection
Overview and Insights
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
The study discusses various approaches using different network architectures.
 However, it lacks any BER/SNR plots and focuses solely on QPSK study.
 According to this research, Recurrent Neural Networks (RNNs) 
\begin_inset CommandInset citation
LatexCommand cite
key "RNN_LSTM"
literal "false"

\end_inset

 appear to be the most effective solution, rendering other proposed strategies
 unnecessary.
 Due to the significant advancements in Recurrent Neural Networks (RNNs)
 over the years, powerful tools such as Sequence to Sequence (Seq2Seq)
\begin_inset CommandInset citation
LatexCommand cite
key "seq_to_seq"
literal "false"

\end_inset

, Attention
\begin_inset CommandInset citation
LatexCommand cite
key "Attention"
literal "false"

\end_inset

, and the Transformer
\begin_inset CommandInset citation
LatexCommand cite
key "transformer"
literal "false"

\end_inset

 models have emerged.
 More recently, the Vision Transformer (ViT) 
\begin_inset CommandInset citation
LatexCommand cite
key "dosovitskiy2020image"
literal "false"

\end_inset

 has also been introduced.
 Given these developments, it is important to prioritize working with ViT,
 which represents a new and promising direction for image analysis.
 Additionally, there is currently no similar technique in the existing literatur
e that deals with channel equalization, making the ViT an even more valuable
 tool for OFDM equalization, treating constelations points as sections of
 an image.
 In the infographic below, we have designed a timeline to make the evolution
 of sequence analysis models clearer.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Networks/TimeLineEvolution.jpg
	lyxscale 20
	scale 28

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsection
\paragraph_spacing onehalf
\noindent

\size large
An Introduction to Deep Learning for the Physical Layer 
\begin_inset CommandInset citation
LatexCommand cite
key "Intro_DL_Physical_Layer"
literal "false"

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
This paper provides a detailed overview of neural networks and their application
 to channel equations, with formal mathematical description included.
 The paper describes the formal structure of feed-forward neural networks,
 as well as some applications of convolutional neural networks, that was
 described in the first section.
 It also introduces autoencoders for end-to-end communication systems and
 proposes the idea that an autoencoder can be used to characterize a complete
 channel.
 What's remarkable about this approach is that it can be extended to channel
 models and loss functions for which the optimal solutions are unknown,
 making it highly versatile.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Papers/ChannelAutoencoder.png

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Autoencoder as Channel 
\size large

\begin_inset CommandInset citation
LatexCommand cite
key "Intro_DL_Physical_Layer"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
In addition, the authors use adversarial networks to manage multiple transmitter
-receiver pairs with competing capacity.
 Although the Multiple-Input Multiple-Output (MIMO) scenario is not currently
 implemented, it could be a promising area for future work.
 Finally, the authors also discuss modulation classification, which involves
 using Convolutional Neural Networks (CNNs) to automatically detect the
 modulation scheme used in a communication process.
\end_layout

\begin_layout Subsubsection
\paragraph_spacing onehalf
\noindent
Autoencoder
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
An autoencoder is a type of artificial neural network used primarily for
 unsupervised learning tasks, such as dimensionality reduction, feature
 extraction, and data compression.
 It is designed to learn efficient representations of input data by encoding
 and decoding the data through a neural network architecture.
 The primary goal of an autoencoder is to reconstruct the input data with
 the highest possible accuracy while learning a compact and meaningful represent
ation of the data.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The architecture of an autoencoder can be likened to a communication system,
 consisting of two main components: the encoder, which acts as the transmitter,
 and the decoder, which serves as the receiver.
 The encoder's responsibility is to compress the input data into a lower-dimensi
onal representation, similar to the role of a transmitter in a communication
 system.
 This compressed representation, often referred to as the latent space or
 bottleneck, is then sent through the channel.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
On the other hand, the decoder, which is analogous to the receiver in a
 communication system, takes the lower-dimensional representation from the
 channel and attempts to reconstruct the original input data.
 In essence, the autoencoder architecture mirrors the basic structure of
 a communication system, with the encoder and decoder functioning as transmitter
 and receiver, respectively.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The goal of the transmitter is to send one of M possible messages,
\begin_inset Formula $\boldsymbol{s∈M=\left\{ 1,2,...,M\right\} }$
\end_inset

, to the receiver using n discrete uses of the communication channel.
 To achieve this, the transmitter applies a transformation, 
\begin_inset Formula $\boldsymbol{f:M→Rn}$
\end_inset

, to the message 
\begin_inset Formula $s$
\end_inset

, generating a transmitted signal 
\begin_inset Formula $\boldsymbol{x=f(s)∈\mathbb{R}^{n}}$
\end_inset

.
 Typically, the transmitter hardware imposes constraints on 
\begin_inset Formula $x$
\end_inset

, such as an energy constraint 
\begin_inset Formula $\boldsymbol{(||x||_{2}^{2}≤n)}$
\end_inset

, an amplitude constraint (
\begin_inset Formula $\boldsymbol{|xi|≤1}$
\end_inset

 
\begin_inset Formula $\boldsymbol{\forall i}$
\end_inset

), or an average power constraint (
\begin_inset Formula $\boldsymbol{E|xi|≤1}$
\end_inset


\begin_inset Formula $\boldsymbol{\forall i}$
\end_inset

).
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The communication rate of this system is 
\begin_inset Formula $\boldsymbol{R=\frac{k}{n}}$
\end_inset

 [bit/channel use], where 
\begin_inset Formula $\boldsymbol{k=log_{2}(M).}$
\end_inset

In the notation (n,k), the system is able to send one of 
\begin_inset Formula $\boldsymbol{M=2^{k}}$
\end_inset

 messages (i.e., k bits) through n channel uses.
 The communication channel is characterized by the conditional probability
 density function 
\begin_inset Formula $\boldsymbol{p(y|x}$
\end_inset

), where 
\begin_inset Formula $\boldsymbol{y∈Rn}$
\end_inset

 represents the received signal.
 After receiving 
\begin_inset Formula $\boldsymbol{y}$
\end_inset

, the receiver applies a transformation 
\begin_inset Formula $\boldsymbol{g:\mathbb{R}^{n}→M}$
\end_inset

 to generate the estimate 
\begin_inset Formula $\boldsymbol{ŝ}$
\end_inset

 of the transmitted message 
\begin_inset Formula $\boldsymbol{s}$
\end_inset

.
 As finall loss function it is used cross entropy loss, which is mention
 in chapter one.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Papers/BasedlineAE_results.png
	lyxscale 50
	scale 80

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
BLER for the AE in differen (n,k) baseline communication.
\size large

\begin_inset CommandInset citation
LatexCommand cite
key "Intro_DL_Physical_Layer"
literal "false"

\end_inset


\size default
 
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Conclusion
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
In this paper, was explored the idea that an autoencoder can learn channel
 representation using all the information available in the system.
 However, this research has not yet attempted more complex constellations,
 such as 16-QAM.
 In our research, we will build on this idea by using an autoencoder for
 encoding only, and employing a forced decoding approach with a zero-forcing
 algorithm.
\end_layout

\begin_layout Subsection
\paragraph_spacing onehalf
\noindent

\size large
A Survey of Complex-Valued Neural Networks 
\begin_inset CommandInset citation
LatexCommand cite
key "A_Survey_of_Complex_valued_nueronal_Netoworks"
literal "false"

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
\begin_inset CommandInset label
LatexCommand label
name "subsec:A-Survey-of"

\end_inset

It is widely recognized that IQ data is represented by complex numbers,
 which can pose challenges when working with them.
 This paper offers a detailed description of a new loss function and the
 necessary adjustments required to perform backpropagation in complex networks.
 Additionally, the paper demonstrates how to preprocess data, activation
 functions, and cost functions, which can be valuable for conducting experiments
 with complex data or complex neural networks.
\end_layout

\begin_layout Subsubsection
Normalize unitary circle
\end_layout

\begin_layout Standard

\size large
If we look at data in the complex plane we should first at deal with normalizati
on, and normalization is given by diviing the data by his absolute max,
 which lead all poins inside a unitary circle.
 
\begin_inset CommandInset label
LatexCommand label
name "subsec:Normalize-unitary-circle"

\end_inset


\end_layout

\begin_layout Standard

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{f(z)=\frac{z}{max(|z|)}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard

\size large
The image below demonstrates how a complex network can handle polar segmentation
, and how weights and biases can be used to define a vector in the complex
 plane
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Papers/ComplexCircle.png

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
A Geometric Interpretation of Segmentation and Function Evaluation in the
 Complex Plane.
 
\begin_inset CommandInset citation
LatexCommand cite
key "A_Survey_of_Complex_valued_nueronal_Netoworks"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Activation functions
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The hyperbolic tangent is an example of a fully complex activation function
 and has been utilized in 
\begin_inset CommandInset citation
LatexCommand cite
key "tanh_complex"
literal "false"

\end_inset

.
 It is apparent that singularities in the output may arise due to values
 on the imaginary axis.
 To prevent an explosion of values, it is necessary to appropriately scale
 the inputs, which mention in the normalization in the section above.
 According to some researchers, imposing the strict constraint of requiring
 the activation function to be holomorphic may not be necessary.
 A holomorphic function is a complex-valued function of a complex variable
 that is complex differentiable at every point within its domain.
 In other words, a function 
\begin_inset Formula $\boldsymbol{f(z)}$
\end_inset

 is holomorphic at a point 
\begin_inset Formula $\boldsymbol{z}$
\end_inset

 if the limit of the difference quotient of 
\begin_inset Formula $\boldsymbol{f(z)}$
\end_inset

 as 
\begin_inset Formula $\boldsymbol{z}$
\end_inset

 approaches that point exists and is independent of the path of approach.
 Therefore, for a basic implementation, we should split the evaluation into
 real and imaginary parts as separate sections to activate the values.
 It's important to note that the real and imaginary parts should not be
 mixed.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Papers/tanhcomplex.png

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Complex function separate for each real and imaginary part.
 
\begin_inset CommandInset citation
LatexCommand cite
key "Survey_Complex_valued_NN"
literal "false"

\end_inset

 
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Loss functions
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
One approach to dealing with the error is to take the complex magnitude
 of the differences between the estimator and the ground truth.
 Given 
\begin_inset Formula $\boldsymbol{d\in\mathbb{C}^{N}}$
\end_inset

(ground truth) and 
\begin_inset Formula $\boldsymbol{o\in\mathbb{C}^{N}}$
\end_inset

(estimated output), the error 
\begin_inset Formula $\boldsymbol{e=d-o}$
\end_inset

 we can calculate the complex mean square loss in a non-negative scalar.
 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{L(e)=\sum_{k=0}^{N-1}|e_{k}|^{2}=\sum_{k=0}^{N-1}e_{k}\overline{e_{k}}}\label{eq:46}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
If we take a polar approach where 
\begin_inset Formula $d=re^{i\phi}$
\end_inset

 and 
\begin_inset Formula $o=\hat{r}e^{i\hat{\phi}}$
\end_inset

, we can convert the error into a log function to bring points closer and
 cancel the exponentials.
 Rewritten in this way, the equation becomes:
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{(e_{log}):=\sum_{k=0}^{N-1}e_{k}\overline{e_{k}}=\sum_{k=0}^{N-1}(log(o_{k})-log(d_{k}))*\overline{((log(o_{k})-log(d_{k})))}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\align center

\size large
\begin_inset Formula $\boldsymbol{log\left(\frac{o_{k}}{d_{k}}\right)*\overline{log\left(\frac{o_{k}}{d_{k}}\right)}=log\left(\frac{\hat{r}e^{i\hat{\phi}}}{re^{i\phi}}\right)*log\left(\frac{\hat{r}e^{-i\hat{\phi}}}{re^{-i\phi}}\right)=log\left(\frac{\hat{r}}{r}e^{i(\hat{\phi}-\phi)}\right)*log\left(\frac{\hat{r}}{r}e^{-i(\hat{\phi}+\phi)}\right)}$
\end_inset


\end_layout

\begin_layout Standard
\align center

\size large
\begin_inset Formula $\boldsymbol{\left[log(\frac{\hat{r}}{r})+log\left(e^{i(\hat{\phi}-\phi)}\right)\right]*\left[log(\frac{\hat{r}}{r})+log\left(e^{-i(\hat{\phi}-\phi)}\right)\right]=}$
\end_inset


\end_layout

\begin_layout Standard
\align center

\size large
\begin_inset Formula $\boldsymbol{\left[log(\frac{\hat{r}}{r})+i(\hat{\phi}-\phi)\right]*\left[log(\frac{\hat{r}}{r})-i(\hat{\phi}-\phi)\right]}=$
\end_inset


\end_layout

\begin_layout Standard
\align center

\size large
Multiply out the terms 
\end_layout

\begin_layout Standard
\align center

\size large
\begin_inset Formula $\boldsymbol{log^{2}(\frac{\hat{r}}{r})+i(\hat{\phi}-\phi)log(\frac{\hat{r}}{r})-i(\hat{\phi}-\phi)log(\frac{\hat{r}}{r})-i^{2}(\hat{\phi}-\phi)^{2}}$
\end_inset


\end_layout

\begin_layout Standard
\align center

\size large
Simplify
\end_layout

\begin_layout Standard
\align center

\size large
\begin_inset Formula $\boldsymbol{log^{2}(\frac{\hat{r}}{r})+(\hat{\phi}-\phi)^{2}}$
\end_inset


\end_layout

\begin_layout Standard
\align center

\size large
We multiply the angle and radius by 0.5 in the loss function to give them
 equal importance since both are equally significant for the loss.
 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{Loss(e_{log})=\frac{1}{2}\left(log\left[\frac{\hat{r}}{r}\right]^{2}+\left[\hat{\phi}-\phi\right]^{2}\right)}\label{eq:48}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
We now have an explicit representation of magnitude and phase in the loss
 function, which could be helpful in the polar equalization approach.
\end_layout

\begin_layout Subsubsection
Conclusion
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
This theory was helpful in implementing a neural network with complex values
 directly, without splitting real part or phase and magnitude.
 However, in our experiments, it did not yield good results, but we took
 it into account and recorded the experiment.
\end_layout

\begin_layout Subsection
\paragraph_spacing onehalf
\noindent

\size large
MobileNet 
\begin_inset CommandInset citation
LatexCommand cite
key "MobileNet"
literal "false"

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
MobileNet achieves its high efficiency by using depthwise separable convolutions
, which are a combination of a depthwise convolution and a pointwise convolution
, while still maintaining high accuracy.
 In terms of time complexity, MobileNet has a lower multiplications compared
 to regular CNNs.
 This results in faster inference times and lower memory requirements,as
 its name says usefull for mobile applications, also include embbeded system
 applications for edge computing.
 However, it's worth noting that the trade-off for MobileNet's efficiency
 has a little less accuracy compared to regular CNNs.
\end_layout

\begin_layout Subsubsection
Depthwise Separable Convolution
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Convolution is a mathematical concept that measures the overlap between
 two functions as one of them slides over the other.
 Mathematically, it can be expressed as a sum of products.
 However, standard convolution operations can be slow to perform due to
 the number of multiplications required.
 An alternative method called depth-wise separable convolution can be used
 to speed up the process.
 This method breaks down the convolution process into two parts: depthwise
 convolution and pointwise convolution.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Let us briefly review the fundamental concepts of convolution on an input
 volume.
 Let's take an input volume F with dimensions DF x DF x M, where DF represents
 the width and height of the input volume and M is the number of input channels.
 In the case of a color image, M would be equal to 3 for the R, G, and B
 channels.
 We perform convolution on a kernel K, which has dimensions DK x DK x M.
 The output will be in the shape of DG x DG x 1.
 When we apply N kernels to the input, we obtain an output volume G with
 dimensions DG x DG x N.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Papers/TraditionalConv.png
	lyxscale 50
	scale 70

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Traditional convolution
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
In a traditional convolution, filters are applied across all input channels
 and their values are combined in a single step.
 However, in depthwise separable convolution, this process is split into
 two stages.
 The first stage is depthwise convolution, which applies convolution to
 a single input channel at a time.
 To perform depthwise convolution, we use filters or kernels K, which are
 of shape DK x DK x 1.
 Here, DK is the width and height of the square kernel, and it has a depth
 of 1 because this convolution is only applied to a single channel.
 Therefore, we require M such DK x DK x 1 kernels over the entire input
 volume F, where F has a shape DF x DF x M.
 For each of these M convolutions, we get an output of DG x DG x 1 in shape.
 By stacking these outputs together, we obtain an output volume G of shape
 DG x DG x M, which marks the end of the first phase, that is, the end of
 depthwise convolution.
 The number of multiplications in the depthwise convolution phase is obtained
 by applying these multiplications to all M input channels separately, with
 each channel having its own kernel.
 Therefore, the total number of multiplications in this phase is :
\end_layout

\begin_layout Standard

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{\boldsymbol{DW=M\times D_{G}{}^{2}\times D_{k}{}^{2}}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Papers/DepthwiseConv.png
	lyxscale 70
	scale 70

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Depthwise convolution
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Pointwise convolution refers to a 1x1 convolution operation applied to each
 of the output channels generated by the depthwise convolution.
 In this step, the input is a volume of shape DG x DG x M, where M is the
 number of output channels generated by the depthwise convolution.
 The filter used for this operation, denoted as KPC, has a shape of 1 x
 1 x M, which means that it is applied across all M output channels.
 The resulting output has the same width and height as the input DG x DG,
 and the number of output channels can be controlled by using N filters.
 Therefore, the final output volume of the depthwise separable convolution
 has a shape of DG x DG x N.
 And hence, the number of multiplications for one instance of convolution
 is M.
 This is applied to the entire output of the first phase, which has a width
 and height of DG.
 So the total number of multiplications for this kernel is DG x DG x M.
 So for some N kernels, we'll have this multiplications :
\end_layout

\begin_layout Standard

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{PW=N\times DG\times DG\times M}
\end{equation}

\end_inset


\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center

\size large
\begin_inset Graphics
	filename Imagenes/Papers/Pointwise.png
	lyxscale 70
	scale 70

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout

\size large
Pointwise convolution
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Hence, the total multiplication count is the sum of multiplication counts
 in the depthwise and pointwise convolution stages.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{\mathbf{Total=DW+PW=M\times D_{G}{}^{2}\times D_{k}{}^{2}+N\times DG\times DG\times M}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{\boldsymbol{Total=M\times D_{G}^{2}(D_{K}^{2}+N)}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
We can compare the computational efficiency of standard convolution with
 depthwise convolution by computing their ratio.
 This ratio is obtained by summing the reciprocal of the depth of the output
 volume, denoted as N, and the reciprocal of the squared dimensions of the
 kernel, denoted as DK.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{\boldsymbol{\frac{DepthWise}{Standard}=\frac{M\times D_{G}^{2}(D_{K}^{2}+N)}{N\times D_{G}^{2}\times D_{k}^{2}\times M}=\frac{1}{N}+\frac{1}{D_{k}^{2}}}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
To better understand this, let's take an example.
 Suppose the output feature volume N is 1024, and the kernel size is 3,
 which means DK is 3.
 Plugging these values into the equation, we obtain a ratio of 0.112.
 This indicates that standard convolution requires 9 times more multiplications
 than depthwise separable convolution.
 This significant difference in computational power can have a considerable
 impact on the performance and efficiency of convolutional neural networks.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{table}[htbp] 
\backslash
centering 
\backslash
caption{Depthwise Separable vs Full Convolution MobileNet} 
\backslash
label{tab:my-table} 
\backslash
begin{tabular}{|l|c|c|c|} 
\backslash
hline Model & ImageNet Accuracy & Mult-Adds (Million) & Parameters (Million)
 
\backslash

\backslash
 
\backslash
hline Conv MobileNet & 71.7
\backslash
% & 4866 & 29.3 
\backslash

\backslash
 
\backslash
hline MobileNet & 70.6
\backslash
% & 569 & 4.2 
\backslash

\backslash
 
\backslash
hline 
\backslash
end{tabular} 
\backslash
end{table} 
\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
MobileNetV3 
\begin_inset CommandInset citation
LatexCommand cite
key "MobilenetV3"
literal "false"

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "subsec:MobileNetV3"

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
The MobileNetV3 architecture uses a combination of depthwise separable convoluti
ons, linear bottlenecks, and other optimizations to reduce the number of
 parameters and computational complexity while maintaining high accuracy.
 It also includes new design elements, such as dynamic activation functions
 and network architecture search techniques, to improve performance on a
 variety of tasks.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{table}[h] 
\backslash
centering 
\backslash
caption{MobileNet architectures} 
\backslash
label{tab:mobilenet} 
\backslash
begin{tabular}{|c|c|c|c|} 
\backslash
hline 
\backslash
textbf{Model} & 
\backslash
textbf{Input Resolution} & 
\backslash
textbf{FLOPS} & 
\backslash
textbf{Parameters} 
\backslash

\backslash
 
\backslash
hline MobileNet v1 & 224x224 & 569 M & 4.2 million 
\backslash

\backslash
 
\backslash
hline MobileNet v2 & 224x224 & 300 M & 3.4 million 
\backslash

\backslash
 
\backslash
hline MobileNet v3 & 224x224 & 219 M & 5.4 million 
\backslash

\backslash
 
\backslash
hline 
\backslash
end{tabular} 
\backslash
end{table}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
FLOPS stands for "Floating Point Operations Per Second".
 It is a measure of a computer's performance based on the number of floating
 point operations (such as additions, subtractions, multiplications, and
 divisions) it can perform in a second.
 It is commonly used to measure the performance of computer processors or
 the computational requirements of machine learning models.
\end_layout

\begin_layout Subsubsection
Reduced complexity for activation functions
\end_layout

\begin_layout Standard

\size large
One of the key components of his low computational cost is the implementation
 of hardsigmoid and hardswish function, which is quite similar that we done
 with hardtanh but with other activation function type.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
hswish[x]=x\frac{RELU6(x+3)}{6}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Papers/hardsigmoid.png

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Hard functions 
\begin_inset CommandInset citation
LatexCommand cite
key "MobilenetV3"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
These functions are integrated into the final stage of MobileNet to serve
 as more efficient functions.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Papers/LastMobileNetv3.png

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Last section optimized 
\begin_inset CommandInset citation
LatexCommand cite
key "MobilenetV3"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Conclusion
\end_layout

\begin_layout Standard
\noindent

\size large
For our project, we have opted to use MobileNetv3 to compress the communication
 channel and encode it into a lower-dimensional representation.
 Since MobileNet is highly efficient, it is one of our top choices for research,
 especially given the constraints in telecom where data processing speed
 could be a critical factor.
\end_layout

\begin_layout Subsection
\paragraph_spacing onehalf
\noindent

\size large
Attention Is All You Need 
\begin_inset CommandInset citation
LatexCommand cite
key "transformer"
literal "false"

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
"Attention is All You Need" is a research paper published by Google in 2017
 that introduced the Transformer model, a neural network architecture for
 sequence-to-sequence modeling.
 The Transformer model is designed to handle variable-length sequences of
 input data and generate variable-length output sequences, making it particularl
y useful for tasks such as machine translation and natural language processing.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The Transformer model differs from previous neural network architectures
 by relying solely on attention mechanisms for input and output processing,
 eliminating the need for recurrent
\begin_inset CommandInset citation
LatexCommand cite
key "RNN_LSTM"
literal "false"

\end_inset

 and convolutional layers
\begin_inset CommandInset citation
LatexCommand cite
key "Conv1"
literal "false"

\end_inset

.
 The attention mechanism
\begin_inset CommandInset citation
LatexCommand cite
key "Attention"
literal "false"

\end_inset

 allows the model to focus on different parts of the input sequence when
 generating the output sequence, making it more accurate and efficient than
 previous models.
\end_layout

\begin_layout Subsubsection
Embedding
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The embedding refers to the process of representing 
\series bold
discrete input
\series default
 tokens as 
\series bold
continuous vectors
\series default
 that can be processed by the model.
 This is achieved using an embedding layer, which maps each input token
 to a high-dimensional 
\begin_inset Formula $\mathbb{R}^{N}$
\end_inset

 vector in a learned embedding space.
 Words cannot be represented as numbers directly.
 Normally, numerical data is transformed into a discrete representation,
 but in order to process it through a transformer network, these discrete
 representations need to be mapped to a continuous vector space using an
 embedding layer.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The input size of an embedding layer is typically the size of the vocabulary
 
\begin_inset Formula $|A|$
\end_inset

, i.e., the number of unique tokens that the model can expect to encounter
 in the input.
 For example, if the vocabulary size is 10,000, then the input size of the
 embedding layer would be 10,000.
 The output size of the embedding layer is determined by the desired dimensional
ity of the embedding space 
\begin_inset Formula $\mathbb{R}^{M}$
\end_inset

, which is a hyperparameter that can be tuned by the model developer.
 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Normally, each word is assigned a unique index, and this index corresponds
 to a row in the embedding matrix.
 To obtain the embedding vector for a word, we retrieve the corresponding
 row from the matrix and multiply it by each element in row to get the new
 vector 
\begin_inset Formula $V$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Networks/EmbbededLayer.jpg
	lyxscale 30
	scale 40

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Embbeded Matrix
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The embedding layer allows the model to capture the semantic relationships
 between different input tokens, and enables it to perform tasks such as
 language modeling and machine translation.
 Is typically followed by positional encoding, which adds information about
 the position of each input token in the sequence.
 Together, the embedding and positional encoding components provide a way
 for the model to process variable-length input sequences of discrete tokens
 in an efficient and effective manner.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Let X be an input sequence of length T, where each element 
\begin_inset Formula $x_{i}$
\end_inset

 is an integer representing the 
\begin_inset Formula $i$
\end_inset

-th token in the vocabulary.
 Let 
\begin_inset Formula $E$
\end_inset

 be a learned embedding matrix of size
\begin_inset Formula $V\times d$
\end_inset

, where 
\begin_inset Formula $V$
\end_inset

 is the size of the vocabulary and 
\begin_inset Formula $d$
\end_inset

 is the dimension of the embedding space.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The embedding layer can be defined as follows:
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\text{E}(X)=[\text{e}_{1},\text{e}_{2},\dots,\text{e}_{T}]
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Positional encoding can be added to the embeddings as follows:
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\text{E'}(X)=[\text{e'}_{1},\text{e'}_{2},\dots,\text{e'}_{T}]
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
where 
\begin_inset Formula $\text{e'}_{i}=\text{e}_{i}+\text{PE}_{i}$
\end_inset

, and 
\begin_inset Formula $\text{PE}_{i}$
\end_inset

 is the 
\begin_inset Formula $i$
\end_inset

-th row of a learned positional encoding matrix of size 
\begin_inset Formula $T\times d$
\end_inset

.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The resulting embeddings 
\begin_inset Formula $\text{E'}(X)$
\end_inset

 are continuous vectors in a high-dimensional embedding space that can be
 processed by the transformer model.
\end_layout

\begin_layout Subsubsection
Multihead attention
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
One of the key components of the Transformer model is multi-head attention.
 Multi-head attention allows the model to attend to different parts of the
 input sequence simultaneously, by splitting the input data into multiple
 representations and computing attention on each of them.
 This allows the model to capture complex relationships between different
 parts of the input sequence, and enables it to handle long sequences more
 efficiently.
 In multi-head attention mechanism of a transformer model, the input sequence
 is split into multiple vectors (heads), and each of these vectors is processed
 independently.
 The attention mechanism then operates on these vectors to compute weighted
 combinations that represent different aspects of the input sequence.The
 multi-head attention mechanism consists of three linear transformations:
 Query, Key, and Value.
 These transformations are learned parameters that are used to compute the
 attention scores and weights for each head.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Papers/Attention.png
	scale 120

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Attention respect to input vectors 
\begin_inset CommandInset citation
LatexCommand cite
key "singh2020multihead"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
Query: This transformation takes the current decoder state as input and
 maps it to a query vector.
 The query vector is used to compute the similarity between the decoder
 state and each of the key vectors.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
Key: This transformation takes the encoder output as input and maps it to
 a key vector.
 The key vector is used to compute the similarity between the decoder state
 and each of the query vectors.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
Value: This transformation takes the encoder output as input and maps it
 to a value vector.
 The value vector is used to compute the weighted sum of the encoder output,
 based on the attention weights calculated from the query and key vectors.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Papers/Multihead.png
	scale 80

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Caption Standard

\begin_layout Plain Layout
Multihead attention 
\begin_inset CommandInset citation
LatexCommand cite
key "transformer"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Let 
\begin_inset Formula $Q$
\end_inset

, 
\begin_inset Formula $K$
\end_inset

, and 
\begin_inset Formula $V$
\end_inset

 be the query, key, and value matrices, respectively, for one head of the
 multi-head attention mechanism.
 Let 
\begin_inset Formula $d_{k}$
\end_inset

 be the dimension of the key vectors, and let 
\begin_inset Formula $d_{v}$
\end_inset

 be the dimension of the value vectors.
 Let 
\begin_inset Formula $h$
\end_inset

 be the number of heads.
 Then, the multi-head attention mechanism can be defined as follows:
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align center

\size large
\begin_inset Formula 
\begin{equation}
MultiHead(Q,K,V)=Concat(head_{1},\ldots,headh_{h})W^{O}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align center

\size large
where
\end_layout

\begin_layout Standard
\align center

\size large
\begin_inset Formula $\text{head}_{i}=\text{Attention}(QW_{i}^{Q},KW_{i}^{K},VW_{i}^{V})$
\end_inset

 and
\end_layout

\begin_layout Standard
\align center

\size large
\begin_inset Formula $\ensuremath{W_{i}^{Q}\in\mathbb{R}^{d{model}\times d_{k}}}$
\end_inset

,
\begin_inset Formula $\ensuremath{W_{i}^{K}\in\mathbb{R}^{d_{model}\times d_{k}}}$
\end_inset

,
\begin_inset Formula $\ensuremath{W_{i}^{V}\in\mathbb{R}^{d_{model}\times d_{v}}}$
\end_inset

and 
\begin_inset Formula $\ensuremath{W^{O}\in\mathbb{R}^{hd_{v}\times d_{model}}}$
\end_inset

 are learned weight matrices.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align center

\size large
The Attention function can be defined as follows:
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align center
\begin_inset Formula 
\begin{equation}
Attention(Q,K,V)=softmax(\frac{QK^{T}}{\sqrt{d_{k}}}+Mask)V
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Papers/Dot product.png
	lyxscale 40
	scale 40

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Self attention dot product 
\begin_inset CommandInset citation
LatexCommand cite
key "singh2020multihead"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Mask
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
In multi-head attention mechanism of a transformer model, a mask is a binary
 matrix that is used to selectively prevent certain elements of the input
 sequence from being attended to by the model.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Papers/Mask.png
	scale 60

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Mask example
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard

\size large
There are two types of masks commonly used in the transformer model: padding
 masks and sequence masks.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\size large
Padding masks: These masks are used to ignore padding tokens in the input
 sequence, which are added to ensure that all input sequences are of the
 same length.
 Padding tokens have no semantic meaning and should not be attended to by
 the model.
 A padding mask is a binary matrix that has a value of 0 for padding tokens
 and 1 for all other tokens.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\size large
Sequence masks: These masks are used to ensure that each position in the
 output sequence can only attend to positions that have already been processed.
 This is important for tasks such as language modeling, where the model
 is trained to predict the next word in a sequence based on the previous
 words.
 A sequence mask is a binary matrix that has a value of 0 for all future
 positions in the sequence and 1 for all other positions.
 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Masks are applied to the attention mechanism by adding them to the attention
 weights before computing the weighted sum of the input sequence.
 The mask ensures that certain elements of the input sequence are not attended
 to by the model, which can improve the accuracy and efficiency of the model.
\end_layout

\begin_layout Subsubsection
Encoder Decoder
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Once we have all building blocks we can say that transformer model consists
 of an encoder and a decoder.
 The encoder processes the input sequence, using multi-head attention and
 position encoding to create a fixed-length representation of the input.
 The decoder then generates the output sequence, using multi-head attention
 and position encoding to attend to the input representation and generate
 each output token.
 The model is trained using maximum likelihood estimation, where the goal
 is to minimize the cross-entropy loss between the predicted output sequence
 and the ground truth.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Papers/TransformerEncodeDecode.png
	lyxscale 50
	scale 70

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Transformer with encoder and decoder sections 
\begin_inset CommandInset label
LatexCommand label
name "fig:Transformer-with-encoder"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
In the transformer diagram, "Nx" is typically used to represent the number
 of encoder-decoder layers in the model.
 For example, a transformer model with 6 encoder layers and 6 decoder layers
 might be represented as "Nx=6" in the diagram.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The output of the Transformer model is a sequence of tokens, which can be
 interpreted as a sequence of words, or other discrete units depending on
 the task at hand.
 These tokens can be further processed by other components of a larger system,
 such as a language model or a downstream task-specific model.
\end_layout

\begin_layout Subsubsection
Autoregresion
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
In an autoregressive mode in the context of an autoencoder, the decoder
 network is designed to generate the output sequence one element at a time,
 based on the previously generated elements.
 In other words, the decoder network takes the previous elements of the
 output sequence as input and generates the next element of the sequence.
 This is in contrast to a non-autoregressive mode, where the decoder network
 generates the entire output sequence at once, without considering the previousl
y generated elements.
\end_layout

\begin_layout Subsubsection
Conclusion
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
Given that our data is sequential in nature and can be interpreted symbol
 by symbol, the Transformer architecture can be applied in the equalization
 stage.
 The resulting encoding-decoding process could be an effective method for
 canceling Inter-Symbol Interference (ISI) using attention mechanisms.
 However, the challenge is that the data is in continuous space and we may
 lose positional encoding if we directly treat continuous data.
 Additionally, the Transformer architecture outputs symbols and not continuous
 values, so we need a mechanism to discretize our received data 
\begin_inset Formula $Y$
\end_inset

 and apply a token for each position to interpret the equalization as a
 machine translation.
 Therefore, our next step is to find a paper that can address this problem,
 as it could be the final key piece of evidence to support our proposal.
\end_layout

\begin_layout Subsection
\paragraph_spacing onehalf
\noindent

\size large
An image is worth 16x16 words 
\begin_inset CommandInset citation
LatexCommand cite
key "dosovitskiy2020image"
literal "false"

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "subsec:An-image-is"

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
The Vision Transformer is a deep learning architecture that is specifically
 designed for image classification tasks.
 Unlike traditional Convolutional Neural Networks (CNNs) that use convolutional
 layers to extract features from images, the ViT uses self-attention mechanisms
 to capture relationships between different parts of the image.
 Its architecture takes as input a sequence of patches, where each patch
 represents a small square region of the image.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Papers/pasted1.png
	lyxscale 80
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Basic example of image splitting in a grid for automatic fungi recognition.
 
\begin_inset CommandInset citation
LatexCommand cite
key "visionTransformer"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
These patches are then flattened and passed through a linear projection
 layer to obtain a sequence of embeddings, which are then fed into a series
 of transformer encoder layers.
 The transformer encoder layers use self-attention mechanisms to model the
 relationships between the different patches in the input sequence.
 This allows the ViT to capture long-range dependencies between different
 parts of the image, which is particularly useful for image classification
 tasks where the spatial relationship between different parts of the image
 is important.
 It takes as input an image and outputs a class label or a set of class
 probabilities, based on the features extracted from the image.
\end_layout

\begin_layout Subsubsection
\paragraph_spacing onehalf
\noindent
The Grid
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The "16x16 words" phrase refers to the fact that the input image is divided
 into a grid of 16x16 patches, each of which is treated as a "word" in the
 input sequence.
 This means that the ViT processes the image as a sequence of 256 patches,
 each represented by an embedding, instead of as a single 2D array of pixel
 values.
 However, there is a trade-off between grid size and computational complexity,
 as larger grids require more memory and processing power to train.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Papers/VITexample-transformed.png
	lyxscale 30
	scale 15

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Vision transforrmer example of 14X14 
\begin_inset CommandInset citation
LatexCommand cite
key "CollabVIT"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Conclusion
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
In conclusion, this paper has been instrumental in the development of our
 Gridnet architecture.
 Our approach involves using the complex plane as a 2D space, much like
 an image, where IQ data points fall into specific grids.
 We then assign each grid a patch-encoded value based on its position.
 Instead of using a traditional encoder, we utilized a transformer decoder
 to equalize the data with the ground truth.
 Our goal is to leverage the grid-based structure of the complex plane to
 effectively eliminate Inter-Symbol Interference (ISI) through the use of
 multihead attention mechanisms.
 This paper has provided us with important insights and tools that will
 help us to continue improving our approach for a range of signal processing
 applications.
\end_layout

\begin_layout Section
Methodology
\end_layout

\begin_layout Subsection
Dataset
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
This project has a dataset of 20,000 channel realizations, each with a size
 of 48x48.
 The dataset is divided into two groups of 10,000: the first group consists
 of Line-of-Sight (LOS) channel realizations, and the second group consists
 of Non-Line-of-Sight (NLOS) channel realizations.
 Each value in the matrix is a complex number with a format of complex128,
 float64 for the real and imaginary parts.
 The data is stored in the .mat format, which is commonly used for storing
 variables on disk from Matlab code.
 However, the dataset is used in Python using the Scipy library.
 To ensure robust predictions, the LOS and NLOS channels have been shuffled,
 with one group following the other.
 As neural networks typically do not work well with complex numbers, the
 real and imaginary parts of the channels have been separated into two channels
 in an image.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Channels/NLOS_Channel_log_view.png
	lyxscale 70
	scale 50

\end_inset


\begin_inset Graphics
	filename Imagenes/Channels/LOS_Channel_log_view.png
	lyxscale 70
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
A comparison of LOS and NLOS channel magnitud in a log scale representation.
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Software 
\size large
Architecture
\end_layout

\begin_layout Subsubsection
Data set
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
In the field of machine learning, data is typically split into three sets:
 training, validation, and testing.
\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf

\series bold
\size large
Training set
\series default
: The training set is a subset of the data used to train the model.
 The model uses the training data to learn the relationships between the
 input features and the target output.
 The model parameters are updated during the training process to minimize
 the prediction error.
\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent

\series bold
\size large
Validation set
\series default
: The validation set is a subset of the data used to evaluate the model
 during training.
 The purpose of the validation set is to ensure that the model is not overfittin
g to the training data.
 Overfitting occurs when the model is too complex and learns the noise in
 the training data instead of the underlying relationships.
 The model is evaluated on the validation set after each training epoch,
 and its performance is used to determine when to stop training or to adjust
 the model's hyperparameters.
\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent

\series bold
\size large
Testing set
\series default
: The testing set is a subset of the data used to evaluate the model's performan
ce after training.
 The model is never trained on the test set and its performance on the test
 set provides an estimate of its generalization performance to new, unseen
 data.
 The test set is used to determine the final accuracy of the model and its
 ability to make predictions on new data.
\end_layout

\begin_layout Subsubsection
Class design and documentation
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
To achieve code reusability, it is important to write modular and maintainable
 code that incorporates class inheritance and shared attributes.
 In order to further enhance the object-oriented programming (OOP) structure
 of our code, we implement the factory pattern.
 The factory pattern allows us to create multiple experiments with little
 changes but have the same base build and experiment structure, increasing
 code efficiency and reusability 
\begin_inset CommandInset citation
LatexCommand cite
key "DesignPatterns"
literal "false"

\end_inset

.
 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
This, combined with the PyTorch Lightning framework, has made the development
 process much easier and faster.
 PyTorch Lightning also offers tools for distributed training that can be
 used to scale the training of big models across several GPUs
\begin_inset CommandInset citation
LatexCommand cite
key "gpu-basic-training"
literal "false"

\end_inset

, TPUs 
\begin_inset CommandInset citation
LatexCommand cite
key "mnist-tpu-training"
literal "false"

\end_inset

, or machines.
 This tooling also facilitates the concept of batches, which involves having
 multiple realizations of the dataset in the format [BATCH, seq_len] or
 [BATCH, channel, height, width].
 By using batches, the training time is reduced and it becomes more manageable
 to handle large amounts of data.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Codigo/SoftwareDiagrams/networkdevelop.png
	lyxscale 50
	scale 28

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Software Architecture Diagram Planning
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
These are the main classes used in the software development:
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
Channel
\end_layout

\begin_deeper
\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
Loads a .mat file containing complex channel coefficient data and converts
 it into a numpy array.
 The class has a constructor __init__ that takes a Boolean parameter LOS
 (default value True) indicating whether to load the line-of-sight (LOS)
 or non-line-of-sight (NLOS) channel data.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
The Channel class has a single attribute con_list that is the numpy array
 containing the channel data.
 The class also defines a __getitem__ method that returns the channel data
 for a specific index in the array.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
The code also imports the scipy.io and numpy libraries and sets up the path
 to the directory containing the .mat files.
 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
Imports the Download_Mat_files function from the DownloadFiles module, and
 adds the path to the conf and tools directories to the Python path.
 
\end_layout

\end_deeper
\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
QAM
\series default
 
\end_layout

\begin_deeper
\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
This class QAM is used to generate QAM modulation schemes and perform demodulati
on on a complex symbol vector.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
The constructor initializes the QAM modulation scheme.
 It takes in the following parameters:
\end_layout

\begin_deeper
\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
num_symbols: The number of QAM symbols to generate.
 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
constelation: The size of the QAM constellation.
 Valid values are 4, 16, 32, and 64.
 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
cont_type: The type of constellation used.
 Valid values are "Data", "Unit_Pow", and "Norm".
 
\end_layout

\begin_deeper
\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
Data
\series default
: constelation as it is.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
Unit_Pow
\series default
: normalized power constelation
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
Norm
\series default
: Normalized constelation to max magnitud to 1 in the complex plane.
 
\end_layout

\end_deeper
\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
noise: Deprecated
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
noise_power: Deprecated
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
load_type: A flag indicating the type of loading.
 Valid values are "Complete" and "Alphabet".
 
\end_layout

\begin_deeper
\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
Complete
\series default
: This is used to get the complex plane data points
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
Alphabet
\series default
: Get the token values, which could be used to retrieve the symbols sent
 without having to put them in the complex domain.
\end_layout

\end_deeper
\end_deeper
\end_deeper
\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
Rx: 
\series default
This class is a PyTorch Dataset that generates a dataset for a communication
 channel.
 The channel is defined by a complex matrix H, and QAM symbols are generated
 with specific parameters such as constellation size, constellation type,
 and load type.
 The dataset consists of a total of 20000 realizations, with each realization
 containing 48 QAM symbols.
 The class generates QAM symbols, generates a complex matrix H, applies
 the channel to the symbols, and adds additive white Gaussian noise to the
 signal.
 The class also defines the AWGN method to add noise with a given SNR.
 The dataset can be loaded as batches using PyTorch's DataLoader.
 The class overloads the __getitem__ method to return the channel tensor
 and the corresponding transmitted tensor.
 The channel tensor is a 48x48x2 tensor of the real and imaginary parts
 of the complex matrix H, and the transmitted tensor is either the QAM symbol
 bits or the QAM symbol complex values depending on the load type.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Codigo/UML/Classes_rx.png
	lyxscale 70
	scale 40

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Rx and their aggregated classes
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
RX_loader
\series default
: This class also splits the dataset into three parts for training, validation,
 and testing.
 The SNR_BER_TEST method of the class is used to calculate the bit error
 rate (BER) for different signal-to-noise ratio (SNR) values.
 This method uses the predict method of the trainer object to predict the
 values of the output of the model and then calculate the BER.
 Class also defines methods to calculate the output of the system given
 the input, including Get_Y, MSE_X, LMSE_X, and ZERO_X.
 These methods calculate the channel output, estimate the transmitted symbols,
 and perform equalization to reduce the effect of the channel on the received
 symbols.
 The class also defines a method to filter the data based on z-score.
\end_layout

\begin_deeper
\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
init
\series default
: Initializes the Rx_loader object with the specified batch size, QAM and
 loading type.
 It also loads the RX dataset and splits it into training, validation and
 testing sets.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
SNR_calc
\series default
: Calculates the signal-to-noise ratio (SNR) and bit error rate (BER) given
 the predicted output and the actual output.
 This is used for internal evaluation in the predict section of the Lightning
 API.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
SNR_BER_TEST:
\series default
 Performs an SNR-BER test by iterating through a range of SNR values and
 printing the BER for each value.
 It also saves the BER values to a CSV file.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
Get_Y:
\series default
 Takes in three arguments: H (channel tensor), x (transmitted symbol tensor),
 conj (boolean flag to indicate whether to take the complex conjugate of
 h), and noise_activ (boolean flag to indicate whether to add noise to the
 received signal).
 It returns the received signal tensor Y of shape (batch_size, 48).
 
\end_layout

\begin_deeper
\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
If noise_activ is True
\series default
, it adds complex Gaussian noise to the received signal Y[i].
 The noise power is computed as the ratio of the signal power to the signal-to-n
oise ratio (SNR) in decibels.
 The noise is generated using the PyTorch function torch.randn to create
 random Gaussian noise with zero mean and standard deviation of sqrt(Pn/2),
 where Pn is the noise power.
 More detail in 
\color blue

\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:SNR"
plural "false"
caps "false"
noprefix "false"

\end_inset


\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
If conj is True
\series default
, it takes the complex conjugate of h using the method 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newline
\end_layout

\end_inset

 conj().resolve_conj(), and performs matrix multiplication with Y[i].
 This helps in data preprocesing in section
\color blue
 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:A-Novel-OFDM"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
 more detail in 
\color blue

\begin_inset CommandInset ref
LatexCommand nameref
reference "Preprocesing"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
 image.
\end_layout

\end_deeper
\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
MSE_X
\series default
: Computes the minimum mean square error (MMSE) estimate of the transmitted
 signal x given the channel matrix H and received signal Y.
 It returns a tensor of shape (batch_size, 48) of complex values.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
LMSE_X
\series default
: Computes the linear minimum mean square error (LMMSE) estimate of the
 transmitted signal x given the channel matrix H, received signal Y and
 SNR.
 It returns a tensor of shape (batch_size, 48) of complex values.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
Chann_diag
\series default
: Extracts the diagonal of each channel matrix in the tensor and returns
 them as a tensor of shape (batch_size, 48) of complex values.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
ZERO_X
\series default
: The method starts by computing the diagonal elements of the channel tensor
 using the 
\series bold
Chann_diag
\series default
 method.
 This helper method extracts the diagonal of each matrix in the tensor and
 combines them into a new tensor.
 Next, the method applies Zero Forcing (ZF) equalization by dividing the
 received signal tensor Y by the diagonal tensor of the channel tensor chann.
 The output is an estimated signal tensor x_hat, which is a tensor of complex
 values with a shape of (batch_size, 48).
 The method returns this tensor as its output.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
filter_z_score
\series default
: Filters out outlier data points from the tensor based on the z-score.
 It returns a filtered tensor and the indices of the valid data points.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
filter_z_score_matrix
\series default
: Filters out outlier data points from the diagonal tensor of a batch of
 channel matrices based on the z-score.
 It returns a filtered tensor and the indices of the valid data points.
\end_layout

\begin_deeper
\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
The default value of the threshold parameter in the filter_z_score() method
 of the Rx_loader class is 1.96, which corresponds to a 95% confidence level
 assuming a normal distribution.
 This means that data points whose absolute z-score is greater than 1.96
 will be considered as outliers and filtered out.
 However, this value can be adjusted by the user based on their specific
 requirements.
\end_layout

\end_deeper
\end_deeper
\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Codigo/UML/Classes_data_loader.png
	lyxscale 70
	scale 40

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Rx Data Loader and usefull classes
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The Rx_loader class is implemented in all classes throughout the project
 for multiple experiments.
 The golden models also use this class because all final application classes
 inherit from this class and use the PyTorch Lightning framework to create
 powerful combinations between custom datasets and helper functions required
 for preprocessing.
\end_layout

\begin_layout Subsubsection
Generic Network Implementation
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The training_step and validation_step methods both call the common_step
 method, which contains the shared implementation between the two.
 This approach reduces code duplication and helps keep the implementation
 DRY (Don't Repeat Yourself)
\begin_inset CommandInset citation
LatexCommand cite
key "CleanCode"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The common_step method takes a batch of data and an optional flag to indicate
 whether the batch is being used for prediction.
 It then performs the 
\series bold
pre-processing
\series default
 of the data, which includes different strategies such as 
\color blue

\begin_inset CommandInset ref
LatexCommand nameref
reference "subsec:Zero-forcing"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
, obtaining Y with its conjugate 
\color blue

\begin_inset CommandInset ref
LatexCommand eqref
reference "Preprocesing"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
, normalizing values 
\color blue

\begin_inset CommandInset ref
LatexCommand eqref
reference "subsec:Normalize-unitary-circle"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
, and filtering outliers by z-score
\color blue
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "subsec:Z-score"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
After the pre-processing is done, the method evaluates the model by computing
 the predicted output and comparing it with the target output.
 The 
\series bold
evaluation
\series default
 process involves passing the pre-processed data through the neural network
 model, which generates the predicted output.
 The predicted output is then compared with the target output using a loss
 function, which calculates the difference between them.
 The method returns the loss value, which is used for updating the model's
 parameters during training.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
By separating the common implementation from the specific training and validatio
n logic, we can easily reuse the same code for different stages of the training
 process, and focus on implementing the logic that is specific to each stage.
 This results in cleaner and more maintainable code, as well as faster developme
nt times.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Codigo/UML/GeneriNet.png
	lyxscale 70
	scale 40

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Generic Net
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Golden Model
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
In this project, the golden model serves as a benchmark for evaluating the
 performance of new models.
 The golden model is based on three equalizers: Least squares (LS), Linear
 Minimum Mean Squared Error (LMMSE), and zero forcing, which are discussed
 in more detail in sections
\color blue
 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:LS"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
, 
\color blue

\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:LMMSE"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
 , 
\color blue

\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Zero-forcing"
plural "false"
caps "false"
noprefix "false"

\end_inset

 
\color inherit
of this document,respectively, and for the non-linear models there was implement
ed
\color blue
 
\begin_inset CommandInset ref
LatexCommand nameref
reference "subsec:OSIC"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
 and
\color blue
 
\begin_inset CommandInset ref
LatexCommand nameref
reference "subsec:NearML"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/Golden_4QAM.png
	lyxscale 40
	scale 55

\end_inset


\begin_inset Graphics
	filename Imagenes/Results/Golden_16QAM.png
	lyxscale 40
	scale 55

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Caption Standard

\begin_layout Plain Layout
Golden linear models plot QPSK and 16QAM
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
When evaluating the performance of a communication system, it is standard
 practice to plot both the Bit Error Rate
\color blue
 (
\begin_inset CommandInset ref
LatexCommand nameref
reference "subsec:BER"
plural "false"
caps "false"
noprefix "false"

\end_inset

) 
\color inherit
and Signal-to-Noise Ratio (SNR) on the same graph, with SNR on the x-axis
 and BER on the y-axis.
 BER measures the number of errors that occur in a transmitted data stream,
 relative to the total number of bits transmitted, while SNR measures the
 strength of the signal relative to the background noise.
 Comparing the BER and SNR values allows us to evaluate the system's performance
 under different levels of noise.To create a more representative view, it
 was decided to average the results of 5 tests and plot the average.
 Additionally, for each test, the SNR was incremented by a step of 2.
 Therefore, an interpolation was performed to smooth the curves.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/Golden/Results_Non_linear_Golden_Models_QPSK_-17_3_2023-11_36.png
	lyxscale 40
	scale 55

\end_inset


\begin_inset Graphics
	filename Imagenes/Results/Golden/Results_Non_linear_Golden_Models_-17_3_2023-11_32.png
	lyxscale 40
	scale 55

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Golden LMMSE and non-linear models plot QPSK and 16QAM
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Another metric we are using is the block error rate 
\color blue
(
\begin_inset CommandInset ref
LatexCommand nameref
reference "subsec:BLER"
plural "false"
caps "false"
noprefix "false"

\end_inset

) 
\color black
which
\color inherit
 is a common metric used to measure the performance of digital communication
 systems, and it is an important factor in determining the quality of the
 transmission.
 A lower block error rate indicates that fewer errors are occurring during
 transmission and the communication system is performing better.
 A "block" is a fixed-length sequence of bits, and in a communication system,
 data is transmitted in these fixed-length blocks, for this case we built
 the blocks of 48 which is the same size as frame.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/BLER/Results_16QAM-10_3_2023-23_51.png
	lyxscale 70
	scale 70

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
16-QAM linear models BLER: LS, LMMSE, ZeroForcing
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Defining the Golden class, which takes the mode ("MSE"(LS), "LMSE", or "ZERO")
 as input and initializes the Rx_loader superclass with the given BATCHSIZE,
 QAM, and "Complete" load.
 Depending on the mode, the class sets the self.estimator attribute to the
 MSE_X, LMSE_X, or ZERO_X method.
 The class also defines the forward method, the configure_optimizers method,
 and the predict_step method, which calculates the bit error rate (BER)
 for a given batch of data.
 Finally, the class defines the predict_dataloader method, which returns
 the test_loader.
 In the main section of the script, a PyTorch Lightning Trainer object is
 instantiated.
 Finally, the SNR_BER_TEST method of the Golden object is called with the
 Trainer object and a file name for the output log.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/Golden/BLER/Results_Non_linear_Golden_Models_-17_3_2023-11_35.png
	lyxscale 70
	scale 70

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Golden LMMSE and non-linear models BLER 16QAM
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsection
\paragraph_spacing onehalf
\noindent
PhaseNet
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
This neural network corrects the distortion and restores the original phase
 given channel and noise.
 It can be used in applications such as phase modulation or PSK.
 However, the network encounters a problem when evaluating the error between
 the estimated and real values.
 When the estimated value is in the second quadrant of the complex plane
 and the real value is in the third quadrant, the error becomes quite large.
 This is because the error is measured as the difference in angles, and
 traversing the second, fourth, and third quadrants causes the error to
 increase significantly.
 It is important to note that angle values are usually represented within
 the range of 
\begin_inset Formula $-\pi$
\end_inset

 to 
\begin_inset Formula $\pi$
\end_inset

 in pytorch and numpy libraries.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Networks/ErrorAngle.png
	scale 80

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Angle error - Red represents high error and green represents smaller error.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
To address the issue of computing the error and achieving precise adjustment
 of the estimation, we adopted a new technique.
 This technique involves generating a complex number with a fixed radius
 of 1 and a variable angle.
 Since neural networks only output angles, we truncated the ground truth
 complex values to a radius of one.
 We used Euler's formula to construct this complex number in rectangular
 form, based only on the angle.
 Specifically, we used the output of the neural network, denoted as 
\begin_inset Formula $\boldsymbol{O(\hat{\theta})}$
\end_inset

, with a radius of one to build the complex number.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{O(\hat{\theta})=e^{i\hat{\theta}}=cos(\hat{\theta})+i*sin(\hat{\theta})}
\end{equation}

\end_inset

By using this approach, we can concentrate solely on the phasors (angles)
 and keep a constant radius.
 We can objectively measure the difference between the complex value of
 the estimated and real values using the method of least squares.
 This method allows us to calculate the difference between two quadrants
 more accurately, resulting in better estimation correction.
 However, to avoid getting a complex error and obtain only a numerical error
 value, we calculate the mean squared error (MSE) separately for the real
 and imaginary parts.Furthermore, by limiting the radius to 1, the loss is
 bounded, preventing it from exploding and introducing a large error.
 This can help with the convergence of the neural network.
 The equation below shows the error measurement that was developed.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{MSE\left(\hat{\theta}\right)=\frac{1}{2}\left(E\left[(cos(\hat{\theta})-x_{real})^{2}\right]+E\left[(sin(\hat{\theta})-x_{imag})^{2}\right]\right)}\label{eq:62}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\align center

\size large
However this expresion can be rewriten and it can be expand each term as
 follows:
\end_layout

\begin_layout Standard
\align center

\size large
\begin_inset Formula $\boldsymbol{E\left[\cos^{2}(\hat{\theta})\right]-2x_{\text{real}}E\left[\cos(\hat{\theta})\right]+x_{\text{real}}^{2}+E\left[\sin^{2}(\hat{\theta})\right]-2x_{\text{imag}}E\left[\sin(\hat{\theta})\right]+x_{\text{imag}}^{2}}$
\end_inset


\end_layout

\begin_layout Standard
\align center

\size large
We can simplify this by noting that:
\end_layout

\begin_layout Standard
\align center

\size large
\begin_inset Formula $\boldsymbol{E\left[\cos^{2}(\hat{\theta})\right]+E\left[\sin^{2}(\hat{\theta})\right]=E\left[\cos^{2}(\hat{\theta})+\sin^{2}(\hat{\theta})\right]=E\left[1\right]=1}$
\end_inset


\end_layout

\begin_layout Standard
\align center

\size large
and
\end_layout

\begin_layout Standard
\align center

\size large
\begin_inset Formula $\boldsymbol{-2x_{\text{real}}E\left[\cos(\hat{\theta})\right]-2x_{\text{imag}}E\left[\sin(\hat{\theta})\right]=-2(x_{\text{real}}\cos(\hat{\theta})+x_{\text{imag}}\sin(\hat{\theta}))}$
\end_inset


\end_layout

\begin_layout Standard
\align center

\size large
Substituting these simplifications back into the previous equation gives:
\end_layout

\begin_layout Standard
\align center

\size large
\begin_inset Formula $\boldsymbol{\frac{1}{2}\left(1-2(x_{\text{real}}\cos(\hat{\theta})+x_{\text{imag}}\sin(\hat{\theta}))+x_{\text{real}}^{2}+x_{\text{imag}}^{2}\right)}$
\end_inset


\end_layout

\begin_layout Standard
\align center

\size large
which can be further simplified to:
\end_layout

\begin_layout Standard
\align center

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{\frac{1}{2}\left((\cos(\hat{\theta})-x_{\text{real}})^{2}+(\sin(\hat{\theta})-x_{\text{imag}})^{2}\right)}\label{eq63}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The final result is the same as the squared Euclidean distance, multiplied
 by a factor of 1/2.
 In complex form, it is represented by the squared magnitude of the difference
 between the complex numbers, which is equivalent to 
\color blue

\begin_inset CommandInset ref
LatexCommand formatted
reference "eq:46"
plural "false"
caps "false"
noprefix "false"

\end_inset

 
\color inherit
with a fixed radius of 1
\end_layout

\begin_layout Standard

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{MSE\left(\hat{\theta}\right)=|O(\hat{\theta})-x|^{2}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard

\size large
Where 
\begin_inset Formula $|.|$
\end_inset

 is the magnitud of the complex number.
\end_layout

\begin_layout Subsubsection
Preprocesing
\end_layout

\begin_layout Standard
\noindent
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{table}[h] 
\backslash
centering 
\backslash
caption{Preprocessing flags PhaseNet} 
\backslash
label{tab:preprocessing} 
\backslash
begin{tabular}{|c|c|} 
\backslash
hline 
\backslash
textbf{Preprocessing} & 
\backslash
textbf{Enable} 
\backslash

\backslash
 
\backslash
hline Conjugate & True 
\backslash

\backslash
 
\backslash
hline Z-score & True 
\backslash

\backslash
 
\backslash
hline  Zero-Forcing & False 
\backslash

\backslash
 
\backslash
hline 
\backslash
end{tabular} 
\backslash
end{table}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Based on the experimentation, it can be concluded that preprocessing plays
 a crucial role in enabling the neural network to converge successfully.
 As demonstrated in the paper 
\shape italic
A Novel OFDM Equalizer for Large Doppler Shift Channel through Deep Learning
\shape default
\color blue
 
\begin_inset CommandInset ref
LatexCommand vpageref
reference "subsec:A-Novel-OFDM"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
, preprocessing helped to achieve a successful outcome.
 In this network, our first preprocessing stage is to multiply 
\begin_inset Formula $Y$
\end_inset

 by the Hermitian transpose of the channel, 
\begin_inset Formula $H^{H}Y$
\end_inset

.
 This results in 
\begin_inset Formula $H^{H}Y$
\end_inset

 being the input to the network.
 Next, we apply a z-score filter 
\begin_inset CommandInset ref
LatexCommand vpageref
reference "subsec:Z-score"
plural "false"
caps "false"
noprefix "false"

\end_inset

 with a 95% confidence interval to eliminate outliers.
 Finally, we normalize angles from -pi to pi to -1 to 1.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Codigo/UML/PhasNet.png
	lyxscale 70
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Preprocesing Stages
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Parameters
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{table}[H]   
\backslash
centering   
\backslash
caption{Number of Parameters in the PyTorch nn.Sequential block}   
\backslash
label{tab:num_params}   
\backslash
begin{tabular}{|l|l|l|}     
\backslash
hline     
\backslash
textbf{Layer} & 
\backslash
textbf{Output Shape} & 
\backslash
textbf{Number of Parameters} 
\backslash

\backslash
     
\backslash
hline     
\backslash
texttt{nn.Linear(48, 240, bias=True)} & 
\backslash
texttt{(batch
\backslash
_size, 240)} & 
\backslash
texttt{(48 + 1) * 240 = 11,760} 
\backslash

\backslash
     
\backslash
hline     
\backslash
texttt{nn.Hardtanh()} & 
\backslash
texttt{(batch
\backslash
_size, 240)} & 
\backslash
texttt{0} 
\backslash

\backslash
     
\backslash
hline     
\backslash
texttt{nn.Linear(240, 720, bias=True)} & 
\backslash
texttt{(batch
\backslash
_size, 720)} & 
\backslash
texttt{2 * 240$^2$ + 2 * 240 = 346,320} 
\backslash

\backslash
     
\backslash
hline     
\backslash
texttt{nn.Linear(720, 240, bias=True)} & 
\backslash
texttt{(batch
\backslash
_size, 240)} & 
\backslash
texttt{4 * 240$^2$ + 2 * 240 = 1,388,160} 
\backslash

\backslash
     
\backslash
hline     
\backslash
texttt{nn.Hardtanh()} & 
\backslash
texttt{(batch
\backslash
_size, 240)} & 
\backslash
texttt{0} 
\backslash

\backslash
     
\backslash
hline     
\backslash
texttt{nn.Linear(240, 48, bias=True)} & 
\backslash
texttt{(batch
\backslash
_size, 48)} & 
\backslash
texttt{(240 + 1) * 48 = 11,568} 
\backslash

\backslash
     
\backslash
hline     
\backslash
multicolumn{2}{|r|}{
\backslash
textbf{Total}} & 
\backslash
textbf{1,757,808 = 13.39 MB} 
\backslash

\backslash
     
\backslash
hline   
\backslash
end{tabular} 
\backslash
end{table} 
\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Hyperparameters
\end_layout

\begin_layout Standard

\size large
SNR stands for Signal-to-Noise Ratio during training.
 This value is applicable to all networks.
 During testing, the SNR is subjected to varying values.

\size default
 
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{table}[H]   
\backslash
centering   
\backslash
caption{Hyperparameters}   
\backslash
label{tab:hyperparams}   
\backslash
begin{tabular}{|l|l|}     
\backslash
hline     
\backslash
textbf{Hyperparameter} & 
\backslash
textbf{Value} 
\backslash

\backslash
 
\backslash
hline     BATCHSIZE & 10 
\backslash

\backslash
 
\backslash
hline     QAM & 16 
\backslash

\backslash
 
\backslash
hline     NUM
\backslash
_EPOCHS & 2 
\backslash

\backslash
 
\backslash
hline     INPUT
\backslash
_SIZE & 48 
\backslash

\backslash
 
\backslash
hline     HIDDEN
\backslash
_SIZE & 240 
\backslash

\backslash
 
\backslash
hline     LEARNING
\backslash
_RATE & 8e-5 
\backslash

\backslash
 
\backslash
hline     CONJ & True 
\backslash

\backslash
 
\backslash
hline  SNRdB & 35 
\backslash

\backslash
 
\backslash
hline 
\backslash
end{tabular} 
\backslash
end{table} 
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
PolarNet
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The Polar_Net consists of two networks: PhaseNet, which we've seen before,
 and a new network called Mag_net.
 The Polar_Net is an integration of these two as pretrained networks.
 Since we're already familiar with PhaseNet, let's now focus on describing
 MagNet.
\end_layout

\begin_layout Subsubsection
MagNet Preprocesing and loss function
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The architecture of MagNet is quite similar to that of Polar_Net, but with
 fewer parameters in the hidden layer.
 As a result, we won't go into as much detail about the layer architecture.
 However, we'll still pay close attention to the preprocessing stage.
 Unlike PhaseNet, MagNet doesn't use the Hermitian transpose of the channel.
 Instead, it uses the diagonal of the channel to perform zero forcing equalizati
on as a preprocessing step.
 Next, a z-score filter is applied, followed by complex normalization by
 absolute.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The loss function for MagNet remains quite simple, let 
\begin_inset Formula $\boldsymbol{O(\hat{\theta})}$
\end_inset

 be the output of the network, which approximates the magnitude of the ground
 truth, and the magnitude of a complex number is denoted by 
\begin_inset Formula $\boldsymbol{|.|}$
\end_inset

, the folowing error is given: 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{MSE(\hat{\theta})=E\left[\left(O(\hat{\theta})-|\theta|\right)^{2}\right]}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
To put it another way, the network produces its output in terms of the magnitude
 of the complex numbers.
 Then, for the loss function, the absolute value of the complex value of
 the ground truth is taken.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Codigo/UML/MagNet.png
	lyxscale 70
	scale 60

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
MagNet Preprocesing
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Magnet Parameters
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{table}[h]   
\backslash
centering   
\backslash
caption{Number of Parameters in the PyTorch nn.Sequential block}   
\backslash
label{tab:num_params}   
\backslash
begin{tabular}{|l|l|l|}     
\backslash
hline     
\backslash
textbf{Layer} & 
\backslash
textbf{Output Shape} & 
\backslash
textbf{Number of Parameters} 
\backslash

\backslash
     
\backslash
hline     
\backslash
texttt{nn.Linear(48, 120, bias=True)} & 
\backslash
texttt{(batch
\backslash
_size, 120)} & 
\backslash
texttt{(48 + 1) * 120 = 5,880} 
\backslash

\backslash
     
\backslash
hline     
\backslash
texttt{nn.Hardtanh()} & 
\backslash
texttt{(batch
\backslash
_size, 120)} & 
\backslash
texttt{0} 
\backslash

\backslash
     
\backslash
hline     
\backslash
texttt{nn.Linear(120, 240, bias=True)} & 
\backslash
texttt{(batch
\backslash
_size, 240)} & 
\backslash
texttt{2 * 120$^2$ + 2 * 120 = 29,040} 
\backslash

\backslash
     
\backslash
hline     
\backslash
texttt{nn.Linear(240, 120, bias=True)} & 
\backslash
texttt{(batch
\backslash
_size, 120)} & 
\backslash
texttt{4 * 120$^2$ + 2 * 120 = 57,840} 
\backslash

\backslash
     
\backslash
hline     
\backslash
texttt{nn.Hardtanh()} & 
\backslash
texttt{(batch
\backslash
_size, 120)} & 
\backslash
texttt{0} 
\backslash

\backslash
     
\backslash
hline     
\backslash
texttt{nn.Linear(120, 48, bias=True)} & 
\backslash
texttt{(batch
\backslash
_size, 48)} & 
\backslash
texttt{(120 + 1) * 48 = 5,856} 
\backslash

\backslash
     
\backslash
hline     
\backslash
multicolumn{2}{|r|}{
\backslash
textbf{Total}} & 
\backslash
textbf{98,716 = 789.7 KB} 
\backslash

\backslash
     
\backslash
hline   
\backslash
end{tabular} 
\backslash
end{table} 
\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
MagNet Hyperparameters
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{table}[H] 
\backslash
centering 
\backslash
caption{Hyperparameters} 
\backslash
label{tab:hyperparams} 
\backslash
begin{tabular}{|l|l|} 
\backslash
hline 
\backslash
textbf{Hyperparameter} & 
\backslash
textbf{Value} 
\backslash

\backslash
 
\backslash
hline BATCHSIZE & 10 
\backslash

\backslash
 
\backslash
hline QAM & 16 
\backslash

\backslash
 
\backslash
hline NUM
\backslash
_EPOCHS & 10 
\backslash

\backslash
  
\backslash
hline INPUT
\backslash
_SIZE & 48 
\backslash

\backslash
 
\backslash
hline HIDDEN
\backslash
_SIZE & 120 
\backslash

\backslash
 
\backslash
hline LEARNING
\backslash
_RATE & 5e-5 
\backslash

\backslash
 
\backslash
hline SNRdB & 25 
\backslash

\backslash
 
\backslash
hline 
\backslash
end{tabular} 
\backslash
end{table}
\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
All Together
\end_layout

\begin_layout Standard
The final size of the network is the sum of the Magnet parameters and the
 Phase parameters, which is approximately 
\series bold
0.753 MB + 13.39 MB = 14.143 MB
\series default
.
 The reason why Magnet has fewer parameters is that more parameters in the
 magnitude can lead to overfitting and the network may not generalize well
 with new data.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Codigo/UML/PolarNet.png
	lyxscale 70
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Overview of PolarNet
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Complex Net
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
This network was motivated in the paper A Survey of Complex-Valued Neural
 Networks 
\color blue

\begin_inset CommandInset ref
LatexCommand vpageref
reference "subsec:A-Survey-of"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color black
.
 The main idea is to investigate the use of complex-valued neural networks
 and attempt to reduce the number of network parameters.
 However, this approach may increase the time complexity due to the need
 for complex number operations between each layer.
 Additionally, we aim to utilize state-of-the-art loss functions proposed
 in mathematical formulas 
\color blue

\begin_inset CommandInset ref
LatexCommand formatted
reference "eq:46"
plural "false"
caps "false"
noprefix "false"

\end_inset

 
\color black
and 
\color blue

\begin_inset CommandInset ref
LatexCommand formatted
reference "eq:48"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color black
.Finally, for preprocessing, the hermitian transpose and normalization steps
 are applied.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Codigo/UML/ComplexUML.png
	lyxscale 70
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Complex Network Implementation
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Codigo/UML/ComplexNet.png
	lyxscale 70
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Complex Preprocesing
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\color black
In the upcoming subsections, we will explain the components required to
 construct a complex network.
 
\end_layout

\begin_layout Subsubsection
Apply Complex
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
One of the key components of layers in this stage is the apply_complex functions
 which is part of the complexLinear layers.
 The apply_complex(fr, fi, input, dtype = torch.complex128) function takes
 as input the real and imaginary parts of the weights fr and fi, the input
 tensor input, and a data type dtype for the output tensor.
 It applies a complex-valued linear transformation to the input tensor,
 given by the expression:
\end_layout

\begin_layout Standard

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{Re(z)=Re(fr)*Re(x)-Im(fi)*Im(x)}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{Im(z)=Re(fi)*Re(x)+Im(fr)*Im(x)}
\end{equation}

\end_inset


\end_layout

\begin_layout Subsubsection
\paragraph_spacing onehalf
\noindent
Complex Linear
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
The ComplexLinear(in_features, out_features) class defines a custom PyTorch
 module for a complex-valued linear layer.
 It has two attributes: fc_r is a standard PyTorch Linear module that applies
 a linear transformation to the real part of the input, and fc_i is another
 Linear module that applies a linear transformation to the imaginary part
 of the input.
 The forward(input) method of this module applies the complex-valued linear
 transformation separately to the real and imaginary parts of the input
 tensor using the apply_complex function.
\end_layout

\begin_layout Subsubsection
\paragraph_spacing onehalf
\noindent
Hardtanh Complex
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
The HardTahn_complex class defines a custom PyTorch module for a complex-valued
 hard tanh activation function.
 It has two attributes: hard_real is a standard PyTorch Hardtanh module
 that applies the hard tanh function to the real part of the input tensor,
 and hard_imag is another Hardtanh module that applies the hard tanh function
 to the imaginary part of the input tensor.
 The forward(input) method of this module applies the hard tanh function
 separately to the real and imaginary parts of the input tensor, and then
 combines them into a complex-valued tensor using torch.float64 and the +1j*
 syntax to create a complex number.
 
\end_layout

\begin_layout Subsubsection
Parameters
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{table}[H] 
\backslash
centering 
\backslash
begin{tabular}{|l|l|l|l|} 
\backslash
hline 
\backslash
textbf{Layer} & 
\backslash
textbf{Input Size} & 
\backslash
textbf{Output Size} & 
\backslash
textbf{Number of Parameters} 
\backslash

\backslash
 
\backslash
hline Linear 1 & 48 & 120 & 11,520 
\backslash

\backslash
 
\backslash
hline HardTanh 1 & 120 & 120 & 0 
\backslash

\backslash
 
\backslash
hline Linear 2 & 120 & 240 & 138,240 
\backslash

\backslash
 
\backslash
hline Linear 3 & 240 & 240 & 115,440 
\backslash

\backslash
 
\backslash
hline Linear 4 & 240 & 120 & 57,720 
\backslash

\backslash
 
\backslash
hline HardTanh 2 & 120 & 120 & 0 
\backslash

\backslash
 
\backslash
hline Linear 5 & 120 & 240 & 138,240 
\backslash

\backslash
 
\backslash
hline Linear 6 & 240 & 48 & 23,088 
\backslash

\backslash
 
\backslash
hline Total & 48 & 48 & 484,248 = 3.87 MB 
\backslash

\backslash
 
\backslash
hline 
\backslash
end{tabular} 
\backslash
caption{Number of parameters in the complex network.} 
\backslash
end{table} 
\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
HyperParameters
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{table}[h] 
\backslash
centering 
\backslash
begin{tabular}{|l|l|} 
\backslash
hline 
\backslash
textbf{Parameter} & 
\backslash
textbf{Value} 
\backslash

\backslash
 
\backslash
hline Batch Size & 50 
\backslash

\backslash
 
\backslash
hline QAM & 16 
\backslash

\backslash
 
\backslash
hline Number of Epochs & 100 
\backslash

\backslash
 
\backslash
hline Learning Rate & 0.00001 
\backslash

\backslash
 
\backslash
hline SNRdB & 40 
\backslash

\backslash
 
\backslash
hline 
\backslash
end{tabular} 
\backslash
caption{Values for network hyperparameters.} 
\backslash
end{table} 
\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Loss functions
\end_layout

\begin_layout Standard

\size large
In the experiments, we evaluate the performance of the complex network using
 both custom loss functions
\size default
 
\size large
\color blue

\begin_inset CommandInset ref
LatexCommand formatted
reference "eq:46"
plural "false"
caps "false"
noprefix "false"

\end_inset

 
\color black
and 
\color blue

\begin_inset CommandInset ref
LatexCommand formatted
reference "eq:48"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color black
.

\color inherit
 The results of these experiments are presented in the next section.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Networks/ComplexLoss.png
	lyxscale 70
	scale 70

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Loss functions code
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsection
MobileNet zeroForcing
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
We conducted experiments with this network to study how well convolutional
 neural networks can be developed in signal equalization.
 However, we opted to employ the efficient architecture of MobileNet as
 our network's goal is to improve the effectiveness of the zero-forcing
 method for communication channels.
 Given the relative simplicity of the zero-forcing algorithm, we determined
 that the 
\color blue

\begin_inset CommandInset ref
LatexCommand nameref
reference "subsec:MobileNetV3"
plural "false"
caps "false"
noprefix "false"

\end_inset

 
\color inherit
architecture was well-suited for our purposes.
 Its time efficiency and competence relative to zero-forcing made it a suitable
 choice.
 However, in the presence of noise in the channel data, the conventional
 zero-forcing approach may not be effective as it does not consider noise
 in its nature.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The channel is initially a 1x48x48 matrix, but it must be transformed into
 a single vector of length 1x48 for the zero-forcing approach to be applicable.
 Thus, this implementation employs two modified MobileNets to process the
 channel data.
 One network is responsible for extracting the absolute value of the channel
 matrix, while the other network extracts the angle matrix of the channel.
 Notably, the first and last layers were modified to fit the specific problem.
 In the image below, they are marked in red.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/MobileNetCustom.png
	lyxscale 70
	scale 70

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Ilustartion of mobileNet customized for our target problem
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The models used in this project were taken from the PyTorch framework, so
 there was no need to test their functionality.
 We did not use pre-trained weights and instead trained the models from
 scratch.
 Thanks to the GPU, we were able to train the models faster.

\size default
 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The idea behind this is to replicate the process of traditional zero-forcing
 
\begin_inset Formula $\boldsymbol{\frac{Y}{H}}$
\end_inset

, where the channel matrix is represented by 
\begin_inset Formula $\boldsymbol{H}$
\end_inset

 and the received signal is represented by 
\begin_inset Formula $\boldsymbol{Y=Hx+n}$
\end_inset

.
 In this process, we estimate the channel using the equation:
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{\hat{x}=\frac{Y}{\hat{\theta}}}
\end{equation}

\end_inset

 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
where 
\begin_inset Formula $\boldsymbol{\hat{\theta}}$
\end_inset

 represents the output of the model.
 However, as we want the estimator values to be in the range of 
\begin_inset Formula $\boldsymbol{0<\hat{\theta}<1}$
\end_inset

, we need to rearrange the estimation equation as follows:
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{\hat{x}=Y*\hat{\theta}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
As we are working with polar coordinates, we should note that when multiplying
 two phasors, their amplitudes are multiplied, and their angles are added
 together.
 So basically net compensate the distorted phasor 
\begin_inset Formula $Y$
\end_inset

 and estimation equations has this form:
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{O(\hat{\theta})=Y_{mag}*\hat{\theta_{mag}}\angle\hat{\theta}_{angle}+Y_{angle}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard

\size large
Finally the MSE loss between this estimated 
\begin_inset Formula $O(\hat{\theta})$
\end_inset

 and the true value is given this form.
 
\end_layout

\begin_layout Standard

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{MSE(\hat{\theta})=E\left[\left(O(\hat{\theta})-\theta\right)^{2}\right]}
\end{equation}

\end_inset


\end_layout

\begin_layout Subsubsection
\paragraph_spacing onehalf
\noindent
Software Implementation 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
In the common_step method, the input data is processed by the PredesignedModel
 network, which is a pre-trained MobileNetv3 network that is modified to
 fit the problem.
 The output of the PredesignedModel network is passed through two separate
 layers: one layer for the magnitude and one layer for the angle of the
 signal.
 The angle layer is used to estimate the phase shift of the received signal.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
It's worth noting that the channel is treated as an image of two channels,
 one for the real and the other for the imaginary part.
 In the software implementation, a complex128 channel of 1 channel is built,
 and then the absolute and angle of this 1 channel matrix is taken to feed
 both mobile nets.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
In this code implementation, the channel magnitude is normalized to the
 maximum magnitude of 1.
 This normalization is done after building the Y, to avoid altering the
 results of calculating the input signal.
 Then the z-score is computed, and outliers are filtered with a confidence
 interval of 99%.
 Finally, for the angle error calculation, the same ideas as in PolarNet
 are followed.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Codigo/UML/MobileNetForwar.png
	lyxscale 80
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
MobileNet Forward process
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Loss Function
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
For the loss function we face the same issue as PhaseNet regarding the calculati
on of angle errors.
 To avoid this problem, we adopt a similar solution, which involves fixing
 the radius to 1 and comparing the angles 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq63"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 So we end up with 3 evalautons for a single loss function.
 However, in this loss, we chose to emphasize the Phasor concept to make
 it more intuitive.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\begin_inset Formula 
\begin{equation}
\boldsymbol{Loss=}\boldsymbol{\begin{array}{c}
\frac{1}{2}MSE(Y_{mag}*\hat{\theta_{mag}},x_{mag})+\\
\frac{1}{4}MSE\left(\left[1\angle\hat{\theta}_{angle}+Y_{angle}\right]_{real},\left[1\angle x_{angle}\right]_{real}\right)+\\
\frac{1}{4}MSE\left(\left[1\angle\hat{\theta}_{angle}+Y_{angle}\right]_{imag},\left[1\angle x_{angle}\right]_{imag}\right)
\end{array}}
\end{equation}

\end_inset


\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf

\size large
The first term computes the MSE between the magnitudes of the estimated
 signal 
\begin_inset Formula $\boldsymbol{Y_{mag}*\hat{\theta_{mag}}}$
\end_inset

 and the true signal magnitud 
\begin_inset Formula $\boldsymbol{x_{mag}}$
\end_inset

.
 Here, 
\begin_inset Formula $\boldsymbol{Y_{mag}}$
\end_inset

 is the magnitude of the received signal 
\begin_inset Formula $\boldsymbol{Y}$
\end_inset

, and 
\begin_inset Formula $\boldsymbol{\hat{\theta_{mag}}}$
\end_inset

 is the estimated magnitude given by network.
\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf

\size large
The second term computes the mean squared error (MSE) between the real component
s of the estimated phasor, with fixed radius plus phase correction, and
 the real value of the angle of x
\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf

\size large
The same as second term in loss, but with imaginary part.
 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The function also includes weighting factors for each term.
 The first term is weighted by 1/2, while the second and third terms are
 each weighted by 1/4.
\end_layout

\begin_layout Subsubsection
Parameters
\end_layout

\begin_layout Standard
MobileNetV3 model has about 2.24 million parameters in an efficient way.
 
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{table}[h] 
\backslash
centering 
\backslash
begin{tabular}{|c|c|c|} 
\backslash
hline 
\backslash
textbf{Name} & 
\backslash
textbf{Type} & 
\backslash
textbf{Params} 
\backslash

\backslash
 
\backslash
hline 0 & loss
\backslash
_f & MSELoss 
\backslash
_ 0 
\backslash

\backslash
 
\backslash
hline 1 & abs
\backslash
_net & PredesignedModel = 1.6 M 
\backslash

\backslash
 
\backslash
hline 2 & angle
\backslash
_net & PredesignedModel = 1.6 M 
\backslash

\backslash
 
\backslash
hline 3 & final
\backslash
_merge
\backslash
_abs & Sequential = 18.6 K 
\backslash

\backslash
 
\backslash
hline 4 & final
\backslash
_merge
\backslash
_ang & Sequential = 18.6 K 
\backslash

\backslash
 
\backslash
hline 
\backslash
multicolumn{2}{|c|}{
\backslash
textbf{Total size}} & 
\backslash
textbf{3.2 MB + 37.2 KB} 
\backslash

\backslash
 
\backslash
hline 
\backslash
end{tabular} 
\backslash
caption{Model architecture} 
\backslash
end{table} 
\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
HyperParameter
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{table}[h] 
\backslash
centering 
\backslash
begin{tabular}{|l|l|} 
\backslash
hline 
\backslash
textbf{Parameter} & 
\backslash
textbf{Value} 
\backslash

\backslash
 
\backslash
hline Batch Size & 50 
\backslash

\backslash
 
\backslash
hline Number of Epochs & 50 
\backslash

\backslash
 
\backslash
hline Learning Rate & 0.0001 
\backslash

\backslash
 
\backslash
hline SNRdB & 30 
\backslash

\backslash
 
\backslash
hline 
\backslash
end{tabular} 
\backslash
caption{Neural network hyperparameters} 
\backslash
label{tab:nn_params} 
\backslash
end{table}
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
\paragraph_spacing onehalf
GridNet
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
At the moment we were conducting this research, nothing had been done before
 with transformers and signal equalization.
 We are aware that transformers are a heavier network, but recent advances
 in Edge Computing TPU processors 
\begin_inset CommandInset citation
LatexCommand cite
key "coral2020accelerator"
literal "false"

\end_inset

 are making them a more feasible solution at a relatively low cost.
 While there is a paper called "Radio Transformer"
\begin_inset CommandInset citation
LatexCommand cite
key "RadioTransformer"
literal "false"

\end_inset

 in the state of the art, it is used for modulation recognition, not for
 signal equalization.
 Additionally, historically, this paper does not align with "Attention is
 All You Need" 
\begin_inset CommandInset citation
LatexCommand cite
key "transformer"
literal "false"

\end_inset

 paper since it was written in 2016, whereas "Attention is All You Need"
 was written in 2017.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
While we were initially inspired by the concept of an image being worth
 16x16 words 
\begin_inset CommandInset citation
LatexCommand cite
key "dosovitskiy2020image"
literal "false"

\end_inset

 as described in the state of the art 
\color blue

\begin_inset CommandInset ref
LatexCommand formatted
reference "subsec:An-image-is"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
, we took this idea further by considering the encoder and decoder for the
 original transformer design 
\color blue

\begin_inset CommandInset ref
LatexCommand formatted
reference "fig:Transformer-with-encoder"
plural "false"
caps "false"
noprefix "false"

\end_inset

 
\color inherit
.
 Additionally, we challenged the assumption that the grid must be based
 on Euclidean geometry and instead rethought the grid in terms of a polar
 geometry.
 This paradigm shift was justified by the fact that our best results were
 obtained using polar representation.
 Furthermore, polar representation results in a non-uniformly distributed
 grid, where values closer to the center are penalized more heavily.
 This is useful because, in the presence of additive white noise, values
 are not expected to be centered, but rather more commonly found towards
 the edges of the polar representation.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The main idea is to divide the complex plane into grids, with each grid
 slot considered as a bucket.
 When a received value 
\begin_inset Formula $\boldsymbol{Y_{i}}$
\end_inset

 arrives, it is placed in an incorrect bucket 
\begin_inset Formula $\boldsymbol{B_{i}},$
\end_inset

which is assigned a number 
\begin_inset Formula $\boldsymbol{A_{i}}$
\end_inset

.
 To train the network, we assign the ground truth value with its correct
 bucket number 
\begin_inset Formula $\boldsymbol{B_{j}}$
\end_inset

and calculate the maximum likelihood cost function between the estimation
 and ground truth , similar to correcting mistranslated text in a language
 task.
 Multihead attention improves Bucket calculation, because it takes care
 of the values passed before.
 In the context of signal processing, this attention mechanism helps to
 handle the ISI (Inter-Symbol Interference), which is a major challenge
 in dealing with a doubly dispersive 
\color blue

\begin_inset CommandInset ref
LatexCommand nameref
reference "subsec:Channel"
plural "false"
caps "false"
noprefix "false"

\end_inset

 .
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Finally, after predicting the bucket 
\begin_inset Formula $\boldsymbol{B_{j}},$
\end_inset

the value passes through the degrid process, which involves placing the
 value in the middle of the patch coordinates.
 This process helps to further equalize the value as it is forced to be
 placed in only this position or any other patch.
\end_layout

\begin_layout Subsubsection
\paragraph_spacing onehalf
Square Grid
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The encoding process involves binning the real and imaginary parts of the
 data into a set of discrete bins and mapping them onto a 2D grid.
 The decoding process reverses this process by mapping the values back to
 their original locations in the complex plane.
 The smallest number used for the grid is 4 because number 2 is reserved
 for the start of sentence token (<sos>) and 3 is reserved for the end of
 sentence token (<eos>), making it compatible with language models.
 The largest number corresponds to the number of bins used in the encoding
 process.
 In other words number of bins is the size of our alphabet.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Codigo/UML/SquareGrid.png
	lyxscale 70
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Class attibutes to do the grid with bins
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
step
\series default
: A float value that represents the step size for binning, from -.85 to .85.
 Note that step is for quadrant and not all plane.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
binsx
\series default
: A tensor that contains the bins for the real part of the data.
 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
binsy
\series default
: A tensor that contains the bins for the imaginary part of the data.
 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
binxy
\series default
: A tensor that contains a 2D bin index matrix for encoding.
 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
x_indices
\series default
: A tensor that stores the indices of the bins for the real part of the
 data.
 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
y_indices
\series default
: A tensor that stores the indices of the bins for the imaginary part of
 the data.
 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
indices_shape
\series default
: A tuple that stores the shape of the input data for encoding.
 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
real_decoded
\series default
: A tensor that stores the decoded values for the real part of the data.
 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
imag_decoded
\series default
: A tensor that stores the decoded values for the imaginary part of the
 data.
 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
decoded_shape
\series default
: A tuple that stores the shape of the input data for decoding.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Encoding Recipe: 
\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent

\size large
Loop over the binsx for the real and binsy for the imaginary parts, and
 check if the data value falls in the range of bin i and bin i+1.
\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent

\size large
Save all the values that fall in the bin as x_indices and y_indices.
 These indices behave more like coordinates for the matrix of binsxy.
\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent

\size large
Encoding is done by putting the indices in the binxy vector.
 The binxy vector returns a numerical token that represents the position
 of the complex plane.
\end_layout

\begin_layout Standard

\size large
Here's an elegant code implementation 
\end_layout

\begin_layout Standard

\size large
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
lstinputlisting[language=python,firstline=39, lastline=48]{Codigo/GridCode.py}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Networks/GridNet.png
	lyxscale 80
	scale 70

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Square grid enconding values with a step of 1/7 per cuadrant
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Decoding Recipe: 
\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent

\size large
Loop over the binsxy matrix and create a mask of indices that correspond
 to the encoded values
\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent

\size large
Use the mask of indices to assign values from the binsx and binsy vectors
 to the corresponding real and imaginary decoded vectors.
 Add half a step to each value to place it in the center of the bin.
\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent

\size large
Build a complex number vector using the real and imaginary decoded vectors.
\end_layout

\begin_layout Standard

\size large
Here's an elegant code implementation 
\end_layout

\begin_layout Standard

\size large
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
lstinputlisting[language=python,firstline=64, lastline=76]{Codigo/GridCode.py}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The gridding step ensures that all possible values in the complex plane
 are now bounded by the alphabet size |A|, which can be beneficial for neural
 networks even if it doesn't compromise the space between QAM points spacing.
 In the picture bellow we show some points that was enconded and decoded,
 and we appreciate how they are centered after decoding.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Networks/SquareGridDegrid.png
	lyxscale 50
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Points after encoding and decoding, shown in a centered position of the
 binxy
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Polar Grid
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The Polar Grid is quite similar to the number ordering of the Square Grid,
 as it starts with 4 as its initial number.
 However, in this code implementation, instead of having x and y bins, we
 will have radius and angle bins.
 One thing to note is that now we have two steps that can be totally independent
: one step for the radius and the other for the angle.
 In the Square Grid, the step was the same for both x and y coordinates.
 One main advantage of the polar grid is that we don't need to take care
 of the angle measurement error, as the encoding will handle it within the
 transformer.
 However, the polar grid uses more space with fewer patches compared to
 the square grid.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Codigo/UML/RadGrid.png
	lyxscale 70
	scale 70

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Class attributes for the Radial Grid
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
step_radius
\series default
: Steps between 0 and 1
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
step_angle
\series default
: Steps between 0 and 
\begin_inset Formula $\boldsymbol{\pi}$
\end_inset


\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
binsr
\series default
: Number of bins for radius
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
binsa
\series default
: Numbers of bins for angles
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
binra
\series default
: Combined Grid between radius and angle.
 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Encoding Recipe: 
\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent

\size large
Loop over the binsr for the radius and binsa for the angle, and check if
 the data value falls in the range of bin i and bin i+1.
\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent

\size large
Save all the values that fall in the bin as r_indices and a_indices.
 These indices behave more like coordinates for the matrix of binsra.
\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent

\size large
Encoding is done by putting the indices in the binra vector.
 The binra vector returns a numerical token that represents the position
 of the complex plane.
\end_layout

\begin_layout Standard

\size large
Here's an elegant code implementation 
\end_layout

\begin_layout Standard

\size large
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
lstinputlisting[language=python,firstline=38, lastline=49]{Codigo/RadGrid.py}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Networks/RadGrid.png
	lyxscale 80
	scale 80

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Radial Grid encoding values.
 Radius step = 0.25 and angle step = pi/6
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Decoding Recipe: 
\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent

\size large
Loop over the binsra matrix and create a mask of indices that correspond
 to the encoded values
\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent

\size large
Use the mask of indices to assign values from the binsr and binsa vectors
 to the corresponding radius and angle decoded vectors.
 Add half a step to each value to place it in the center of the bin.
\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent

\size large
Build a complex number vector using the magnitud and phase decoded vectors.
\end_layout

\begin_layout Standard

\size large
Here's an elegant code implementation 
\end_layout

\begin_layout Standard

\size large
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
lstinputlisting[language=python,firstline=59, lastline=74]{Codigo/RadGrid.py}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Similarly to the square grid, the values in the polar grid are also centered
 in the grid during decoding, thus closing again the possible states of
 the points in the complex plane.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Networks/RadGridOriginalData.png
	lyxscale 50
	scale 57

\end_inset


\begin_inset Graphics
	filename Imagenes/Networks/RadGridOriginal_Decoded_Data.png
	lyxscale 50
	scale 57

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Points after encoding and decoding, shown in a centered position of the
 binra
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Data Augmentation for Improving Error Performance in PolarGrid 
\begin_inset CommandInset label
LatexCommand label
name "subsec:Data-Augmentation"

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Due to the superior ICI cancellation performance of Polar Net, some of the
 high SNR, had BER errors were reduced to zero.
 However, this does not indicate a perfect system; rather, it suggests that
 the error rate did not fail often enough across all of the samples.
 Therefore, we combined the validation set and training set to artificially
 augment the data and allow the system to fail more often.
 It is important to note that this step of merging the validation and testing
 set was carried out only after confirming that the network was functioning
 well with the established parameters.
 This decision does not affect the training stage in any way.
\end_layout

\begin_layout Subsubsection
Transformer implementation
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Our transformer implementation can handle both grids by simply changing
 a hyperparameter, which provides a generic interface for experimentation.
 For positional embedding, we use a logical sequence of numbers ranging
 from 0 to 48 positions.
 Although there were some experiments with the sin embedding, it did not
 work well for this task.
 We apply a padding mask to the source and pass it to the transformer.
 The transformer is not a custom implementation but rather a predefined
 block already available in PyTorch that contains an encoder and decoder.
 Note that we implemented a transformer from scratch during the study of
 this network, but we decided to use PyTorch's standard APIs instead.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The vocabulary size is determined based on the number of patches we have
 in the grid strategy.
 This means that the number of possible values that a patch can take in
 the grid is equal to the number of patches in the grid.
 For example, if we have a grid with 25 patches, then the vocabulary size
 is 25.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The loss function used in the training process is given by the cross-entropy
 
\color blue

\begin_inset CommandInset ref
LatexCommand formatted
reference "subsec:Cross-Entropy-Loss"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
.
 This is a commonly used loss function for multi-class classification tasks,
 such as image classification.
 Mathematically, the cross-entropy loss measures the distance between the
 predicted probability distribution and the true probability distribution.
 In the context of the grid encoding task, the predicted probability distributio
n is the distribution over the patches in the grid, and the true probability
 distribution is a one-hot vector representing the true patch in the grid.
 The figure 
\begin_inset CommandInset ref
LatexCommand formatted
reference "fig:Transformer-with-encoder"
plural "false"
caps "false"
noprefix "false"

\end_inset

 in the state of the art can be used to visualize the transformer architecture
 , at the right is placed the transformer decoder which its has output the
 output probabilities for symbol 
\begin_inset Formula $A_{i}$
\end_inset

 using the softmax function 
\begin_inset CommandInset ref
LatexCommand formatted
reference "fig:Softmax"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Codigo/UML/GridNet.png
	lyxscale 50
	scale 40

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
GridNet Workflow
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Autoregression in predicting mode
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Autoregression in a Transformer refers to the technique of feeding previously
 generated output tokens as input to the model in order to generate subsequent
 tokens.
 In other words, the model generates one token at a time, and each token
 is conditioned on the previously generated tokens.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
This autoregression technique is achieved in a Transformer through a process
 called self-attention.
 Self-attention allows the model to capture dependencies between different
 positions in the input sequence by weighing each input token's relevance
 to the current token being generated.
 During training, the model learns to attend to the most relevant tokens
 from the previous generated output, which in turn influences the distribution
 of probabilities over the vocabulary for the next token.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
In practice, autoregression in a Transformer involves a process called decoding,
 where the model generates tokens one at a time, starting with a special
 start-of-sequence <sos> token and continuing until a special end-of-sequence
 <eos> token is generated or a maximum sequence length is reached.
 The output tokens generated by the model at each decoding step are fed
 back as input to the model for the next step, creating a feedback loop
 that allows the model to incorporate information from previously generated
 tokens to generate subsequent ones.
\end_layout

\begin_layout Subsubsection
Noise in Trainning
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
This network is the only one that uses variable noise ratios during training
 to help the model generalize better.
 The noise varies each epoch and is determined by the following equation:
\end_layout

\begin_layout Standard

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{SNR_{dB}=45-5\times(mod(Epoch,4))}
\end{equation}

\end_inset


\end_layout

\begin_layout Subsubsection
Transformer hyperparameters
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
In this section, we first list the hyperparameters that directly affect
 the final parameter size of the model.
 Before we show the table, let's review the meaning of the parameters to
 better understand the hyperparameters table.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
Embedding_size
\series default
: the embedding size refers to the size of the vector that is used to represent
 each input token in the network.
 Each token in the input sequence is mapped to a high-dimensional vector
 of fixed size, which is called the embedding.
 The embedding captures the semantic meaning of the token in a continuous
 vector space, which can be learned by the network during training.
 In practice, the embedding size is often set to a value between 100 and
 1000, depending on the size of the input vocabulary and the complexity
 of the task
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
Num_heads
\series default
: Is a hyperparameter that controls the number of parallel self-attention
 mechanisms in the network.
 Self-attention is a mechanism that allows the model to weigh the importance
 of different positions in the input sequence when making a prediction.
 Self-attention is applied to the input sequence multiple times, with different
 linear projections of the input sequence used as inputs to each attention
 mechanism
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
Encoder and Decoder Layers
\series default
: The output of the encoder layer is a sequence of hidden representations
 that captures the relevant information from the input sequence.Both the
 encoder and decoder layers can be stacked multiple times to improve the
 quality of the feature representation and the final output sequence.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
Forward Expansion
\series default
: After performing multi-head attention on the input, the result is passed
 through a feedforward neural network (FFN) layer, which typically consists
 of two fully connected layers with a ReLU activation function in between,
 in our case was ever setup to GELU activation function.
 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
Dropout
\series default
: The dropout rate to apply during training to prevent overfitting.
 This value typically ranges between 0.1 and 0.3.
\end_layout

\begin_layout Standard

\size large
Other parameters, such as CONJ_ACTIVE, refer to the same preprocessing step
 of taking the conjugate of the channel 
\begin_inset Formula $H^{H}Y$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{table}[h] 
\backslash
centering  
\backslash
begin{tabular}{|l|l|} 
\backslash
hline 
\backslash
textbf{Hyperparameters} & 
\backslash
textbf{Value} 
\backslash

\backslash
 
\backslash
hline BATCHSIZE & 100 
\backslash

\backslash
 
\backslash
hline QAM & 16 
\backslash

\backslash
 
\backslash
hline NUM
\backslash
_EPOCHS & 24 
\backslash

\backslash
 
\backslash
hline SNR & 45-25 
\backslash

\backslash
 
\backslash
hline CONJ
\backslash
_ACTIVE & True 
\backslash

\backslash
 
\backslash
hline NOISE & True 
\backslash

\backslash
 
\backslash
hline LEARNING
\backslash
_RATE & .0001 
\backslash

\backslash
 
\backslash
hline GRID & Square 
\backslash

\backslash
 
\backslash
hline STEP & 1/7 
\backslash

\backslash
 
\backslash
hline 
\backslash
end{tabular} 
\backslash
caption{Square GridNet hyperparameters} 
\backslash
label{tab:transformer_hyper} 
\backslash
end{table}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{table}[h] 
\backslash
centering  
\backslash
begin{tabular}{|l|l|} 
\backslash
hline 
\backslash
textbf{Hyperparameters} & 
\backslash
textbf{Value} 
\backslash

\backslash
 
\backslash
hline BATCHSIZE & 100 
\backslash

\backslash
 
\backslash
hline QAM & 16 
\backslash

\backslash
 
\backslash
hline NUM
\backslash
_EPOCHS & 13 
\backslash

\backslash
 
\backslash
hline SNR & 45-20 
\backslash

\backslash
 
\backslash
hline CONJ
\backslash
_ACTIVE & True 
\backslash

\backslash
 
\backslash
hline NOISE & True 
\backslash

\backslash
 
\backslash
hline LEARNING
\backslash
_RATE & .0001 
\backslash

\backslash
 
\backslash
hline GRID & Polar 
\backslash

\backslash
 
\backslash
hline STEP
\backslash
_RADIUS & 0.25 
\backslash

\backslash
 
\backslash
hline STEP
\backslash
_ANGLE & $
\backslash
pi/6$ 
\backslash

\backslash
 
\backslash
hline 
\backslash
end{tabular} 
\backslash
caption{Polar GridNet hyperparameters} 
\backslash
label{tab:transformer_hyper} 
\backslash
end{table}
\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Parameters
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{table}[H] 
\backslash
centering 
\backslash
begin{tabular}{|l|l|} 
\backslash
hline 
\backslash
textbf{Name} & 
\backslash
textbf{Value} 
\backslash

\backslash
 
\backslash
hline loss
\backslash
_f & CrossEntropyLoss 
\backslash

\backslash
 
\backslash
hline src
\backslash
_word
\backslash
_embedding & Embedding (101 K) 
\backslash

\backslash
 
\backslash
hline src
\backslash
_position
\backslash
_embedding & Embedding (25.6 K) 
\backslash

\backslash
 
\backslash
hline trg
\backslash
_word
\backslash
_embedding & Embedding (101 K) 
\backslash

\backslash
 
\backslash
hline trg
\backslash
_position
\backslash
_embedding & Embedding (25.6 K) 
\backslash

\backslash
 
\backslash
hline transformer & Transformer (44.1 M) 
\backslash

\backslash
 
\backslash
hline fc
\backslash
_out & Linear (102 K) 
\backslash

\backslash
 
\backslash
hline dropout & Dropout (0) 
\backslash

\backslash
 
\backslash
hline 
\backslash
multicolumn{2}{|l|}{Total params: 44.5 M} 
\backslash

\backslash
 
\backslash
multicolumn{2}{|l|}{Total estimated model params size (MB): 177.990} 
\backslash

\backslash
 
\backslash
hline 
\backslash
end{tabular} 
\backslash
caption{Square Grid Transformer Parameters} 
\backslash
label{tab:polar-grid-transformer-parameters} 
\backslash
end{table}
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{table}[H] 
\backslash
centering 
\backslash
begin{tabular}{|l|l|} 
\backslash
hline 
\backslash
textbf{Name} & 
\backslash
textbf{Value} 
\backslash

\backslash
 
\backslash
hline loss
\backslash
_f & CrossEntropyLoss 
\backslash

\backslash
 
\backslash
hline src
\backslash
_word
\backslash
_embedding & Embedding (26.1 K) 
\backslash

\backslash
 
\backslash
hline src
\backslash
_position
\backslash
_embedding & Embedding (25.6 K) 
\backslash

\backslash
 
\backslash
hline trg
\backslash
_word
\backslash
_embedding & Embedding (26.1 K) 
\backslash

\backslash
 
\backslash
hline trg
\backslash
_position
\backslash
_embedding & Embedding (25.6 K) 
\backslash

\backslash
 
\backslash
hline transformer & Transformer (69.3 M) 
\backslash

\backslash
 
\backslash
hline fc
\backslash
_out & Linear (26.2 K) 
\backslash

\backslash
 
\backslash
hline dropout & Dropout (0) 
\backslash

\backslash
 
\backslash
hline 
\backslash
multicolumn{2}{|l|}{Total params: 69.5 M} 
\backslash

\backslash
 
\backslash
multicolumn{2}{|l|}{Total estimated model params size (MB): 277.842} 
\backslash

\backslash
 
\backslash
hline 
\backslash
end{tabular} 
\backslash
caption{Polar Grid Transformer Parameters} 
\backslash
label{tab:polar-grid-transformer-parameters} 
\backslash
end{table}
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
To summarize, the Radial Grid prioritizes investing less in the vocabulary
 size and compensating for it by adjusting other hyperparameters such as
 multi-head attention and increasing the number of feedforward parameters
 in order to achieve better results.
\end_layout

\begin_layout Section
Results
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The equalization of signals in telecommunications is a challenging problem,
 particularly when dealing with noisy scenarios.
 To evaluate the effectiveness of various equalization methods, we conducted
 an average of five experiments in a consistent manner and then averaged
 the results.
 This methodology helps to smooth out the curves and provide a reliable
 representation of the performance of each method.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
In our research, we focused on both noisy and non-noisy scenarios and evaluated
 the performance of our method across a wide range of signal-to-noise ratios
 (SNRs) ranging from 45 to 5 with a step of 2 between each SNR.
 This comprehensive evaluation helped us to identify the strengths and weaknesse
s of each method and determine which methods are most effective in different
 scenarios.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Our performance metrics are the
\color blue
 
\begin_inset CommandInset ref
LatexCommand nameref
reference "subsec:BER"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
 (Bit Error Rate) and 
\color blue

\begin_inset CommandInset ref
LatexCommand nameref
reference "subsec:BLER"
plural "false"
caps "false"
noprefix "false"

\end_inset


\color inherit
 (Block Error Rate) , which have been explained in the theoretical framework.
 BER measures the ratio of incorrectly received bits to the total number
 of transmitted bits, while BLER measures the ratio of incorrectly received
 blocks to the total number of transmitted blocks.
 A lower value for both metrics indicates better performance of the system.
\end_layout

\begin_layout Subsection
FLOPS and Time complexity
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
In this section, we estimated the complexity of the model and calculated
 the FLOPS for each equalizer.
 To accomplish this task, we used the execution time and performed a static
 code analysis to estimate the number of parameters.
 By considering both the number of parameters and the execution time, we
 could approximate the FLOPS of the equalizers.
 Additionally, it is important to consider the processor and operating system
 on which the algorithms run.
 In the table below, we provide a detailed description of the specifications
 of the system used to conduct the experiments.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{table}[htbp]   
\backslash
centering   
\backslash
caption{Processor specifications}    
\backslash
begin{tabular}{|l|l|}     
\backslash
hline     Property & Value 
\backslash

\backslash
  
\backslash
hline     Architecture & x86
\backslash
_64 
\backslash

\backslash
 
\backslash
hline    CPU op-mode(s) & 32-bit, 64-bit 
\backslash

\backslash
  
\backslash
hline   Address sizes & 43 bits physical, 48 bits virtual 
\backslash

\backslash
 
\backslash
hline    Byte Order & Little Endian 
\backslash

\backslash
 
\backslash
hline   CPU(s) & 16 
\backslash

\backslash
  
\backslash
hline   Model name & AMD Ryzen 7 3700X 8-Core Processor 
\backslash

\backslash
 
\backslash
hline    CPU family & 23 
\backslash

\backslash
 
\backslash
hline    Model & 113 
\backslash

\backslash
 
\backslash
hline     Thread(s) per core & 2 
\backslash

\backslash
 
\backslash
hline    Core(s) per socket & 8 
\backslash

\backslash
 
\backslash
hline     Frequency boost & enabled 
\backslash

\backslash
 
\backslash
hline    CPU max MHz & 4426.1709 
\backslash

\backslash
   
\backslash
hline  CPU min MHz & 2200.0000 
\backslash

\backslash
  
\backslash
hline   BogoMIPS & 7186.16 
\backslash

\backslash
  
\backslash
hline      
\backslash
end{tabular}   
\backslash
label{tab:processor_specs} 
\backslash
end{table}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Time complexity refers to the number of operations or amount of time taken
 by an algorithm to solve a problem, while Big O notation is a mathematical
 notation used to describe the upper bound of the growth rate of an algorithm
 in terms of its input size.
 Specifically, Big O notation provides a way to express the worst-case time
 complexity of an algorithm in terms of a simple function of the input size,
 while ignoring constant factors and lower-order terms.
 Therefore, time complexity analysis often involves determining the Big
 O notation of an algorithm, which can provide useful insights into its
 efficiency and scalability.
\end_layout

\begin_layout Subsubsection
LMMSE
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The matrix inversion operation requires 
\begin_inset Formula $\boldsymbol{O(n^{3})}$
\end_inset

 operations, where n is the matrix size.
 Therefore, the total number of operations involved in this operation is
 48 x 48 x 2 for the conjugate and Hermitian transpose operations, 48 x
 48 x 48 x 2 for the matrix multiplication operations, 48 x 48 x 3 for the
 identity matrix, scalar multiplication, and matrix addition operations,
 and 
\begin_inset Formula $\boldsymbol{O(n^{3})}$
\end_inset

 for the matrix inversion operation.
 Combining these operations yields a total of 223,872 operations for this
 particular operation.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{table}[H] 
\backslash
centering 
\backslash
caption{Number of Operations by Type} 
\backslash
label{tab:operations} 
\backslash
begin{tabular}{|l|l|} 
\backslash
hline Operation & Number of Operations 
\backslash

\backslash
 
\backslash
hline Conjugate & $48 
\backslash
times 48 
\backslash
times 2$ 
\backslash

\backslash
 
\backslash
hline Hermitian transpose & $48 
\backslash
times 48 
\backslash
times 2$ 
\backslash

\backslash
 
\backslash
hline Matrix multiplication & $48 
\backslash
times 48 
\backslash
times 48 
\backslash
times 2$ 
\backslash

\backslash
 
\backslash
hline Identity matrix & $48 
\backslash
times 48 
\backslash
times 1$ 
\backslash

\backslash
 
\backslash
hline Scalar multiplication & $48 
\backslash
times 48 
\backslash
times 1$ 
\backslash

\backslash
 
\backslash
hline Matrix addition & $48 
\backslash
times 48 
\backslash
times 3$ 
\backslash

\backslash
 
\backslash
hline Matrix inversion (approximate) & 110,592 
\backslash

\backslash
 
\backslash
hline Matrix multiplication & $48 
\backslash
times 48 
\backslash
times 2$ 
\backslash

\backslash
 
\backslash
hline 
\backslash
textbf{Total number of operations} & 
\backslash
textbf{223,872} 
\backslash

\backslash
 
\backslash
hline 
\backslash
end{tabular} 
\backslash
end{table}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard

\size large
The time measurements in the code give an average time of 5.96e-02, which
 is equal to t = 59.6 ms.
 Therefore, the estimated FLOPS is calculated as follows:
\end_layout

\begin_layout Standard

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{FLOPS\simeq\frac{1}{59.6ms}\times223,872=3.74\times10^{6}}
\end{equation}

\end_inset


\end_layout

\begin_layout Subsubsection
Zero Forcing
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Extract diagonal: self.Chann_diag(chann).
 This involves 48 extractions of diagonal elements.
 Element-wise division: Y/self.Chann_diag(chann).
 This involves 48 divisions of complex numbers.
 So the total number of operations in this line of code is approximately
 48*2 = 96.
 The time measurements in the code give an average time of 2.62e-03, which
 is equal to t = 2.62 ms.
 Therefore, the estimated FLOPS is calculated as follows:
\end_layout

\begin_layout Standard

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{FLOPS\simeq\frac{1}{2.62ms}\times96=36\times10^{3}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard

\size large
For the time complexity of this algorithm is conisdered a 
\begin_inset Formula $O(n)$
\end_inset

 complexity, because diagonal is size of N.

\size default
 
\end_layout

\begin_layout Subsubsection
PhaseNet,PolarNet, ComplexNet
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Given the in the methodology seciton the total number of operations in the
 forward pass is approximately 1,761,808.
 To calculate the FLOPS, we need to divide the total number of operations
 by the execution time which give us 1.19e-01.
 Therefore, the approximate FLOPS for this model is:
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{FLOPS\simeq\frac{1,761,808}{.119}=14.8\times10^{6}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
for Polar Net is 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{FLOPS\simeq\frac{1,761,808+5,856}{.392}=4.5\times10^{6}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
and for ComplexNet is
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{FLOPS\simeq\frac{484,248}{.173}=2.7\times10^{6}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The time complexity of a linear layer in a neural network, also known as
 a fully connected layer, is proportional to the number of weights and biases
 in the layer.
 Specifically, the time complexity of a forward pass through a linear layer
 with input size m and output size n is 
\begin_inset Formula $\boldsymbol{O(mn)}$
\end_inset

, which corresponds to the number of multiplications and additions required
 to compute the output of the layer.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
During the forward pass, the input tensor is flattened into a vector and
 multiplied by a weight matrix of size (m x n), resulting in an intermediate
 tensor of size (n x 1).
 The bias vector, which has size (n x 1), is then added to the intermediate
 tensor to produce the output tensor of size (n x 1).
 As our input size and ouput size is the same shape final complexity results
 in 
\begin_inset Formula $\boldsymbol{O(n^{2})}$
\end_inset


\end_layout

\begin_layout Subsubsection
MobileNet
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{FLOPS\simeq\frac{3,236,000}{.834}=3.88\times10^{6}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The original MobileNet model has a time complexity of approximately 
\begin_inset Formula $\boldsymbol{O(n^{2.3})}$
\end_inset

, MobileNetV2 has a time complexity of approximately 
\begin_inset Formula $\boldsymbol{O(n^{2})}$
\end_inset

 and MobileNetV3 has a time complexity of approximately 
\begin_inset Formula $\boldsymbol{O(n\times log(n))}$
\end_inset

.
 It's important to note that the actual runtime performance of MobileNet
 can also be affected by factors such as the hardware platform, software
 optimization, and batch size.
\end_layout

\begin_layout Subsubsection
GridNet
\end_layout

\begin_layout Standard
for GridNet Square is 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{FLOPS\simeq\frac{44.5\times10^{6}}{1.93}=23.05\times10^{6}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
for GridNet Polar is 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{FLOPS\simeq\frac{69.5\times10^{6}}{2.5}=27.8\times10^{6}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The Transformer model, which is widely used in natural language processing,
 has a time complexity of 
\begin_inset Formula $\boldsymbol{O(n^{2})}$
\end_inset

, where n is the length of the input sequence.
 This is due to the self-attention mechanism, which computes a similarity
 score between each pair of tokens in the input sequence, resulting in an
 n x n matrix.
 The computation of this matrix requires 
\begin_inset Formula $\boldsymbol{O(n^{2})}$
\end_inset

 time.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
In addition to the self-attention mechanism, the Transformer also includes
 feedforward layers and normalization layers, but their time complexity
 is typically much lower than that of the self-attention mechanism.
 Therefore, the overall time complexity of the Transformer can be approximated
 as
\begin_inset Formula $\boldsymbol{O(n^{2})}$
\end_inset

.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
However, there are optimizations that can be applied to reduce the time
 complexity of the Transformer, such as restricting the maximum length of
 the input sequence or using approximate attention mechanisms.
 These optimizations can reduce the time complexity to
\begin_inset Formula $\boldsymbol{O(n*log(n))}$
\end_inset

 or even 
\begin_inset Formula $\boldsymbol{O(n)}$
\end_inset

, but at the cost of reduced accuracy or increased memory usage.
\end_layout

\begin_layout Subsubsection
OSIC
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
Loop 1 (cols iterations): 1 division + dim subtractions + dim absolute values
 + dim exponentiations + dim * log(dim) comparisons + 1 assignment + cols
 multiplications + cols subtractions 
\end_layout

\begin_deeper
\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
The operations inside the loop are executed cols times: cols * (1 + dim
 + dim + dim + dim * log(dim) + 1 + cols + cols) 
\end_layout

\end_deeper
\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
Loop 2 (cols iterations): 1 assignment 
\end_layout

\begin_deeper
\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
The operations inside the loop are executed cols times: cols * 1
\end_layout

\end_deeper
\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
Total floating-point operations :
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{OP=cols*(3+4*dim+dim*log(dim)+2*cols)+cols}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
Given cols = 48 and dim = 16 operations are 10,944, and the time taken 
\begin_inset Formula $t=640ms$
\end_inset

 let's calculate the total floating-point operations per seconds (FLOPS):
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\noindent

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{FLOPS\simeq\frac{10\times10^{3}}{640\times10^{-3}}=15\times10^{3}}
\end{equation}

\end_inset


\end_layout

\begin_layout Subsubsection
NearML
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
To estimate the number of Multiply-Accumulate (MAC) operations in this algorithm
, we can analyze the nested loops and matrix operations.
 The algorithm's complexity is mainly determined by the following operations:
\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf

\size large
Detection at level 'nt' loop (range(QRM)): This loop iterates 'QRM' times,
 where QRM is the length of the constellation (conste).
 Inside this loop, there is a nested loop that iterates 'nt - 1' times.
 This nested loop contains vector subtraction and element-wise multiplication,
 which have 'nt' operations each.
\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf

\size large
Estimation of the 'nt-1' levels loop (range(QRM)): This loop iterates 'QRM'
 times.
 Inside this loop, there is another loop that iterates 'nt - 1' times.
 This nested loop contains a loop that iterates 'M' times (M = 4).
 Inside this loop, there are vector subtraction and element-wise multiplication
 with 'nt' operations each.
\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf

\size large
In the last part of the algorithm, there is a loop iterating 'nt' times.
 This loop has a single assignment operation.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Considering the main loops and the operations mentioned, we can estimate
 the number of MAC operations as follows:
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{MAC=QRM*(nt-1)*nt\left(1+M\right)+nt}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Given 
\begin_inset Formula $\boldsymbol{nt=48}$
\end_inset

 , 
\begin_inset Formula $\boldsymbol{QRM=16}$
\end_inset

, 
\begin_inset Formula $\boldsymbol{M=4}$
\end_inset

 ,the total MAC operations amount to 103,664.
 Since each MAC consists of two operations, and the execution time is measured
 at 7.35 seconds.
 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset Formula 
\begin{equation}
\boldsymbol{FLOPS\simeq\frac{180.528\times10^{3}}{7.35}*2\simeq49.110\times10^{3}}
\end{equation}

\end_inset


\end_layout

\begin_layout Subsubsection
Performance Analysis: FLOPs and Time Complexity Benchmark
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
This FLOPS value works like an estimate and should not be taken as definitive.
 One of the main advantages of deep learning techniques is that they are
 easy to parallelize, and FLOPS can be significantly reduceded.
 Big O notation is a mathematical notation used to describe the upper bound
 of the growth rate of a function or algorithm in terms of its input size.
 
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{table}[H] 
\backslash
centering 
\backslash
caption{FLOPS and Time Complexity} 
\backslash
label{tab:operations} 
\backslash
begin{tabular}{|l|l|l|} 
\end_layout

\begin_layout Plain Layout


\backslash
hline Name & FLOPS & Big O Complexity
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

OSIC & $ 15 
\backslash
times 10^3 $ & $O(N 
\backslash
times |
\backslash
mathbb{A}|) $  
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

NearML & $ 49.110
\backslash
times10^{3} $ & $O(|
\backslash
mathbb{A}|^2 
\backslash
times N 
\backslash
times M) $  
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

Zero Forcing & $36
\backslash
times10^{3}$ & $O(n)$ 
\backslash

\backslash
 
\backslash
hline 
\end_layout

\begin_layout Plain Layout

ComplexNet & $2.7
\backslash
times10^{6}$ & $O(n^2)$  
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

LMMSE & $3.74
\backslash
times10^{6}$ &  $O(n^3)$ 
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

MobileNet & $3.88
\backslash
times10^{6}$ &  $O(n*log(n))$
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

PolarNet & $4.5
\backslash
times10^{6}$ &  $O(n^2)$
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

PhaseNet & $14.8
\backslash
times10^{6}$ & $O(n^2)$
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

GridNet Square & $23.05
\backslash
times10^{6}$ & $O(n*log(n))$ 
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

GrideNet Polar & $27.8
\backslash
times10^{6}$ & $O(n*log(n))$ 
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout


\backslash
end{tabular} 
\backslash
end{table}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsection
BER and BLER
\end_layout

\begin_layout Subsubsection
PhaseNet
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The angle error adjustment implemented in the PhaseNet methodology has been
 found to be very useful for signal equalization.
 The network performs well across a range of signal-to-noise ratios, from
 5dB to 35dB.
 
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
However, the graph shows a fall in performance at an SNR of 35dB compared
 to 45dB.
 This is because the model was trained using data with an SNR of 35dB, as
 indicated in the hyperparameters table of PhaseNet.
 When the model encounters new data with less noise, it does not equalize
 the signal as well as it was trained to do.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Therefore, it is important to carefully balance the SNR of the training
 data to ensure that the model can perform well across a wide range of noise
 conditions.
 This will help to improve the generalization ability of the model and ensure
 that it can handle various noise conditions.
 By doing so, the model can provide more reliable and accurate signal equalizati
on in practical applications.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/PhaseNET/QPSK_vs_LMMSE_PhasNet.png
	lyxscale 70
	scale 80

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
QPSK BER : PhaseNet vs.
 LMMSE
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
On the other hand, the block error rate performs very well and reduces the
 highest noise scenario to an order of magnitude.
 This helps to show that erroneous bits are specific outlier groups in certain
 blocks, and in general, the equalizer guarantees good frame recovery.
 Next, we can observe the same effect explained in the last paragraph about
 the 35dB fall.
 However, there is another fall in the BLER at 20dB SNR values.
 One possible reason for this is that the noise is canceling some factor
 of the channel, causing these points to be closer together and causing
 the network to find some points as the best ones.
 But this is not possible in noisier scenarios because the noise has much
 power.
 For 20dB, the signal is 100 times stronger than the noise, and an increase
 of 10dB represents a tenfold increase in noise power, which essentially
 means that information is lost and not feasible to recover.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/BLER/Results_PhaseNet-10_3_2023-23_39.png
	lyxscale 80
	scale 80

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Caption Standard

\begin_layout Plain Layout
QPSK BLER : PhaseNet vs.
 LMMSE
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
As seen in the graph below, non-linear models do not reach the same level
 of performance as PhaseNet.
 One positive aspect of the network is that the number of symbols for bigger
 PSK does not affect the time complexity.
 Only the number of symbols in the frame matters.
 Given that, the OSIC and NML equalizers will take much longer time execution
 for the 16 symbols case.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/PhaseNET/BER_Non_linear_Golden vs PhaseNet_-17_3_2023-12_36.png
	lyxscale 80
	scale 80

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Caption Standard

\begin_layout Plain Layout
QPSK BER: PhaseNet vs.
 OSIC and NML
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
This network works well for block integrity, but in low noise scenarios,
 OSIC performs better.
 This may be because OSIC focuses on canceling interference.
 Therefore, this probably means that PhaseNet is not quite as effective
 for ICI, but it is good for removing noise.
 The results we are seeing are likely due to more noise cancellation than
 interference cancellation because this network does not follow an iterative
 nature.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/PhaseNET/BLER_Non_linear_Golden vs PhaseNet_-17_3_2023-12_36.png
	lyxscale 80
	scale 80

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
QPSK BLER: PhaseNet vs.
 OSIC and NML
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
PolarNet
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
This network combines a 16-PSK PhaseNet equalization with an additional
 MagNet equalization.
 In this model, we assume that phase and magnitude are completely separate
 from each other.
 One of the main reasons is to maintain a more modular architecture, which
 means that in a future implementation, it can be equalized a 16-PSK or
 16-QAM with almost the same processing stages.
 Another key feature is that each network is specialized, reducing the error
 to only its specific task.
 Therefore, in theory, this will make the error not influence each other.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Observing the graph below, it can be seen that the model flattens at a BER
 of 
\begin_inset Formula $10^{-3}$
\end_inset

 from 30dB to 45dB.
 The main reason errors get stuck in neural networks is that they are generalize
rs, which means that they learn to make predictions based on patterns in
 the training data.
 Therefore, all points seen forward should be treated with the expected
 behavior.
 In the case of training both networks and given MSE error applied to both
 in the training stages, the least error was from 
\begin_inset Formula $10^{-4}$
\end_inset

, which is pretty good enough of a nueronal networks using MSE.
 However, when we mixed both networks, the error increases to 
\begin_inset Formula $10^{-3}$
\end_inset

, resulting in an almost linear relation with BER.
 Finnally we can se the same valley pattern in 20-25dB, as a result of the
 PhaseNet integration in the Polarnet.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/PolarNet/Linear/Polar_16QAM.png
	lyxscale 70
	scale 80

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
16-QAM BER: PolarNet vs.
 LMMSE 
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
For the BLER graph, we can visualize a smoother performance with lower values
 between 35dB and 15dB, and it almost saturates at the same point as the
 LMMSE.
 It can be seen that the same model error truncation applies to this metric,
 but it is not so far away from the golden model in the lowest noise scenarios.
 In general, this means that most of the BLER is given by outlier values,
 and the system can equalize consistently between a certain quantity of
 blocks.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/PolarNet/Linear/Results_PolarNet-10_3_2023-23_36.png
	lyxscale 80
	scale 80

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
16-QAM BLER: PolarNet vs.
 LMMSE
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The non-linear equalizers perform better than the network only up to 30dB.
 At higher SNRs, the model does not perform well because it truncates its
 error and does not perform better for non-noisy scenarios.
 The model error is based on the training error itself, and it is important
 to keep in mind that neural networks try to find a general solution with
 fixed weight matrices.
 Trying to achieve a lower BER may cause the neural network to overfit and
 only learn non-noisy data.
 Therefore, to maintain a balance between good denoising and overfitting,
 sacrificing the performance beyond 30dB is necessary.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/PolarNet/NonLinear/BER_Non_linear_Golden vs PolarNet_-17_3_2023-11_44.png
	lyxscale 80
	scale 80

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
16-QAM BER: PolarNet vs.
 OSIC and NML
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Despite the model being truncated for a BLER of 35dB, the compromise is
 reasonable since the model outperforms the non-linear equalizers within
 a range of 15dB to 35dB.
 This suggests that most of the errors reported in the BER section are outliers.
 By centering the input values around the mean, neural networks can learn
 patterns in the data more effectively without being overly influenced by
 extreme values.
 Therefore, values closer to the mean can provide a balanced representation
 of the data and be well-suited for neural networks, in this case it can
 be seen in BLER plot.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/PolarNet/NonLinear/BLER_Non_linear_Golden vs PolarNet_-17_3_2023-11_44.png
	lyxscale 80
	scale 80

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Caption Standard

\begin_layout Plain Layout
16-QAM BLER: PolarNet vs.
 OSIC and NML
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
ComplexNet
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
In complex net we try two different loss functions to traing the neuronal
 network.
 However, logarithmic polar loss was not as effective because it produced
 high loss numbers that were larger than 1, which may not be very meaningful
 for the network.
 As a result, the network had difficulties updating its weights and optimizing
 its performance using this loss function.
 On the other hand, the complex MSE loss was much more effective because
 its output values were lower than those of the initial loss functions.
 This made it easier for the networks to determine which parameters were
 good or not.
 By using an effective loss function, the network can optimize its performance
 and achieve higher accuracy in its predictions.
 This is particularly important in communication systems where accuracy
 and reliability are critical for successful operation.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/ComplexNet/ComplexNet.png
	lyxscale 70
	scale 80

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
16-QAM BER: ComplexNet with Two Losses vs.
 LMMSE
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
In the BLER results, we avoided plotting the ComplexNet Polar Loss training
 because it performed poorly with a BLER of 1 across all blocks.
 On the other hand, Abs loss networks attempted to approximate the golden
 standard, but were not quite good enough.
 One of the main reasons for this is that the proposed methods in the state-of-t
he-art literature and the ones implemented in our research are not mature
 enough to help with the equalization task.
 As seen in 
\begin_inset CommandInset citation
LatexCommand cite
key "A_Survey_of_Complex_valued_nueronal_Netoworks"
literal "false"

\end_inset

, there are some assumptions about the activation functions in the complex
 plane.
 Additionally, we used automatic differentiation provided by the pytorch
 framework, which may have struggled with complex conjugation.
 Implementing a solution from complex differentiation can be challenging
 and may require a separate research project for someone with strong mathematica
l skills.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/BLER/Results_ComplexNet-10_3_2023-23_43.png
	lyxscale 80
	scale 80

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
16-QAM BLER: ComplexNet with Two Losses vs.
 LMMSE
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
ComplexNet performs marginally better than NML in situations with higher
 noise levels and is nearly identical to OSIC for values below 15dB.
 Intriguingly, the model's loss closely mirrors that of OSIC, indicating
 that the neural networks are attempting to generalize a solution similar
 to OSIC.
 The primary advantage of these neural networks is their greater parallelizabili
ty.
 Concerning time complexity, the network's growth is only dependent on the
 N scale and not the alphabet of symbols.
 Therefore, for larger QAM systems, this network may be a more suitable
 solution.
 It is recommended to conduct further testing with higher QAM constellations.
 However, higher QAM constelations is outside this research scope.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/ComplexNet/BER_Non_linear_Golden vs ComplexNet_-17_3_2023-12_31.png
	lyxscale 80
	scale 80

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Caption Standard

\begin_layout Plain Layout
16-QAM BER: ComplexNet vs.
 OSIC and NML
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
In the block error rate, nearly all errors are independent of the frame
 or the manner in which data is received.
 The model does not take into account whether the data is close to the mean
 or an outlier, as it faces difficulties in generalizing effectively.
 Consequently, the presence or absence of outliers in the data has little
 impact on the model's inherent error.
 This could be attributed to the error function, and as previously mentioned,
 the research on complex values for neural networks is still in its early
 stages.
 Therefore, it is reasonable to expect that the current state-of-the-art
 implementation may not be well-suited for this specific problem.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/ComplexNet/BLER_Non_linear_Golden vs ComplexNet_-17_3_2023-12_35.png
	lyxscale 80
	scale 80

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
16-QAM BLER: ComplexNet vs.
 OSIC and NML
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
MobileNet
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Although MobileNet was not very effective, it is still considered one of
 the fastest convolutional neural networks in the state of the art in terms
 of processing speed.
 From SNR23 and below, it could be a viable option instead of zero forcing.
 In fact, it performs better than zero forcing in the range of 15dB to 25dB,
 which is encouraging because it supports the hypothesis that it is essentially
 a zero forcing with noise consideration.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/MobileNEt/MobileNet_16QAM.png
	lyxscale 70
	scale 80

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
16-QAM BER: MobileNet vs.
 ZeroForcing
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Since the MobileNet has knowledge of the noise and works as a denoiser,
 its block rate is lower than the golden model until it is permitted.
 Consequently, we naturally obtain an error model that ranges from 35dB
 to high SNR, while this one is performing better than the zero-forcing
 method at lower SNR than 30dB.
 It is important to note, however, that the MobileNet has a higher computational
 complexity, and there is a trade-off between computational speed and accuracy.
 Nevertheless, MobileNet is one of the fastest and most lightweight convolutiona
l neural networks in the state of the art.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/BLER/Results_MobileNet-10_3_2023-23_45.png
	lyxscale 80
	scale 80

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
16-QAM BLER: MobileNet vs.
 ZeroForcing
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
It appears that MobileNet performs best at 22dB and lower SNR values.
 One notable success of this network is that its output is simply a one-hot
 encoded vector representing the channel.
 By dividing this vector with the received signal, a more intelligent zero-forci
ng approach is achieved.
 Furthermore, MobileNet is among the most time-efficient networks in terms
 of complexity.
 These two factors make it a suitable solution for scenarios with higher
 noise levels.
 Additionally, compared to non-linear methods, this network requires only
 a single feedforward evaluation rather than iterative processing, as seen
 in non-linear models.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/MobileNEt/Non-lineal/BER/Results_Zero_Non_linear_Golden vs MobileNet_-17_3_2023-11_53.png
	lyxscale 80
	scale 80

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
16-QAM BER: MobileNet vs.
 Zero forcing, OSIC and NML
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The block error rate is quite good for values lower than 30dB, which can
 be attributed to the intelligent zero-forcing approach that effectively
 cancels the Intersymbol Interference (ISI), resulting in an improved BLER.
 This helps to ensure data integrity is maintained as much as possible.
 One potential future strategy could involve using this network as a preprocessi
ng step to feed data into other advanced networks, further enhancing their
 performance.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/MobileNEt/Non-lineal/BLER/Results_Zero_Non_linear_Golden vs MobileNet_-17_3_2023-11_54.png
	lyxscale 80
	scale 80

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
16-QAM BLER: MobileNet vs.
 Zero forcing, OSIC and NML
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
GridNet Square
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
We conducted experiments with different grid steps for GridNet Square and
 found that the best step size was 1/7.
 In conclusion, having more batches in the complex planes results in higher
 resolution but lower tolerance to noise, as the networks can quickly overfit.
 On the other hand, using larger steps means that points affected by noise
 fall within the same region or closer to each other, which could be advantageou
s in noisy scenarios.
 However, having squares that are too large could be harmful for final equalizat
ion because the grids can be bigger than the distances between the ideal
 constellation points.
 Model learns without error truncation as other models, but is 1dB upper
 the ideal Golden Model, only in 5dB is slightly better than LMMSE.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/GridNet/Results_GridNetSquare-13_3_2023-11_47.png
	lyxscale 80
	scale 80

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
16-QAM BER: GridNet Square Grid vs LMMSE
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The Blocks metrics are not performing as expected for high SNR.
 Surprisingly, the performance is better than the golden model just from
 25dB to 27dB.
 One of the main reasons why it may not be working well as expected is that
 all points in the grid have the same relevance to each other and are equally
 weighted, which introduces uncertainty about positions.
 This issue may not occur on the polarGrid because the points are closer
 together near the center are weighter different from the border ones, which
 reduces uncertainty, and give certain perspective of position.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/BLER/Results_GridNetSquare-11_3_2023-0_24.png
	lyxscale 80
	scale 80

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
16-QAM BLER: GridNet Square Grid vs.
 LMMSE
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The GridNet can be considered as an intermediate solution between the linear
 and non-linear methods.
 This is because GridNet Square can be seen as a linear quantizer of the
 constellation points.
 This means that all IQ points are discretized, which is equivalent to a
 loss of resolution in a lower bit scenario.
 However, for GridNet, a higher number of patches, which means a thinner
 grid, makes it a more vulnerable solution to noise.
 This is because the model needs to model more possible bucket points into
 a single ideal bucket, which can lead to a loss of accuracy.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/GridNet/Square/BER_Non_linear_Golden vs GridNetSquare_-17_3_2023-11_46.png
	lyxscale 80
	scale 80

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
16-QAM BER: GridNet Square Grid MobileNet vs.OSIC and NML
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The non-linear methods outperform GridNet Square in terms of BLER overall.
 There is a special case between 25dB and 30dB where the system almost reaches
 the same performance, as it was trained with the lowest SNR values in this
 range.
 However, having more noise does not necessarily mean that the entire frame
 can be recovered.
 In the case of BER, the noise is reduced due to the degridding process,
 which converts the grid patch to a complex point in the constellation and
 places the calculated value in a fixed position depending on the grid.
 This results in a slightly lower BER because the reduced and discrete possible
 values, but it does not guarantee that the blocks will be completely error-free.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/GridNet/Square/BLER_Non_linear_Golden vs GridNetSquare_-17_3_2023-11_46.png
	lyxscale 80
	scale 80

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
16-QAM BLER: GridNet Square Grid MobileNet vs.OSIC and NML
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
GridNet Polar
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
GridNet with a polar grid resulted in some of the best performance between
 25 dB and 45 dB.
 Our hypothesis that the attention mechanisms used are highly effective
 in reducing inter-symbol interference (ISI) can be substantiated by these
 results, because at low SNR, the only thing that affects the signal is
 the ISI.
 However, below 25 dB, the model cannot handle the noise as effectively
 and begins to produce errors, and it almost behaves like LMMSE.
 We trained the model with variable noise levels ranging from 25 dB to 45
 dB, and the hypothesis that the best equalization occurs within this range
 is supported by the image below.
 It may seem that reducing the noise training range could result in better
 performance within the training range, but this idea is incorrect.
 Training the network with more noise scenarios would cause the network
 to learn more about the noise than the relevant data, resulting in a noisy
 overfit.
 Finally, we can say that, for instance, in the noisiest scenario with 5
 dB, this network has the best BER relation, but this doesn't mean that
 the error in the block will be the best.
 Most of the noise reduction is due to the effect of polar quantization.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/GridNet/Polar/BER/Results_LMMSE vs GridNetPolar_-22_3_2023-10_35.png
	lyxscale 80
	scale 80

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
16-QAM BER: GridNet Polar Grid vs LMMSE
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Since Polar Net iterates over more blocks than LMMSE, it is not entirely
 fair to compare the two methods directly.
 However, Polar Net is one of the methods with the lowest BLER for high
 SNR values between 33 dB and 45 dB.
 This is because the attention mechanisms used in the autoregression of
 the transformer model are effective in capturing the relationship between
 the first and last values, thereby reducing ISI.
 Unfortunately, at lower SNR values, the noise begins to affect the network,
 and the BLER increases exponentially.
 This suggests that the attention mechanisms are not effective in maintaining
 consistency between blocks under high noise conditions.
 Nevertheless, the degrading step and constellation point quantization help
 to reduce the possible values of the IQ data.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/GridNet/Polar/BLER/Results_LMMSE vs GridNetPolar_-22_3_2023-10_41.png
	lyxscale 80
	scale 80

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
16-QAM BLER: GridNet Polar Grid vs LMMSE
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
GridNetPolar is a visual transformer that uses attention mechanisms to cancel
 out the effects of interference in a signal, while OSIC is an iterative
 algorithm that relies on a feedback loop to refine the estimate of the
 interference.
 This is a good comparison because we have two non-linear models designed
 for the same task with different approaches.
 By comparing these two strategies and looking at BER reduction, we can
 see potential for a new branch of inter-symbol interference cancellation
 based on attention mechanisms instead of the traditional iterative approach.
 In terms of the comparison between non-linear models, it can be observed
 that OSIC yields slightly better results in the SNR range between 15 dB
 and 25 dB, while GridNet performs better for all values outside this range.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/GridNet/Polar/BER/Results_GrinNetPolar vs OSIC and NML_-22_3_2023-12_49.png
	lyxscale 80
	scale 80

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
16-QAM BER: GridNet Polar Grid MobileNet vs.OSIC and NML
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Attention mechanisms work by assigning different weights to the input data,
 which allows the model to focus on the most relevant information for a
 given task.
 However, when the input data is noisy, it can be difficult for the model
 to distinguish between the signal and the noise.
 This can lead to the attention mechanism failing to assign the correct
 weights and focusing on irrelevant features, which can cause the BLER to
 increase.
 Therefore, while attention mechanisms can be effective for reducing ISI
 in certain situations and have shown the lowest BLER of all our experiments
 at low SNR values, they may not be the best approach for dealing with noisy
 data.
 Alternative techniques such as OSIC or NearML may be more suitable.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/GridNet/Polar/BLER/Results_GrinNetPolar vs OSIC and NML_-22_3_2023-12_50.png
	lyxscale 80
	scale 80

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
16-QAM BLER: GridNet Polar Grid MobileNet vs.OSIC and NML
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
GridNet Both
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Due to its complexity, GridNetSquare does not perform as well as the golden
 model, whereas PolarNet outperforms the golden model and shows significant
 improvement for high SNR values greater than 25, with at least an order
 of magnitude improvement in the BER metric.
 Furthermore, GridNetPolar potentially has fewer parameters because the
 number of patches reduces the alphabet size used in the transformer, resulting
 in a smaller data model.
 Although there is at least one order of magnitude difference between PolarNet
 and GridNetSquare in terms of BER, SquareGrid is more consistent in the
 BER/SNR slope, while PolarNet exhibits rapid growth in BER over a short
 range of SNR values.
 This could be undesired, especially if the communication oscillates between
 these SNR values in certain communication scenarios.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/GridNet/BOTH/BER/GridNetBoth.png
	lyxscale 80
	scale 80

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
16-QAM BER: GridNet, Polar and Square Grid vs LMMSE
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
In the figure below, it can be appreciated that SquareGrid behaves more
 similarly to NML for lower SNR values, while GridNetPolar works similarly
 to OSIC, with an improvement for SNR values lower than 15 dB.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/GridNet/BOTH/BER/GridNetBoth_5_25.png
	lyxscale 80
	scale 80

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
16-QAM BER: GridNet, Polar and Square Grid vs LMMSE from 5dB to 27dB
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
In terms of Block Error Rate, SquareGrid has a slower increase than PolarNet
 between 27 dB to 20 dB, as seen in the BER metric.
 Both methods perform well for SNR values higher than 25 dB.
 However, for lower noise, other non-linear methods are preferred, and these
 methods also have a lower number of FLOPS.
 The main disadvantage of iterative methods is that they are not as easily
 parallelizable compared to transformers, which can be parallelized in a
 more natural manner.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/GridNet/BOTH/BLER/GridNetBoth.png
	lyxscale 80
	scale 80

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Caption Standard

\begin_layout Plain Layout
16-QAM BLER: GridNet, Polar and Square Grid vs LMMSE
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
Square grid works better with noise handling than the Polar grid.
 Basically both grids are a finnaly trade off between consisten noise reduction
 or ISI cancelation.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/GridNet/BOTH/BLER/GridNetBoth_5_25.png
	lyxscale 80
	scale 80

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
16-QAM BLER: GridNet, Polar and Square Grid vs LMMSE from 5dB to 30dB
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Outlook of results
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The results presented here are based on the visual and experimental representati
on of the Block Error Rate (BER) and Bit Error Rate (BLER) with different
 Signal-to-Noise Ratio (SNR) scenarios.
 The results provide valuable insights into the strengths and weaknesses
 of each equalization method and can inform the development of more effective
 equalization techniques for equalization task.
\end_layout

\begin_layout Itemize

\size large
PolarNet appears to perform well overall in the presence of noise, with
 one of the best performances in the range between 15 dB to 25 dB for reducing
 bit errors.
 Additionally, it exhibits a smooth increase in BER, making its behavior
 well predictable, also has is an intermidiate term of complexity.
 
\end_layout

\begin_layout Itemize

\size large
MobileNet performs well for values lower than 25 dB, with lower BER than
 all golden models and some networks such as GridNet Square.
 Additionally, it strikes a good balance between the number of parameters
 and time complexity, making it a good candidate for embedded applications.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
Complex is slightly better than NML and GridNetSquare for SNR values lower
 than 18 dB.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
GridNet Polar has the lower BER values from 27dB to 45dB
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/All/BER/Results_All equalization methods_-22_3_2023-11_15.png
	lyxscale 80
	scale 80

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Caption Standard

\begin_layout Plain Layout
16-QAM BER: All methods
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
GridNet Square behaves similar to NML
\end_layout

\begin_layout Itemize

\size large
MobileNet, PolarNet and ComplexNet converge to the NML model for the most
 noiser scnearios, from 5dB to 15dB
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/All/BER/Results_All equalization methods_5_35.png
	lyxscale 80
	scale 80

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
16-QAM BER: All methods from 5dB to 27dB
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
GridNetPolar performs well at high SNR, it degrades faster from 35dB to
 lower values, resulting in the worst BLER below 25dB.
 This means that while PolarGrid reduces bit errors, it consistently fails
 over the blocks.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
PolarNet outperforms all methods for SNR values lower than 30 dB, while
 also exhibiting the same growth relation with its BER metric.
 This mean a good outlier and noise handling for this Network.
 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
MobileNet shows promising results as an upgrade to the standard zero-forcing
 equalizer, handling both network denoising and channel compression with
 a single vector.
 This can be observed as it displays the second-best BLER plot among all
 the models.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
MobileNet exhibits a very close BER performance to PolarNet.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/All/BLER/Results_All equalization methods_-22_3_2023-11_19.png
	lyxscale 80
	scale 80

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Caption Standard

\begin_layout Plain Layout
16-QAM BLER: All methods from 5dB to 45dB
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
GridNet is the first netowork to reach the block error rate of 1.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
After not well performacne of complexNet has better BLER than GridNet from
 22dB to lower.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Imagenes/Results/All/BLER/Results_All equalization methods_14_30.png
	lyxscale 80
	scale 80

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
16-QAM BLER: All methods from 14dB to 30dB
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Section
Conclusion
\end_layout

\begin_layout Subsection
Contributions
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
Compared to the state of art that use neural networks for signal equalization,
 we employed larger frame sizes and higher constellation points, such as
 16QAM.
 Typically, smaller frame sizes and lower constellation points, such as
 QPSK, are used:
\end_layout

\begin_deeper
\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
Larger frame sizes of 48
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
A channel of 48x48
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
Support up to 16QAM.
\end_layout

\end_deeper
\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
In order to help the neural network generalize better during the training
 stage, the z-score was utilized to reduce outliers.
 This approach was particularly necessary for the equalization task, as
 it prevented the neural network from having to adapt to all possible solutions
 and improved its ability to generalize effectively.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
PhaseNet
\series default
:
\end_layout

\begin_deeper
\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
Designed for PSK systems equalization.
 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
Generated the idea to use a unitary circle to exploit the concept of using
 distance as a metric of the phase, setting a constant radius of one but
 measuring the error distance based on how well the angle is estimated by
 the network.
 This avoids wrong angle measurements, which would result in an incorrect
 error being passed to the network.
 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
Network learns faster and generalizes better for phase prediction with the
 distance error metric.
\end_layout

\end_deeper
\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
PolarNet
\series default
: 
\end_layout

\begin_deeper
\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
A combination of PhaseNet and MagNet, which is an equalizer that separately
 deals with phase and magnitude error reduction and estimates them as separate
 values in a phasor manner.
 The idea behind this network is to make it more modular, as a system can
 work with either PSK equalization or QAM, depending on the requirement
 of the system.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
Combination of different preprocesing stages on for magnitud and another
 for phase.
 
\end_layout

\end_deeper
\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
ComplexNet
\series default
:
\end_layout

\begin_deeper
\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
First Implementation of complex of a feedforward neural network for OFDM
 equalization.
 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
Although it did not produce the best results for equalization, it opens
 new avenues for possible implementation and mathematical study to upgrade
 gradients and network evaluation, to make a better estimate of the ground
 truth.
\end_layout

\end_deeper
\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
MobileNet
\series default
:
\end_layout

\begin_deeper
\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
A network typically used for classification modified for our research, it
 was utilized for a regression task to simulate zero-forcing with known
 noise.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
Modification of the first and final layer to ensure the network fits with
 the data dimensionality.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
Using one of the most efficient convolutional neural networks for an equalizatio
n task, striking a balance between accuracy and time complexity
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
The network significantly reduced the BER and BLER with just one single
 vector of size 48 performing zero-forcing.
\end_layout

\end_deeper
\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
Identified a gap
\series default
 in the existing literature regarding the use of transformers in the signal
 processing scenario.
\end_layout

\begin_deeper
\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
Taking inspiration from image-to-image translation models, we implemented
 a square grid that divides the IQ plane into buckets.
 These buckets are a quantization of all infinite possible values in the
 plane into a reduced alphabet.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
Translated the uncorrected image given by the data, which had channel deformatio
n and noise, and recovered the image with the desired buckets based on the
 ground truth.
\end_layout

\end_deeper
\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
PolarGrid
\series default
 preprocessing stage in GridNet:
\end_layout

\begin_deeper
\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
Although existing square grids are commonly used for image processing in
 image transformers, the use of PolarGrid was unexplored before this research.
 Which is quite useful in this case, as our image represents the complex
 plane that can be analyzed in polar geometry.
\end_layout

\end_deeper
\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\series bold
\size large
GridNet
\series default
:
\end_layout

\begin_deeper
\begin_layout Itemize
\paragraph_spacing onehalf
\noindent

\size large
The first transformer applied to signal equalization in the modulation scheme
 for OFDM.
\end_layout

\end_deeper
\begin_layout Subsection
Outlook
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
In this work, new networks for equalizing variant channels were presented.
 The proposed networks met the objectives by presenting the following advantages
:
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\size large
MobileNet and PolarGrid enable adequate mitigation of impairments caused
 by ISI and doppler effects.
 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\size large
PhaseNet, PolarNet, and ComplexNet allow for adequate noise reduction.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\size large
The networks time complexity can be parallelized without implementing complex
 architectures.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\size large
Except for ComplexNet, the networks outperform the non-linear classical
 methods OSCI and NML for lower SNR values.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\size large
PolarGridNet is proof that transformers can be used in the telecom industry
 with adequate preprocessing.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
The following observations were made regarding the work presented in this
 study:
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\size large
Neural networks work better with closely spaced data points, hence a pre-process
ing stage plays a fundamental role.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\size large
Attention mechanisms assign weights to input data, enabling the model to
 focus on relevant information and reduce inter-symbol interference (ISI).
 However, in the presence of noise, this can cause attention mechanisms
 to fail in assigning correct weights, leading to a focus on irrelevant
 features and increased block error rate (BLER).
 
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\size large
Variable SNR values work better for GridNet training, while constant SNR
 works better for the other models.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\size large
Training with low SNR values can result in the network learning noise patterns
 instead of accurately representing the signal.
 
\end_layout

\begin_deeper
\begin_layout Itemize
\paragraph_spacing onehalf

\size large
Our experiments showed that a minimum SNR value of 20dB is required for
 training.
\end_layout

\end_deeper
\begin_layout Itemize
\paragraph_spacing onehalf

\size large
All networks should be implemented in Python due to the GPU and TPU APIs
 support, which accelerates the training process.
\end_layout

\begin_layout Itemize
\paragraph_spacing onehalf

\size large
The use of a larger dataset is recommended to increase the robustness of
 the network testing.
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
In conclusion, the field of neural networks has seen tremendous advancements
 in recent years, with the development of more complex architectures, such
 as deep neural networks, convolutional neural networks, and transformers.
 It is essential to strike a balance between accuracy and memory footprint
 for signal equalization to avoid affecting data throughput.
 These advancements have led to significant improvements in the ability
 of neural networks to process complex data, including doubly dispersive
 channels.
 These developments have resulted in numerous practical applications, ranging
 from self-driving cars and drone flying to the development of new 6G technologi
es.
 However, despite the remarkable progress made in the field, there are still
 many challenges that need to be addressed, such as reducing noise overfitting,
 managing outliers, MIMO signal cleaning, and the need for more formal mathemati
cal descriptions of some network architectures.
 Further research is necessary to continue to advance the field and unlock
 the full potential of neural networks in the telecom area, which is an
 area that is just starting to show its potential.
\end_layout

\begin_layout Subsection
Future Work
\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent

\size large
Model quantization is a technique for reducing the memory footprint and
 computational cost of deep neural networks by converting the weights and
 activations of the network to a lower numerical precision format.
 While it can significantly reduce the memory and power requirements of
 neural networks, it can also lead to a loss of accuracy.
 Adjustments to the network architecture and training process are needed
 to ensure that the quantized network still achieves good performance.
 Google's Coral platform is an example of a system that uses model quantization
 for efficient inference, including a set of tools for quantizing and compressin
g neural network models to run on the Coral Edge TPU.
 Coral's quantization tools include both post-training and quantization-aware
 training methods, and are compatible with popular deep learning frameworks
 such as TensorFlow and PyTorch.
 
\begin_inset CommandInset citation
LatexCommand cite
key "coral2020accelerator"
literal "false"

\end_inset


\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent

\size large
One potential future work is to use the latest reinforcement learning algorithms
 to discover a matrix inversion algorithm.
 AlphaTensor is a well-known network that discovers many provably correct
 matrix multiplication algorithms that improve over existing algorithms
 in terms of the number of scalar multiplications, and is adaptable to different
 use-cases, including discovering algorithms for structured matrix multiplicatio
n and optimizing for actual runtime.
 The results demonstrate that the space of matrix multiplication algorithms
 is richer than previously thought, and AlphaTensor can efficiently search
 this space to discover novel algorithms that outperform human-designed
 ones on the same hardware.
 Therefore, a possible future direction could be to create an algorithm
 that outperforms existing ones and achieves a time complexity of almost
 
\begin_inset Formula $O(N^{2})$
\end_inset

 for matrix inversion.
\begin_inset CommandInset citation
LatexCommand cite
key "alphatensor"
literal "false"

\end_inset


\end_layout

\begin_layout Enumerate
\paragraph_spacing onehalf
\noindent

\size large
Equalization in MIMO scenarios could be a potential candidate, as it involves
 classification tasks that are typically more effective with neural networks.
\begin_inset CommandInset citation
LatexCommand cite
key "DeepMimoOFDM"
literal "false"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newpage
\end_layout

\end_inset


\end_layout

\begin_layout Section
References
\end_layout

\begin_layout Standard
\paragraph_spacing onehalf

\size large
\begin_inset CommandInset bibtex
LatexCommand bibtex
btprint "btPrintCited"
bibfiles "Bibliography"
options "plain"

\end_inset


\end_layout

\begin_layout Standard

\end_layout

\begin_layout Standard

\end_layout

\begin_layout Standard

\end_layout

\begin_layout Standard

\end_layout

\end_body
\end_document
