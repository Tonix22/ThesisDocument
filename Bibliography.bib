@ARTICLE{8054694,  author={OShea, Timothy and Hoydis, Jakob},  journal={IEEE Transactions on Cognitive Communications and Networking},   title={An Introduction to Deep Learning for the Physical Layer},   year={2017},  volume={3},  number={4},  pages={563-575},  doi={10.1109/TCCN.2017.2758370}}

@article{Hornik1989MultilayerFN,
  title={Multilayer feedforward networks are universal approximators},
  author={Kurt Hornik and Maxwell B. Stinchcombe and Halbert L. White},
  journal={Neural Networks},
  year={1989},
  volume={2},
  pages={359-366}
}
@article{The_Roadmap_to_6G,  
author={Letaief, Khaled B. and Chen, Wei and Shi, Yuanming and Zhang, Jun and Zhang, Ying-Jun Angela},  
journal={IEEE Communications Magazine},   
title={The Roadmap to 6G: AI Empowered Wireless Networks},   
year={2019},  
volume={57},  
number={8},  
pages={84-90},  
doi={10.1109/MCOM.2019.1900271}
}

@article{Surpassing_Human_Level_Performance,
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={2015 IEEE International Conference on Computer Vision (ICCV)}, 
  title={Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification}, 
  year={2015},
  volume={},
  number={},
  pages={1026-1034},
  doi={10.1109/ICCV.2015.123}
}




@article{HORNIK1989359,
title = {Multilayer feedforward networks are universal approximators},
journal = {Neural Networks},
volume = {2},
number = {5},
pages = {359-366},
year = {1989},
issn = {0893-6080},
doi = {https://doi.org/10.1016/0893-6080(89)90020-8},
url = {https://www.sciencedirect.com/science/article/pii/0893608089900208},
author = {Kurt Hornik and Maxwell Stinchcombe and Halbert White},
keywords = {Feedforward networks, Universal approximation, Mapping networks, Network representation capability, Stone-Weierstrass Theorem, Squashing functions, Sigma-Pi networks, Back-propagation networks},
abstract = {This paper rigorously establishes that standard multilayer feedforward networks with as few as one hidden layer using arbitrary squashing functions are capable of approximating any Borel measurable function from one finite dimensional space to another to any desired degree of accuracy, provided sufficiently many hidden units are available. In this sense, multilayer feedforward networks are a class of universal approximators.}
}

@INPROCEEDINGS{7997434,  author={Jeon, Yo-Seb and Hong, Song-Nam and Lee, Namyoon},  booktitle={2017 IEEE International Conference on Communications (ICC)},   title={Blind detection for MIMO systems with low-resolution ADCs using supervised learning},   year={2017},  volume={},  number={},  pages={1-6},  doi={10.1109/ICC.2017.7997434}}

@INPROCEEDINGS{otfs_transceivers_design_using_deep_neural_networks_2022,booktitle={OTFS Transceivers Design using Deep Neural Networks},url={https://www.youtube.com/watch?v=ErB9tZXeofY},publisher={A. Chockalingam},year={2022}}

@INPROCEEDINGS{Autoencoder_Based_PAPR_Reduction_for_OTFS_Modulation,
  author={Liu, Mengxue and Zhao, Ming-Min and Lei, Ming and Zhao, Min-Jian},
  booktitle={2021 IEEE 94th Vehicular Technology Conference (VTC2021-Fall)}, 
  title={Autoencoder Based PAPR Reduction for OTFS Modulation}, 
  year={2021},
  pages={1-5},
  doi={10.1109/VTC2021-Fall52928.2021.9625251},
  ISSN={2577-2465},
  month={Sep.}
  }


@InProceedings{pmlr-v27-baldi12a,
  title = 	 {Autoencoders, Unsupervised Learning, and Deep Architectures},
  author = 	 {Baldi, Pierre},
  booktitle = 	 {Proceedings of ICML Workshop on Unsupervised and Transfer Learning},
  pages = 	 {37--49},
  year = 	 {2012},
  editor = 	 {Guyon, Isabelle and Dror, Gideon and Lemaire, Vincent and Taylor, Graham and Silver, Daniel},
  volume = 	 {27},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Bellevue, Washington, USA},
  month = 	 {02 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v27/baldi12a/baldi12a.pdf},
  url = 	 {https://proceedings.mlr.press/v27/baldi12a.html}
}

@misc{aflak_2022,
      title={GitHub - TheIndependentCode/Neural-Network: Machine Learning library for educational purpose.},
      url={https://github.com/TheIndependentCode/Neural-Network},
      journal={GitHub},
      author={Aflak, Omar},
      year={2022}}

@book{Goodfellow-et-al-2016,
    title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    url={http://www.deeplearningbook.org},
    year={2016}}
    
@misc{DeepC_library,
title={GitHub - ai-techsystems/deepC: vendor independent TinyML deep learning library, compiler and inference framework microcomputers and micro-controllers}, url={https://github.com/ai-techsystems/deepC},
journal={GitHub},
author={Sharma, Rohit and Nandy, Gunjan and Sarkar, Subham},
year={2022}}

@book{kolmogorov_fomin_1957,
edition={1},
title={Elements of the theory of functions and functional analysis},
publisher={Russian Edition},
author={Kolmogorov, A. N and Fomin, A. N},
year={1957},pages={16}}
